{
  "channelHandle": "@aiDotEngineer",
  "channelId": "UCLKPca3kwwd-B59HNr-_lvA",
  "totalVideos": 539,
  "fetchedAt": "2025-08-24T15:52:10.828Z",
  "videos": [
    {
      "id": "a4BV0gGmXgA",
      "title": "Five hard earned lessons about Evals — Ankur Goyal, Braintrust",
      "description": "The main thesis of the video is that building successful AI applications requires a sophisticated engineering approach that goes beyond simply writing good prompts. The speaker argues for the importance of evaluations (evals) as a core component of the development process, highlighting that they should be intentionally engineered to reflect real-world user feedback and drive product improvements. The video also introduces the concept of \"context engineering\" as the new frontier, where the focus is on optimizing the entire context provided to the model, including tool definitions and their outputs. Ultimately, the speaker advocates for a flexible, model-agnostic architecture that can quickly adapt to the rapidly evolving landscape of AI models.\n\nTimestamps:\n\n00:00 Introduction to 5 Lessons in AI Product Development\n00:19 Lesson 1: Effective Evals Speak for Themselves\n02:09 Lesson 2: Great Evals Need to Be Intentionally Engineered\n04:03 Lesson 3: Context Engineering is the New Prompt Engineering\n06:37 Lesson 4: Be Prepared for a New Model to Change Everything\n09:09 Lesson 5: Optimize the Entire Evaluation System, Not Just the Prompts\n12:21 Recap of the Five Lessons",
      "publishedAt": "2025-08-23T17:45:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M46S",
      "viewCount": 2359,
      "likeCount": 82,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/a4BV0gGmXgA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/a4BV0gGmXgA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/a4BV0gGmXgA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/a4BV0gGmXgA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/a4BV0gGmXgA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=a4BV0gGmXgA"
    },
    {
      "id": "h5ItAJuB3Fc",
      "title": "Perceptual Evaluations: Evals for Aesthetics — Diego Rodriguez, Krea.ai",
      "description": "Special session with KREA.ai's cofounder Diego Rodriguez on how evals for aesthetics and image/generative media work — the hardest kinds of evals.\n\n  linkedin.com/in/asciidiego/\n\nTimestamps\n00:15 Introduction to Perceptual Evaluations\n00:50 The Problem with Current AI Evaluations\n02:16 Historical Context and Compression\n05:14 Limitations in AI and Human-centric Metrics\n08:00 Rethinking Evaluation and the Future of AI\n12:44 Evaluating Our Evaluations\n13:32 Krea's Role and Call to Action",
      "publishedAt": "2025-08-23T16:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M28S",
      "viewCount": 754,
      "likeCount": 27,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/h5ItAJuB3Fc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/h5ItAJuB3Fc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/h5ItAJuB3Fc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/h5ItAJuB3Fc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/h5ItAJuB3Fc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=h5ItAJuB3Fc"
    },
    {
      "id": "08mH36_NVos",
      "title": "How BlackRock Builds Custom Knowledge Apps at Scale — Vaibhav Page & Infant Vasanth, BlackRock",
      "description": "Investment Operations teams are the backbone of asset and investment management firms. Their day-to-day work not only enables portfolio managers to respond swiftly to market events but also ensures that complex, unstructured data flows seamlessly across the organization.\nIn this talk, we introduce a modular, Kubernetes-native AI framework purpose-built to scale custom Knowledge Apps across the enterprise. Designed with speed, flexibility, and compliance in mind, the framework empowers teams to launch production-grade document extraction applications in minutes instead of months, unlocking new levels of automation and efficiency for investment management workflows.\nWe’ll also share how this framework has helped BlackRock streamline document extraction processes, generate investment signals, reduce operational overhead, and accelerate the delivery of high-impact business use cases—all while maintaining the robustness and control required in a regulated industry.\n\n00:30 Introduction to BlackRock's AI Initiatives\n01:31 Classifying AI Applications\n02:22 Use Case: New Issue Operations\n03:59 Challenges with Scaling AI Knowledge Apps\n07:02 Architecture of BlackRock's AI Framework\n08:32 Demonstration of the Sandbox\n15:52 Key Takeaways from the Discussion\n\nVaibhav Page\nPrincipal Engineer\n\nVaibhav is a Principal Engineer at BlackRock, where he leads the development of the Data Science and AI platform powering\ninvestment research and automation across the firm. Vaibhav is also the author of Argo-Events, a CNCF-graduated project widely used for event-driven automation in cloud-native environments.\n\nInfant Vasanth\nSenior Director of Engineering\n\nInfant Vasanth leads the engineering team responsible for the Studio Compute Platform, BlackRock's analytics and automation platform that enables our users to conduct research & analysis, run automations and distribute research at scale.\nIn addition, Infant is also leading the Data & AI Acceleration team focusing on efforts to enhance Aladdin Studio's AI capabilities along side the Operational AI capabilities(prospectus analyzer, operational agents etc.)",
      "publishedAt": "2025-08-23T09:30:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M47S",
      "viewCount": 6646,
      "likeCount": 105,
      "commentCount": 9,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/08mH36_NVos/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/08mH36_NVos/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/08mH36_NVos/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/08mH36_NVos/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/08mH36_NVos/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=08mH36_NVos"
    },
    {
      "id": "CiMVKnX-CNI",
      "title": "Form factors for your new AI coworkers — Craig Wattrus, Flatfile",
      "description": "Designing user experiences for AI means moving beyond traditional interfaces.\n\nDesigners are grappling with how to create intuitive and effective interactions for these new AI capabilities, while growing their practice to include philosophy, ethics and coding.\n\nWhat if AI interactions could be reimagined as new 'coworkers'? This talk explores AI systems as your new coworkers. Covering novel UX patterns we’ve implemented and are researching at Flatfile as well as a state of the union on emergent patterns we’re seeing and using from the industry.\n\nAttendees will get a peek into explorations into AI cursors, forward-leaning chat paradigms and tool UX. We will discuss both work thats in production today at some of our biggest customers as well as thought-provoking demos, offering a vision for the future of AI UX.\n\nTimestamps\n\n00:25 Design Engineering: Form Factors for your new AI coworkers\n01:04 Four main categories of AI stack: invisible, ambient, inline, and conversational\n02:14 Invisible AI: Personalized demos\n03:06 Ambient AI: Analyzing data for opportunities\n03:10 Inline AI: Direct data manipulation\n03:46 Shifting from helicopter parent to character coach\n04:32 The \"chat tuner\" tool\n05:20 Feeling the material of AI\n08:20 Finding the grain in AI design\n11:08 Courting emergence\n11:48 Example of emergence: Combining datasets and generating reports\n12:37 Example of emergence: Suggesting human intervention\n14:09 Eyes on the future\n14:27 \"Auto-complete\" for data transformations\n\n\n\n\n\n---\n\nCraig Wattrus\nAI Design Engineer\n\nCraig Wattrus is a product designer and technologist working at the edge of human-computer interaction and AI. He designs and codes at Flatfile, where he’s leading a product called AI Transform. He's building adaptive data systems that use agentic AI to automate complex workflows across Fortune 500 companies. With a background in both computer science and design, Craig’s work focuses on shaping new UX patterns for AI systems that observe, learn, and act alongside users not just for them.\n\nCraig is deeply interested in rethinking form factors for AI, exploring how designers can create new patterns of interaction that feel more collaborative, contextual, and adaptive. His approach blends practical, production-ready work with speculative design exploration with working PoC's offering a grounded yet forward-looking take on what AI-native UX can become. When he’s not dreaming up new ideas or testing AI behaviors in production, he’s probably making lamps, tinkering with small-scale hardware, or enjoying a perfect espresso.",
      "publishedAt": "2025-08-22T15:00:20Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M35S",
      "viewCount": 1884,
      "likeCount": 34,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/CiMVKnX-CNI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/CiMVKnX-CNI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/CiMVKnX-CNI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/CiMVKnX-CNI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/CiMVKnX-CNI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=CiMVKnX-CNI"
    },
    {
      "id": "OMGPvW8TBHc",
      "title": "Fuzzing in the GenAI Era — Leonard Tang, Haize Labs",
      "description": "\"Evaluation\" is one of those concepts that every AI practitioner vaguely knows is important, but few practitioners truly understand. Is \"eval\" the dataset for measuring the quality of your AI system? Is \"eval\" the measure, the metric of quality? Is \"eval\" the process of human annotation and scoring? Or is \"eval\" a third-party dataset run once to benchmark a model?\n\nTo mitigate this cacophony, this talk will provide an opinionated and principled perspective for what we actually mean when we say “evaluation”, beyond the traditional for-loop-over-a-static dataset.\n\nIn particular, this perspective draws heavy inspiration from *fuzzing*, i.e. bombarding AI with simulated, unexpected user inputs to uncover corner cases at scale. This factors into sub-problems regarding:\n\n- Quality Metric. What is the actual criteria we, as humans, are using to determine if an AI system is producing good or bad responses? How do we elicit these criteria before the human SME can articulate them? How do we, as efficiently as possible, operationalize this criteria with an automated *Judge*?\n\n- Stimuli Generation. Given a metric, how do we know, with confidence, that an AI system is performing well with respect to the metric? What data is representative and sufficient for discovering all potential bugs of an AI system? And how do we generate this complex, diverse, faithful data at scale?\n\nWe will discuss in detail the philosophy, technology, and case studies behind both problems of Quality Metric and Stimuli Generation, and how they interact in concert.\n\nTimestamps\n00:00 Introduction to Haizing\n01:16 The \"Last Mile Problem\" in AI\n02:47 The Brittleness of GenAI Applications\n03:54 Examples of Brittle Chatbots\n04:29 Inadequacy of Standard Evaluation Methods\n06:09 Haizing: Simulating the Last Mile\n08:43 Scaling Evaluation with Agents as Judges\n09:29 Verdict: Accuracy vs. Latency\n11:47 Scaling Evaluation with RL-Tuned Judges\n14:06 Fuzzing vs. Adversarial Testing in AI\n14:37 Simulation as Prompt Optimization\n16:23 Case Study: Haizing a Major European Bank's AI App\n17:05 Case Study: Haizing a F500 Bank's Voice Agents\n17:46 Case Study: Scaling Voice Agent Evals with Verdict\n\nLeonard Tang\nFounder & CEO\n\nI am the co-founder and CEO of Haize Labs, where we are solving the ultimate extant problem in AI: ensuring its reliability, quality, and alignment for any application. You might also know of us for our red-teaming work.\n\nPrior, I studied math and computer science at Harvard. My research then covered adversarial robustness, math reasoning, computational neuroscience, interpretability, and large(-ish) language models. Much of that has now been distilled into the Haize technology agenda. I also dropped out of, before starting, a Stanford PhD in computer science.\n\nIn the limit of my life, I am chiefly invested in starting Bell Labs 2.0.",
      "publishedAt": "2025-08-22T15:00:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M12S",
      "viewCount": 1340,
      "likeCount": 39,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/OMGPvW8TBHc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/OMGPvW8TBHc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/OMGPvW8TBHc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/OMGPvW8TBHc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/OMGPvW8TBHc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=OMGPvW8TBHc"
    },
    {
      "id": "m0dxZ-NDKHo",
      "title": "Multi Agent AI and Network Knowledge Graphs for Change — Ola Mabadeje, Cisco",
      "description": "Traditional ticketing and testing workflows for change management and network operations often operate independently and lack critical real-world context and adaptive decision making capabilities. This fragmented approach results in delayed resolutions, repeated incidents, escalations, and dissatisfied stakeholders.\n\nThis session explores an innovative solution leveraging the synergy of natural language processing from IT Service Management (ITSM) systems, Multi-agent reasoning, and dynamic context derived from live knowledge network graphs. Attendees will gain insights into an end-to-end architecture where natural language intents from ITSM tickets seamlessly integrate with experts AI agents for complex workflow tasks, supported by continuous network knowledge graph ingestion pipelines.\n\nThrough a detailed production case study, we will demonstrate how Agentic reasoning combined with dynamic network knowledge graph contexts significantly improves critical validation and workflow interactions. The showcased results will highlight dramatic improvements in ticket resolution efficiency, accuracy of network testing, and overall execution quality, delivering tangible value to both technical teams and business stakeholders.",
      "publishedAt": "2025-08-22T06:14:21Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M49S",
      "viewCount": 2715,
      "likeCount": 50,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/m0dxZ-NDKHo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/m0dxZ-NDKHo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/m0dxZ-NDKHo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/m0dxZ-NDKHo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/m0dxZ-NDKHo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=m0dxZ-NDKHo"
    },
    {
      "id": "9AQOvT8LnMI",
      "title": "Wisdom-Driven Knowledge Augmented Generation at Scale - Chin Keong Lam, Patho AI",
      "description": "The main thesis of the video is that by using a Wisdom-Driven Knowledge Graph, we can significantly enhance the quantitative analysis capabilities of Knowledge-Augmented Generation (KAG) systems. This allows for the creation of smarter AI systems that can not only retrieve information but also understand, reason, and provide expert-level advice. The talk argues that this approach surpasses traditional Retrieval-Augmented Generation (RAG) systems, which primarily rely on unstructured vector search.\n\n00:00 Introduction to Patho AI and KAG\n01:09 Defining Knowledge and Knowledge Graphs\n01:56 KAG vs. RAG\n02:37 The Wisdom-Decision Making-Situation Diagram\n06:26 Practical Application: Competitive Analysis Chatbot\n08:37 Implementation with N8n and Multi-Agent System\n11:37 Why Use Knowledge Graphs over RAG\n14:01 Challenges with Vector RAG and Numerical Reasoning\n15:34 Building KAG Systems and Hybrid Models\n16:45 Graph Extraction and Benchmarks\n17:42 Conclusion and Resources\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-22T06:13:55Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M43S",
      "viewCount": 1334,
      "likeCount": 42,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/9AQOvT8LnMI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/9AQOvT8LnMI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/9AQOvT8LnMI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/9AQOvT8LnMI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/9AQOvT8LnMI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=9AQOvT8LnMI"
    },
    {
      "id": "12v5S1n1eOY",
      "title": "Building an Agentic Platform — Ben Kus, CTO Box",
      "description": "Explore the technical evolution of metadata extraction at Box and how it shaped the foundation of our AI platform. We’ll walk through our transition to an agentic-first design—why it was necessary, how we approached the rebuild, challenges we encountered along the way, and the advantages it unlocked.\n\nTimestamps\n00:00 Box's Content Platform and Enterprise Focus\n01:50 Initial AI Deployment in 2023\n02:54 The Challenge of Unstructured Data in Enterprises\n03:56 Limitations of Pre-Generative AI Data Extraction\n04:54 First Version: LLM-Based Extraction\n07:05 Challenges with the Pure LLM Approach\n08:58 Despair and the Need for a New Architecture\n09:30 Introducing Agentic Architecture\n10:04 AI Agent Reasoning Framework\n10:45 Agentic Routine for Data Extraction\n12:28 Advantages of Agentic Architecture\n14:05 Key Lesson Learned: Build Agentic Architecture Early\n18:37 Approach to Fine-tuning and Model Support\n\nBen Kus\nCTO\n\nBen Kus is the Chief Technology Officer at Box and is responsible for developing Box’s technology vision and strategy and ensuring that technological resources are aligned with the company's business needs. Previously Ben was the VP of Product Management at Box. Before joining Box, Ben was the Co-Founder and CTO of Subspace, Inc., an enterprise security solution that was acquired by Box. Ben has held various leadership positions, including the role of Chief Architect for IBM, and Senior Director of Technology for BigFix, Inc. Ben studied Computer Science at the University of California, Berkeley.",
      "publishedAt": "2025-08-21T18:15:08Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "viewCount": 2,
      "likeCount": 21,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/12v5S1n1eOY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/12v5S1n1eOY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/12v5S1n1eOY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/12v5S1n1eOY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/12v5S1n1eOY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=12v5S1n1eOY"
    },
    {
      "id": "bCGbuyv8PMk",
      "title": "Rishabh Garg, Tesla Optimus — Challenges in High Performance Robotics Systems",
      "description": "A robot's behavior is influenced by the control policy, the software configuration, and electrical characteristics of the communication protocol.\n\nWhen unexpected behaviors arise, it is not straightforward to root cause them to the RL policy, electrical characteristics, mechanical characteristics. This talk walks through some of these issues and explains what might cause the observed behavior.\n\nWe will talk about concrete issues that audience will be able to take away from and develop their understanding of physical systems. It will build intuition for what kind of issues to expect when communication data rates increase manifold.\n\nTimestamps\n00:00 Introduction to high-performance robotics challenges\n00:15 The problem of unexplained robot behavior\n00:54 Root cause analysis: policy vs. software\n01:17 Designing a toy robotics system for analysis\n01:24 System architecture: sensors, CPU, GPU, actuators, CAN bus\n01:57 The initial, simple code loop\n02:14 Expectation vs. reality: unexpected loop execution gaps\n02:42 The impact of CAN bus data rate on loop execution\n03:13 Potential solutions: accepting delay vs. multithreading\n04:00 A new, pipelined design for reduced cycle time\n04:32 New problems: \"stuttering\" and abnormal motor behavior\n04:49 Data collection with external transceivers and \"candump\"\n05:24 Expected vs. actual message plots: missed messages and jitter\n06:12 Using cycle time plots to identify desynchronization\n06:58 Transmit phase desynchronization: missed and queued data\n08:03 Receive phase desynchronization: stale data and overcompensation\n08:38 Resolving synchronization issues: kernel primitives and padding\n09:25 The impact of logging on system performance\n11:09 Reception and priority inversion\n12:02 Conclusion and summary of key takeaways\n\nRishabh Garg\nRobotics Engineer at Tesla Optimus\n\nI am Rishabh Garg, a robotics software engineer pushing the boundaries of software hardware integration to meet the ever increasing demand for data. I have been working with robots and embedded systems for the past 4 years, making systems more reliable and performant at companies like Tesla and Amazon. Eager to learn what experts in the industry are doing differently and share my own experience and insights into the challenges frequently encountered at the system software level for robotics.",
      "publishedAt": "2025-08-21T16:41:43Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "viewCount": 11,
      "likeCount": 9,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/bCGbuyv8PMk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/bCGbuyv8PMk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/bCGbuyv8PMk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/bCGbuyv8PMk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/bCGbuyv8PMk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=bCGbuyv8PMk"
    },
    {
      "id": "L8-5ezsoI5A",
      "title": "The Next Unicorns: 7 Top AI startups from the HF0 Residency",
      "description": "HF0's Demo Days are usually hilariously oversubscribed and have never before been aired publicly. For the first time, they are joining the AIE stage to pitch AI Engineers.\n\nhttps://www.hf0.com/\n\nTimestamps\n\n00:15 Diego Rodriguez - Krea\n03:02 OpenHome\n06:09 Josh - Coframe\n07:31 Eugene - Featherless AI\n10:39 Jonas Bauer - Upside\n13:48 Lengyue - OpenAudio\n18:48 Alex Atallah - OpenRouter",
      "publishedAt": "2025-08-21T15:23:20Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT22M16S",
      "viewCount": 5231,
      "likeCount": 125,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/L8-5ezsoI5A/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/L8-5ezsoI5A/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/L8-5ezsoI5A/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/L8-5ezsoI5A/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/L8-5ezsoI5A/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=L8-5ezsoI5A"
    },
    {
      "id": "avWhreBUYF0",
      "title": "#define AI Engineer - Greg Brockman, OpenAI (ft. Jensen Huang)",
      "description": "Greg Brockman's career and advice for AI Engineers\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\n00:00 Greg Brockman's Journey and the Power of Independent Study\n02:50 Joining Stripe and the Grind of a Startup\n08:04 The Power of Independent Study\n10:18 Journey into Machine Learning and Belief in AGI\n16:10 The Relationship Between Engineering and Research at OpenAI\n21:11 Scaling Challenges and Successes at OpenAI\n24:32 Vibe Coding and the Future of Software Engineering\n26:06 Impact of Codex on Coding Practices\n29:20 Scaling Bottlenecks and Future of AI Infrastructure\n38:06 Evolution of Development Workflow with AGI",
      "publishedAt": "2025-08-10T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT41M5S",
      "viewCount": 53138,
      "likeCount": 1063,
      "commentCount": 58,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/avWhreBUYF0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/avWhreBUYF0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/avWhreBUYF0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/avWhreBUYF0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/avWhreBUYF0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=avWhreBUYF0"
    },
    {
      "id": "MC55hdWLq4o",
      "title": "The Future of Evals - Ankur Goyal, Braintrust",
      "description": "About Ankur\nAnkur Goyal is the founder & CEO of Braintrust—the developer platform that companies like Zapier, Notion, Instacart, Airtable, and more use to evaluate, log, and ship reliable AI products to millions. He was previously Head of AI platform at Figma, founder and CEO of Impira, and VP Eng at Singlestore. After Figma acquired Impira, he led the AI team there, and saw a number of the same blockers to AI development at Impira, Figma, and other peer companies, which led to founding Braintrust\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps\n00:00 Introduction to AI Engineer World's Fair\n00:15 Speaker Introduction: Ankur Goyal, CEO of Braintrust\n00:22 The Future of Evals\n00:30 Increasing Adoption of Eval\n01:58 Introducing Loop\n04:09 Call to Action: Try Loop and Join the Team",
      "publishedAt": "2025-08-09T15:12:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M14S",
      "viewCount": 6055,
      "likeCount": 74,
      "commentCount": 21,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/MC55hdWLq4o/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/MC55hdWLq4o/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/MC55hdWLq4o/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/MC55hdWLq4o/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/MC55hdWLq4o/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=MC55hdWLq4o"
    },
    {
      "id": "IHkyFhU6JEY",
      "title": "Designing AI-Intensive Applications - swyx",
      "description": "Whether you call it a workflow or an agent, AI engineered applications are seeing user-input:LLM-call ratios go from 1:1 (ChatGPT) to 1:100 (Deep Research, Codex) and even 0:n (Ambient/Proactive agents). How does AI Engineering change as you build increasingly AI intensive applications?\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n00:00 Conference Welcome and Overview\n00:42 Conference Logistics and Growth\n01:47 Audience Preferences and Survey\n02:22 Innovations in AI Engineering (MCP and Chatbots)\n02:58 Evolution of AI Engineering (Past Talks)\n03:50 Simplicity in AI Engineering\n04:17 AI Engineering as a Developing Field\n05:23 Seeking the \"Standard Model\" in AI Engineering\n06:02 Candidate Standard Models in AI Engineering\n09:26 Human Input vs. AI Output (AI News Example)\n11:05 SPADE Model for AI-Intensive Applications\n12:29 Call to Action for Conference Attendees",
      "publishedAt": "2025-08-09T15:10:51Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M2S",
      "viewCount": 24047,
      "likeCount": 385,
      "commentCount": 14,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/IHkyFhU6JEY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/IHkyFhU6JEY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/IHkyFhU6JEY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/IHkyFhU6JEY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/IHkyFhU6JEY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=IHkyFhU6JEY"
    },
    {
      "id": "jryZvCuA0Uc",
      "title": "How to look at your data — Jeff Huber (Choma) + Jason Liu (567)",
      "description": "By the end of this talk, you'll understand what it takes to apply clustering techniques and data analysis to understand what is the valuable work that your AI application is doing through analyzing conversation histories and how to create generative evals to benchmark your newly discovered superpowers.\n\nAbout Jeff Huber\nJeff Huber is the CEO and cofounder of Chroma. Jeff's work has been featured in TechCrunch, VentureBeat, MacWorld, GQ, Fast Company, Fortune, Forbes, Business Insider, Quartz and others. Chroma is a widely-loved and adopted open-source vector database.\n\nAbout Jason Liu\nMachine learning engineer, consultant, educator.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-06T16:22:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M23S",
      "viewCount": 6748,
      "likeCount": 150,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/jryZvCuA0Uc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/jryZvCuA0Uc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/jryZvCuA0Uc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/jryZvCuA0Uc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/jryZvCuA0Uc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=jryZvCuA0Uc"
    },
    {
      "id": "qdmxApz3EJI",
      "title": "On Engineering AI Systems that Endure The Bitter Lesson - Omar Khattab, DSPy & Databricks",
      "description": "Will discuss the principles for building AI software that underpin DSPy, highlighting the differences between conventional prompting (or finetuning/RL) versus the design and programming of truly modular AI systems.\n\nAbout Omar Khattab   \nOmar Khattab is a Research Scientist at Databricks and an incoming Assistant Professor at MIT EECS (July 2025). His research creates models, algorithms, and abstractions for building modular, reliable, and scalable AI systems. He is the author of the ColBERT retrieval model, which has helped shape the modern landscape of neural information retrieval, and the creator of the DSPy framework for building and optimizing declarative natural-language programs.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps\n00:00 AI Engineer World's Fair\n00:22 On Engineering AI Systems that Endure the Bitter Lesson\n00:32 The Challenges of AI Software Engineering\n00:40 The Bitter Lesson\n04:50 AI Engineering's Purpose\n06:39 Takeaway 1: Engineering for Scalability\n07:19 Premature Optimization\n12:18 The Problem with Prompts\n14:26 Trusty Old Separation of Concerns\n17:11 Takeaway 2: Invest in Decoupling\n17:21 The Pyramid of LLM Software and DSPy\n17:45 The DSPy Concept: Declarative Signatures",
      "publishedAt": "2025-08-06T16:15:49Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M12S",
      "viewCount": 12269,
      "likeCount": 263,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/qdmxApz3EJI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/qdmxApz3EJI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/qdmxApz3EJI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/qdmxApz3EJI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/qdmxApz3EJI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=qdmxApz3EJI"
    },
    {
      "id": "L8OoYeDI_ls",
      "title": "Evals Are Not Unit Tests — Ido Pesok, Vercel v0",
      "description": "How to think about evaluating a non-deterministic system — and how to actually succeed at it.\n\nAbout Ido Pesok\nIdo Pesok is an engineer and researcher at Vercel, working on the AI behind v0 and focused on building reliable and intuitive AI systems.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n00:00 Introduction to Vercel's V0 and its growth\n01:00 The problem with AI unreliability\n02:44 The \"Fruit Letter Counter\" app example of AI failure\n03:33 Introducing \"evals\" and the basketball court analogy\n05:09 Defining the \"court\": understanding the domain of user queries\n07:53 Data collection for evals\n09:13 Structuring evals: constants in data, variables in task\n10:45 Scoring evals\n12:35 Integrating evals into CI/CD\n13:40 The benefits of using evals",
      "publishedAt": "2025-08-06T16:14:42Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M22S",
      "viewCount": 9833,
      "likeCount": 185,
      "commentCount": 14,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/L8OoYeDI_ls/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/L8OoYeDI_ls/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/L8OoYeDI_ls/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/L8OoYeDI_ls/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/L8OoYeDI_ls/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=L8OoYeDI_ls"
    },
    {
      "id": "CQGuvf6gSrM",
      "title": "2025 is the Year of Evals! Just like 2024, and 2023, and … — John Dickerson, CEO Mozilla AI",
      "description": "AI is getting deployed without guardrails, without governance, without due diligence.  Surely this is the year we’ll see a Fortune 500 CEO fired because of a preventable AI incident.  Surely this is the year we’ll see enterprises wake up to pre-deployment evaluation and post-deployment monitoring being an urgent need.  This story hasn’t changed for a decade, but surely this is the year it will.\n\nIn this talk, I’ll cover what enterprise-level AI/ML evaluation has looked like for the last decade - what’s changed, what hasn’t, what sells, what doesn’t, and where I see things going from here on out.  Evaluation matters - we all know this - but using my experience in the trenches over the last decade or so I hope to bridge the gap between what practitioners need and what the C-suite pays for in the space of AI evaluations.\n\n\n\n---related links---\n\nhttps://x.com/johnpdickerson\nhttps://www.linkedin.com/in/john-dickerson/\nhttps://jpdickerson.com/\nhttps://www.mozilla.ai/\n\nTimestamps:\n\n00:00 Introduction to Arthur AI and Mozilla AI\n00:46 2025: The Year of Evals\n01:15 AI/ML monitoring and evaluation\n02:48 The Year of the Agent\n03:26 The need for 'evals' wasn't obvious to the C-suite\n04:15 Pre-ChatGPT launch\n06:06 Venture capitalists' predictions\n07:03 Macroeconomic side of things\n08:06 OpenAI launching ChatGPT\n09:15 2023: The Year of GenAI\n09:39 2024: GenAI applications in production\n10:22 2025: Scaling and autonomy\n11:35 Definition of an agent\n12:06 Connecting to downstream business KPIs\n14:40 Shift to multi-agent systems monitoring\n15:42 Q&A\n16:16 Discussion on domain expertise in evaluations\n18:13 Discussion on LLMs as judges",
      "publishedAt": "2025-08-06T16:11:52Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M14S",
      "viewCount": 3753,
      "likeCount": 58,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/CQGuvf6gSrM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/CQGuvf6gSrM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/CQGuvf6gSrM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/CQGuvf6gSrM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/CQGuvf6gSrM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=CQGuvf6gSrM"
    },
    {
      "id": "n991Yxo1aOI",
      "title": "Vibe Coding with Confidence — Itamar Friedman, Qodo",
      "description": "Everyone wants to do Vibe Code, even large Enterprises. But how can we ensure that the generated code is well-grounded with the dev team's code and software development standards? In this talk, Itamar will present how to use various tools and agents, including MCP and A2A, to achieve precisely that.\n\nAbout Itamar Friedman\nItamar Friedman is the CEO and co-founder of Qodo (fka CodiumAI), the leader in the emerging code integrity space.\nPrior to that, Itamar was the co-founder and CTO of Visualead, which Alibaba Group acquired. As a director at Alibaba, he led teams to create innovative ML-based B2C and B2D applications and tools used by millions.\nItamar holds a BSc & MSc in Electrical Engineering (Summa Cum Laude) from the Technion, majoring in Machine Learning and Computer Vision.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n00:00 The Evolution of AI in Development\n\n03:08 The Rise of the Command Line Interface (CLI)\n\n03:50 AI Across the Software Development Life Cycle (SDLC)\n\n06:40 The Importance of \"Vibe Coding with Confidence\"\n\n08:15 The Role of Workflows and Agents\n\n12:21 Qodo's Multi-Agent Approach\n\n13:55 Why the CLI is the Future of AI in Development\n\n20:33 The Future: A \"Swarm of Agents\"",
      "publishedAt": "2025-08-06T15:59:51Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M55S",
      "viewCount": 4619,
      "likeCount": 94,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/n991Yxo1aOI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/n991Yxo1aOI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/n991Yxo1aOI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/n991Yxo1aOI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/n991Yxo1aOI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=n991Yxo1aOI"
    },
    {
      "id": "WnTq5Mc5bIU",
      "title": "AI Automation that actually works: $100M, messy data, zero surprises - Tanmai Gopal, Hasura/PromptQL",
      "description": "We will review the different kinds of automation use-cases, and the approach we used, that will drive over a $100M of expected annual impact by deploying AI for business critical initiatives.\n\nWe will discuss what kinds of automation initiatives become possible because of Gen AI. These were not tenable before because of the amount of customization required per customer or per scenario, and the kind of data involved in these workflows. Previously, these workflows were driven manually which were both error prone and required expensive training.\n\nTo replace or augment these manual business critical processes, automation _has_ to cross a very high bar of reliability.\n\nWe will share how we addressed the inherent non-determinism of Gen AI to create a predictable system that doesn’t have any surprising failure modes. We’ll also discuss how we worked with our existing data that was spread across various systems without an expensive centralisation and clean up effort.\n\nAbout Tanmai Gopal\nTanmai Gopal is the co-founder and CEO of Hasura, where he has been at the forefront of rethinking how organizations access and work with data.\n\nA passionate product builder, Tanmai first led the creation of the Hasura GraphQL Engine, transforming how developers interact with data to build modern applications. Hasura has since expanded beyond developers to the enterprise level, driving the adoption of Data Delivery Network (DDN) and PromptQL—technologies that CXOs are now choosing to drive mission-critical AI transformation in their organizations.\n\nBefore Hasura, Tanmai worked with large enterprises to modernize their technology stacks, moving from monoliths to cloud-native architectures. A full-stack engineer at heart, he is passionate about building technology that increases individual agency. He also created and taught one of the largest MOOCs on modern application development at the time, reaching over 250,000 students.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps\n00:00 Introduction to the problem in healthcare\n02:43 The challenges faced by operators\n07:09 The \"Automation Paradox\" and the AI idea\n08:16 Challenges in implementing AI solutions (language, DevOps, security)\n09:55 Proposed solution: AcmeQL and domain-specific language for non-technical users\n11:37 Demo of the solution (GitHub issue assignment)\n16:46 Impact and future outlook",
      "publishedAt": "2025-08-06T15:48:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M49S",
      "viewCount": 2280,
      "likeCount": 39,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/WnTq5Mc5bIU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/WnTq5Mc5bIU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/WnTq5Mc5bIU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/WnTq5Mc5bIU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/WnTq5Mc5bIU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=WnTq5Mc5bIU"
    },
    {
      "id": "nxuTVd7v7dg",
      "title": "Full Workshop: Realtime Voice AI — Mark Backman, Daily",
      "description": "Voice AI agents today can conduct natural, human-like conversations and perform a wide variety of tasks: customer support, lead qualification, healthcare patient intake, market research, and more.\n\nToday's best voice agents combine: realtime responsiveness, open-ended conversational intelligence, reliable instruction following, and flexible integration with existing back-end systems.\n\nLearn how to build state of the art voice agents using Pipecat's open source, vendor neutral tooling. You can deploy Pipecat agents to your own infrastructure or to Pipecat Cloud.\n\nPipecat is used and supported by teams at NVIDIA, AWS, Google DeepMind, OpenAI, and hundreds of other companies.\n\n\n---related links---\n\nhttps://x.com/mark_backman\nhttps://www.linkedin.com/in/mark-backman/\nhttps://daily.co",
      "publishedAt": "2025-08-03T18:53:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H9M41S",
      "viewCount": 8898,
      "likeCount": 202,
      "commentCount": 16,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/nxuTVd7v7dg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/nxuTVd7v7dg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/nxuTVd7v7dg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/nxuTVd7v7dg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/nxuTVd7v7dg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=nxuTVd7v7dg"
    },
    {
      "id": "IQc05eCvNYE",
      "title": "Vision AI in 2025 — Peter Robicheaux, Roboflow",
      "description": "Attendee-Only and Attendee-Led 10min lightning talks: see https://crowdcomms.com/aiengineer25/qanda/41445\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-03T17:45:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M24S",
      "viewCount": 8200,
      "likeCount": 190,
      "commentCount": 17,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/IQc05eCvNYE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/IQc05eCvNYE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/IQc05eCvNYE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/IQc05eCvNYE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/IQc05eCvNYE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=IQc05eCvNYE"
    },
    {
      "id": "-T6uZYYzkWw",
      "title": "Practical tactics to build reliable AI apps — Dmitry Kuchin, Multinear",
      "description": "[last round of Attendee-Led 10min lightning talks] Practical tactics to build reliable AI apps. Reverse engineering real-world evals with o3. Nobody does it this way. Companies pay me $500/h for this knowledge. I help them get from POC that works 50% of the time - to the solution they can trust to deploy to production.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-03T04:34:32Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M55S",
      "viewCount": 4573,
      "likeCount": 110,
      "commentCount": 13,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/-T6uZYYzkWw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/-T6uZYYzkWw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/-T6uZYYzkWw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/-T6uZYYzkWw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/-T6uZYYzkWw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=-T6uZYYzkWw"
    },
    {
      "id": "g03m-WFEu1U",
      "title": "How to Improve your Vibe Coding — Ian Butler",
      "description": "[last round of Attendee-Led 10min lightning talks] Are your vibes immaculate? - Vibe coding is the new hotness but everyone has a story of AI making really dumb choices. Let's talk about how you can improve your vibe coding so your vibes are safe and bug free and you spend more Ian Butler\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-03T04:32:57Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7M30S",
      "viewCount": 2233,
      "likeCount": 38,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/g03m-WFEu1U/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/g03m-WFEu1U/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/g03m-WFEu1U/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/g03m-WFEu1U/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/g03m-WFEu1U/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=g03m-WFEu1U"
    },
    {
      "id": "Dc3qOA9WOnE",
      "title": "Vibes won't cut it — Chris Kelly, Augment Code",
      "description": "What's the role of vibe coding in a production-grade applications? Join Augment Code's Chris Kelly as he talks about the role of context in software engineering, not code.\n\nAbout Chris Kelly\nChris is the head of developer experience where he works across Augment to make building software better for every developer. He’s been making developers happier and more productive for 15 years at innovative companies like New Relic, GitHub, Salesforce, and FireHydrant. You can find him at @amateurhuman everywhere on the internet.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-03T04:32:17Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M34S",
      "viewCount": 36626,
      "likeCount": 1024,
      "commentCount": 133,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Dc3qOA9WOnE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Dc3qOA9WOnE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Dc3qOA9WOnE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Dc3qOA9WOnE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Dc3qOA9WOnE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Dc3qOA9WOnE"
    },
    {
      "id": "eOxOzcw70f0",
      "title": "Real World Development with GitHub Copilot and VS Code — Harald Kirschner, Christopher Harrison",
      "description": "Join us to see how VS Code and GitHub Copilot's expanding suite of AI features can match or even surpasses the benefits of other popular AI developer tools.  We'll focus on practical scenarios to ensure immediate applicability and work through live demos of Copilot features such as: Code generation using Edits, Planning/problem solving using Chat, Inline terminal command generation, Boilerplate code generation using Agent mode, Improving boilerplate with custom instructions and then refactoring using Agent mode and Edits, Improving test generation and code reviews with custom instructions, as well as an Introduction to MCP.",
      "publishedAt": "2025-08-03T04:30:57Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H19M33S",
      "viewCount": 8259,
      "likeCount": 144,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/eOxOzcw70f0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/eOxOzcw70f0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/eOxOzcw70f0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/eOxOzcw70f0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/eOxOzcw70f0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=eOxOzcw70f0"
    },
    {
      "id": "WJjInLeaJjo",
      "title": "Building Agents at Cloud Scale — Antje Barth, AWS",
      "description": "Let's explore  practical strategies for building and scaling agents in production. Discover  how to move from local MCP implementations to cloud-scale architectures and  how engineering teams leverage these patterns to develop sophisticated agent  systems. Expect a mix of demos, use case discussions, and a glimpse into the  future of agentic services!\n\nAbout Antje Barth\nAntje Barth is a Principal Developer Advocate at AWS, based in San Francisco. She frequently speaks at AI engineering conferences, events, and meetups, and works closely with product teams to build the future of agentic AI. Antje is also co-author of the O’Reilly books Generative AI on AWS and Data Science on AWS.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-02T18:15:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M",
      "viewCount": 3959,
      "likeCount": 91,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/WJjInLeaJjo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/WJjInLeaJjo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/WJjInLeaJjo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/WJjInLeaJjo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/WJjInLeaJjo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=WJjInLeaJjo"
    },
    {
      "id": "3MZS5gNElZM",
      "title": "State of Startups and AI 2025 - Sarah Guo, Conviction",
      "description": "Recorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-02T16:45:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT23M52S",
      "viewCount": 50027,
      "likeCount": 1282,
      "commentCount": 53,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/3MZS5gNElZM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/3MZS5gNElZM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/3MZS5gNElZM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/3MZS5gNElZM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/3MZS5gNElZM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=3MZS5gNElZM"
    },
    {
      "id": "Dj0b_cEBHBI",
      "title": "Useful General Intelligence — Danielle Perszyk, Amazon AGI",
      "description": "We’re all hearing that AI agents will enable AGI, but they can’t yet reliably perform even basic computer tasks. It turns out that getting AI to click, type, and scroll is more challenging than getting it to generate code. How can we build general-purpose agents that can do anything we can do on a computer?\n\nThis is our goal at the Amazon AGI SF Lab. In this talk, I’ll propose a new approach to agents that we call Useful General Intelligence. After describing how we’re solving the biggest challenges in computer use while enabling developers to access our tech in it’s earliest developmental stages, I’ll show real workflows that developers have built with Nova Act, our agentic model and SDK.\n\nAbout Danielle\nDanielle is a cognitive scientist at the new Amazon AGI SF Lab. She received her PhD from Northwestern, where she studied the evolution and development of language. Previously, she was at Google and Adept.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-02T13:15:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M58S",
      "viewCount": 6531,
      "likeCount": 160,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Dj0b_cEBHBI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Dj0b_cEBHBI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Dj0b_cEBHBI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Dj0b_cEBHBI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Dj0b_cEBHBI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Dj0b_cEBHBI"
    },
    {
      "id": "mQ7_Zje7WKE",
      "title": "The 2025 AI Engineering Report — Barr Yaron, Amplify",
      "description": "Come hear the results of the 2025 State of AI Engineering: https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report\n\nAbout Barr Yaon\nBarr is a data scientist turned investment partner at Amplify Partners where she invests in AI infrastructure and apps\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-01T22:51:37Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M33S",
      "viewCount": 5813,
      "likeCount": 157,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/mQ7_Zje7WKE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/mQ7_Zje7WKE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/mQ7_Zje7WKE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/mQ7_Zje7WKE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/mQ7_Zje7WKE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=mQ7_Zje7WKE"
    },
    {
      "id": "8SUJEqQNClw",
      "title": "Agents vs Workflows: Why Not Both? — Sam Bhagwat, Mastra.ai",
      "description": "One current hot debate is should you make your top-level abstraction a ReAct type agent running in a loop? or should you make it a structured workflow graph?\n\nOpenAI is launching their new framework and throwing shade on workflow graph approaches\n\nTBH we think this whole debate is kinda dumb.\n\nWe've seen a lot of folks be able to structure the problem in a way that a workflow graph makes a lot of sense.\n\nWe also see a ton of agents where you need to run the core bit in a loop for a long time.\n\nYou can also give your agents structured workflow graphs as a tool. You can use structured workflow graphs as a handoff mechanism between agents. What we've seen from the community is frankly that folks need to tinker with multiple approaches and combine primitives in interesting ways\n\nWe'll share a couple stories where teams ended up with workflow graph based approaches, a couple where teams ended up with agent based approaches, and a couple where a blended approach made sense.\n\nAbout Sam Bhagwat\nSam is the co-founder and CEO of Mastra and the author of Principles of AI Agents. Previously, Sam was the co-founder of Gatsby.js, the popular web framework.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n00:00 Introduction: Agents vs. Workflows\n01:00 The Debate and Controversy\n02:15 \"Don't Be That Guy\": Critiquing Dogma in AI Development\n03:40 Harmful APIs and the Case for Fluent Syntax\n08:00 Defining Agents and Workflows\n10:00 Composition, Design Patterns, and Trade-offs\n11:49 Composing Agents and Workflows\n12:12 Architectural Patterns for Composition\n14:43 Q&A and Concluding Thoughts",
      "publishedAt": "2025-08-01T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M37S",
      "viewCount": 15487,
      "likeCount": 267,
      "commentCount": 25,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/8SUJEqQNClw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/8SUJEqQNClw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/8SUJEqQNClw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/8SUJEqQNClw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/8SUJEqQNClw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=8SUJEqQNClw"
    },
    {
      "id": "M6Vbaig1TsM",
      "title": "Why We Don’t Need More Data Centers - Dr. Jasper Zhang, Hyperbolic",
      "description": "AI infrastructure today is caught in an endless cycle: build more data centers, deploy more GPUs, repeat.\n\nBut this approach is fundamentally flawed—expensive, inefficient, and environmentally unsustainable.\n\nIn this talk, we will unpack why continuously expanding data centers masks deeper infrastructure inefficiencies, and why leveraging a GPU marketplace to dynamically allocate existing resources is essential.\n\nWe will explore practical use-cases where companies scale GPU capacity flexibly, startups gain affordable compute, and idle GPUs are monetized, enabling a future of sustainable and democratized AI infrastructure.\n\nAbout Dr  Jasper Zhang, PhD\nDr. Jasper Zhang is the CEO and Co-founder of Hyperbolic. A mathematical prodigy, he completed his Ph.D. in Mathematics at UC Berkeley in just two years. He is a Gold Medalist in both the Alibaba Global Math Competition and the Chinese Mathematical Olympiad. Before founding Hyperbolic, he held roles at Ava Labs and Citadel Securities, bringing deep expertise in quantitative finance and AI.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-01T15:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M18S",
      "viewCount": 2645,
      "likeCount": 53,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/M6Vbaig1TsM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/M6Vbaig1TsM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/M6Vbaig1TsM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/M6Vbaig1TsM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/M6Vbaig1TsM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=M6Vbaig1TsM"
    },
    {
      "id": "2goSS66XRBk",
      "title": "Infrastructure for the Singularity — Jesse Han, Morph",
      "description": "We're at an inflection point where AI agents are transitioning from experimental tools to practical coworkers. This new world will demand new infrastructure for RL training, test-time scaling, and deployment. This is why Morph Labs developed Infinibranch last year, and we are excited to finally unveil what's next.\n\nAbout Jesse Han   \nJesse Han is the Founder and CEO of Morph Labs, a company building the infrastructure for the singularity. Morph is the creator of Infinibranch, a breakthrough in cloud technology that enables scaling train-time and test-time search for agentic reasoning models. Jesse began his career as a pure mathematician and research scientist at OpenAI working on test-time compute scaling, GPT-4, and reasoning.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-08-01T14:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M31S",
      "viewCount": 1419,
      "likeCount": 38,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/2goSS66XRBk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/2goSS66XRBk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/2goSS66XRBk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/2goSS66XRBk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/2goSS66XRBk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=2goSS66XRBk"
    },
    {
      "id": "Y2qc0UhDSnc",
      "title": "Hacking the Inference Pareto Frontier - Kyle Kranen, NVIDIA",
      "description": "Your model works! It aces the evals! It even passes the vibe check! All that’s required is inference, right? Oops, you’ve just stepped into a minefield:\n\n-Not low-latency enough? Choppy experience. Users churn from your app. \n-Not cheap enough? You’re losing money on every query.\n-Not high enough output quality? Your system can’t be used for that application.\n\nA model and the inference system around it form a “token factory” associated with a Pareto frontier— a curve representing the best possible trade-offs between cost, throughput, latency and quality, outside of which your LLM system cannot be applied successfully. \n\nOutside of the Pareto frontier? You’re back to square one.\nThat is, unless you’re able to change the shape of the Pareto frontier.\n\nIn this session, we’ll introduce NVIDIA Dynamo, a datacenter-scale distributed inference framework as well as the bleeding-edge techniques it enables to hack the Pareto frontier of your inference systems, including:\n\n-Disaggregation - separating phases of LLM generation to make them more efficient\n-Speculation - predicting multiple tokens per cycle\n-KV routing, storage, and manipulation - ensuring that we don’t redo work that has already been done\n-Pipelining improvements for agents - accelerating our workflows using information about the agent\n\nBy the end of the talk, we’ll understand how the Pareto frontier limits where models can be applied, the intuition behind how inference techniques can be used to modify it, as well as the mechanics of how these techniques work.\n\n\n\n---related links---\n\nhttps://x.com/kranenkyle\nhttps://www.linkedin.com/in/kyle-kranen/\nhttps://www.nvidia.com/en-us/\n\nTimestamps:\n\n00:00 Introduction to Breaking the Inference Pareto Frontier\n00:33 Introduction of Kyle Cranon and NVIDIA Dynamo\n01:31 The Three Pillars of Deployment (Quality, Latency, Cost)\n02:11 Understanding the Pareto Frontier\n03:06 Application-Specific Prioritization of Quality, Latency, and Cost\n04:32 Common Techniques to Manipulate the Pareto Frontier (Quantization, RAG, Reasoning)\n05:19 Compounding Techniques\n06:04 Three Drivers for Modifying the Pareto Frontier (Scale, Structure, Dynamism)\n06:20 Scale: Disaggregation\n11:02 Scale: Routing\n13:00 Structure: Inference Time Scaling\n16:14 Structure: KV Manipulation\n17:43 Dynamism: Worker Specialization\n18:42 Dynamism: Dynamic Load Balancing\n19:55 Conclusion and NVIDIA Dynamo Resources",
      "publishedAt": "2025-08-01T13:45:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M25S",
      "viewCount": 1278,
      "likeCount": 29,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Y2qc0UhDSnc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Y2qc0UhDSnc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Y2qc0UhDSnc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Y2qc0UhDSnc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Y2qc0UhDSnc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Y2qc0UhDSnc"
    },
    {
      "id": "IA4lZjh9sTs",
      "title": "Pipecat Cloud: Enterprise Voice Agents Built On Open Source - Kwindla Hultman Kramer, Daily",
      "description": "Voice AI agents today can conduct natural, human-like conversations and perform a wide variety of tasks: customer support, lead qualification, healthcare patient intake, market research, and more.\n\nToday's best voice agents combine: realtime responsiveness, open-ended conversational intelligence, reliable instruction following, and flexible integration with existing back-end systems.\n\nLearn how to build state of the art voice agents using Pipecat's open source, vendor neutral tooling. You can deploy Pipecat agents to your own infrastructure or to Pipecat Cloud.\n\nPipecat is used and supported by teams at NVIDIA, AWS, Google DeepMind, OpenAI, and hundreds of other companies.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-31T18:56:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT26M46S",
      "viewCount": 2600,
      "likeCount": 62,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/IA4lZjh9sTs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/IA4lZjh9sTs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/IA4lZjh9sTs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/IA4lZjh9sTs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/IA4lZjh9sTs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=IA4lZjh9sTs"
    },
    {
      "id": "MPtCBaZn84A",
      "title": "[Full Workshop] Building Conversational AI Agents - Thor Schaeff, ElevenLabs",
      "description": "In this workshop you will learn how to build multilingual Conversational AI agents that can automatically detect your user's spoken language and can seamlessly switch to their preferred language.\n\nAbout Thor Schaef  \nThor is a software engineer who loves to teach and help developers build. \n\nHaving grown up around the SAP headquarters in Germany, he started building on the web back in high-school, later studied Computer Science and Media across Germany, Ireland, and Switzerland, and interned with the Google Maps Team in London. \n\nHe joined early Stripe in Dublin, building out various customer-facing engineering teams across Europe and Southeast Asia, contributing to open-source software, while mentoring and investing in early stage startups along the way. \n\nSettled in sunny Singapore since 2019, he helped grow Supabase from 800 to over a million databases, and recently joined ElevenLabs to help build the developer platform for AI audio!\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-31T18:45:56Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H1M42S",
      "viewCount": 2445,
      "likeCount": 61,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/MPtCBaZn84A/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/MPtCBaZn84A/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/MPtCBaZn84A/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/MPtCBaZn84A/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/MPtCBaZn84A/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=MPtCBaZn84A"
    },
    {
      "id": "kDczF4wBh8s",
      "title": "From Self-driving to Autonomous Voice Agents — Brooke Hopkins, Coval",
      "description": "The reliability challenges facing voice & chat AI deployment today mirror those that the autonomous vehicle industry confronted years ago. This talk explores how evaluation methodologies developed for self-driving cars can be transferred to create autonomous, self-improving evaluation systems for conversational AI. Drawing from my experience building evaluation infrastructure at Waymo and now developing Coval, an enterprise-grade reliability platform for conversational agents, I'll demonstrate how systematic testing infrastructure is not just a technical requirement but a competitive advantage in the rapidly evolving AI landscape.\n\n--\n\n \nBrooke Hopkins is the Founder at Coval, where her team builds the enterprise-grade reliability infrastructure for conversational AI. Previously, she built evaluation systems at Waymo that helped enable safe autonomous driving. With experience spanning both physical and digital AI domains, Brooke brings unique insights into creating robust testing frameworks that can scale with AI's rapid development.",
      "publishedAt": "2025-07-31T16:45:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M32S",
      "viewCount": 1237,
      "likeCount": 27,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/kDczF4wBh8s/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/kDczF4wBh8s/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/kDczF4wBh8s/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/kDczF4wBh8s/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/kDczF4wBh8s/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=kDczF4wBh8s"
    },
    {
      "id": "1v9zBiZKlIY",
      "title": "Why ChatGPT Keeps Interrupting You — Dr. Tom Shapland, LiveKit",
      "description": "ChatGPT Advanced Voice Mode isn’t interrupting just you. Interruptions, and turn-taking in general, are unsolved problems for all Voice AI agents. Nobody likes being cut short – and people have much less patience for machines than they do for other humans. Turn-taking failures take many forms (e.g., the agent interrupts the user, the agent mistakes a cough for an interruption), and all of them lead to users immediately hanging up the phone.\n\nIn this talk, we use human conversation as a framework for understanding both today’s approaches to turn detection and where the field is headed. You’ll learn about how linguists think about turn detection in human dialogue, what’s working (and what’s broken) in current methods, and how we might build Voice AIs that interrupt you less than your human brother.\n\nAbout Tom Shapland\nTom Shapland, PhD, is a Product Manager at LiveKit. LiveKit is an open source platform for building, deploying, and scaling realtime multimodal agents. He's passionate about the multimodal future of human-computer interfaces. Before LiveKit, he was the cofounder of a Voice AI observability platform (Canonical AI) and an agriculture technology startup (Tule, YC S14). He lives in the East Bay and coaches lacrosse for his two kids.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-31T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT27M3S",
      "viewCount": 2161,
      "likeCount": 56,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1v9zBiZKlIY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1v9zBiZKlIY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1v9zBiZKlIY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1v9zBiZKlIY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1v9zBiZKlIY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1v9zBiZKlIY"
    },
    {
      "id": "E71YtNbCFXY",
      "title": "Your realtime AI is ngmi — Sean DuBois (OpenAI), Kwindla Kramer (Daily)",
      "description": "Sean DuBois of OpenAI and Pion, and Kwindla Hultman Kramer of Daily and Pipecat, will talk about why you have to design realtime AI systems from the network layer up.\n\nMost people who build realtime AI apps and frameworks get it wrong. They build from either the model out or the app layer down. But unless you start with the network layer and build up, you'll never be able to deliver realtime audio and video streams reliably. And perhaps even worse, you'll get core primitives wrong: interruption handling, conversation state management, asynchronous function calling.\n\nSean and Kwin agree on most things: old-school realtime systems people against the rest of the world. But they disagree on some important things, too, and will argue about those things live on stage. Do you need to give developers \"thick\" client-side realtime SDKs? Can you build truly great vendor neutral APIs? (You'll be surprised which of them argues which side, on that topic.)\n\nAbout Kwindla Kramer\nKwin works on large-scale WebRTC infrastructure at Daily. He is the originator of Pipecat, the widely used, open source, vendor neutral voice agent framework supported by NVIDIA, Google, AWS and used by hundreds of startups. Before co-fonding Daily, Kwin built the sci-fi user interfaces in Minority Report and Iron Man.\n\nAbout Sean DuBois\nSean works on WebRTC and the Realtime API at OpenAI. He built 1-800-CHATGPT. He is the founder of Pion, the most widely used open source WebRTC project. He has previously worked at AWS, LiveKit, Apple, and Etsy.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\n\n00:00 [Voice Keynote] Your realtime AI is ngmi — Sean DuBois (OpenAI), Kwindla Kramer (Daily)\n01:29 Introduction to Voice AI and Latency\n02:46 Latency Breakdown in a Voice AI Application\n03:27 WebRTC vs. WebSockets for Real-Time Audio\n06:41 Advantages of WebRTC\n07:49 Applications of WebRTC\n08:52 Future of Voice AI and User Interfaces\n09:59 Squabbert Demo\n12:44 Flexibility of WebRTC Connections\n13:09 Community Showcase: Yashin's Project\n15:46 Call to Action and Resources",
      "publishedAt": "2025-07-31T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M30S",
      "viewCount": 1593,
      "likeCount": 46,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/E71YtNbCFXY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/E71YtNbCFXY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/E71YtNbCFXY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/E71YtNbCFXY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/E71YtNbCFXY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=E71YtNbCFXY"
    },
    {
      "id": "rD23-VZZHOo",
      "title": "Serving Voice AI at $1/hr: Open-source, LoRAs, Latency, Load Balancing - Neil Dwyer, Gabber",
      "description": "This is a talk that goes over our experience deploying Orpheus (Emotive, Realtime TTS) to production. It will cover topics:\n\n- Latency and optimizations\n- High fidelity voice clones w/ examples\n- Load balancing w/ multiple GPUs and multiple LoRas\n\nAbout Neil Dwyer\nSpent a lot of my career building real-time applications. First at a company called Bebo circa 2018 where I built a live streaming + computer vision pipeline that watched people play Fortnite. More recently at a company called LiveKit where I worked on the Agents platform along with some amazing people. And now at my own startup, Gabber, where we are making it easier (and cheaper!) to make real-time, multi-modal consumer apps.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps\n\n00:00 Introduction to Gabber and Real-Time AI\n02:15 Gabber's Mission for Consumer AI\n04:17 The Orpheus Voice Model\n05:43 Challenges in Voice Cloning\n07:44 Latency Management and \"Head of Line Silence\"\n11:07 Infrastructure for Batch Inference\n11:36 Leveraging vLLM and Dynamic Quantization\n13:21 Load Balancing with a Consistent Hash Ring\n14:17 System Architecture Overview\n15:07 Conclusion and Open Source Shout-outs",
      "publishedAt": "2025-07-31T13:45:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M9S",
      "viewCount": 5594,
      "likeCount": 154,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/rD23-VZZHOo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/rD23-VZZHOo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/rD23-VZZHOo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/rD23-VZZHOo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/rD23-VZZHOo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=rD23-VZZHOo"
    },
    {
      "id": "Gi4V8viBGYQ",
      "title": "How to defend your sites from AI bots — David Mytton, Arcjet",
      "description": "Constantly seeing CAPTCHAs? It used to be easy to detect the humans from the droids, but what else can we do when synthetic clients make up nearly half of all web requests. Rotating IPs, spoofed browsers, and agents acting on behalf of real users - are we doomed to forever be solving puzzles?\n    \n    In this talk, we’ll explore user agents, HTTP fingerprints, and IP reputation signals that make humans and agents stand out from scrapers, build a realistic threat model, and dig into the behaviors that reveal the LLM-mimicry. Leave with AX- and UX-safe code, benchmarks, and tools to help you take back control.",
      "publishedAt": "2025-07-30T17:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M12S",
      "viewCount": 1735,
      "likeCount": 56,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Gi4V8viBGYQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Gi4V8viBGYQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Gi4V8viBGYQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Gi4V8viBGYQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Gi4V8viBGYQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Gi4V8viBGYQ"
    },
    {
      "id": "CCsWZ5bJlO8",
      "title": "The Unofficial Guide to Apple’s Private Cloud Compute - Jmo, CONFSEC",
      "description": "In October 2024, Apple released a new private AI technology onto millions of devices called “Private Cloud Compute”. It brings the same level of privacy and security a local device offers but on an “untrusted\" remote server. This talk discusses how Private Cloud Compute represents a paradigm shift in confidential computing and explores the core advancements that made it possible to become mainstream. We’ll explore its novel architecture that allows developers to run sensitive, multi-tenant workloads with cryptographically-provably privacy guarantees at scale and at reasonable cost. Attendees will leave with an understanding of how to leverage this technology for data and AI applications where privacy and security is paramount.\n\nAbout Jonathan Mortensen\nJonathan Mortensen is a technology executive and founder with expertise spanning AI, data infrastructure, and cybersecurity. Currently serving as CEO of a stealth AI startup and Founder Fellow at South Park Commons, Jonathan previously founded bit.io, a multi-cloud serverless PostgreSQL platform acquired by Databricks. As bit.io's CTO, he built innovative database technology that handled hundreds of thousands of databases securely across multiple cloud providers. Prior to founding bit.io, Jonathan led data science and engineering teams at BlueVoyant, where he designed high-volume data pipelines processing 50 million events per second. He holds a PhD in Biomedical Informatics from Stanford University and combines technical depth with leadership experience across engineering, revenue, and operations.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\n\n00:00 Introduction to Apple's Private Cloud Compute (PCC)\n00:58 The Motivation for Privacy in AI\n02:20 The Core Problem: Balancing AI Compute Needs with User Privacy\n03:59 Apple's Five Key Requirements for Private Cloud Compute\n05:22 Conceptual Architecture of the PCC System\n08:06 The Six Core Technical Components of PCC\n10:22 Deep Dive: Remote Attestation\n11:52 Deep Dive: Transparency Log\n13:22 How Remote Attestation and the Transparency Log Work Together\n15:09 Gaps, Downsides, and Trade-offs of the System\n17:33 How Developers Can Use Similar Privacy-Enhancing Technologies\n19:17 Industry Trends in Private Processing",
      "publishedAt": "2025-07-30T17:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M36S",
      "viewCount": 1283,
      "likeCount": 28,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/CCsWZ5bJlO8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/CCsWZ5bJlO8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/CCsWZ5bJlO8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/CCsWZ5bJlO8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/CCsWZ5bJlO8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=CCsWZ5bJlO8"
    },
    {
      "id": "blmAkayzE8M",
      "title": "How to Secure Agents using OAuth — Jared Hanson (Keycard, Passport.js)",
      "description": "We all know sharing passwords is bad (unless you want free TV), so why are we sharing API keys with AI?  We shouldn't, and that’s why we need to talk about OAuth.\n\nIn this talk, we will give a brief intro to OAuth.  Then we will talk about the state of authorization in MCP.  We will show how an MCP client uses OAuth to authenticate a user and securely access private resources and tools hosted by an MCP server.  Then we’ll look at ways autonomous agents can use OAuth on their own behalf, talking to other agents and MCP servers directly.  We’ll learn how to use OAuth to build agents that humans and machines can trust.\n\nAbout Jared Hanson\nJared Hanson is the co-founder of Keycard, a company building identity infrastructure for the agent-native world. Previously at Okta and Auth0, Jared is an expert on OpenID, OAuth, and all things identity. He’s also the author of Passport.js, the popular authentication framework for Node.js. At Keycard, he is applying that knowledge to securing AI and infrastructure.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-30T16:30:15Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M59S",
      "viewCount": 5206,
      "likeCount": 140,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/blmAkayzE8M/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/blmAkayzE8M/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/blmAkayzE8M/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/blmAkayzE8M/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/blmAkayzE8M/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=blmAkayzE8M"
    },
    {
      "id": "kv-QAuKWllQ",
      "title": "How we hacked YC Spring 2025 batch’s AI agents — Rene Brandel, Casco",
      "description": "We hacked 7 of the16 publicly-accessible YC X25 AI agents. This allowed us to leak user data, execute code remotely, and take over databases. All within 30 minutes each. In this session, we'll walk through the common mistakes these companies made and how you can mitigate these security concerns before your agents put your business at risk.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n00:00 Introduction to Casco and AI Agents\n01:31 Evolution of Agent Stacks and Security Concerns\n02:56 Why Casco Hacked AI Agents\n04:00 Common Issue 1: Cross-User Data Access (IDOR)\n07:38 Common Issue 2: Arbitrary Code Execution\n12:38 Common Issue 3: Server-Side Request Forgery (SSRF)\n14:48 Key Takeaways\n15:28 Casco's Solution and Contact Information\n15:56 Q&A",
      "publishedAt": "2025-07-30T15:45:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M33S",
      "viewCount": 1862,
      "likeCount": 80,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/kv-QAuKWllQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/kv-QAuKWllQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/kv-QAuKWllQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/kv-QAuKWllQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/kv-QAuKWllQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=kv-QAuKWllQ"
    },
    {
      "id": "w7IMuYsBNr8",
      "title": "OpenAI on Securing Code-Executing AI Agents — Fouad Matin (Codex, Agent Robustness)",
      "description": "Code is the lingua franca for both software engineers and highly capable AI models. As we give agents the ability to build, test, and run code that they generate, the command line becomes their canvas—and their attack surface.\n\nThis keynote explores what it takes to bring code-executing agents from research to real-world deployment while maintaining control and security. We’ll cover how terminals offer AI an ideal interface, why they’re deceptively risky, and what it means to embed security, guardrails, and trust at every layer.\n\nIt’s not just about what agents can do—it’s about what they should do, and how we make sure they do it safely.\n\nJoin the new Agent Robustness team! https://x.com/gdb/status/1930831992171749773\n\nAbout Fouad Matin   \nFouad Matin is an engineer who co-founded Indent, temporary access control startup, before joining OpenAI to work on AGI-ready security, and previously worked on data infrastructure products at Segment. In 2016, he co-founded VotePlz, a non-partisan voter registration and turnout non-profit. Passionate about helping people find fulfilling work, he previously started a referral recruiting company which went through Y Combinator in W16 batch.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n00:00 Introduction to Code-Executing Agents\n02:29 Shifting Paradigm in AI Agent Building\n03:07 Security Concerns with Code Execution\n04:25 Safety Safeguards: Sandboxing\n05:02 Safety Safeguards: Disabling/Limiting Internet Access\n09:44 Safety Safeguards: Human Review\n11:19 Building Agents and Future Work",
      "publishedAt": "2025-07-30T15:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M",
      "viewCount": 2170,
      "likeCount": 69,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/w7IMuYsBNr8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/w7IMuYsBNr8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/w7IMuYsBNr8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/w7IMuYsBNr8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/w7IMuYsBNr8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=w7IMuYsBNr8"
    },
    {
      "id": "wRJD0inpmjU",
      "title": "Evaluating AI Search: A Practical Framework for Augmented AI Systems — Quotient AI + Tavily",
      "description": "AI search is becoming the front door to information, whether through Retrieval-Augmented Generation (RAG), Search-Augmented Generation (SAG), or custom agents that synthesize answers on top of indexed content. As users rely more heavily on these systems, evaluating their quality becomes mission-critical. But traditional metrics like precision and recall don’t capture the full picture.\n\nIn this talk, we introduce a practical evaluation framework for AI-powered search, across three dimensions:\n- Are the retrieved sources relevant to the query?\n- And is the final answer complete?\n- Are the sources faithfully used in the generated answer?\n\nWe’ll share lessons from working with search companies and present early findings from a new benchmark evaluating popular augmented AI systems across these dimensions. Rather than ranking winners and losers, we explore where different systems excel or break down, and how these tradeoffs inform product decisions.\n\nThis talk is for AI engineers and product teams who want to build trusted, high-quality AI search experiences, and need a way to measure if it’s actually working.\n\nAbout Julia Neagu\nJulia is the co-founder and CEO of Quotient AI, which provides intelligent observability for AI apps by automatically detecting failures, uncovering root causes, and recommending improvements. Before Quotient, she was the Director of Data for Copilot, GitHub's AI pair programmer, where her team built the systems evaluating the large language models behind Copilot. Previously, she was the Director of Analytics at Tamr and led end-to-end quantitative modeling at Aon's Intellectual Property Solutions group. Julia has a PhD and MA in Physics from Harvard, an AB in Physics from Princeton.\n\nAbout Deanna Emery\nDeanna is the Founding AI Researcher at Quotient AI, where she is leading research on evaluation of Large Language Models in real-world products and applications. Before Quotient, Deanna was a Principal Data Scientist at Aon, where she led the team building language models for valuation of intellectual property assets. She began her career as a researcher at Harvard-Smithsonian Center for Astrophysics and Caltech LIGO. Deanna has a MS in Machine Learning from UC Berkeley and BA in Physics from Harvard University. She is passionate about diversity and inclusion in STEM; she has conducted research on diversity in named patent inventors, working with companies to measure and address diversity gaps, and she is an active board member at a STEM education non-profit.\n\nAbout Maitar Asher\nMaitar Asher is a founding member and Head of Engineering at Tavily, a New York–based startup developing a web infrastructure layer for AI agents.\n\nShe leads the technology build and has architected core systems—including Tavily’s intelligent caching layer and enhanced search retrieval—to power the industry’s premier search engine for large language models.\n\nPrior to Tavily, she developed deep learning tools for PET/CT image segmentation as a Machine Learning Research Engineer at Stanford University. She holds a B.S. in Computer Science (Machine Learning) from Columbia University.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-29T16:01:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M33S",
      "viewCount": 2153,
      "likeCount": 48,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/wRJD0inpmjU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/wRJD0inpmjU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/wRJD0inpmjU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/wRJD0inpmjU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/wRJD0inpmjU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=wRJD0inpmjU"
    },
    {
      "id": "W1MiZChnkfA",
      "title": "Scaling Enterprise-Grade RAG: Lessons from Legal Frontier - Calvin Qi (Harvey), Chang She (Lance)",
      "description": "In domains like law, compliance, and tax, building enterprise-grade RAG means very large scale, spikey workloads, a focus on accuracy, and non-negotiable privacy. In this talk, we'll share war stories and battle scars of how Harvey has built the world's most advanced AI agents for the legal profession on top of a highly optimized retrieval architecture. We'll cover how to get better retrieval via both sparse and dense retrieval methods, why domain-specific reranking is essential, and how to handle ambiguity in real-world queries. We'll also touch on how LanceDB's search engine enables this architecture by delivering low-latency, high-throughput retrieval across millions of documents of varying sizes without compromising privacy. This solid foundation enables Harvey to build a product that brings highly accurate answers to hundreds of law firms and professional services firms across 45 countries.\n\nAbout Chang She\nTwo decades of building data tools for ML/AI. Pandas co-author. Building LanceDB, the database for multimodal AI.\n\nAbout Calvin Qi\nCalvin works on Retrieval Augmented Generation at Harvey for expert use cases in Legal, Tax, and more.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-29T16:00:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M40S",
      "viewCount": 2374,
      "likeCount": 59,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/W1MiZChnkfA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/W1MiZChnkfA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/W1MiZChnkfA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/W1MiZChnkfA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/W1MiZChnkfA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=W1MiZChnkfA"
    },
    {
      "id": "KWmkMV0FNwQ",
      "title": "Building Alice’s Brain: an AI Sales Rep that Learns Like a Human - Sherwood & Satwik, 11x",
      "description": "AI agents are becoming essential tools for teams of all sizes and industries - but training them to become experts in your product, business, and customerbase remains a challenge.\n\nWhat if onboarding a digital worker was as simple as uploading your pitch deck? At 11x, we built Alice, an AI SDR that writes outbound emails with the nuance and context of a top-performing human sales rep - because she learns like one too!\n\nIn this talk, we'll share how we built a knowledge base that allows 11x customers to \"train\" Alice on their internal materials: PDFs, websites, call recordings, and more. We'll talk through the ingestion pipeline in detail, discuss storage/retrieval technologies and their tradeoffs, and explain how Alice uses the knowledge base to drive high-performance email outreach at scale.\n\nAbout Sherwood Callaway\nSherwood Callaway is an emerging leader in the world of AI startups and AI product development. He currently serves as the first engineering manager at 11x, a series B AI startup backed by Benchmark and Andreessen Horowitz, where he oversees technical work on \"Alice\", an AI sales rep that outperforms top human SDRs.\n\nAlice is an advanced agentic AI working in production and at scale. Under Sherwood’s leadership, the system grew from initial prototype to handling over 1 million prospect interactions per month across 300+ customers, leveraging partnerships with OpenAI, Anthropic, and LangChain while maintaining consistent performance and reliability. Alice is now generating eight figures in ARR.\n\nSherwood joined 11x in 2024 through the acquisition of his YC-backed startup, Opkit, where he built and commercialized one of the first-ever AI phone calling solutions for a specific industry vertical (healthcare). Prior to Opkit, he was the second infrastructure engineer at Brex, where he designed, built, and scaled the production infrastructure that supported Brex’s application and engineering org through hypergrowth. He currently lives in San Francisco, CA.\n\nAbout Satwik Singh\nSatwik Singh is a core builder and emerging technical leader in the rapidly evolving field of applied AI and agentic systems. As a Member of Technical Staff at 11x AI, Satwik is at the forefront of developing \"Alice\", an AI sales representative that operates autonomously at scale—transforming how modern GTM teams work.\n\nAt 11x, Satwik has architected and delivered several of the company's most critical agent capabilities. He led the creation of the Knowledge Base Retrieval-Augmented Generation (RAG) and Deep Research pipeline, which powers Alice's ability to reason over complex product information and tailor responses with high fidelity: a first-of-its-kind system in the GTM agent space. He has also worked across systems to handle the credits ledger, and engineered the Sourcing Agent that autonomously crafts campaigns. Satwik has been instrumental in shaping the technical foundation of Alice's intelligence and reliability.\n\nPrior to 11x, Satwik was a software engineer at Meta, where he worked on Generative AI products within the Core Ads organization and contributed to infrastructure across Reality Labs. His work helped ship first-generation GenAI creative enhancements for Feed Ads—driving significant revenue gains at scale.\n\nSatwik's unique strength lies in his ability to move seamlessly between infrastructure, AI product, and agent behavior—designing systems that are production-ready, high-impact, and aligned with real business outcomes. With deep hands-on experience and a vision for what Agentic AI can become, he's helping define the next era of intelligent software.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-29T15:30:16Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT22M18S",
      "viewCount": 5227,
      "likeCount": 126,
      "commentCount": 9,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/KWmkMV0FNwQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/KWmkMV0FNwQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/KWmkMV0FNwQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/KWmkMV0FNwQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/KWmkMV0FNwQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=KWmkMV0FNwQ"
    },
    {
      "id": "w9u11ioHGA0",
      "title": "Layering every technique in RAG, one query at a time - David Karam, Pi Labs (fmr. Google Search)",
      "description": "Start with the simplest Search - in-memory embeddings with relevance ranking. End with the most complex planet-scale Search - 70+ corpus mix of token, embeddings, and knowledge graphs, all jointly retrieved, custom ranked, joint re-ranked, and then LLM-processed, at 160,000 queries per second in under 200msec.\n\nThis talk will be a fun “one query at a time” survey of all techniques in RAG in incremental complexity, showing the limits of each technique and what the next layered one opens up in terms of capabilities to handle ever-more complex queries in RAG. You’ll learn why queries like [falafel] are notoriously hard to Search over, why chunking your documents can be disastrous, how you can sometimes can get away with a simple bm25, and how some Search problems are so hard to solve that you’re better off punting the problem to the LLM or the UX. Brought to you by the team that worked on 50+ Search products, in the context of Google.com and custom Enterprise Search.\n\nAbout David Karam\nI'm David K. I love straddling the line between deep tech research and application development. I’ve spent a decade at Google as Product Director working on Search’s core AI and NLU systems, helping Search’s own version of “AI Engineers” develop magical applications. Around a year ago I left with my cofounder to start Pi Labs where we’re trying to bring that same spirit to the rest of the industry. Outside work I love to read, cook, and spend time in nature.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n00:00 Introduction and Context\n01:41 Quality Engineering Loop and Mindset\n04:09 In-Memory Retrieval\n04:50 Term-Based Retrieval (BM25)\n05:18 Relevance Embeddings (Vector Search)\n06:15 Re-Rankers (Cross Encoders)\n07:59 Custom Embeddings\n09:40 Domain-Specific Ranking Signals\n11:09 User Preference Signals\n12:17 Query Orchestration (Fan Out)\n14:26 Supplementary Retrieval\n16:09 Distillation\n17:14 Punting the Problem and Graceful Degradation",
      "publishedAt": "2025-07-29T14:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M22S",
      "viewCount": 9819,
      "likeCount": 276,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/w9u11ioHGA0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/w9u11ioHGA0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/w9u11ioHGA0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/w9u11ioHGA0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/w9u11ioHGA0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=w9u11ioHGA0"
    },
    {
      "id": "xnXqpUW_Kp8",
      "title": "Building a Smarter AI Agent with Neural RAG - Will Bryk, Exa.ai",
      "description": "RAG quality for AI agents is critical, and traditional keyword-based search engines consistently underperform in agentic or multi-step tasks, where semantic grounding and contextual nuance matter most.\n\nIn this talk, Will Bryk, CEO of Exa will live code two AI agent applications–one using traditional keyword search RAG and one using neural network RAG via vector search. He’ll then evaluate both applications based on task performance, relevance, and latency. With a live demo (no theory or pre-baked applications), the audience will get a firsthand look at the practical differences between keyword and semantic systems in production, and learn embedding strategies, indexing trade-offs, hybrid retrieval techniques, prompt tuning, and more.\n\nAbout Will Bryk\nA year before ChatGPT launched, Will was already spending his time building Exa’s API to crawl the web intelligently, focusing on finding quality sources over SEO spam. Backed by NVIDIA and Lightspeed, Exa now powers products for customers like Databricks, Cursor, and LlamaIndex.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-29T07:01:00Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M42S",
      "viewCount": 14573,
      "likeCount": 287,
      "commentCount": 24,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/xnXqpUW_Kp8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/xnXqpUW_Kp8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/xnXqpUW_Kp8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/xnXqpUW_Kp8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/xnXqpUW_Kp8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=xnXqpUW_Kp8"
    },
    {
      "id": "jxrGodnopHo",
      "title": "[Full Workshop] Building Metrics that actually work — David Karam, Pi Labs (fmr Google Search)",
      "description": "One of the biggest challenges in building evals you can trust is building metrics that reliably measure goodness in your application; metrics that are highly accurate, rapid fast, and tunable to ground truth rater and user behavior. This workshop is inspired by decades of AI and machine learning development in Google Search, reinvented for the modern LLM stack by the Pi team over the past year.\n\nIn this workshop you will learn how to:\n\n1. Brainstorm and design custom metrics tailored to your specific application needs.\n2. Identify which types of signals (natural language, code, other models) work best for your use case through rapid trial and error.\n3. Combine & calibrate your metrics against ground truth data using real examples from your domain.\n4. Use simple tools like Google Sheets for visualizing and analyzing your inputs and outputs with those metrics.\n5. Integrate your scoring models into both online workflows like agent control and offline ones like model comparison and training evaluation.\n\nAbout David Karam\nI'm David K. I love straddling the line between deep tech research and application development. I’ve spent a decade at Google as Product Director working on Search’s core AI and NLU systems, helping Search’s own version of “AI Engineers” develop magical applications. Around a year ago I left with my cofounder to start Pi Labs where we’re trying to bring that same spirit to the rest of the industry. Outside work I love to read, cook, and spend time in nature.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-29T00:29:21Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT40M28S",
      "viewCount": 1285,
      "likeCount": 30,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/jxrGodnopHo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/jxrGodnopHo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/jxrGodnopHo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/jxrGodnopHo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/jxrGodnopHo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=jxrGodnopHo"
    },
    {
      "id": "MRM7oA3JsFs",
      "title": "Make your LLM app a Domain Expert: How to Build an Expert System — Christopher Lovejoy, Anterior",
      "description": "Vertical AI is a multi-trillion-dollar opportunity. But you can't build a domain-expert application simply by grabbing the latest LLMs off-the-shelf: you need a system for codifying latent insights from domain experts and using that to drive development of your application.\n\nIn this talk, we'll describe the system we've built at Anterior which has enabled us to achieve SOTA clinical reasoning and serve health insurance providers covering 50 million American lives. We'll share:\n- how and why to encode domain-specific failure modes as an ontology\n- a practical system for converting domain expertise into quantifiable eval metrics\n- how we structure work and collaboration between our clinicians, engineer and PMs\n- our eval-driven AI iteration process and how this can be adapted to any industry\n\n\n---related links---\n\nhttps://x.com/chrislovejoy_\nhttps://www.linkedin.com/in/dr-christopher-lovejoy/\nhttps://chrislovejoy.me/\nhttps://www.anterior.com/",
      "publishedAt": "2025-07-28T19:55:45Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M18S",
      "viewCount": 49420,
      "likeCount": 1110,
      "commentCount": 35,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/MRM7oA3JsFs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/MRM7oA3JsFs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/MRM7oA3JsFs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/MRM7oA3JsFs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/MRM7oA3JsFs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=MRM7oA3JsFs"
    },
    {
      "id": "PthmdT92qNg",
      "title": "Shipping Products When You Don't Know What they Can Do — Ben Stein, Teammates",
      "description": "A customer recently asked me: “Hey, can I tag your AI agent in a Google Doc comment?”\n\nThe honest answer: I have no idea! We never designed our agents to handle Google Doc comments, but we tried it anyway… and it worked! The agent performed beautifully, the customer was thrilled, and I was left bewildered.\n\nWelcome to Product Management for AI agents, where roadmaps are fuzzy and we only learn the boundaries of our products after they’re released. When a product doesn’t follow predefined requirements but instead learns and improvises at runtime, PMs must give up control and lean into uncertainty, curiosity, experimentation, and fast feedback loops.\n\nThis talk is a field guide for Product/Engineering teams navigating this new reality. We’ll cover how to write specs for affordances instead of features, how to use AI evals as a product development tool, and how to perform User Acceptance Testing on undocumented emergent behavior. Most importantly, we’ll explore how to build trust with customers even when the answer is, truthfully, “I don’t know.”\n\nIf you’re managing AI-native products in 2025 the same way you managed web apps in 2020, you might find yourself A/B testing an agent that decided to go off and do C, D, and E all by themselves!\n\nAbout Ben Stein\nBen is a customer-obsessed technology executive and product leader who seamlessly bridges the worlds of business, product, and technology. He has repeated success leading cross-functional teams at multiple lifecycle stages, from 3x startup founder, to scaling through hypergrowth, to managing mature lines of business.\n\nIn 7 years at Twilio, Ben was GM of multiple business units (Developer Experience, Enterprise), Product Director for text messaging, and Head of R&D for Twilio.org. As CPTO at Arcadia (climate tech unicorn), he led a global team building APIs to decentralize and decarbonize the electrical grid. He cofounded multiple startups including Mobile Commons (acquired by $UPLD), an early platform for SMS marketing; and QuitCarbon, an AI platform to transition 100M homes off fossil fuels.\n\nHe is currently building Teammates, a platform for designing and managing a virtual workforce of truly autonomous virtual colleagues.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-28T19:55:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M34S",
      "viewCount": 1129,
      "likeCount": 15,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/PthmdT92qNg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/PthmdT92qNg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/PthmdT92qNg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/PthmdT92qNg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/PthmdT92qNg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=PthmdT92qNg"
    },
    {
      "id": "mHzJhXppwUA",
      "title": "Shipping something to someone always wins — Kenneth Auchenberg (ex. Stripe, VSCode)",
      "description": "Learnings from building products at Stripe and applying them in an AI native word.\n\nAbout Kenneth Auchenberg\nPartner at @alley_corp, investor focused on backing founders building for developers.\n\nPast building at @stripe, VS @Code, @microsoft and a few startups (acq)\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-28T19:54:23Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M17S",
      "viewCount": 773,
      "likeCount": 18,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/mHzJhXppwUA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/mHzJhXppwUA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/mHzJhXppwUA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/mHzJhXppwUA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/mHzJhXppwUA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=mHzJhXppwUA"
    },
    {
      "id": "xzJdSi2Tsqw",
      "title": "Why your product needs an AI product manager, and why it should be you — James Lowe, i.AI",
      "description": "So you've built another cool demo. Now what? You have hype, but not impact. You have kudos but no users. Ultimately you have a demo, but not a product.\n\nThe unique uncertainty of AI technology demands a new approach – beyond traditional product management. You need an AI Product Manager. This talk explains why this role is essential for building real AI products, using real case studies from the incubator for Artificial Intelligence in the UK Government.\n\nMore importantly, it reveals why your technical depth makes you uniquely suited to step into this critical leadership gap. Discover why could be the ideal candidate to be the AI Product Manager your product needs, and how to step into that role.\n\nAbout James Lowe\nJames Lowe has been a data scientist in public sector for 8 years, including working at 10 Downing Street. He is now the Head of AI Engineering for the Incubator for AI, a small team of experts in the centre of the UK Government building AI products that are delivering public good.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-28T19:53:56Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M37S",
      "viewCount": 4005,
      "likeCount": 87,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/xzJdSi2Tsqw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/xzJdSi2Tsqw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/xzJdSi2Tsqw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/xzJdSi2Tsqw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/xzJdSi2Tsqw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=xzJdSi2Tsqw"
    },
    {
      "id": "yG5d5UaGz1M",
      "title": "Everything is ugly, so go build something that isn't — Raiza Martin, Huxe (ex NotebookLM)",
      "description": "We're in an awkward adolescent phase of AI product (design). But what if this chaotic moment is actually our greatest opportunity? Enter the rebuilding revolution.\n\nIn this talk, we'll explore how the current state of AI interfaces offers a once-in-a-career chance to rethink fundamental UX patterns, with practical guidance on avoiding common pitfalls that plague first-generation AI products. \n\nLearn how to balance technical constraints with user needs, identify which conventional wisdom to keep versus discard, and ship AI experiences that actually delight users rather than frustrate them.\n\nAbout Raiza Martin\nA product leader with a unique lens on AI's user experience challenges, Raiza brings insights from both big tech and startup trenches.\n\nMost recently leading Google's NotebookLM team, she has shaped how millions of users interact with generative AI. Now, as a founder, she is reimagining these experiences from first principles.\n\nWith years of hands-on PM experience guiding technical teams through the practical realities of shipping AI products, Raiza offers a rare combination of enterprise-scale perspective and startup-speed execution.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-28T19:53:11Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT25M15S",
      "viewCount": 3638,
      "likeCount": 85,
      "commentCount": 12,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/yG5d5UaGz1M/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/yG5d5UaGz1M/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/yG5d5UaGz1M/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/yG5d5UaGz1M/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/yG5d5UaGz1M/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=yG5d5UaGz1M"
    },
    {
      "id": "UG9IAdmi2Dg",
      "title": "Building the platform for agent coordination — Tom Moor, Linear",
      "description": "Learn how we're evolving Linear into an operating system for engineering teams to ship product with agents as a first class citizen.\n\nAbout Tom Moor\nTom Moor is the Head of Engineering at Linear, a company redefining how modern teams build software. Linear streamlines issue tracking and project management for high-performance teams like Vercel, Ramp, Replit, and Retool.\n\nTom previously co-founded and scaled multiple SaaS startups including Abstract and Buffer. He draws on over a decade of experience building collaborative tools and design-led products.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-28T19:37:32Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M43S",
      "viewCount": 2609,
      "likeCount": 57,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/UG9IAdmi2Dg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/UG9IAdmi2Dg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/UG9IAdmi2Dg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/UG9IAdmi2Dg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/UG9IAdmi2Dg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=UG9IAdmi2Dg"
    },
    {
      "id": "mWKYvT9Lc50",
      "title": "What Is a Humanoid Foundation Model? An Introduction to GR00T N1 - Annika & Aastha",
      "description": "Foundation models don’t just write or draw anymore—they’re starting to move.\n\nGR00T N1 is NVIDIA’s open Vision-Language-Action (VLA) foundation model for humanoid robots. Built with a dual-system architecture, it combines a System 2 module for high-level reasoning with a System 1 module for real-time, fluid motor control. It’s trained end-to-end on a an impressive mix of data—from human videos to robot trajectories to synthetic simulations—and deployed on a full-sized humanoid robot performing bimanual manipulation tasks in the real world.\n\nThis talk is a high-level, beginner-friendly overview of GR00T N1:\n- What makes a robot foundation model different from an LLM or vision model\n- How GR00T’s architecture is inspired by cognitive systems\n- Why grounding language, vision, and action together unlocks new generalist capabilities\n\nIf you’ve ever wondered how large-scale AI is crossing over into the physical world, this session will get you up to speed—no robotics PhD required.\n\nAbout Annika Brundyn\nAnnika Brundyn is a Senior Solutions Architect at NVIDIA focused on deploying generative AI systems in the real world. She works at the intersection of inference infrastructure, reasoning models, and retrieval pipelines, and has contributed to flagship projects like NVIDIA’s NeMo Retriever and the GR00T vision-language-action model. Her experience spans frontier model research and enterprise-grade deployment. She spends a lot of time helping models make fewer “creative” mistakes in production.\n\nAbout Aastha Jhunjhunwala \nAastha Jhunjhunwala is a Solutions Architect at NVIDIA, focused on building optimized generative AI applications across industries. She works at the intersection of large-scale LLM pretraining, large language model inference, and NVIDIA’s full-stack generative AI infrastructure. Aastha has helped enterprises scale LLM workflows—from training models with billions of parameters to serving them efficiently with high-throughput inference. When she’s not working with language models, you’ll find her deep in the mountains, trading tokens for trail markers.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-28T16:29:53Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M47S",
      "viewCount": 5079,
      "likeCount": 164,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/mWKYvT9Lc50/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/mWKYvT9Lc50/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/mWKYvT9Lc50/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/mWKYvT9Lc50/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/mWKYvT9Lc50/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=mWKYvT9Lc50"
    },
    {
      "id": "wNH3q9pqn0U",
      "title": "Real-time Experiments with an AI Co-Scientist - Stefania Druga, fmr. Google Deepmind",
      "description": "The sheer volume of data and complexity of modern scientific challenges necessitate tools that go beyond mere analysis. The vision of an \"AI Co-scientist\" – a true collaborative partner in the lab – requires sophisticated engineering to bridge the gap between powerful AI reasoning and the dynamic reality of physical experiments. This talk dives into the engineering required to build robust AI Co-scientists for hands-on research. We will explore scalable architectures, such as multi-agent systems leveraging foundation models like Gemini for complex reasoning, hypothesis refinement (inspired by the \"generate, debate, evolve\" paradigm described in recent AI Co-scientist research), and intelligent tool use. The core focus will be on the engineering challenges and solutions for integrating diverse, real-time empirical data streams – visual data from cameras, quantitative readings from sensors, positional feedback from actuators, and instrument outputs – directly into the AI's reasoning loop. I will illustrate this with concrete, technically detailed examples in chemistry (adaptive reaction monitoring), robotics (vision-guided assembly with SO Arm 100 and LeRobot library), and synthetic biology (real-time bacterial growth monitoring & interpretation). We'll discuss engineering strategies for handling data heterogeneity, latency, noise, and enabling the AI to interpret, correlate, and act upon live experimental feedback. Finally, we will touch upon how thoughtful engineering of these AI Co-scientists can contribute to democratizing access to advanced scientific capabilities.\n\nAbout Stefania Druga\nHi! I am Stef. I am an independent researcher, formerly a Research Scientist in Google DeepMind working on novel multimodal AI applications. Previously I was a Principal Researcher in the Center of Applied AI Research at the University of Chicago. I graduated with a Ph.D. in Creative AI Literacies at the University of Washington Information School and have a master in Science from MIT,\n\nMy research focuses on Large Language Models and the design of Multimodal AI tools and resources and during grad school I built the first open-source platform for K12 AI Education - Cognimates. When I am not coding & writing papers. I love trail running, yoga, and riding my bike.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-28T16:29:39Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M42S",
      "viewCount": 2879,
      "likeCount": 87,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/wNH3q9pqn0U/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/wNH3q9pqn0U/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/wNH3q9pqn0U/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/wNH3q9pqn0U/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/wNH3q9pqn0U/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=wNH3q9pqn0U"
    },
    {
      "id": "1izYWsokr9s",
      "title": "Scaling AI Agents Without Breaking Reliability — Preeti Somal, Temporal",
      "description": "As AI agents move from prototypes to production, developers are running into new challenges with orchestration, failure handling, and infrastructure. This session will unpack lessons from teams already building real-world systems and share how to design for reliability from the start.\n\nAbout Preeti Somal\nPreeti is Senior Vice President of Engineering at Temporal. Preeti is passionate about building great products, growing world class organizations and solving complex problems. Prior to Temporal, Preeti led the Platform, Security and IT engineering organizations at HashiCorp. Her extensive career includes engineering leadership roles at Yahoo!, VMware and Oracle. While at Yahoo! Preeti was VP of Cloud Services in the Platform organization delivering highly scalable services used by engineers across Yahoo to build and operate applications with improved agility, reliability and security. These services power Yahoo!’s consumer and advertising business.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-28T15:15:00Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M1S",
      "viewCount": 2644,
      "likeCount": 61,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1izYWsokr9s/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1izYWsokr9s/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1izYWsokr9s/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1izYWsokr9s/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1izYWsokr9s/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1izYWsokr9s"
    },
    {
      "id": "cFxWPP1ik6A",
      "title": "Government Agents: AI Agents vs Tough Regulations — Mark Myshatyn, Los Alamos National Laboratory",
      "description": "https://www.linkedin.com/in/markmyshatyn/",
      "publishedAt": "2025-07-28T04:15:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M33S",
      "viewCount": 1283,
      "likeCount": 52,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/cFxWPP1ik6A/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/cFxWPP1ik6A/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/cFxWPP1ik6A/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/cFxWPP1ik6A/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/cFxWPP1ik6A/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=cFxWPP1ik6A"
    },
    {
      "id": "Fzb1a24hF-o",
      "title": "Ship Agents that Ship: A Hands-On Workshop - Kyle Penfound, Jeremy Adams, Dagger",
      "description": "Coding agents are transforming how software gets built, tested, and deployed, but engineering teams face a critical challenge: how to embrace this automation wave without sacrificing trust, control, or reliability.\n\nIn this 80 minute workshop, you’ll go beyond toy demos and build production-minded AI agents using Dagger, the programmable delivery engine designed for real CI/CD and AI-native workflows. Whether you're debugging failures, triaging pull requests, generating tests, or shipping features, you'll learn how to orchestrate autonomous agents that live in and around your codebase: from your laptop to your CI platform.\nWe’ll guide you through:\n\nBuilding real-world agents with Dagger and popular LLMs (GPT, Claude, etc.)\n\nProgramming agent environments using real languages (Go, Python, TypeScript)\n\nExecuting agent workflows locally and in GitHub Actions, so you can bring them to production\n\nUsing a composable runtime that ensures isolation, determinism, traceability, and repeatability\n\nDesigning agents that automate and enhance debugging, test generation, code review, bug fixing, and feature implementation\n\nBy the end of the workshop, you’ll walk away ready to build your own army of autonomous agents, working collaboratively across your codebase, locally and in CI, accelerating development without ceding control. Let’s build agents that don’t just talk, they ship!\n\nAbout Kyle Penfound\nKyle is part of the ecosystem team at Dagger working on the future of composable software. He has a background in DevOps and just loves giving demos!\n\nAbout Jeremy Adams\nJeremy is a senior leader with both a technical and a strategic streak. Passionate about people and entrepreneurship, integration and automation. Through technical/business roles at Dagger, GitHub, Twistlock, and Puppet, Jeremy has both zoomed in and zoomed out a lot, acquiring an appreciation for the details and an ever-broader sense of the big architectural picture.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-27T22:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H21M",
      "viewCount": 2847,
      "likeCount": 61,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Fzb1a24hF-o/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Fzb1a24hF-o/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Fzb1a24hF-o/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Fzb1a24hF-o/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Fzb1a24hF-o/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Fzb1a24hF-o"
    },
    {
      "id": "YYNXFsUutbM",
      "title": "The AI Engineer’s Guide to Raising VC — Dani Grant (Jam), Chelcie Taylor (Notable)",
      "description": "A no fluff, all tactics discussion. More AI engineers should build startups, the world needs more software. But there’s a way to raise VC and it’s hard to do it if you’ve never seen it done. We are going to walk through the exact playbook to raise your first round of funding. We will show you real pitch decks, real cold emails and real term sheets so when you go out to raise your first round of funding, you are setup to do it. Every AI Engineer should be equip to start their own company and this session makes sure raising $$$ is not going to be the blocker.\n\nAbout Dani Grant\nDani Grant is the CEO of Jam, a dev tools startup helping 65,000+ improve their bug reporting process, backed by executives from Apple, GitHub, and Vercel, and VCs such as Village Global (LPs include Mark Zuckerberg, Bill Gates, Jeff Bezos). Before Jam, Dani was an early product manager at Cloudflare, where she worked on core developer products such as 1.1.1.1 (now used by 10 million+ people). She also worked as a VC at Union Square Ventures.\n\nAbout Chelcie Taylor\nLeading early stage AI apps investments at Notable Capital ($5B AUM VC).\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-27T18:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT34M17S",
      "viewCount": 2818,
      "likeCount": 79,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/YYNXFsUutbM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/YYNXFsUutbM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/YYNXFsUutbM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/YYNXFsUutbM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/YYNXFsUutbM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=YYNXFsUutbM"
    },
    {
      "id": "89NuzmKokIk",
      "title": "Strategies for LLM Evals (GuideLLM, lm-eval-harness, OpenAI Evals Workshop) — Taylor Jordan Smith",
      "description": "Accuracy scores and leaderboard metrics look impressive—but production-grade AI requires evals that reflect real-world performance, reliability, and user happiness. Traditional benchmarks rarely help you understand how your LLM will perform when embedded in complex workflows or agentic systems. How can you realistically and adequately measure reasoning quality, agent consistency, MCP integration, and user-focused outcomes?\n\nIn this practical, example-driven talk, we'll go beyond standard benchmarks and dive into tangible evaluation strategies using various open-source frameworks like GuideLLM and lm-eval-harness. You'll see concrete examples of how to create custom eval suites tailored to your use case, integrate human-in-the-loop feedback effectively, and implement agent reliability checks that reflect production conditions. Walk away with actionable insights and best practices for evaluating and improving your LLMs, ensuring they meet real-world expectations—not just leaderboard positions!\n---\nBenchmarks and leaderboards are helpful—but they rarely reflect the realities of production AI. Evaluating real-world performance demands deeper insight into reasoning quality, agent reliability, user satisfaction, and integration with agentic systems and MCP (Model Context Protocol).\n\nThis hands-on workshop teaches you tangible evaluation methods using popular open-source frameworks (GuideLLM, lm-eval-harness, OpenAI Evals). No prior evaluation expertise required!\n\nYou’ll learn how to:\n\n- Build custom evaluation workflows beyond traditional accuracy benchmarks.\n- Evaluate reasoning skills, consistency, and reliability in agentic AI applications.\n- Integrate human-in-the-loop assessments for better user-aligned outcomes.\n- Validate MCP and agent interactions with practical reliability tests.\n\nWhether you're deploying chatbots, copilots, or autonomous AI agents, robust evaluation is critical. Join us to learn actionable strategies to confidently deploy your LLMs in real-world applications.\n\n---related links---\n\nhttps://www.linkedin.com/in/taylorjordansmith/\nhttps://www.redhat.com/en/products/ai",
      "publishedAt": "2025-07-27T16:15:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT32M28S",
      "viewCount": 6219,
      "likeCount": 152,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/89NuzmKokIk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/89NuzmKokIk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/89NuzmKokIk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/89NuzmKokIk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/89NuzmKokIk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=89NuzmKokIk"
    },
    {
      "id": "6AVMHZPjpTQ",
      "title": "Why you should care about AI interpretability - Mark Bissell, Goodfire AI",
      "description": "The goal of mechanistic interpretability is to reverse engineer neural networks. Having direct, programmable access to the internal neurons of models unlocks new ways for developers and users to interact with AI — from more precise steering to guardrails to novel user interfaces. While interpretability has long been an interesting research topic, it is now finding real-world use cases, making it an important tool for AI engineers.\n\nAbout Mark Bissell\nMark Bissell is an applied researcher at Goodfire AI working on real-world applications for mechanistic interpretability. He recently joined Goodfire after 3 years at Palantir, where he worked on various U.S. healthcare initiatives including research projects with the NIH, vaccine distribution during the Covid pandemic (Operation Warp Speed), and AI-enabled hospital operations across many of the nation's leading health systems.\n\nMark is passionate about translating frontier research into practical solutions. He believes that recent AI developments increase the importance broad skillsets, and that roles of the future will blur the lines between traditionally distinct categories such as engineer, researcher, inventor, designer, and entrepreneur.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-27T15:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M11S",
      "viewCount": 2772,
      "likeCount": 98,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/6AVMHZPjpTQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/6AVMHZPjpTQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/6AVMHZPjpTQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/6AVMHZPjpTQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/6AVMHZPjpTQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=6AVMHZPjpTQ"
    },
    {
      "id": "4Xe_iMYxBQc",
      "title": "Information Retrieval from the Ground Up - Philipp Krenn, Elastic",
      "description": "Vector search is only a feature. Search engines and information retrieval have retaken their position as the foundation of RAG. This workshop takes you through decades of research, what has been working for a long time, and how it got better with Machine Learning.\n\nAbout Philipp Krenn\nPhilipp leads Developer Relations at Elastic — the company behind the Elasticsearch, Kibana, Beats, and Logstash. Based in San Francisco, he lives to demo interesting technology and solve challenging problems — all with a smile and a terminal window.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-27T05:08:44Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H48M7S",
      "viewCount": 3788,
      "likeCount": 88,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/4Xe_iMYxBQc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/4Xe_iMYxBQc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/4Xe_iMYxBQc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/4Xe_iMYxBQc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/4Xe_iMYxBQc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=4Xe_iMYxBQc"
    },
    {
      "id": "Ahtaha9fEM0",
      "title": "Introduction to LLM serving with SGLang - Philip Kiely and Yineng Zhang, Baseten",
      "description": "Do you want to learn how to serve models like DeepSeek and Qwen with SOTA speeds on launch day? SGLang is an open-source fast serving framework for LLMs and VLMs that generates trillions of tokens per day at companies like xAI, AMD, and Meituan. This workshop guides AI engineers who are familiar with serving models using frameworks like vLLM, Ollama, and TensorRT-LLM through deploying and optimizing their first model with SGLang, as well as providing guidance on when SGLang is the appropriate tool for LLM workloads.\n\nAbout Philip Kiely\nPhilip Kiely leads Developer Relations at Baseten. Prior to joining Baseten in 2022, he worked across software engineering and technical writing for a variety of startups. Outside of work, you'll find Philip practicing martial arts, reading a new book, or cheering for his adopted bay area sports teams.\n\nAbout Yineng Zhang\nYineng Zhang is a Software Engineer at Baseten Model Performance team. He is also a core developer of the SGLang project.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\n00:00 Introduction to LLM serving with SGLang\n02:14 What is SGLang?\n03:36 History of SGLang\n06:49 Deploying Your First Model\n13:01 Optimizing Performance with CUDA Graph Max Batch Size\n24:19 Optimizing Performance with Eagle 3 Speculative Decoding\n30:02 SGLang Community and Contributions\n35:24 Invitations and Job Opportunities\n36:52 Q&A",
      "publishedAt": "2025-07-26T17:45:00Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT43M42S",
      "viewCount": 1854,
      "likeCount": 29,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Ahtaha9fEM0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Ahtaha9fEM0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Ahtaha9fEM0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Ahtaha9fEM0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Ahtaha9fEM0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Ahtaha9fEM0"
    },
    {
      "id": "cGLa8DsOYdk",
      "title": "Robotics: why now? - Quan Vuong and Jost Tobias Springberg, Physical Intelligence",
      "description": "Sharing recent progress from Physical Intelligence and why it is an exciting time to push the frontier in general purpose robotics\n\nAbout Quan Vuong\nQuan Vuong is co-founder at Physical Intelligence. His research focuses on generalist robotics and algorithms that enable intelligent behaviors through large scale learning.\n\nAbout Jost Tobias Springenberg\nTobias is currently a research scientist at Physical Intelligence where he works on bringing AI into the real world and understanding the fundamentals of sequential decision making (e.g. imitation and reinforcement learning). He likes his machine learning models big and his data to be plentiful and focuses most of his research on engineering driven machine learning at scale for robotics.\nBefore joining Physical Intelligence Tobias was a research scientist Google Deepmind in London within the control team which generally focuses on applications of ML to control for science and robotics. Before that he was a researcher at the University of Freiburg working with the Machine Learning Group and Computer Vision Groups. Tobias holds a BSc. in Cognitive Science from the University of Osnabrueck – from which he still retains an interest in understanding human cognition – and a MSc. in Computer Science from the University of Freiburg.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-26T17:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M7S",
      "viewCount": 22995,
      "likeCount": 779,
      "commentCount": 20,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/cGLa8DsOYdk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/cGLa8DsOYdk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/cGLa8DsOYdk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/cGLa8DsOYdk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/cGLa8DsOYdk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=cGLa8DsOYdk"
    },
    {
      "id": "iS9YFW28XyM",
      "title": "Waymo's EMMA: Teaching Cars to Think - Jyh Jing Hwang, Waymo",
      "description": "This session explores Waymo's latest research on the End-to-End Multimodal Model for Autonomous Driving (EMMA) and advanced sensor simulation techniques. Jyh-Jing Hwang will demonstrate how multimodal large language models like Gemini could improve autonomous driving through unified end-to-end architectures that process raw sensor data directly into driving decisions.\n\nThe presentation will showcase EMMA's state-of-the-art performance in trajectory planning, 3D object detection, and road graph understanding, as well as another Drive&Gen research approach to sensor simulation for evaluating an end-to-end motion planning model. Attendees will gain insights into the benefits of co-training across multiple autonomous driving tasks and the potential of controlled video generation for testing under various environmental conditions.\n\nMore on EMMA here: https://waymo.com/blog/2024/10/introducing-emma\n\nAbout Jyh Jing Hwang\nJyh-Jing is currently a Research Scientist and TLM at Waymo Research. He also taught machine learning and computer vision as a lecturer at UPenn MCIT Online in 2022 and 2023. Before joining Waymo in 2020, Jyh-Jing received his Ph.D. degree in Computer and Information Science from University of Pennsylvania, advised by Prof. Jianbo Shi and Prof. Stella Yu at UC Berkeley / ICSI. Before coming to the U.S., he received the B.S. and M.S. degrees from National Taiwan University and worked with Dr. Tyng-Luh Liu at Academia Sinica. His research interests are broadly in artificial intelligence, computer vision, and machine learning. Particularly, he's interested in end-to-end autonomous driving, large multimodal models, general image/video structures, and sensor fusion for robust perception.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-26T17:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M28S",
      "viewCount": 2007,
      "likeCount": 83,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/iS9YFW28XyM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/iS9YFW28XyM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/iS9YFW28XyM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/iS9YFW28XyM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/iS9YFW28XyM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=iS9YFW28XyM"
    },
    {
      "id": "wXVvfFMTyzY",
      "title": "A2A & MCP Workshop: Automating Business Processes with LLMs — Damien Murphy, Bench",
      "description": "Ever wished your webhooks could think for themselves? Join us to discover how A2A agents can transform passive webhook endpoints into intelligent workflow processors.\n\nIn this session, we'll show you how to build a system that automatically spawns AI Agents to handle incoming webhooks.\n\nUsing Google's Agent-to-Agent framework and MCP, you'll learn how to create dynamic AI agents that respond to events, communicate with external services, and make decisions based on content analysis.\n\nSee the future of workflow automation where webhooks don't just trigger actions—they trigger intelligence!\n\nAbout Damien Murphy\nFull Stack Dev for 20+ years focusing on AI Agents\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-26T14:15:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H23M14S",
      "viewCount": 20509,
      "likeCount": 399,
      "commentCount": 27,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/wXVvfFMTyzY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/wXVvfFMTyzY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/wXVvfFMTyzY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/wXVvfFMTyzY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/wXVvfFMTyzY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=wXVvfFMTyzY"
    },
    {
      "id": "DdaAABdAqZY",
      "title": "Piloting agents in GitHub Copilot - Christopher Harrison, Microsoft",
      "description": "The agent capabilities added to GitHub Copilot have enhanced its ability to act as a peer programmer. Copilot can now discover and generate code based on existing standards, run tests, recover from errors, and call tools using Model Context Protocol (MCP). This workshop will guide you through piloting Copilot's agent capabilities and how to best integrate with the most widely adopted AI coding assistant in the world.\n\nKey takeaways include:\n\n- Understanding how and when to bring agents into your software development workflow\n- Providing context through the use of custom instructions and prompt files to ensure consistency across your team\n- Discovering how MCP provides access to an additional set of external tools and capabilities that the agent can use\n- Configuring Copilot's agentic capabilities to take advantage of your custom MCP server\n- Recommended best practices to help your responsibly accelerate your development while maintaining code quality and governance\n\nAbout Christopher Harrison\nChristopher is a long-time geek who's spent the bulk of his career training, supporting and upskilling developers. He's a web developer at heart with passions which span from Python to DevOps to TypeScript to AI. In his current role as an Enterprise Advocate for GitHub he seeks to help organizations improve their DevOps process and culture. When not found writing code he can be found running, playing Civilization, or spending time with his partner and their four-legged child (a rescue mutt).\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-26T07:00:13Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT59M7S",
      "viewCount": 4598,
      "likeCount": 66,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/DdaAABdAqZY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/DdaAABdAqZY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/DdaAABdAqZY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/DdaAABdAqZY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/DdaAABdAqZY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=DdaAABdAqZY"
    },
    {
      "id": "iheWKg2Tkrk",
      "title": "Ship Production Software in Minutes, Not Months — Eno Reyes, Factory",
      "description": "Planning, coding, testing, monitoring—the endless cycle that spans 10+ tools that fragment our focus and slows delivery to a crawl. Vibe coding doesn't work when you've got 10TB of code. If you just sighed, you're one of many professional software engineers trapped in the traditional software development lifecycle (SDLC) that was designed before AI could parallelize your entire workflow.\n\nBut what if you could orchestrate multiple AI agents on tasks beyond just generating code, while you focus on the creative decisions that matter?\n\nIn this talk, I'll demonstrate how real enterprise organizations are changing their entire SDLC—going from understanding, planning, coding, and testing all the way to incident response—using AI agents. You'll witness the next evolution of software engineering—where AI doesn't just generate code, but orchestrates the entire development lifecycle.\n\nAbout Eno Reyes\nEno Reyes is cofounder and CTO of Factory, a platform that accelerates enterprise software development with autonomous AI agents and unified context from across your engineering tools. Enterprises are using Factory to accelerate everything from bug-fixing and coding to PRD creation, release automation, migrations, and more.\n\nPrior to Factory, he was an ML engineer at Hugging Face working on enterprise LLMs.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-25T23:11:00Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M6S",
      "viewCount": 4800,
      "likeCount": 113,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/iheWKg2Tkrk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/iheWKg2Tkrk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/iheWKg2Tkrk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/iheWKg2Tkrk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/iheWKg2Tkrk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=iheWKg2Tkrk"
    },
    {
      "id": "x_1EumTaXeE",
      "title": "Beyond the Prototype: Using AI to Write High-Quality Code - Josh Albrecht, Imbue",
      "description": "In this case study-based keynote, Josh Albrecht, CTO of Imbue, examines the critical engineering challenges in building AI coding systems that create more than just prototypes. Drawing from Imbue's research developing Sculptor, an experimental coding agent environment, Josh shares key insights into the fundamental technical obstacles encountered when evolving AI-assisted coding from toy applications to more robust software systems. \n\nThe session will explore approaches to core challenges like safely executing code, managing context across large codebases, automating test generation, and creating systems that can identify potential pitfalls in AI-generated code. Attendees will gain practical insights into the technical underpinnings of next-generation coding agents that aim to handle complex software engineering challenges architecting larger systems, increasing meaningful test coverage and designing systems that are easy to debug—moving us closer to AI systems that can help create maintainable software.\n\nAbout Josh Albrecht\nJosh Albrecht is CTO and Co-founder of Imbue, an AI lab launched in 2022 that has since raised $230M at a $1B valuation to create coding agents that make it easier for more people to write software. Josh is also a partner at angel fund Outset Capital, where he invests in promising pre-seed companies. Previously, Josh founded multiple companies including an AI recruiting startup that went through Y Combinator and a 3D injection molding software company that was acquired. He was also an early engineer at Addepar, served as a Thiel Fellow mentor, and published machine learning research as an academic researcher.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-25T23:10:37Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M59S",
      "viewCount": 12814,
      "likeCount": 256,
      "commentCount": 18,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/x_1EumTaXeE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/x_1EumTaXeE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/x_1EumTaXeE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/x_1EumTaXeE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/x_1EumTaXeE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=x_1EumTaXeE"
    },
    {
      "id": "o_hhkJtlbSs",
      "title": "Software Development Agents: What Works and What Doesn't - Robert Brennan, AllHands/OpenHands",
      "description": "The adoption of AI into software development has been bumpy. While autocomplete tools like Copilot have gone mainstream, autonomous agents like Devin and OpenHands have generated both enthusiasm and skepticism. Some engineers claim they generate a 10x productivity boost; others that they just create noise and tech debt.\n\nThe difference between the enthusiasts and the skeptics is that the enthusiasts have reasonable expectations for what these agents can do, and have both practical and intuitive knowledge for how to use them effectively.\n\nIn this session, we'll talk about what tasks are appropriate for today's software agents, what tasks they might start to succeed at in 2025, and what tasks are best left to humans no matter how good they get.\n\nSession Outline:\nLearn how to use software development agents like OpenHands (fka OpenDevin) effectively, without creating noise and tech debt.\n\n\n---related links---\n\nhttps://x.com/rbren_dev\nhttps://linkedin.com/in/robert-a-brennan\nhttps://www.all-hands.dev/blog\nhttps://www.all-hands.dev",
      "publishedAt": "2025-07-25T23:10:11Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M46S",
      "viewCount": 15850,
      "likeCount": 330,
      "commentCount": 22,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/o_hhkJtlbSs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/o_hhkJtlbSs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/o_hhkJtlbSs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/o_hhkJtlbSs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/o_hhkJtlbSs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=o_hhkJtlbSs"
    },
    {
      "id": "MI83buT_23o",
      "title": "Devin 2.0 and the Future of SWE - Scott Wu, Cognition",
      "description": "A talk on the future of software engineering with Scott Wu of Cognition AI, the makers of Devin.\n\nAbout Scott Wu\nScott is the co-founder and CEO of Cognition AI. He previously competed in international programming competitions (3x IOI gold medalist) and co-founded Lunchclub, an AI-powered professional networking platform. Scott grew up in Louisiana and attended Harvard University.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-25T23:07:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M13S",
      "viewCount": 14132,
      "likeCount": 211,
      "commentCount": 14,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/MI83buT_23o/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/MI83buT_23o/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/MI83buT_23o/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/MI83buT_23o/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/MI83buT_23o/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=MI83buT_23o"
    },
    {
      "id": "X4BwOu0GWb8",
      "title": "Your Coding Agent Just Got Cloned And Your Brain Isn't Ready - Rustin Banks, Google Jules",
      "description": "Will the future engineer code alongside a single coding agent, or will they spend their day orchestrating many agents? Traditional development rewards synchronous focus. This session dives into the significant mindshift required to move from sequential coding to orchestrating parallel agents. We are the builders of \"\"Jules\"\", Google's massively parallel asynchronous coding agent (to be opened up in May). We'll share real-world insights from building Jules and explore how to rewire your brain for this powerful new \"\"post-IDE\"\" development paradigm.\n\nAbout Rustin Banks\nI'm Rustin, an AI Product Manager at Google Labs. I taught myself to program at age 12 using a compiler I purchased on AOL classifieds. As a teenager I hosted a popular bulletin board system (BBS) out of my cousin’s closet using salvaged 286 computers. I’ve always had a passion for making the world better using technology. When I saw AI write code I dedicated the rest of my career to AI coding. At Google labs I am lucky to explore the frontier of coding models and agents.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-25T23:06:43Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M40S",
      "viewCount": 5305,
      "likeCount": 109,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/X4BwOu0GWb8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/X4BwOu0GWb8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/X4BwOu0GWb8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/X4BwOu0GWb8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/X4BwOu0GWb8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=X4BwOu0GWb8"
    },
    {
      "id": "9k3xPh-40mo",
      "title": "Latent Space Paper Club: AIEWF Special Edition (Test of Time, DeepSeek R1/V3) — VIbhu Sapra",
      "description": "Recorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n00:00:00 Paper Club Year in Review & Future Plans\n\n00:08:00 DeepSeek Paper Discussion\n\n00:09:10 DeepSeek R1 (May 28th Update)\n\n00:12:40 DeepSeek Distillation\n\n00:16:51 Original DeepSeek Model Overview (DeepSeek V3 and R1)\n\n00:21:15 Development of reasoning capabilities through a pure RL process\n\n00:24:46 DeepSeek R10\n\n00:39:05 DeepSeek R1 four-stage training pipeline\n\n00:35:01 Emergence of \"reflection moments\" and \"aha moments\"\n\n00:44:15 Distillation Strategy\n\n00:52:34 Community and Call to Action",
      "publishedAt": "2025-07-25T07:18:30Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT53M54S",
      "viewCount": 1082,
      "likeCount": 27,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/9k3xPh-40mo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/9k3xPh-40mo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/9k3xPh-40mo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/9k3xPh-40mo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/9k3xPh-40mo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=9k3xPh-40mo"
    },
    {
      "id": "o_LRtAomJCs",
      "title": "Human seeded Evals — Samuel Colvin, Pydantic",
      "description": "In this talk I'll introduce the concept of Human-seeded Evals, explain the principle and demo them with Pydantic Logfire.\n\n---related links---\n\nhttps://x.com/samuel_colvin\nhttps://www.linkedin.com/in/samuel-colvin/\nhttps://github.com/samuelcolvin\nhttps://pydantic.dev/",
      "publishedAt": "2025-07-25T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M2S",
      "viewCount": 2439,
      "likeCount": 59,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/o_LRtAomJCs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/o_LRtAomJCs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/o_LRtAomJCs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/o_LRtAomJCs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/o_LRtAomJCs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=o_LRtAomJCs"
    },
    {
      "id": "eSvXbb2EBYc",
      "title": "Building AI Products That Actually Work — Ben Hylak (Raindrop), Sid Bendre (Oleve)",
      "description": "You've made the demo. How do you make the product? A lot of AI products don't actually work. Even worse, a lot of the techniques being advertised for making AI products better don't work either. We'll cover the challenges + techniques we've seen actually work in the real world.\n\nAbout Ben Hylak\nBen Hylak is co-founder at Raindrop, building Sentry for AI products. He was previously a designer at Apple for 4 years, building the Apple Vision Pro.\n\nAbout Sid Bendre\nSid Bendre is the co-founder of Oleve, a company building a portfolio of iconic consumer software across multiple verticals. With a lean team, Oleve has already launched two virally successful consumer AI products that have amassed over 250 million views across social media platforms. One of their products reached #4 on the App Store's Education charts in 2024 and #5 in 2025, competing alongside giants like Photomath (Google) and Duolingo. Backed by Neo, Cal Henderson (co-founder of Slack), Russell Kaplan (President of Cognition), and Maria Zhang (ex-CTO of Tinder), Oleve is building the AI infrastructure to run a $1B portfolio of consumer software over the next decade. At Oleve, Sid leads technical and AI efforts, running the “Platform” team responsible for the underlying AI infrastructure that powers their lean scaling approach. Before Oleve, Sid led AI experimentation efforts at a startup hedge fund and worked at Slack, Zendesk, and Microsoft.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-24T17:15:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M42S",
      "viewCount": 2184,
      "likeCount": 35,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/eSvXbb2EBYc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/eSvXbb2EBYc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/eSvXbb2EBYc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/eSvXbb2EBYc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/eSvXbb2EBYc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=eSvXbb2EBYc"
    },
    {
      "id": "C3geUfBR2js",
      "title": "Rise of the AI Architect — Clay Bavor, Cofounder, Sierra w/ Alessio Fanelli",
      "description": "As the amount of consumer facing AI products grows, the most forward leaning enterprises have created a new role: the AI Architect. These leaders are responsible for helping define, manage, and evolve their company's AI agent experiences over time.\n\nIn this session, Clay Bavor (Cofounder of Sierra) will join Alessio Fanelli (co-host of Latent Space) in a fireside chat to share what it means to be an AI Architect, success stories from the market, and the future of the role.\n\n\n---related links---\n\nhttps://x.com/fanahova\nhttps://www.linkedin.com/in/fanahova/\nhttps://alessiofanelli.com",
      "publishedAt": "2025-07-24T16:45:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M55S",
      "viewCount": 34127,
      "likeCount": 666,
      "commentCount": 19,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/C3geUfBR2js/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/C3geUfBR2js/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/C3geUfBR2js/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/C3geUfBR2js/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/C3geUfBR2js/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=C3geUfBR2js"
    },
    {
      "id": "TquUsN1QsWs",
      "title": "AI That Pays: Lessons from Revenue Cycle — Nathan Wan, Ensemble Health",
      "description": "While much of the AI innovation in healthcare has centered on clinical and patient-facing applications, Revenue Cycle Management (RCM) remains an underexplored yet critical domain. Given the growing financial pressures facing providers, rethinking how healthcare gets paid is essential to ensuring access and sustainability. The combination of which makes RCM an opportune area for AI disruption.\n\nThis session explores how the combination of vast structured and unstructured data, often rule-based workflows, and direct financial opportunity to drive meaningful outcomes. We’ll also share practical lessons from our journey evolving a traditional machine learning mindset to incorporate the latest advances in Generative AI, and how that shift is reshaping what's possible in healthcare operations.\n\n---related links---\n\nhttps://www.linkedin.com/in/nwan1/",
      "publishedAt": "2025-07-24T16:15:10Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M19S",
      "viewCount": 614,
      "likeCount": 5,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/TquUsN1QsWs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/TquUsN1QsWs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/TquUsN1QsWs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/TquUsN1QsWs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/TquUsN1QsWs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=TquUsN1QsWs"
    },
    {
      "id": "SbUxRluVRwk",
      "title": "Structuring a modern AI team — Denys Linkov, Wisedocs",
      "description": "You've been given an AI mandate but don't have additional headcount, what next? Re-skilling, up-skilling and team augmentation become essential to delivering on a new mandate. In this talk we'll cover strategies to structure cross functional AI teams with domain experts, software engineers and ML engineers. We'll cover key skills and milestones that each traditional role can contribute to in unique ways.\n\n\n---related links---\n\nhttps://www.linkedin.com/in/denyslinkov/",
      "publishedAt": "2025-07-24T15:45:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M40S",
      "viewCount": 34606,
      "likeCount": 779,
      "commentCount": 13,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/SbUxRluVRwk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/SbUxRluVRwk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/SbUxRluVRwk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/SbUxRluVRwk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/SbUxRluVRwk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=SbUxRluVRwk"
    },
    {
      "id": "3WV1vT0B0cg",
      "title": "The Rise of Open Models in the Enterprise — Amir Haghighat, Baseten",
      "description": "This year kicked off with the DeepSeek-R1 news cycle breaking out of our AI Engineering bubble into the mainstream tech and business world. Leaders at the highest levels of the largest enterprises started asking how open source models could enhance and accelerate their AI strategy.\n\nOpen source models promise increased ownership of AI systems: control over performance and price, improved uptime and reliability, better compliance, and flexible hosting options. How are these promises playing out after months of implementation? In this talk, I’ll draw on hundreds of conversations with AI leaders at enterprise companies to discuss what has — and hasn’t — changed about enterprise AI strategy in a world where open-source models compete on the frontier of intelligence.\n\n\n---related links---\n\nhttp://twitter.com/amiruci\nhttps://www.linkedin.com/in/amirhaghighat/\nhttps://www.baseten.co/blog/\nhttps://www.baseten.co/",
      "publishedAt": "2025-07-24T15:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M50S",
      "viewCount": 2109,
      "likeCount": 65,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/3WV1vT0B0cg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/3WV1vT0B0cg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/3WV1vT0B0cg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/3WV1vT0B0cg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/3WV1vT0B0cg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=3WV1vT0B0cg"
    },
    {
      "id": "Zniw5c9_jx8",
      "title": "Mentoring the Machine — Eric Hou, Augment Code",
      "description": "You’d never let a swarm of fresh interns ship to prod on day one—same deal with AI agents. Mentoring the Machine dives into how acting like a tech lead (not just a user) turns those bots into real leverage. In this talk, Eric will deliver practical advice for working with AI agents in the SDLC. He'll also preview how effective use of AI agents changes the calculus of software engineering at both a micro and macro level.\n\n\n\n---related links---",
      "publishedAt": "2025-07-24T15:01:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M6S",
      "viewCount": 987,
      "likeCount": 28,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Zniw5c9_jx8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Zniw5c9_jx8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Zniw5c9_jx8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Zniw5c9_jx8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Zniw5c9_jx8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Zniw5c9_jx8"
    },
    {
      "id": "R30col3UPUg",
      "title": "Building Applications with AI Agents — Michael Albada, Microsoft",
      "description": "Generative AI has dramatically shortened the distance between ideas and implementation, enabling faster prototyping and deployment than ever before. But while language models can streamline individual tasks, true transformation comes from combining these capabilities into intelligent, autonomous systems—AI agents.\n\nThis talk explores how to build and deploy foundation model-enabled agent systems that go beyond simple prompt chaining or chatbots. Drawing from real-world implementations and the latest research, it offers a clear and practical path to designing both single-agent and multi-agent systems capable of handling complex workflows with minimal oversight.\n\nAttendees will gain a deeper understanding of the core design principles behind agentic systems, the architectural trade-offs involved in orchestrating multiple agents, and the strategies required to develop tailored solutions that enhance efficiency and innovation. Whether just beginning or scaling up, participants will leave with actionable insights to navigate the rapidly evolving world of AI autonomy.\n\n\n---related links---\n\nhttps://x.com/michaelalbada\nhttps://www.linkedin.com/in/albada/\nhttps://theneuralnexus.substack.com/\nhttps://michaelalbada.com\n\nTimestamps\n00:00 - Introduction by Michael Albada, Principal Applied Scientist at Microsoft.\n\n01:14 - The Promise and Obstacles of Agentic Development.\n\n02:37 - Defining What an AI Agent Is (and Isn't).\n\n04:42 - Core Component 1: Tool Use and Function Calling.\n\n06:37 - Core Component 2: Orchestration Patterns (Chains, Trees, Agentic).\n\n08:47 - Core Component 3: Multi-Agent Systems.\n\n09:43 - Common Pitfall 1: Insufficient Evaluation.\n\n11:25 - Overview of specific Evaluation Tools.\n\n12:57 - Common Pitfall 2: Lack of Observability.\n\n13:50 - Other Common Pitfalls (Tool issues, complexity).\n\n14:45 - The Critical Importance of Security and Safety.\n\n15:15 - Conclusion and Future Outlook.",
      "publishedAt": "2025-07-24T15:00:53Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M50S",
      "viewCount": 12388,
      "likeCount": 323,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/R30col3UPUg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/R30col3UPUg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/R30col3UPUg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/R30col3UPUg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/R30col3UPUg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=R30col3UPUg"
    },
    {
      "id": "e9sLVMN76qU",
      "title": "AX is the only Experience that Matters - Ivan Burazin, Daytona",
      "description": "If you’re building devtools for humans, you’re building for the past. \n\nAlready a quarter of Y Combinator’s latest batch used AI to write 95% or more of their code. AI agents are scaling at an exponential rate and soon, they’ll outnumber human developers by orders of magnitude.\n\n\nThe real bottleneck isn’t intelligence. It’s tooling. Terminals, local machines, and dashboards weren’t built for agents. They make do… until they can’t.\n\nIn this talk, I’ll share how we killed the CLI at Daytona, rebuilt our infrastructure from first principles, and what it takes to build devtools that agents can actually use. Because in an agent-native future, if agents can’t use your tool, no one will.\n\nAbout Ivan Burazin\nIvan Burazin co-founded Codeanywhere, the very first cloud IDE, back in 2009 where he and the team had to create everything from scratch, from the IDE itself, to the entire orchestration. Concurrently, he established Shift, the premier developer conference in Europe, which was later acquired by Infobip - a global communications cloud giant in 2021. Following the acquisition, Ivan served on the executive board of this 4,000-person company and as the Chief Developer Experience Officer, where he oversaw global developer-oriented operations.\n\nIn 2023, Ivan co-founded Daytona, a fast-growing open-source platform addressing the limitations of AI coding agents by enabling them to programmatically and securely interact with runtime environments.\n\nBacked by $7M in funding, Daytona empowers developers, from startups to Fortune 500 companies to enable AI agents to achieve their full potential.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-24T14:15:04Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M25S",
      "viewCount": 2677,
      "likeCount": 55,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/e9sLVMN76qU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/e9sLVMN76qU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/e9sLVMN76qU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/e9sLVMN76qU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/e9sLVMN76qU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=e9sLVMN76qU"
    },
    {
      "id": "hxFpUcvWPcU",
      "title": "How to build Enterprise Aware Agents - Chau Tran, Glean",
      "description": "While LLMs demonstrated impressive reasoning capabilities, their out-of-the-box reasoning is akin to hiring a brilliant but brand-new employee who doesn’t have the enterprise context of “how things are done at this company”. In this talk, I'll introduce “Workflow Search” as a paradigm to build enterprise-aware agents that can balance predictability on common tasks, and flexibility on unforeseen tasks.\n\nAbout Chau Tran\nChau Tran is a Software Engineer at Glean, currently leading the technical work on Glean Assistant and semantic search. They have been with Glean for over 3 years and have a history of impactful contributions in engineering teams. Previously, Chau worked as a Research Engineer at FAIR within Meta and held technical roles at Quora. They graduated from Brown University with a Bachelor's degree in Computer Science.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-24T09:22:32Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M53S",
      "viewCount": 8174,
      "likeCount": 171,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/hxFpUcvWPcU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/hxFpUcvWPcU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/hxFpUcvWPcU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/hxFpUcvWPcU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/hxFpUcvWPcU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=hxFpUcvWPcU"
    },
    {
      "id": "6WQYLQB0odc",
      "title": "Monetizing AI — Alvaro Morales, Orb",
      "description": "As AI continues to transform industries, companies are faced with the critical challenge of effectively monetizing AI-driven products in a way that captures value, ensures customer adoption, and scales revenue sustainably. Unlike traditional SaaS models, AI-powered products have unique complexities - such as fluctuating usage patterns, variable compute costs, and evolving customer demands, making conventional pricing strategies unhelpful to the growth of an AI product-led startup.\n\nIn this session, Alvaro Morales, CEO and co-founder of Orb, will explore why the often overlooked monetization aspect of AI is critical for businesses. He’ll share real-world examples and data to demonstrate how adaptive pricing models can drive cost savings, enhance customer experience, and reduce operational bottlenecks.\n\nAlvaro will lead a live demo, showcasing how engineers can simulate AI pricing strategies and subsequently integrate them with a simple plug-and-play solution. He’ll also share how real-world revenue simulations enable companies to test and refine pricing before implementing — reducing risk, boosting adoption, and unlocking new revenue streams. As a quick example, cloud software development platform Replit was looking to adopt a usage-based pricing model for a new product, but their existing billing system couldn't support the new model, and building a new billing system would delay the launch timeline. In order to get things done, they turned to Orb, which enabled them to make pricing changes up to the last minute. After the launch, Orb became the single source of truth for both Replit and its customers - providing usage alerts to notify Replit when users hit cost thresholds and provide insights into user spend and payment methods.\n\nKey takeaways: \nThe challenge of AI monetization – Why traditional subscription-based SaaS pricing models don’t work for AI-powered products.\nPrecision pricing – Exploring how usage-based, tiered, and hybrid pricing models can maximize revenue potential. \nRevenue simulation for AI pricing – Leveraging real-time data to test, adjust and optimize pricing strategies.\nAvoiding common pricing pitfalls – Identifying mistakes that can lead to revenue leakage and customer churn.\n\nThis session is designed for AI executives, product leaders, and engineering teams looking for actionable strategies to build adaptive, scalable pricing models that drive long-term growth and profitability.\n\n\n\n\n---related links---\n\nhttps://x.com/alvaromorales\nhttps://www.linkedin.com/in/alvaro-morales/\nhttps://www.withorb.com/",
      "publishedAt": "2025-07-23T19:45:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M18S",
      "viewCount": 6694,
      "likeCount": 197,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/6WQYLQB0odc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/6WQYLQB0odc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/6WQYLQB0odc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/6WQYLQB0odc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/6WQYLQB0odc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=6WQYLQB0odc"
    },
    {
      "id": "tbDDYKRFjhk",
      "title": "Does AI Actually Boost Developer Productivity? (100k Devs Study) - Yegor Denisov-Blanch, Stanford",
      "description": "Forget vendor hype: Is AI actually boosting developer productivity, or just shifting bottlenecks? Stop guessing.\n\nOur study at Stanford cuts through the noise, analyzing real-world productivity data from nearly 100,000 developers across hundreds of companies. We reveal the hard numbers: while the average productivity boost is significant (~20%), the reality is complex – some teams even see productivity decrease with AI adoption.\n\nThe crucial insights lie in why this variance occurs. Discover which company types, industries, and tech stacks achieve dramatic gains versus minimal impact (or worse). Leave with the objective, data-driven evidence needed to build a winning AI strategy tailored to your context, not just follow the trend.\n\nAbout Yegor Denisov-Blanch\nResearcher at Stanford University researching all things developer productivity\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\n\n----\n\nThe main thesis of the video is that while AI does increase developer productivity, it is not a one-size-fits-all solution. The speaker, Yegor Denisov-Blanch from Stanford, presents findings from a large-scale study on software engineering productivity to support this claim, arguing that the effectiveness of AI in software development is highly dependent on a variety of factors including task complexity, codebase maturity, language popularity, and codebase size.\n\ntimestamps:\n\n- 00:00 Introduction and the context of AI in software development, including Mark Zuckerberg's bold claims.\n- 04:37 Limitations of existing studies on AI's impact on developer productivity.\n- 07:19 The methodology used by the Stanford research group to measure productivity.\n- 09:50 The overall impact of AI on developer productivity, including the concept of \"rework.\"\n- 11:42 How productivity gains vary by task complexity and project maturity (Greenfield vs. Brownfield).\n- 14:21 The impact of programming language popularity on AI's effectiveness.\n- 15:42 How codebase size affects AI-driven productivity gains.\n- 17:22 The final conclusions of the study.",
      "publishedAt": "2025-07-23T17:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M12S",
      "viewCount": 223016,
      "likeCount": 5456,
      "commentCount": 623,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/tbDDYKRFjhk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/tbDDYKRFjhk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/tbDDYKRFjhk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/tbDDYKRFjhk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/tbDDYKRFjhk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=tbDDYKRFjhk"
    },
    {
      "id": "Lqq_LcBaJCc",
      "title": "How agents will unlock the $500B promise of AI - Donald Hruska, Retool",
      "description": "AI agents are on the cusp of revolutionizing work as we know it. The number of use cases software can tackle is set to explode as AI handles tasks requiring real judgment. But to cross the gap between an interesting AI prototype and an essential business tool, you need agents built by developers with real guardrails and security.\n\nThis means blending AI assistance with traditional coding in a multimodal approach that maximizes efficiency and control. The future isn't about dropping in an LLM — it requires integrating any model, any data, any system to deliver results.\n\nCompanies utilizing this approach can finally turn their slice of the $500B+ of total AI investment into real business results.\n\nAbout Donald Hruska\nDonald is the engineering lead for Retool's new Agents product.\n\nIn his three years at Retool, Donald has led teams across AI, Mobile, and Retool's core app building product. Prior to his time at Retool, Donald co-founded and spent 5+ years growing Draftbit, a Y Combinator-backed company in the low code app building space.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-23T15:51:38Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M22S",
      "viewCount": 3020,
      "likeCount": 66,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Lqq_LcBaJCc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Lqq_LcBaJCc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Lqq_LcBaJCc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Lqq_LcBaJCc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Lqq_LcBaJCc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Lqq_LcBaJCc"
    },
    {
      "id": "_zl_zimMRak",
      "title": "How Intuit uses LLMs to explain taxes to millions of taxpayers - Jaspreet Singh, Intuit",
      "description": "I will talk about how Intuit uses LLMs to explain tax situations to Turbotax users.\n\nUsers want explanations of their tax situations - this drives confidence in the product. Over the course of last two tax years, Intuit has built out explanations using Anthropic and openAI’s models to develop genAI powered explanations. This includes design a complex system with prompt engineered solutions and both LLM & human powered evaluations to ensure high quality bar that our users expect when filing taxes with us.\n\nDuring the course of my talk, I will talk across GenAI development lifecycle at scale - including development , evaluations and scaling. And security evaluations. We also developed a fine-tuned version of Claude Haiku & shall be covering that in the presentation.\n\nWe also expanded into tax question and answering powered by RAG, including graphRAG and I would be covering those developments too.\n\nAbout Jaspreet Singh\nI’m Jaspreet Singh, a Senior Staff Software Engineer with 12 years of experience in the tech industry. I am the tech lead for the Smart Turbotax AI team at Intuit - focusing on development of new GenAI powered experiences in Intuit Turbotax. I have worked extensively on Personalization and Recommendations problems in the past and I’m very passionate about bringing the latest in AI to help drive Taxes are done experiences for our users. I recently became a father for the first time, and enjoy spending time with my little one. As a speaker at the AI Engineer World’s Fair, I’m excited to share our journey of transforming our user’s tax filing journeys with the power of Gen AI..\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-23T15:51:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M59S",
      "viewCount": 737,
      "likeCount": 16,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/_zl_zimMRak/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/_zl_zimMRak/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/_zl_zimMRak/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/_zl_zimMRak/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/_zl_zimMRak/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=_zl_zimMRak"
    },
    {
      "id": "kTnfJszFxCg",
      "title": "3 ingredients for building reliable enterprise agents - Harrison Chase, LangChain/LangGraph",
      "description": "It's easy to build a prototype of an agent, but hard to put an agent in production - especially in an enterprise setting. In this section, will talk about three ingredients for building reliable agents in the enterprise.\n\nAbout Harrison Chase\nHarrison Chase is the CEO and co-founder of LangChain, a company formed around the popular open source Python/Typescript packages. The goal of LangChain is to make it as easy as possible to use LLMs to develop context-aware reasoning applications. Prior to starting LangChain, he led the ML team at Robust Intelligence (an MLOps company focused on testing and validation of machine learning models), led the entity linking team at Kensho (a fintech startup), and studied stats and CS at Harvard.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-23T15:51:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M55S",
      "viewCount": 31134,
      "likeCount": 608,
      "commentCount": 29,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/kTnfJszFxCg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/kTnfJszFxCg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/kTnfJszFxCg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/kTnfJszFxCg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/kTnfJszFxCg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=kTnfJszFxCg"
    },
    {
      "id": "3YGRcgZJ3yc",
      "title": "From Hype to Habit: How We’re Building an AI-First SaaS Company—While Still Shipping the Roadmap",
      "description": "What does it really take to move a modern SaaS company from AI experimentation to becoming truly AI-first?\n\nAt Sprout Social, we’re in the midst of that transformation—rearchitecting strategy, systems, teams, and incentives to put AI at the heart of how we think, build, and deliver value. This is a story in motion: a behind-the-scenes look at how we’re evolving from isolated AI feature experiments to an AI-native operating model.\n\nI’ll share what we’re learning as we navigate the innovation dilemma—integrating disruptive AI capabilities without breaking what already works or our roadmap. That includes rethinking how we define success, how we hire, reward, grow talent, and how we handle legal and ethical complexity without slowing down. We’ll explore the real-world tensions between rapid innovation, value delivery, making progress on Responsible AI, all while elevating internal AI fluency, and engaging with the broader AI ecosystem to stay at the edge.\n\nThis isn’t a playbook from the finish line—it’s a candid reflection from deep inside the journey.\n\nAbout Rossella Blatt Vital\nRossella Blatt Vital is a passionate AI leader with nearly 20 years of experience turning data into business value—from hands-on research and model-building to strategic executive leadership. She began her journey with a PhD in machine learning, focusing on brain-computer interfaces and cancer detection, and spent years writing code, building models, and shipping AI-powered products before stepping into leadership roles across startups, academia, and Fortune 100 companies.\n\nAs VP of AI, Data, and Data Science at Sprout Social, Rossella leads the company’s AI transformation—driving strategy across engineering, applied science, and analytics. Her team is building AI-first capabilities across product experiences, platform infrastructure, and foundational data systems.\n\nShe’s passionate about building meaningful technology—and the teams that power it—with the belief that AI, when led with vision and integrity, can help shape a more thoughtful and human-centered future.\n\nAbout Deepsha Menghani\nDeepsha Menghani is a passionate AI leader with over a decade of experience translating data and machine learning into meaningful business impact—from predictive modeling and customer analytics to large language model applications. Her career spans hands-on data science, applied AI, and strategic leadership across global tech organizations. As Director of Engineering – AI at Sprout Social, her team is responsible for embedding AI into core product experiences and delivering insights that accelerate growth, improve customer understanding, and inform business strategy across the company.\n\nShe’s especially passionate about building AI that is not only technically robust, but also responsible, human-centered, and aligned with real-world decision-making.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-23T15:51:20Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M29S",
      "viewCount": 618,
      "likeCount": 12,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/3YGRcgZJ3yc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/3YGRcgZJ3yc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/3YGRcgZJ3yc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/3YGRcgZJ3yc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/3YGRcgZJ3yc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=3YGRcgZJ3yc"
    },
    {
      "id": "zlZz0mDF2eg",
      "title": "Machines of Buying and Selling Grace - Adam Behrens, New Generation",
      "description": "How to go beyond browser automation to truly agentic commerce, where AI can buy, sell and negotiate on behalf of users and merchants.\n\nAbout Adam Behrens\nAdam Behrens is the co-founder and CEO of New Gen, a company that partners with global brands and merchants to unlock AI native commerce opportunities. New Gen builds infrastructure for brands to host their own conversational AI experiences and to connect their data into 3rd party chat clients like ChatGPT and Claude. Adam previously worked on trading infrastructure at Bridgewater and Banking-as-a-Service at Stripe. Outside of training AI models he is busy training his 8 month old Vizsla puppy.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-23T15:51:11Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M37S",
      "viewCount": 386,
      "likeCount": 8,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/zlZz0mDF2eg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/zlZz0mDF2eg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/zlZz0mDF2eg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/zlZz0mDF2eg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/zlZz0mDF2eg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=zlZz0mDF2eg"
    },
    {
      "id": "sl3icG-IjHo",
      "title": "How to Build Planning Agents without losing control - Yogendra Miraje, Factset",
      "description": "LLMs are getting smarter—but Agents are still unpredictable, unreliable, and hard to control.\n\nIn this talk, I’ll share practical lessons from building real-world plan-and-execute agents —covering how to steer autonomous agents using agentic workflows, blueprints, and evals.\n\nIf you’re struggling to make your agents behave (without giving up flexibility), this one’s for you.\n\nAbout Yogendra Miraje\nI'm a backend engineer turned ML engineer turned AI engineer, with 16 years of experience building intelligent systems. I hold a Master’s degree in Computer Science from Northeastern University in Boston, and I currently work as an AI Engineer in FactSet.\n\nI'm also the host of AI Blindspot, a podcast where we explore the frontiers of artificial intelligence—and the blind spots we often overlook in its development and deployment.\n\nWith a strong foundation in Machine Learning and software Engineering and a product-minded approach, I focus on aligning autonomous agents with real-world user goals, emphasizing safety, control, and robust evaluation techniques.\n\nI'm passionate about building AI that’s not just powerful, but grounded, aligned, and truly useful in practice.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-23T15:51:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M58S",
      "viewCount": 7075,
      "likeCount": 173,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/sl3icG-IjHo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/sl3icG-IjHo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/sl3icG-IjHo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/sl3icG-IjHo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/sl3icG-IjHo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=sl3icG-IjHo"
    },
    {
      "id": "j_TKDweOsYE",
      "title": "Building Agents (the hard parts!) - Rita Kozlov, Cloudflare",
      "description": "AI workloads are rapidly shifting from AI being used for augmentation (co-pilots), to AI becoming responsible for full, end-to-end automation (agents). But building effective agents, and even more importantly, agent experiences that boost productivity requires many pieces. In this talk, we'll be covering the building blocks of agents, how to put them together, and what we've learned from top companies building agents along the way.\n\nAbout Rita Kozlov\nFrom the very beginning, Rita has been a key figure in the development of Cloudflare's developer platform. Their initial experience as a solutions engineer, helping early enterprise customers adopt the service, gave them firsthand insight into user needs. It was the power of Cloudflare Workers that truly resonated, inspiring a vision for a serverless future. For the past eight years, they have built out the platform which now spans products including storage, compute and AI, and is used by everyone from indie millions of indie developers to Fortune 500 companies.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-23T15:51:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M12S",
      "viewCount": 3400,
      "likeCount": 64,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/j_TKDweOsYE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/j_TKDweOsYE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/j_TKDweOsYE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/j_TKDweOsYE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/j_TKDweOsYE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=j_TKDweOsYE"
    },
    {
      "id": "vW8wLsb3Nnc",
      "title": "POC to PROD: Hard Lessons from 200+ Enterprise GenAI Deployments - Randall Hunt, Caylent",
      "description": "The transition from experimental GenAI demonstrations to robust, production-grade systems involves significant technical and organizational complexities. Humans provide a ceiling on the true ROI of automations. This session synthesizes key patterns and practical strategies gathered from more than 200 GenAI implementations across multiple industries and business sizes.\n\nBeyond the general lessons that apply to most products leveraging GenAI, we'll cover detailed observations within three application areas: multimodal understanding and search, enterprise knowledge retrieval, and AI agent architectures. We will share real-world comparative performance data and metrics on embedding models, vector index implementations, and explore various implementation methodologies that balance performance and cost.\n\nAdditionally, the session addresses organizational insights critical to successful AI deployments, such as the importance of clearly defined evaluation processes and understanding real-world user interaction challenges, highlighted by examples from healthcare environments. Attendees will gain an understanding of decision-making criteria, including the appropriate complexity of prompt engineering versus more elaborate orchestration methods, token/cost management strategies in multilingual settings, and the challenges in driving behavioral change with new UX and application interaction capabilities.\n\nParticipants will leave equipped with practical, data-supported insights for effectively navigating their own GenAI projects, including benchmarks and criteria for informed technology selection, and techniques to streamline the transition from initial concept to sustainable operational deployment. Please note, we all know this field evolves rapidly and we will mark which lessons we believe are immutable.\n\nAbout Randall Hunt\nRandall Hunt is a technology leader, investor, and hands-on keyboard coder based in Los Angeles, CA. Previously, Randall led software and developer relations teams at Facebook, SpaceX, AWS, MongoDB, and NASA. Randall spends most of his time listening to customers, building demos, writing blog posts, and mentoring junior engineers. Python and C++ are his favorite programming languages, but he begrudgingly admits that Javascript rules the world. Outside of work, Randall loves to read science fiction, advise startups, travel, and ski.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-23T15:50:56Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M16S",
      "viewCount": 30537,
      "likeCount": 660,
      "commentCount": 13,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/vW8wLsb3Nnc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/vW8wLsb3Nnc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/vW8wLsb3Nnc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/vW8wLsb3Nnc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/vW8wLsb3Nnc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=vW8wLsb3Nnc"
    },
    {
      "id": "CB-4NKDYnRs",
      "title": "Build Dynamic Products, and Stop the AI Sideshow — Eliza Cabrera (Workday) + Jeremy Silva (Freeplay)",
      "description": "AI across product, GTM, and strategy was a great approach in 2023, but by now, we all already know that AI is disrupting the global landscape and how business gets done. Now is the time to stop chasing your competitors, and letting the technology lead your product strategy. There’s a better way to build that will allow you to differentiate and keep pace.\n\nJoin AI product managers Eliza Cabrera and Jeremy Silva to learn how to crawl, walk, and run your way towards building dynamic products.\n\nAbout Jeremy Silva\nA seasoned ML engineer with extensive experience building and deploying language models in the healthcare sector, Jeremy currently serves as Product Lead at Freeplay. At Freeplay, he oversees an enterprise-ready platform that empowers teams to run experiments, create evaluations, monitor production systems, and label data—all within a unified environment.\n\nDrawing from hands-on collaboration with Freeplay's enterprise customers, Jeremy brings valuable \"in-the-trenches\" experience building LLM systems at scale. This direct customer engagement has also positioned him as a trusted advisor, helping organizations shape and refine their AI product roadmaps for maximum impact.\n\nJeremy’s unique perspective spans technical implementation and product development making him well-positioned to share insights on effectively bridging the gap between AI capabilities and real-world product outcomes.\n\nAbout Eliza Cabrera\nBuilding and scaling 0-1 products in the enterprise.\n\nhttps://www.linkedin.com/in/itselizacab/\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-23T15:50:50Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M10S",
      "viewCount": 61,
      "likeCount": 2,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/CB-4NKDYnRs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/CB-4NKDYnRs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/CB-4NKDYnRs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/CB-4NKDYnRs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/CB-4NKDYnRs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=CB-4NKDYnRs"
    },
    {
      "id": "Wv1tAxKYLeE",
      "title": "The Billable Hour is Dead; Long Live the Billable Hour — Kevin Madura + Mo Bhasin, Alix Partners",
      "description": "If software was eating the world before, knowledge work will soon be devoured by AI. In corporate America there are thousands of hours spent on rote tasks every day by employees, consultants, and lawyers alike. But is AI really capable of replacing work in the real world yet? Productivity estimates from GenAI range from 1.5% (NBER) to 96% (☝ us! ️). \n\nIn this talk we'll share war stories of where the answer is yes (and no) and how we reduced human time spent on tasks from days to minutes in high-impact situations. The path from promise to actual product, used in real world settings, from our experience, is still unmapped. Learn what we built, how we built it - with code - and how we got stakeholder buy-in to deploy it.\n\nAbout Kevin Madura\nKevin leads technical advisory engagements and investigations in situations involving complex software, applied AI, and digital assets. As testifying expert and \"translator\" of technical material, he regularly interfaces with executive leadership, legal counsel, regulators, and engineers, balancing deep technical expertise with strategic clarity to drive outcomes.\n\nAbout Mo Bhasin\nMo Bhasin is Director of AI Products at AlixPartners, where he leads development of the firm's internal genAI platform. He helped scale the platform to 50+ deployments, and grew the AI team from 2 to 20 in under a year.\n\nOver the last 15 years, he's built products as a data scientist at Google, Nest, and most recently as a startup founder at Outoftheblue.ai.\n\nHe holds an engineering degree from the University of California Berkeley, and an MBA from University of Chicago Booth School of Business.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps\n00:00 Introduction to Alix Partners and the AI Shift\n01:05 How AI is Reshaping Knowledge Work\n02:19 The Future of Professional Services Models with AI\n03:36 AI's Impact on the Three Phases of Engagements\n05:07 Scaling Data Analysis Beyond Human Limitations\n06:36 The Paradox of AI Investment and Productivity\n07:22 Use Case 1: Categorization with Structured Outputs\n10:34 Use Case 2: Retrieval-Augmented Generation (RAG)\n12:46 Use Case 3: Structured Data Extraction from Unstructured Data\n15:54 Key Requirements for Scaling GenAI Initiatives\n16:48 Final Thoughts: The Future of LLMs in the Enterprise",
      "publishedAt": "2025-07-23T15:50:35Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M4S",
      "viewCount": 145,
      "likeCount": 11,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Wv1tAxKYLeE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Wv1tAxKYLeE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Wv1tAxKYLeE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Wv1tAxKYLeE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Wv1tAxKYLeE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Wv1tAxKYLeE"
    },
    {
      "id": "kDEvo2__Ijg",
      "title": "From Copilot to Colleague: Trustworthy Agents for High-Stakes - Joel Hron, CTO Thomson Reuters",
      "description": "This keynote will explore what it takes to move from basic generative assistants to fully agentic AI—systems that don’t just suggest but plan, act, and adapt—all within the structured, high-trust environments where professionals actually work.\n\nAbout Joel Hron\nJoel Hron is a passionate innovator driving the future of product technology and AI at Thomson Reuters. As Chief Technology Officer, he leads Product Engineering and AI Research & Development, pushing the boundaries of what’s possible in Legal, Tax, Audit, Trade, Compliance, and Risk solutions.\n\nJoel joined Thomson Reuters in 2022 through the acquisition of ThoughtTrace, where he served as CTO. Previously, he led AI and TR Labs, launching seven groundbreaking GenAI products in just 18 months, transforming legal research, tax analysis, and contract drafting.\n\nHis approach is centered on rethinking processes through technology, building teams rooted in trust, transparency, and customer-centric innovation. Joel envisions AI not as a replacement for human expertise, but as a force that enhances professional decision-making, making expert information more accessible and impactful.\n\nA New Orleans native, Joel’s global career spans work in London and Africa, and he now calls Zug, Switzerland home. He holds a Master’s in Mechanical Engineering from the University of Texas at Austin and a Bachelor’s in Engineering from Texas Christian University.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-23T12:15:13Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M45S",
      "viewCount": 1461,
      "likeCount": 31,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/kDEvo2__Ijg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/kDEvo2__Ijg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/kDEvo2__Ijg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/kDEvo2__Ijg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/kDEvo2__Ijg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=kDEvo2__Ijg"
    },
    {
      "id": "Zqu0VaJw3vo",
      "title": "How to Hire AI Engineers when EVERYONE is cheating with AI — Beth Glenfield, DevDay",
      "description": "AI broke recruitment - how to think about hiring for AI-enabled engineers in the era of AI cheating agents and AI customised resumes.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-22T19:55:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT6M45S",
      "viewCount": 6895,
      "likeCount": 169,
      "commentCount": 21,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Zqu0VaJw3vo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Zqu0VaJw3vo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Zqu0VaJw3vo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Zqu0VaJw3vo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Zqu0VaJw3vo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Zqu0VaJw3vo"
    },
    {
      "id": "5rMc-moNVx0",
      "title": "Stateful environments for vertical agents — Josh Purtell, Synth Labs",
      "description": "Hey All - gave a talk on building stateful environments for vertical agents at AI tinkerers and ppl really liked it, happy to do again. Here's the repo - general code that endows environments like Pokemon Red, Minecraft, Swe-Bench, and others with the same interface for development and agent training. github.com/synth-laboratories/Environments\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-22T19:52:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT6M51S",
      "viewCount": 1242,
      "likeCount": 22,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/5rMc-moNVx0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/5rMc-moNVx0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/5rMc-moNVx0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/5rMc-moNVx0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/5rMc-moNVx0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=5rMc-moNVx0"
    },
    {
      "id": "Kcka7rzcxLk",
      "title": "Books reimagined: AI to create new experiences for things you know — Lukasz Gandecki, TheBrain.pro",
      "description": "[last round of Attendee-Led 10min lightning talks] I will showcase how I got tired of waiting for an AI assisted/no spoiler book reading experience and built my own. Check 30s video at https://youtu.be/JjwnYqy668M or go to demo book at https//bookgenius.net Open Sourcing!\n\ncontact: https://x.com/lgandecki\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-22T19:50:46Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT9M44S",
      "viewCount": 1836,
      "likeCount": 46,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Kcka7rzcxLk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Kcka7rzcxLk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Kcka7rzcxLk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Kcka7rzcxLk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Kcka7rzcxLk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Kcka7rzcxLk"
    },
    {
      "id": "TswQeKftnaw",
      "title": "AI powered entomology: Lessons from millions of AI code reviews — Tomas Reimers, Graphite",
      "description": "This talk will explore insights from millions of automated code reviews, revealing trends in bugs, vulnerabilities, and code health that Graphite’s AI code review agent have uncovered. This talk will also provide meta commentary into the types of bugs AI code review agents are great at spotting, and how far the field of AI code review has come in the last year alone.\n\n\n---related links---",
      "publishedAt": "2025-07-22T19:50:08Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT10M21S",
      "viewCount": 2384,
      "likeCount": 42,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/TswQeKftnaw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/TswQeKftnaw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/TswQeKftnaw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/TswQeKftnaw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/TswQeKftnaw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=TswQeKftnaw"
    },
    {
      "id": "6Tpm4m1YxHk",
      "title": "Critical AI Inference your CIO can Trust — Sahil Yadav, Hariharan Ganesan, Telemetrak",
      "description": "Enterprise AI adoption is accelerating, but with it comes a hard question: Do we trust the model’s decisions? In this 18-minute talk, I’ll explore the invisible risks behind automated decision-making in safety-critical and revenue-sensitive environments. Drawing on case studies across manufacturing, telecom, and industrial IoT, I’ll highlight how explainability, traceability, and robust guardrails drive adoption and protect enterprise value.\nAttendees will walk away with:\n• A 3-step framework for operationalizing AI trust\n• Real-world lessons from building guardrails in on-prem and hybrid systems\n• Tools and techniques for debugging and explaining inferences at scale\n• A blueprint for building trust between models, engineers, and executive stakeholders\n\n\n---related links---\n\nhttps://www.linkedin.com/in/yadavsahil/\nhttps://telemetrak.com",
      "publishedAt": "2025-07-22T19:46:37Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M4S",
      "viewCount": 541,
      "likeCount": 18,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/6Tpm4m1YxHk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/6Tpm4m1YxHk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/6Tpm4m1YxHk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/6Tpm4m1YxHk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/6Tpm4m1YxHk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=6Tpm4m1YxHk"
    },
    {
      "id": "coKKKKh8Vns",
      "title": "How to run Evals at Scale: Thinking beyond Accuracy or Similarity — Muktesh Mishra, Adobe",
      "description": "https://www.linkedin.com/in/mukteshkrmishra/",
      "publishedAt": "2025-07-22T19:46:22Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT9M24S",
      "viewCount": 668,
      "likeCount": 8,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/coKKKKh8Vns/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/coKKKKh8Vns/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/coKKKKh8Vns/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/coKKKKh8Vns/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/coKKKKh8Vns/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=coKKKKh8Vns"
    },
    {
      "id": "wt8gzWR6auQ",
      "title": "Continuous Profiling for GPUs — Matthias Loibl, Polar Signals",
      "description": "Continuous Profiling for GPUs extends our industry-leading continuous profiling platform to provide deep, always-on visibility into your GPU workloads.\n\nNow you can see exactly how your GPUs are being utilized millisecond by millisecond. Our solution helps you move from guesswork to data-driven optimization.\n\n\n---related links---\n\nhttps://twitter.com/metalmatze\nhttps://www.linkedin.com/in/metalmatze/\nhttps://matthiasloibl.com/\nhttps://polarsignals.com",
      "publishedAt": "2025-07-22T19:46:14Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT11M31S",
      "viewCount": 248,
      "likeCount": 3,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/wt8gzWR6auQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/wt8gzWR6auQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/wt8gzWR6auQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/wt8gzWR6auQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/wt8gzWR6auQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=wt8gzWR6auQ"
    },
    {
      "id": "ypyvj_56sBU",
      "title": "Top Ten Challenges to Reach AGI — Stephen Chin, Andreas Kollegger",
      "description": "an opener to the GraphRAG track!",
      "publishedAt": "2025-07-22T19:45:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT4M23S",
      "viewCount": 673,
      "likeCount": 10,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ypyvj_56sBU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ypyvj_56sBU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ypyvj_56sBU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ypyvj_56sBU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ypyvj_56sBU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ypyvj_56sBU"
    },
    {
      "id": "XNneh6-eyPg",
      "title": "Practical GraphRAG: Making LLMs smarter with Knowledge Graphs — Michael, Jesus, and Stephen, Neo4j",
      "description": "RAG has become one standard architecture component for GenAI applications to address hallucinations and integrate factual knowledge. While vector search over text is common, knowledge graphs represent a proven advancement by leveraging advanced RAG patterns to access and integrate interconnected factual information, complementing the language skills of LLMs. This talk explores GraphRAG challenges, implementation patterns, and real-world agentic examples with Google's ADK, demonstrating how this approach delivers more trustworthy and explainable GenAI solutions with enhanced reasoning capabilities.\n\nAbout Michael Hunger\nMichael Hunger has been passionate about software development for more than 30 years.\n\nFor the last 15 years, he has been working on the open source Neo4j graph database filling many roles, most recently heading product innovation and GenAI.\n\nAs a developer Michael enjoys many aspects of software development and architecture, learning new things every day, participating in exciting and ambitious open source projects and contributing and writing software related books and articles. Michael spoke at numerous conferences and helped organize others.\n\nMichael helps kids to learn to program by running weekly girls-only coding classes at local schools.\n\nAbout Jesús Barrasa\nDr. Jesús Barrasa is the AI Field CTO at Neo4j, where he works with organisations combining the power of GenAI with Knowledge Graphs. He co-authored \"Building Knowledge Graphs\" (O'Reilly 2023) and is cohost of the monthly Going Meta live webcast (https://goingmeta.live/) since 2022.\nJesús holds a Ph.D. in Artificial Intelligence/Knowledge Representation and is an active thought leader in the KG and AI space.\n\nAbout Stephen Chin\nStephen Chin is VP of Developer Relations at Neo4j, conference chair of the LF AI & Data Foundation, and author of numerous titles including the upcoming GraphRAG: The Definitive Guide for O'Reilly. He has given keynotes and main stage talks at numerous conferences around the world including AI Engineer Summit, AI DevSummit, Devoxx, DevNexus, JNation, JavaOne, Shift, Joker, swampUP, and GIDS. Stephen is an avid motorcyclist who has done evangelism tours in Europe, Japan, and Brazil, interviewing developers in their natural habitat. When he is not traveling, he enjoys teaching kids how to do AI, embedded, and robot programming together with his daughters.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-22T17:59:20Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M46S",
      "viewCount": 11336,
      "likeCount": 270,
      "commentCount": 15,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/XNneh6-eyPg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/XNneh6-eyPg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/XNneh6-eyPg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/XNneh6-eyPg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/XNneh6-eyPg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=XNneh6-eyPg"
    },
    {
      "id": "yYxr6LdXNWM",
      "title": "Knowledge Graphs in Litigation Agents — Tom Smoker, WhyHow",
      "description": "Structured Representations are pretty important in the law, where the relationships between clauses, documents, entities, and multiple parties matter. Structured Representation means Structured Context Injection. Better Context, Less Hallucinations. We walk through a couple of case studies of systems that we’ve built in production for legal use-cases - from recursive contractual clause retrieval, to HITL legal reasoning news agents.\n\nYou'll gain insights into how structured representations significantly improve the effectiveness and reliability of legal agents.\n\n---related links---\n\nhttps://www.linkedin.com/in/thomassmoker\nhttps://www.whyhow.ai/",
      "publishedAt": "2025-07-22T17:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M13S",
      "viewCount": 2964,
      "likeCount": 105,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/yYxr6LdXNWM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/yYxr6LdXNWM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/yYxr6LdXNWM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/yYxr6LdXNWM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/yYxr6LdXNWM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=yYxr6LdXNWM"
    },
    {
      "id": "XlAIgmi_Vow",
      "title": "When Vectors Break Down: Graph-Based RAG for Dense Enterprise Knowledge - Sam Julien, Writer",
      "description": "Enterprise knowledge bases are filled with \"dense mapping,\" thousands of documents where similar terms appear repeatedly, causing traditional vector retrieval to return the wrong version or irrelevant information. When our customers kept hitting this wall with their RAG systems, we knew we needed a fundamentally different approach.\n\nIn this talk, I'll share Writer's journey developing a graph-based RAG architecture that achieved 86.31% accuracy on the RobustQA benchmark while maintaining sub-second response times, significantly outperforming vector approaches.\n\nI'll survey the key techniques behind this performance leap and why graph-based approaches excel with complex enterprise information structures like product documentation, financial documents, and technical specifications that challenge traditional RAG systems. You'll learn about using specialized LLMs to build semantic relationships, how compression techniques efficiently handle concentrated enterprise data patterns, and how infusing key data points in the memory layer of the LLM lowers hallucination.\n\nThe presentation will provide practical insights into identifying when graph-based approaches make sense for your organization's specific data challenges, helping you make informed architectural decisions for your next enterprise RAG system.\n\nAbout Sam Julien\nSam Julien is the Director of Developer Relations at Writer and is passionate about helping engineers improve their effectiveness and advance their careers. He loves spending time outside with his family in the Pacific Northwest. You can find more of Sam's work at samjulien.com.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-22T16:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M47S",
      "viewCount": 20984,
      "likeCount": 434,
      "commentCount": 14,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/XlAIgmi_Vow/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/XlAIgmi_Vow/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/XlAIgmi_Vow/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/XlAIgmi_Vow/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/XlAIgmi_Vow/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=XlAIgmi_Vow"
    },
    {
      "id": "T5IMo5ntyhA",
      "title": "Stop Using RAG as Memory — Daniel Chalef, Zep",
      "description": "RAG is great for static knowledge retrieval—but terrible at memory. Vectorstore-based systems sold as memory lack relational and temporal awareness, leading agents astray with outdated or ambiguous information.\n\nDiscover how temporally-aware knowledge graphs—built by the open-source Graphiti framework—solve these limitations. You’ll learn practical strategies to maintain precise, context-rich memory, enabling agents to reason accurately about historical context and knowledge provenance.\n\nAbout Daniel Chalef   \nI’m Daniel Chalef, an engineer turned startup founder currently building Zep, where we're creating AI's foundational memory layer powered by knowledge graphs. Our vision is a world where AI agents reliably handle personalized tasks, from the mundane to the monumental, always prioritizing privacy and compliance.\n\nPreviously, I've led ML and data science teams, marketing, and corporate development at both early-stage startups and late-stage companies, building data-driven products at scale. My first startup was an open source document management application, KnowledgeTree.\n\nWhen I’m not building Zep (which is seldom 🙂), you’ll likely find me cycling or hiking around the Bay Area with my dog.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-22T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7M2S",
      "viewCount": 1090,
      "likeCount": 48,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/T5IMo5ntyhA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/T5IMo5ntyhA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/T5IMo5ntyhA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/T5IMo5ntyhA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/T5IMo5ntyhA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=T5IMo5ntyhA"
    },
    {
      "id": "-tgQa8Fzf80",
      "title": "HybridRAG: A Fusion of Graph and Vector Retrieval  - Mitesh Patel, NVIDIA",
      "description": "Interpreting complex information from unstructured text data poses significant challenges to Large Language Models (LLM), with difficulties often arising from specialized terminology and the multifaceted relationships between entities in document architectures. Conventional Retrieval Augmented Generation (RAG) methods face limitations in capturing these nuanced interactions, leading to suboptimal performance. In our talk, we introduce a novel approach integrating Knowledge Graph-based RAG (GraphRAG) with VectorRAG, designed to refine question-answering (Q&A) systems for more effective information extraction from complex texts. Our approach employs a dual retrieval strategy that harnesses both knowledge graphs and vector databases, enabling the generation of precise and contextually appropriate answers, thereby setting a new standard for LLMs in processing sophisticated data.\n\nAbout Mitesh Patel\nMitesh Patel is a developer advocate manager at NVIDIA. His team is responsible for creating workflows to showcase how developers can harness GPU acceleration in their workflows using tools and frameworks popular in the developer community. Before NVIDIA, he was a senior research scientist at Fuji Xerox Palo Alto Laboratory Inc. (a research subsidiary of Fuji Xerox), where he worked on developing indoor localization technologies for applications such as asset tracking in hospitals and delivery cart tracking in manufacturing facilities. Mitesh received his Ph.D. in Robotics from the Center of Autonomous Systems (CAS) at the University of Technology Sydney, Australia in 2014.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-22T16:00:02Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M24S",
      "viewCount": 8600,
      "likeCount": 234,
      "commentCount": 15,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/-tgQa8Fzf80/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/-tgQa8Fzf80/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/-tgQa8Fzf80/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/-tgQa8Fzf80/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/-tgQa8Fzf80/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=-tgQa8Fzf80"
    },
    {
      "id": "1C2TdPkj6aQ",
      "title": "tldraw.computer - Steve Ruiz, tldraw",
      "description": "Learn about tldraw's latest experiments with AI on an infinite canvas. In 2024, we created tldraw computer, a loose visual programming environment where arrows and LLMs powered every step of a graph on tldraw's canvas.\n\nAbout Steve Ruiz\nSteve Ruiz is founder and CEO of tldraw, a London-based startup building an infinite canvas component for the web.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-21T19:14:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M45S",
      "viewCount": 57717,
      "likeCount": 2345,
      "commentCount": 95,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1C2TdPkj6aQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1C2TdPkj6aQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1C2TdPkj6aQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1C2TdPkj6aQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1C2TdPkj6aQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1C2TdPkj6aQ"
    },
    {
      "id": "aopgVJBQC0o",
      "title": "Excalidraw: AI and Human Whiteboarding Partnership - Christopher Chedeau",
      "description": "Covid sent everybody home and created the space of virtual whiteboards. At first the experience reused the physical constraints but soon it became better than a physical whiteboard thanks to using virtual native concepts like copy-paste and using keyboard input.\nThe next step in this evolution is to integrate AI into the workflow. We've tried a lot of things with Excalidraw and ended up landing on turning prompt into diagram. Come to the talk to understand how it fits into the workflow and how we implemented it.\n\nAbout Christopher Chedeau   \nCo-creator of React Native and Prettier. Creator of Excalidraw, \"CSS-in-JS\", Yoga and React Conf.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-21T19:12:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M59S",
      "viewCount": 2435,
      "likeCount": 59,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/aopgVJBQC0o/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/aopgVJBQC0o/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/aopgVJBQC0o/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/aopgVJBQC0o/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/aopgVJBQC0o/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=aopgVJBQC0o"
    },
    {
      "id": "BZtD0yYAgCQ",
      "title": "The Bitter Layout or: How I Learned to Love the Model Picker — Maximillian Piras, Yutori",
      "description": "Are conversational interfaces the future or, as many designers have suggested, a lazy solution that is bottlenecking AI-HCI? Despite well-documented usability issues, the design of many AI applications defaults to an input field, turn-by-turn flow, and an endless model picker — I call this “The Bitter Layout”.\n\nIn this talk, we’ll explore how Clay Christensen’s theory of commoditization from the early PC industry can explain why scaling laws require AI interfaces to remain modular until models fully commoditize. The killer feature of conversational interfaces may not be that they’re natural, but that they’re conformable. Learn how to evolve interfaces as inference scales, spot shifts in the basis of competition, and stop worrying about the next model update steamrolling your design decisions.\n\nFoothill G 1&2: Design Engineering\n\nAbout Maximillian Piras\nCurrently the Founding Designer at Yutori working on AI web agents. Previously, Head of Design at Headliner and Sr. Designer at 8tracks. Led cross-platform UIUX design for multiple early-stage consumer startups shipping to millions of users. Contributing writer to Smashing Magazine covering AI-first design. Before that, developed graphics and animations for clients including Giphy, MIT, and Ryuichi Sakamoto.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-21T19:12:09Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M24S",
      "viewCount": 1213,
      "likeCount": 20,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/BZtD0yYAgCQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/BZtD0yYAgCQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/BZtD0yYAgCQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/BZtD0yYAgCQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/BZtD0yYAgCQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=BZtD0yYAgCQ"
    },
    {
      "id": "fmZWvE7yDZo",
      "title": "UX Design Principles for Semi Autonomous Multi Agent Systems — Victor Dibia, Microsoft",
      "description": "Autonomous or semi-autonomous multi-agent systems (MAS) involve exponentially complex configurations (system config, agent configs, task management and delegation, etc.). These present unique interface design challenges for both developer tooling and end-user experiences.\nIn this session, I'll explore UX design principles for multi-agent systems, addressing critical questions: What is the true configuration space for autonomous MAS? How can users arrive at the correct mental model of an MAS's capabilities, if at all? How can we improve trust and safety through techniques like cost-aware action delegation? What makes agent actions observable? How do we enable seamless interruptibility? Attendees will gain actionable insights to create more transparent, trustworthy, and user-centered multi-agent applications, illustrated through real-world implementations in AutoGen Studio - a low code developer tool built on AutoGen (44k stars on GitHub, MIT license) and similar tools.\n\n\n---related links---\n\nhttps://x.com/vykthur\nhttps://www.linkedin.com/in/dibiavictor/\nhttps://newsletter.victordibia.com/\nhttps://victordibia.com/",
      "publishedAt": "2025-07-21T19:11:17Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M28S",
      "viewCount": 3972,
      "likeCount": 97,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/fmZWvE7yDZo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/fmZWvE7yDZo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/fmZWvE7yDZo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/fmZWvE7yDZo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/fmZWvE7yDZo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=fmZWvE7yDZo"
    },
    {
      "id": "AvVoJBxgSQk",
      "title": "Agentic GraphRAG: AI’s Logical Edge — Stephen Chin, Neo4j",
      "description": "AI models are getting tasked to do increasingly complex and industry specific tasks where different retrieval approaches provide distinct advantages in accuracy, explainability, and cost to execute. GraphRAG retrieval models have become a powerful tool to solve domain specific problems where answers require logical reasoning and correlation that can be aided by graph relationships and proximity algorithms. We will demonstrate how an agent architecture combining RAG and GraphRAG retrieval patterns can bridge the gap in data analysis, strategic planning, and retrieval to solve complex domain specific problems. \n\n\n---related links---\n\nhttps://twitter.com/steveonjava\nhttps://www.linkedin.com/in/steveonjava/\nhttp://steveonjava.com/\nhttps://neo4j.com/",
      "publishedAt": "2025-07-21T17:15:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M27S",
      "viewCount": 19579,
      "likeCount": 399,
      "commentCount": 24,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/AvVoJBxgSQk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/AvVoJBxgSQk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/AvVoJBxgSQk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/AvVoJBxgSQk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/AvVoJBxgSQk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=AvVoJBxgSQk"
    },
    {
      "id": "D4Dswf-__RM",
      "title": "CIAM for AI: Authn/Authz for Agents — Michael Grinich, CEO of WorkOS",
      "description": "AI agents are changing the way modern SaaS products operate. Whether automating workflows, integrating with APIs, or acting on behalf of users, AI-driven assistants and autonomous systems are becoming core product features. But securing these agents presents a fundamental challenge: How do you authenticate AI agents? How do you control what they can access? How do you ensure they act within the right permissions? This talk will explore these concepts and more while highlighting current research and best practices.\n\n\n---related links---\n\nhttps://x.com/grinich/\nhttps://www.linkedin.com/in/grinich/\nhttps://workos.com/guides\nhttps://workos.com/",
      "publishedAt": "2025-07-21T17:00:14Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M13S",
      "viewCount": 1371,
      "likeCount": 38,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/D4Dswf-__RM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/D4Dswf-__RM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/D4Dswf-__RM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/D4Dswf-__RM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/D4Dswf-__RM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=D4Dswf-__RM"
    },
    {
      "id": "7e7eVtcygCM",
      "title": "Good design hasn’t changed with AI — John Pham, SF Compute",
      "description": "Bad designs are still bad. AI doesn’t make it good. The novelty of AI makes the bad things tolerable, for a short time. Building great designs and experiences with AI have the same first principles pre-AI. When people use software, they want it to feel responsive, safe, accessible and delightful. We’ll go over the big and small details that goes into software that people want to use, not forced to use.\n\nAbout John Pham   \nI'm John Pham, an engineer and a self-taught designer. I seek the dopamine hits of building delightful experiences for others. I've worked at Vercel, Microsoft and NASA doing just that.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-21T16:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M25S",
      "viewCount": 3195,
      "likeCount": 107,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/7e7eVtcygCM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/7e7eVtcygCM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/7e7eVtcygCM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/7e7eVtcygCM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/7e7eVtcygCM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=7e7eVtcygCM"
    },
    {
      "id": "-OXiljTJxQU",
      "title": "Building Effective Voice Agents — Toki Sherbakov + Anoop Kotha, OpenAI",
      "description": "How to build production voice applications and learnings from working with customers along the way!\n\nhttps://x.com/tokisherbakov\nhttps://www.linkedin.com/in/akotha7/",
      "publishedAt": "2025-07-20T16:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M17S",
      "viewCount": 6180,
      "likeCount": 197,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/-OXiljTJxQU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/-OXiljTJxQU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/-OXiljTJxQU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/-OXiljTJxQU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/-OXiljTJxQU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=-OXiljTJxQU"
    },
    {
      "id": "y-UGrYbJsJk",
      "title": "What every AI engineer needs to know about GPUs — Charles Frye, Modal",
      "description": "Every programmer needs to know a few things about hardware, like processors, memory, and disks. Due to AI systems' extreme demand for mathematical processing power, AI engineers need to know a few things about GPUs -- the world's most popular high-throughput mathematical co-processor.\n\nIn this talk, I will explain the fundamental engineering constraints and design decisions that shape GPUs and trace those up to some counter-intuitive facts about the performance characteristics of AI systems, with actionable insights for their deployers and consumers.\n\n\n---related links---",
      "publishedAt": "2025-07-20T07:00:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M52S",
      "viewCount": 18315,
      "likeCount": 495,
      "commentCount": 15,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/y-UGrYbJsJk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/y-UGrYbJsJk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/y-UGrYbJsJk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/y-UGrYbJsJk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/y-UGrYbJsJk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=y-UGrYbJsJk"
    },
    {
      "id": "8-fWbQAoqPI",
      "title": "Brian Balfour: How Granola Beat Giants Like Zoom & Otter in the AI Note-Taking War",
      "description": "",
      "publishedAt": "2025-07-20T07:00:07Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT51S",
      "viewCount": 2898,
      "likeCount": 35,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/8-fWbQAoqPI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/8-fWbQAoqPI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/8-fWbQAoqPI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/8-fWbQAoqPI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/8-fWbQAoqPI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=8-fWbQAoqPI"
    },
    {
      "id": "MBWGiWJDlSo",
      "title": "Robots as professional Chefs - Nikhil Abraham, CloudChef",
      "description": "How we converted a bimanual robot into a professional chef that works in novel kitchens and learn new recipes from a single demonstration\n\nAbout Nikhil Abraham\nNikhil is the CEO of CloudChef - reimagining cooking using embodied AI. CloudChef builds robots that enable commercial kitchens to cook high quality meals while solving for availability of skilled chefs. Our robots are already doing full-time work in several leading commercial kitchens. Nikhil is an alum of IIT Bombay and was the cofounder of Rephrase AI (acquired by Adobe)\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-20T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M58S",
      "viewCount": 1445,
      "likeCount": 24,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/MBWGiWJDlSo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/MBWGiWJDlSo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/MBWGiWJDlSo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/MBWGiWJDlSo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/MBWGiWJDlSo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=MBWGiWJDlSo"
    },
    {
      "id": "OkEGJ5G3foU",
      "title": "[Full Workshop] Reinforcement Learning, Kernels, Reasoning, Quantization & Agents — Daniel Han",
      "description": "Why is Reinforcement Learning (RL) suddenly everywhere, and is it truly effective? Have LLMs hit a plateau in terms of intelligence and capabilities, or is RL the breakthrough they need?\n\nIn this workshop, we'll dive into the fundamentals of RL, what makes a good reward function, and how RL can help create agents.\n\nWe'll also talk about kernels, are they still worth your time and what you should focus on. And finally, we’ll explore how LLMs like DeepSeek-R1 can be quantized down to 1.58-bits and still perform well, along with techniques to maintain accuracy.\n\nAbout Daniel Han\nI'm building Unsloth and we're an open-source startup trying to make AI more accessible and accurate for everyone! We have 40K GitHub stars, 10M monthly downloads on Hugging Face and worked with Google, Meta, Hugging Face teams to fix bugs in open-source models like Llama, Phi & Gemma models. I was previously working at NVIDIA making TSNE 2000x faster.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps\n\n00:00 Introduction and Unsloth's Contributions\n03:25 The Evolution of Large Language Models (LLMs)\n09:47 LLM Training Stages and Yann LeCun's Cake Analogy\n16:56 Agents and Reinforcement Learning Principles\n23:17 PPO and the Introduction of GRPO\n48:12 Reward Model vs. Reward Function\n51:22 The Math Behind the Reinforce Algorithm\n01:08:50 PPO Formula Breakdown\n01:16:29 GRPO Deep Dive\n02:00:20 Practical Implementation and Demo with Unsloth\n02:33:07 Quantization and the Future of GPUs\n02:41:59 Conclusion and Call to Action",
      "publishedAt": "2025-07-19T21:23:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT2H42M28S",
      "viewCount": 72556,
      "likeCount": 2724,
      "commentCount": 116,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/OkEGJ5G3foU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/OkEGJ5G3foU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/OkEGJ5G3foU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/OkEGJ5G3foU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/OkEGJ5G3foU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=OkEGJ5G3foU"
    },
    {
      "id": "jQcsVk0KWiQ",
      "title": "A Taxonomy for Next-gen Reasoning — Nathan Lambert, Allen Institute (AI2) & Interconnects.ai",
      "description": "Current AI models are extremely skilled, which was seen as the step change in evaluation scores across the industry in the first half of 2025, but often fail when presented with even medium time-horizon tasks. This talk presents a taxonomy of 4 traits of reasoning models -- skills, calibration, strategy, and abstraction -- that will be crucial to creating the next generation of AI applications. With this, we focus on the latter two, strategy and abstraction, and discuss how these traits will enable long-horizon and reliable agents. The talk concludes with a scenario where these agentic behaviors are the foundation for RL continuing to scale in the coming years and post-training techniques reaching compute parity with pretraining methors sooner than later.\n\nAbout Nathan Lambert\nNathan Lambert is a Senior Research Scientist and post-training lead at the Allen Institute for AI focusing on building open language models. At the same time he founded and operates Interconnects.ai to increase transparency and understanding of current AI models and systems.\n\nPreviously, he helped build an RLHF research team at HuggingFace. He received his PhD from the University of California, Berkeley working at the intersection of machine learning and robotics. He was advised by Professor Kristofer Pister in the Berkeley Autonomous Microsystems Lab and Roberto Calandra at Meta AI Research. He was lucky to intern at Facebook AI and DeepMind during his Ph.D. Nathan was was awarded the UC Berkeley EECS Demetri Angelakos Memorial Achievement Award for Altruism for his efforts to better community norms.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n[00:00] The Current State of Reasoning in AI Models\n\n[01:06] Unlocking New Language Model Applications\n\n[03:48] The Need for Advanced Planning in AI\n\n[04:29] A Proposed Taxonomy for Next-Generation Reasoning\n\n[06:16] Reinforcement Learning with Verifiable Rewards\n\n[08:23] Current Challenges and Future Directions\n\n[12:07] The Effort Required to Build New Capabilities\n\n[16:20] A Research Plan for Training Reasoning Models\n\n[17:36] The Shift in Compute Allocation from Pre-training to Post-training",
      "publishedAt": "2025-07-19T21:15:55Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M21S",
      "viewCount": 13564,
      "likeCount": 241,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/jQcsVk0KWiQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/jQcsVk0KWiQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/jQcsVk0KWiQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/jQcsVk0KWiQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/jQcsVk0KWiQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=jQcsVk0KWiQ"
    },
    {
      "id": "gEDl9C8s_-4",
      "title": "How to Train Your Agent: Building Reliable Agents with RL — Kyle Corbitt, OpenPipe",
      "description": "Have you ever launched an awesome agentic demo, only to realize no amount of prompting will make it reliable enough to deploy in production? Agent reliability is a famously difficult problem to solve!\n\nIn this talk we’ll learn how to use GRPO to help your agent learn from its successes and failures and improve over time. We’ve seen dramatic results with this technique, such as an email assistant agent that whose success rate jumped from 74% to 94% after replacing o4-mini with an open source model optimized using GRPO.\n\nWe’ll share case studies as well as practical lessons learned around the types of problems this works well for and the unexpected pitfalls to avoid.\n\nAbout Kyle Corbitt\nKyle Corbitt is the co-founder and CEO of OpenPipe, the RL post-training company. OpenPipe has trained thousands of customer models for both enterprises and tech-forward startups.\n\nBefore founding OpenPipe, Kyle led the Startup School team at Y Combinator, which was responsible for the product and content that YC produces for early-stage companies. Prior to that he worked as an engineer at Google and studied ML at school.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n[00:00] - Introduction to building reliable agents with RL.\n\n[00:49] - Case Study: ART-E, an AI email assistant.\n\n[02:19] - The importance of starting with prompted models before moving to RL.\n\n[03:17] - Performance improvements of RL over prompted models.\n\n[05:18] - Cost and latency benefits of the RL approach.\n\n[08:02] - The two hardest problems in modern RL: realistic environments and reward functions.\n\n[13:13] - Optimizing agent behavior with \"extra rewards.\"\n\n[15:25] - The problem of \"reward hacking\" and how to address it.\n\n[18:37] - The solution to reward hacking:",
      "publishedAt": "2025-07-19T21:12:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M48S",
      "viewCount": 39404,
      "likeCount": 997,
      "commentCount": 21,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/gEDl9C8s_-4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/gEDl9C8s_-4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/gEDl9C8s_-4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/gEDl9C8s_-4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/gEDl9C8s_-4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=gEDl9C8s_-4"
    },
    {
      "id": "liG97YXaTSA",
      "title": "OpenThoughts: Data Recipes for Reasoning Models — Ryan Marten, Bespoke Labs",
      "description": "Peel back the curtain on state of the art model post-training through the story of OpenThinker, a SOTA small reasoning model (outperforming DeepSeek distill), built in the open. Learn about the dataset recipe used to build the strongest reasoning models which you can apply to your own domain-specific specialized reasoning models. Hear about the strategies that scale (and that don't) based on our rigorous experimentation on the journey from thousands of data points (Bespoke-Stratos) to millions of data (OpenThinker3). Build upon our open source engineering solutions for large-scale synthetic data generation, training on multiple supercomputing clusters, and building out fast reliable evaluations.\n\nAbout Ryan Marten\nRyan Marten is co-lead of OpenThinker collaboration and a founding engineer at Bespoke Labs, working on data curation and model post-training. Previously, Ryan has been an AI researcher at the University of Illinois Urbana-Champaign, University of Toronto, University of Oxford, AI2, and Vector Institute. When he's not at the lab, he's probably out surfing.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n0:00 - Introduction to the problem of open-source reasoning in AI models.\n\n1:09 - The effectiveness of Supervised Fine-Tuning (SFT) for reasoning.\n\n3:38 - Introduction to OpenThoughts 3 and its performance.\n\n7:52 - Key learnings from the data recipe development.\n\n11:34 - Guidance on adapting the dataset recipe to specific domains.\n\n15:15 - Call for open collaboration and where to find the project's resources",
      "publishedAt": "2025-07-19T21:10:30Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M59S",
      "viewCount": 2923,
      "likeCount": 88,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/liG97YXaTSA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/liG97YXaTSA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/liG97YXaTSA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/liG97YXaTSA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/liG97YXaTSA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=liG97YXaTSA"
    },
    {
      "id": "C13jiFWNuo8",
      "title": "Google Photos Magic Editor: GenAI Under the Hood of a Billion-User App - Kelvin Ma, Google Photos",
      "description": "Go behind the scenes of Google Photos' Magic Editor. Explore the engineering feats required to integrate complex CV and cutting-edge generative AI models into a seamless mobile experience. We'll discuss optimizing massive models for latency/size, the crucial interplay with graphics rendering (OpenGL/Halide), and the practicalities of turning research concepts into polished features people actually use.\n\nAbout Kelvin Ma\nI'm Kelvin Ma. A product engineer with 15 years of experience working across innovative consumer applications that is used by millions of consumers. I'm passionate about using technology to build tools that improves users lives by allowing greater expression, building skills, and fostering communication.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-19T19:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M28S",
      "viewCount": 1839,
      "likeCount": 53,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/C13jiFWNuo8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/C13jiFWNuo8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/C13jiFWNuo8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/C13jiFWNuo8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/C13jiFWNuo8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=C13jiFWNuo8"
    },
    {
      "id": "EY4O9M6AsWI",
      "title": "Dream Machine: Scaling to 1m users in 4 days — Keegan McCallum, Luma AI",
      "description": "Talking about Luma AI, our mission, and how our ML infrastructure enables SOTA multimodal model development\n\nAbout Keegan McCallum \nI'm Keegan McCallum, the Head of ML infrastructure at Luma AI. I began my career in research focusing on portfolio optimization. Since then I've founded two startups, lead engineering at two others and have landed at Luma AI working on an unconventional multimodal path to AGI among a cracked team of researchers and engineers. When I'm not working, I'm usually out in the woods hiking with my family, or exploring the culinary delights in whatever city I happen to be in. I'm excited to share the insights and war stories I've gathered launching one of the most successful AI products to date in a (hopefully) fun and engaging way\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps\nThe initial launch challenges [00:00]: Luma AI was unprepared for the high traffic, quickly exhausting their initial GPU allocation and facing a large queue of requests.\n\nRapid scaling efforts [00:57]: They rapidly scaled their GPU capacity from 500 to 5,000 H100 GPUs within six hours, and later added another 4,000 H100 GPUs from their training cluster to keep up with demand.\n\nLuma AI's mission [03:10]: Beyond just video models, Luma AI aims to build general multimodal intelligence that can generate, understand, and operate in the physical world.\n\nTheir product capabilities [03:22]: They demonstrate a \"modify video\" feature where users can upload iPhone videos and transform them with text prompts. They also highlight their public API for integrating this functionality into applications [03:52].\n\nInfrastructure re-architecture [06:02]: They moved from a brittle, tightly coupled container setup using Triton inference server to a custom-built serving stack on vanilla PyTorch, which offers better support for multiple GPUs, nodes, and different chipsets.\n\nChallenges and solutions in scaling [07:39]:\n\nBack pressure [07:51]: They implemented a dispatch limitation system to prevent too many CPU workers from queuing jobs in one cluster.\n\nFair scheduling and work starvation [08:36]: To address issues with different user tiers (API, enterprise, unlimited, light, free) and prevent lower-priority jobs from being starved, they developed an SLO (Service Level Objective) based system that prioritizes jobs based on the percentage of their worst-case waiting time [11:14].\n\nHandling different models and bursts [08:43]: They built a system to automatically scale up compute on their training cluster to handle demand bursts [09:16].\n\nModel management [13:24]: They use a model repository system where each model has immutable versions stored in object storage, including the full Python environment and checkpoints. This allows for reproducible rollbacks and seamless, on-the-fly version switching for workers [14:46].\n\nHiring [15:13]: Luma AI is actively hiring engineers, researchers, and AI enthusiasts",
      "publishedAt": "2025-07-19T17:45:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M3S",
      "viewCount": 1406,
      "likeCount": 54,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/EY4O9M6AsWI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/EY4O9M6AsWI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/EY4O9M6AsWI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/EY4O9M6AsWI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/EY4O9M6AsWI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=EY4O9M6AsWI"
    },
    {
      "id": "_FKeSzM9fPc",
      "title": "ComfyUI Full Workshop — first workshop from ComfyAnonymous himself!",
      "description": "Quick introduction to ComfyUI and what's new followed by a QA session.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-19T16:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT51M25S",
      "viewCount": 2883,
      "likeCount": 79,
      "commentCount": 13,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/_FKeSzM9fPc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/_FKeSzM9fPc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/_FKeSzM9fPc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/_FKeSzM9fPc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/_FKeSzM9fPc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=_FKeSzM9fPc"
    },
    {
      "id": "huQPkrwVWwc",
      "title": "Design like Karpathy is watching — Zeke Sikelianos, Replicate",
      "description": "Legendary AI engineer and educator Andrej Karpathy recently blogged about his experiences building, deploying, and monetizing a vibe-coded web app called MenuGen. Let's dig into the challenges he faced and learn what we as AI designers can do to make life better for the Andrejs of the world.\n\nAbout Zeke Sikelianos\nZeke's been building developer tools at companies like Heroku, npm, GitHub, and Replicate for over ten years. He cares deeply about simple and tasteful developer experiences, and thinks the world of generative AI deserves small, sharp, and composable tools!\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-19T16:15:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M26S",
      "viewCount": 5892,
      "likeCount": 155,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/huQPkrwVWwc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/huQPkrwVWwc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/huQPkrwVWwc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/huQPkrwVWwc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/huQPkrwVWwc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=huQPkrwVWwc"
    },
    {
      "id": "0F8mnGPUycY",
      "title": "On Curiosity — Sharif Shameem, Lexica",
      "description": "Creating and sharing demos is the easiest way to influence the future. It gets people to think about what's possible. A good tech demo doesn't have to be fully fleshed out. It doesn't even have to be fully functional. The purpose of a demo is to inspire. A good demo makes you feel like someone jumped into the future and pulled back an idea to the present.\n\nAbout Sharif Shameem\nI'm the founder of Lexica – we're building creative tools backed by state-of-the-art generative models (P.S. we're hiring). I previously worked on a low-code tool powered by language models called Debuild.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-19T16:00:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M35S",
      "viewCount": 1374,
      "likeCount": 42,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/0F8mnGPUycY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/0F8mnGPUycY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/0F8mnGPUycY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/0F8mnGPUycY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/0F8mnGPUycY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=0F8mnGPUycY"
    },
    {
      "id": "RkVILz06y08",
      "title": "Real world MCPs in GitHub Copilot Agent Mode — Jon Peck, Microsoft",
      "description": "As developers, we don't spend most of our time vibe-coding prototypes. More often, we're adding features, squashing bugs, and building tests for existing apps across a wide variety of services and technologies. Come learn how MCPs help GitHub Copilot to untangle real engineering problems. By allowing agent mode to securely work with data sources, testing tools, infrastructure providers, and even core DevOps tooling -- we can go beyond the hype, and solve the actual engineering problems we face every day.\n\n\n---related links---\n\nhttp://twitter.com/peckjon\nhttp://linkedin.com/in/peckjon\nhttps://github.com/peckjon",
      "publishedAt": "2025-07-19T07:00:21Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M27S",
      "viewCount": 4345,
      "likeCount": 88,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/RkVILz06y08/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/RkVILz06y08/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/RkVILz06y08/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/RkVILz06y08/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/RkVILz06y08/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=RkVILz06y08"
    },
    {
      "id": "xcsVkDelNis",
      "title": "Brian Balfour: The #1 Question Every AI Product Manager Must Answer",
      "description": "",
      "publishedAt": "2025-07-18T19:00:54Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT56S",
      "viewCount": 1792,
      "likeCount": 18,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/xcsVkDelNis/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/xcsVkDelNis/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/xcsVkDelNis/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/xcsVkDelNis/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/xcsVkDelNis/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=xcsVkDelNis"
    },
    {
      "id": "blW-lSd5CYQ",
      "title": "The rise of the agentic economy on the shoulders of MCP — Jan Curn, Apify",
      "description": "Thanks to MCP and all the MCP server directories, agents can now autonomously discover new tools and other agents. This lays down the foundation for the future agentic economy, where businesses will sell to autonomous agents (B2A) and eventually agents will sell to other agents (A2A).\n\nBut one key part is still missing: agents do not have a standard way to subscribe to external services and pay for them.\n\nIn this talk, we’ll show how to give agents full autonomy to discover and pay for new external MCP-enabled services, even if those services don’t support it, using a little-known MCP server nesting capability. We’ll also cover how to monetize AI agents and the B2A/A2A business models.\n\n\n\n---related links---\n\nhttps://x.com/jancurn\nhttps://www.linkedin.com/in/jancurn/\nhttps://blog.apify.com/author/jancurn/\nhttps://apify.com/\n\nTimestamps\n[00:00] Emergence of Intelligence\n\n[02:42] Apify and the Agentic Economy\n\n[07:30] Challenges and Solutions for Agent Autonomy\n\n[11:50] Demo of Apify's MCP Integration\n\n[15:52] Monetization and Future Outlook",
      "publishedAt": "2025-07-18T18:59:57Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M8S",
      "viewCount": 5858,
      "likeCount": 128,
      "commentCount": 9,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/blW-lSd5CYQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/blW-lSd5CYQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/blW-lSd5CYQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/blW-lSd5CYQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/blW-lSd5CYQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=blW-lSd5CYQ"
    },
    {
      "id": "bmWZk9vTze0",
      "title": "MCP is all you need — Samuel Colvin, Pydantic",
      "description": "Everyone is talking about agents, and right after that, they’re talking about agent-to-agent communications. Not surprisingly, various nascent, competing protocols are popping up to handle it.\n\nBut maybe all we need is MCP — the OG of GenAI communication protocols (it's from way back in 2024!).\n\nLast year, Jason Liu gave the second most watched AIE talk — “Pydantic is all you need”.\n\nThis year, I (the creator of Pydantic) am continuing the tradition by arguing that MCP might be all we need for agent-to-agent communications.\n\nWhat I’ll cover:\n\n- Misusing Common Patterns: MCP was designed for desktop/IDE applications like Claude Code and Cursor. How can we adapt MCP for autonomous agents?\n- Many Common Problems: MCP is great, but what can go wrong? How can you work around it? Can the protocol be extended to solve these issues?\n- Monitoring Complex Phenomena: How does observability work (and not work) with MCP?\n- Multiple Competing Protocols: A quick run-through of other agent communication protocols like A2A and AGNTCY, and probably a few more by June 😴\n- Massive Crustaceans Party: What might success look like if everything goes to plan?\n\n\n---related links---\n\nhttps://x.com/samuel_colvin\nhttps://www.linkedin.com/in/samuel-colvin/\nhttps://github.com/samuelcolvin\nhttps://pydantic.dev/\n\n\nTimestamps\n00:00:00 - Introduction: Speaker Samuel Colvin introduces himself as the creator of Pydantic.\n\n00:00:42 - Pydantic Ecosystem: Introduction to Pydantic the company, the Pydantic AI agent framework, and the Logfire observability platform.\n\n00:01:18 - Talk Thesis: Explaining the title \"MCP is all you need\" and the main argument that MCP simplifies agent communication.\n\n00:02:05 - MCP's Focus: Clarifying that the talk focuses on MCP for autonomous agents and custom code, not its original desktop automation use case.\n\n00:02:48 - Tool Calling Primitive: Highlighting that \"tool calling\" is the most relevant MCP primitive for this context.\n\n00:03:10 - MCP vs. OpenAPI: Listing the advantages MCP has over a simple OpenAPI specification for tool calls.\n\n00:03:21 - Feature 1: Dynamic Tools: Tools can appear and disappear based on server state.\n\n00:03:26 - Feature 2: Streaming Logs: The ability to return log data to the user while a tool is still executing.\n\n00:03:33 - Feature 3: Sampling: A mechanism for a tool (server) to request an LLM call back through the agent (client).\n\n00:04:01 - MCP Architecture Diagram: Visualizing the basic agent-to-tool communication flow.\n\n00:04:43 - Complex Architecture: Discussing scenarios where tools are themselves agents that need LLM access.\n\n00:05:24 - Explaining Sampling: Detailing how sampling solves the problem of every agent needing its own LLM by allowing tools to \"piggyback\" on the client's LLM access.\n\n00:06:42 - Pydantic AI's Role in Sampling: How the Pydantic AI library supports sampling on both the client and server side.\n\n00:07:10 - Demo Start: Beginning the demonstration of a research agent that uses an MCP tool to query BigQuery.\n\n00:08:23 - Code Walkthrough: Validation: Showing how Pydantic is used for output validation and automatic retries (model_retry).\n\n00:09:00 - Code Walkthrough: Context Logging: Demonstrating the use of mcp_context.log to send progress updates back to the client.\n\n00:10:51 - MCP Server Setup: Showing the code for setting up an MCP server using fast_mcp.\n\n00:11:54 - Design Pattern: Inference Inside the Tool: Explaining the benefit of having the tool perform its own LLM inference to reduce the context burden on the main agent.\n\n00:12:27 - Main Application Code: Reviewing the client-side code that defines the agent and registers the MCP tool.\n\n00:13:16 - Observability with Logfire: Switching to the Logfire UI to trace the execution of the agent's query.\n\n00:14:09 - Observing Sampling in Action: Pointing out the specific span in the trace that shows the tool making an LLM call back through the client via sampling.\n\n00:14:48 - Inspecting the SQL Query: Showing how the observability tool can be used to see the exact SQL query that was generated by the internal agent.\n\n00:15:15 - Conclusion: Final summary of the talk's points.",
      "publishedAt": "2025-07-18T18:52:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M24S",
      "viewCount": 57757,
      "likeCount": 1008,
      "commentCount": 33,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/bmWZk9vTze0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/bmWZk9vTze0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/bmWZk9vTze0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/bmWZk9vTze0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/bmWZk9vTze0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=bmWZk9vTze0"
    },
    {
      "id": "ExeD-8gFUMM",
      "title": "Full Spec MCP: Hidden Capabilities of the MCP spec — Harald Kirschner, Microsoft/VSCode",
      "description": "The true power of Model Context Protocol emerges when clients and servers collaborate across the full spectrum of the specification. This talk presents practical examples of how VS Code's comprehensive implementation of MCP transforms the capabilities of AI assistants, making them more contextual, efficient, and user-friendly. We'll showcase advanced features like dynamic tool discovery and workspace-aware roots, demonstrating how they create experiences impossible with standard tools integrations while confronting the reality gap between MCP's theoretical potential and practical implementation challenges.\n\nTimestamps\n\n[00:00] Introduction to MCP and its Current State\n\n[01:42] The \"MCP is just another API wrapper\" Syndrome\n\n[02:51] VS Code's Full Spec Support\n\n[03:40] Challenges with Tools and Solutions\n\n[06:35] Resources and Their Importance\n\n[07:41] Sampling\n\n[09:21] Developer Experience Improvements\n\n[10:28] Staying Updated with the Spec\n\n[10:53] Key Upcoming Features and Community Efforts\n\n[12:46] Call to Action",
      "publishedAt": "2025-07-18T18:42:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M53S",
      "viewCount": 3655,
      "likeCount": 52,
      "commentCount": 11,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ExeD-8gFUMM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ExeD-8gFUMM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ExeD-8gFUMM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ExeD-8gFUMM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ExeD-8gFUMM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ExeD-8gFUMM"
    },
    {
      "id": "HOYLZ7IVgJo",
      "title": "Shipping an Enterprise Voice AI Agent in 100 Days - Peter Bar, Intercom Fin",
      "description": "What does it take to go from blank page to live enterprise voice agent in 100 days?\n\nThat’s the challenge we took on with Fin Voice at Intercom. Enterprise customer service demands high-quality, reliable voice interactions - but delivering that fast means wrestling with tough problems like latency, hallucinations, voice quality, and answer accuracy.\n\nWe rapidly evaluated and integrated a full voice stack - including transcription, language model, text-to-speech, retrieval-augmented generation, and telephony - while designing tools that fit seamlessly into existing human support workflows.\n\nIn this session, I’ll share key lessons from our accelerated development of Fin Voice. We'll explore the technical and operational hurdles we faced, the trade-offs we made, and how we built deployment and handover tools that work for customer service teams. You'll leave with insights into building AI-driven voice products that are both powerful and practical.\n\nAbout Peter Bar\nI’m Peter Bar, a Product Lead with over 10 years of experience in the tech industry. At Intercom, I’m responsible for Voice AI initiatives and led the development and launch of Fin Voice, our AI voice agent. My background spans both B2B and consumer tech, blending technical depth with strategic product leadership. Before Intercom, I drove growth and customer experience efforts at Deliveroo (food delivery) and worked on music discovery products at Shazam. I hold a Master’s degree in Computer Science from Imperial College London.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-18T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M10S",
      "viewCount": 2291,
      "likeCount": 66,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/HOYLZ7IVgJo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/HOYLZ7IVgJo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/HOYLZ7IVgJo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/HOYLZ7IVgJo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/HOYLZ7IVgJo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=HOYLZ7IVgJo"
    },
    {
      "id": "EzwROCrSUFM",
      "title": "Brian Balfour of Reforge: Survive the AI Knife Fight: How to Build Winning AI Products",
      "description": "",
      "publishedAt": "2025-07-18T01:45:02Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT58S",
      "viewCount": 3799,
      "likeCount": 50,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/EzwROCrSUFM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/EzwROCrSUFM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/EzwROCrSUFM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/EzwROCrSUFM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/EzwROCrSUFM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=EzwROCrSUFM"
    },
    {
      "id": "P370D8Kmlkw",
      "title": "The State of Generative Media - Gorkem Yurtseven, FAL",
      "description": "Generative AI is reshaping the creative landscape, enabling the production of images, audio, and video with unprecedented speed and sophistication. This session offers an in-depth exploration of the current state of generative media, highlighting cutting-edge models, platforms, and tools that are transforming the industry.\n\nAbout Gorkem Yurtseven\nGorkem Yurtseven is the co-founder and CTO of fal, a generative media platform empowering developers to build with cutting-edge AI models. Previously, he was a Senior Software Engineer at AWS and holds a degree in Computer Engineering from the University of Pennsylvania.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\n\nTimestamps\n[00:00:00] Introduction to Generative Media\n\n[00:03:49] Evolution of Generative Image Models\n\n[00:05:11] Impact on Industries\n\n[00:10:50] The Rise of Generative Video\n\n[00:14:23] Future of Generative Media\n\n[00:16:33] Conclusion and Call to Action",
      "publishedAt": "2025-07-16T20:19:33Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M14S",
      "viewCount": 1341,
      "likeCount": 32,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/P370D8Kmlkw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/P370D8Kmlkw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/P370D8Kmlkw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/P370D8Kmlkw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/P370D8Kmlkw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=P370D8Kmlkw"
    },
    {
      "id": "LxQsQ3vZDqo",
      "title": "Teaching Gemini to Speak YouTube: Adapting LLMs for Video Recommendations to 2B+DAU - Devansh Tandon",
      "description": "YouTube recommendations drive the majority of video watch time for billions of daily users. Traditionally powered by large embedding models (LEMs), we're undertaking a fundamental shift: rebuilding our recommendation stack using foundation models like Gemini. This talk dives into our engineering journey adapting general-purpose LLMs (Gemini) for the highly specialized, dynamic, and massive-scale task of YouTube recommendations.\n\nWe'll discuss:\n\nSemanticID: creating a \"language\" for YouTube videos, from our paper last year – Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations\nAdapting Gemini checkpoints to understand SemanticID\nGenerative Video Retrieval with prompts\nThere’s a lot of attention on the LLM-led transformation of Search (with AI Overviews, Perplexity, ChatGPT-Search etc). However, across large consumer apps, it’s the recommendation systems & feeds that drive most consumer engagement, not just search. This talk is about the LLM-led transformation of recommendations & feeds – building a recommendation engine on top of Gemini.\n\nAbout Devansh Tandon\nDevansh Tandon is a Product Manager at Google, leading YouTube’s discovery system and GenAI efforts. At YouTube, Devansh leads a team of research scientists and ML engineers to develop the recommendation engine, which powers the majority of YouTube watchtime for billions of daily active users.\n\nHe led Google DeepMind & YouTube partnerships, and has launched GenAI products including video summaries & AI dubbing for YouTube. At DeepMind, Devansh led the development of a new generative recommendation system – adapting Gemini to power YouTube recommendations – from research to scaled consumer launch.\n\nPreviously, Devansh has led AI teams in Google Search, Google News and Google Ads. He graduated Magna Cum Laude from Yale University, with a BS in Computer Science and Economics.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-16T18:01:50Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT22M51S",
      "viewCount": 9141,
      "likeCount": 243,
      "commentCount": 16,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/LxQsQ3vZDqo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/LxQsQ3vZDqo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/LxQsQ3vZDqo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/LxQsQ3vZDqo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/LxQsQ3vZDqo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=LxQsQ3vZDqo"
    },
    {
      "id": "PjaVHm_3Ljg",
      "title": "Transforming search and discovery using LLMs — Tejaswi & Vinesh, Instacart",
      "description": "Learn how Instacart uses cutting-edge LLMs to redefine search and product discovery. \n- Explore innovative solutions overcoming traditional search engine limitations for grocery shopping.\n- Discover how LLMs enhance user intent understanding and generate engaging content.\n- See practical applications of LLM technology to improve search relevance and user experience.\n\nAbout Tejaswi Tenneti\nTejaswi Tenneti is currently a Director of Machine Learning at Instacart, the north american leader in online grocery. Prior to Instacart, Tejaswi was a tech lead in machine learning teams at Apple and Oracle where he worked on various applications related to Search and Recommendations for local maps data and Enterprise. Tejaswi holds a BS from IIIT, Allahabad and an MS from Stanford University specializing in AI\n\nAbout Vinesh Gudla\nVinesh is a Staff Machine Learning Engineer at Instacart on the search and discovery team. He has previously worked on balancing multiple objectives in search in a marketplace and has authored numerous well-received blogposts and articles about his work. He is currently working on bringing Generative AI to production at ecommerce scale at Instacart.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-16T18:01:03Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M10S",
      "viewCount": 2806,
      "likeCount": 41,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/PjaVHm_3Ljg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/PjaVHm_3Ljg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/PjaVHm_3Ljg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/PjaVHm_3Ljg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/PjaVHm_3Ljg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=PjaVHm_3Ljg"
    },
    {
      "id": "AbZ4IYGbfpQ",
      "title": "Netflix's Big Bet: One model to rule recommendations: Yesu Feng, Netflix",
      "description": "Discuss the foundation model strategy for personalization at Netflix based on this post https://netflixtechblog.com/foundation-model-for-personalized-recommendation-1a0bd8e02d39 and recent developments.\n\nAbout Yesu Feng\nYesu Feng is a staff research scientist/engineer at Netflix, his work focused on generative foundation models for personalized recommendation. Before Netflix, he was at Linkedin and later Uber, worked on homepage feed and marketplace optimization, respectively.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-16T18:00:36Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT22M28S",
      "viewCount": 4780,
      "likeCount": 109,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/AbZ4IYGbfpQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/AbZ4IYGbfpQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/AbZ4IYGbfpQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/AbZ4IYGbfpQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/AbZ4IYGbfpQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=AbZ4IYGbfpQ"
    },
    {
      "id": "U0S6CfzAY5c",
      "title": "360Brew: LLM-based Personalized Ranking and Recommendation - Hamed and Maziar, LinkedIn AI",
      "description": "We will give a talk about our journey of building a foundation model for solving ranking and recommendation tasks\n\nAbout Hamed Firooz\nPrincipal AI Scientist at LinkedIn Core AI. With 15 years in large-scale AI, Hamed leads the 50-person team behind LinkedIn’s 150-billion-parameter foundation model that personalizes the experience for hundreds of millions of members. Before LinkedIn, he led multimodal Content Understanding model at Meta AI that handle tens of billions of daily requests. His work spans open-source projects like Hateful Memes benchmark dataset and papers at venues such as NeurIPS and ICML.\n\nAbout Maziar Sanjabi\nMaziar is a Principal Scientist at LinkedIn AI, where he leads efforts in training large language models (LLMs) for personalization tasks. Prior to joining LinkedIn AI, he worked at Meta AI, applying AI research to the development of multimodal systems for real-world applications. With over a decade of experience in AI research across both industry and academia, Maziar has a proven track record of building and scaling cutting-edge AI technologies, including LLMs, multimodal systems, and privacy-aware AI. He has published over 60 papers, many of which have been featured in top-tier AI conferences such as NeurIPS, ICML, ICLR, ACL, EMNLP, and CVPR.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-16T17:59:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M59S",
      "viewCount": 890,
      "likeCount": 18,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/U0S6CfzAY5c/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/U0S6CfzAY5c/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/U0S6CfzAY5c/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/U0S6CfzAY5c/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/U0S6CfzAY5c/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=U0S6CfzAY5c"
    },
    {
      "id": "XdAWgO11zuk",
      "title": "What We Learned from Using LLMs in Pinterest — Mukuntha Narayanan, Han Wang, Pinterest",
      "description": "Pinterest Search integrates Large Language Models (LLMs) to enhance relevance scoring by combining search queries with rich multimodal content, including visual captions, link-based text, and user curation signals. A semi-supervised learning framework enables scaling to large and multilingual datasets, going beyond English and limited human labels. These LLM-driven models are distilled into efficient architectures for real-time serving, with experimental validation and large-scale deployment demonstrating substantial improvements in search relevance for Pinterest users worldwide.\n\n\nTimestamps\n[00:00] Introduction to Pinterest and its search functionality.\n\n[01:52] Overview of the Pinterest search backend architecture.\n\n[02:29] The search relevance model.\n\n[02:55] Key learnings from using LLMs for search relevance.\n\n[05:04] The value of VLM-generated captions and user actions as content annotations.\n\n[07:16] Productionizing LLMs with knowledge distillation.\n\n[12:14] The utility of relevance-tuned LLM embeddings as general-purpose semantic representations.\n\n[13:55] Q&A session.",
      "publishedAt": "2025-07-16T17:58:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M13S",
      "viewCount": 1321,
      "likeCount": 30,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/XdAWgO11zuk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/XdAWgO11zuk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/XdAWgO11zuk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/XdAWgO11zuk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/XdAWgO11zuk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=XdAWgO11zuk"
    },
    {
      "id": "3XmFPwjG8pg",
      "title": "Measuring AGI: Interactive Reasoning Benchmarks for ARC-AGI-3 — Greg Kamradt, ARC Prize Foundation",
      "description": "ARC Prize Foundation is building the North Star for AGI—rigorous, open benchmarks that track reasoning progress in modern AI. We'll show why static AGI evaluations are useful, but fall short when comparing models to human intelligence. Sneak peak preview of ARC-AGI-3: a dynamic, game-like benchmark launching Q1 '26.\n\nAbout Greg Kamradt   \nGreg Kamradt is President of the ARC Prize Foundation, the ARC‑AGI benchmark series that challenges frontier AI models on out‑of‑distribution reasoning tasks.​ He has taught thousands of developers to build production AI applications.​\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-16T17:57:02Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M28S",
      "viewCount": 244,
      "likeCount": 12,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/3XmFPwjG8pg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/3XmFPwjG8pg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/3XmFPwjG8pg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/3XmFPwjG8pg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/3XmFPwjG8pg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=3XmFPwjG8pg"
    },
    {
      "id": "QluDzKVfp6A",
      "title": "RL for Autonomous Coding — Aakanksha Chowdhery, Reflection.ai",
      "description": "The models and techniques to build fully autonomous coding agents - not just coding copilots - are already here. In this talk, former Google DeepMind staff research scientist, now CEO of Reflection Misha Laskin will present new research on post-training open weight LLMs for autonomous SWE tasks. He’ll focus on how scaling LLMs with Reinforcement Learning improves the autonomous coding capabilities of LLMs, and provide insight on the technical challenges required to train such systems at scale.\n\nAbout Aakanksha Chowdhery \nAakanksha Chowdhery is a Research Leader at Reflection AI pushing the frontier of reasoning for coding agents. She is also an adjunct faculty at Stanford. Before her startup journey, she was the technical Lead of 540B PaLM model and lead researcher at Google in pre-training, scaling, and post-training of Large Language Models. She was a lead researcher in Gemini, PaLM-E, MedPaLM, and Pathways project at Google. Prior to joining Google, she led interdisciplinary research initiatives at Microsoft Research and Princeton University across machine learning and distributed systems.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n[00:00:00] Introduction to LLMs and Scaling Laws\n\n[00:01:41] Emergent Behavior in LLMs\n\n[00:04:00] Reinforcement Learning from Human Feedback (RLHF)\n\n[00:06:11] Inference-Time Scaling and Verification\n\n[00:10:33] Challenges with Inference-Time Scaling\n\n[00:11:16] The Next Frontier: Reinforcement Learning for Correct Generation\n\n[00:13:20] Challenges in Scaling RL\n\n[00:14:58] Autonomous Coding as a Prime Domain for RL\n\n[00:15:53] Reflection.ai's Mission",
      "publishedAt": "2025-07-16T16:18:38Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M27S",
      "viewCount": 5610,
      "likeCount": 131,
      "commentCount": 11,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/QluDzKVfp6A/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/QluDzKVfp6A/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/QluDzKVfp6A/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/QluDzKVfp6A/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/QluDzKVfp6A/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=QluDzKVfp6A"
    },
    {
      "id": "2vlCqD6igVA",
      "title": "Recsys Keynote: Improving Recommendation Systems & Search in the Age of LLMs - Eugene Yan, Amazon",
      "description": "Recommendation systems and search have long adopted advances in language modeling, from early adoption of Word2vec for embedding-based retrieval to the transformative impact of GRUs, Transformers, and BERT on predicting user interactions. Now, the rise of large language models (LLMs) is inspiring innovations in model architecture, scalable system designs, and richer customer experiences.\n\nIn this keynote, we'll dive into cutting-edge industry applications of LLMs in recommendation and search systems, exploring real-world implementations and measurable outcomes. Join us for an look at current trends and an exciting vision of how LLM-driven techniques will shape the future of content discovery and intelligent search.\n\nAbout Eugene Yan\nEugene Yan is a Principal Applied Scientist at Amazon building recommendation systems and AI-powered products that serve customers at scale. He's led ML/AI teams at Alibaba, Lazada, and a Healthtech Series A. He writes about RecSys, LLMs, and engineering at eugeneyan.com.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n[00:00] Introduction to Language Modeling in Recommendation Systems\n\n[01:31] Challenge 1: Hash-based Item IDs\n\n[02:14] Solution: Semantic IDs\n\n[05:37] Challenge 2: Data Augmentation and Quality\n\n[06:10] Solution: LLM-Augmented Synthetic Data\n\n[06:21] Indeed Case Study\n\n[10:37] Spotify Case Study\n\n[13:34] Challenge 3: Separate Systems and High Operational Costs\n\n[14:24] Solution: Unified Models\n\n[14:51] Netflix Case Study (Unicorn)\n\n[16:46] Etsy Case Study (Unified Embeddings)\n\n[20:26] Key Takeaways",
      "publishedAt": "2025-07-16T15:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M54S",
      "viewCount": 6845,
      "likeCount": 203,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/2vlCqD6igVA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/2vlCqD6igVA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/2vlCqD6igVA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/2vlCqD6igVA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/2vlCqD6igVA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=2vlCqD6igVA"
    },
    {
      "id": "hSXIAP3rBWI",
      "title": "OpenAI's Sean Grove: Code is NOT all you do",
      "description": "",
      "publishedAt": "2025-07-16T07:00:42Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT40S",
      "viewCount": 6990,
      "likeCount": 90,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/hSXIAP3rBWI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/hSXIAP3rBWI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/hSXIAP3rBWI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/hSXIAP3rBWI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/hSXIAP3rBWI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=hSXIAP3rBWI"
    },
    {
      "id": "hSdP5EiroQI",
      "title": "OpenAI's Sean Grove: Everything is a Spec: The Universal Language of Intent",
      "description": "Mind-blowing revelation: Programmers, product managers, lawmakers - we're ALL spec authors! Discover how specifications are the universal language that aligns everything from silicon to humans.",
      "publishedAt": "2025-07-16T00:01:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT52S",
      "viewCount": 13527,
      "likeCount": 278,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/hSdP5EiroQI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/hSdP5EiroQI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/hSdP5EiroQI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/hSdP5EiroQI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/hSdP5EiroQI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=hSdP5EiroQI"
    },
    {
      "id": "W3khHzajE04",
      "title": "Benchmarks Are Memes: How What We Measure Shapes AI—and Us - Alex Duffy, Every.to",
      "description": "Benchmarks shape more than just AI models—they shape our future. The things we choose to measure become self-fulfilling prophecies, guiding AI toward specific abilities and, ultimately, defining humanity’s evolving role in the AI era. Today’s benchmarks have propelled incredible progress, but now we have an exciting opportunity: thoughtfully designing benchmarks around what genuinely matters to us—cooperation, creativity, education, and meaningful human experiences.\n\nIn this talk, we’ll explore how benchmarks function as powerful cultural memes, influencing not only technical outcomes but societal direction. Drawing on practical examples we have seen at Every consulting in industries like finance, journalism, education, and even personally making AI play diplomacy. We’ll uncover what makes a benchmark impactful, approachable, and inspiring. You’ll see our engaging new AI Diplomacy benchmark demo, illustrating vividly how thoughtful evaluation design can excite both engineers and the wider community.\n\nYou’ll hopefully walk away inspired and equipped to define benchmarks intentionally, helping steer AI toward outcomes that truly matter.\n\nAbout Alex Duffy\nI’m Alex Duffy. I lead AI strategy at Every Inc., helping teams across industries put AI into practice. Previously, I co-founded AI Camp, teaching thousands of students to build their own AI projects, and launched Salt AI, creating tools to help researchers, designers, and creators bring ideas to life. I’m passionate about building teams and tools to empower people with AI. I really believe in creating technology that works for us, not that is work for us\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-15T17:05:49Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M44S",
      "viewCount": 1213,
      "likeCount": 34,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/W3khHzajE04/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/W3khHzajE04/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/W3khHzajE04/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/W3khHzajE04/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/W3khHzajE04/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=W3khHzajE04"
    },
    {
      "id": "K-iYKDMFKhE",
      "title": "Small AI Teams with Huge Impact — Vik Paruchuri, Datalab",
      "description": "We scaled Datalab 5x this year - to 7-figure ARR, with customers that include tier 1 AI labs. We train custom models for document intelligence (OCR, layout), with popular repos surya and marker.\n\nI'll talk about a new approach to building AI teams, including lessons I learned from Jeremy Howard, and how we manage building popular repos, scaling revenue, and training models with a tiny team.\n\nAbout Vikas Paruchuri\nCEO of Datalab\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-15T17:05:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M36S",
      "viewCount": 7256,
      "likeCount": 146,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/K-iYKDMFKhE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/K-iYKDMFKhE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/K-iYKDMFKhE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/K-iYKDMFKhE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/K-iYKDMFKhE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=K-iYKDMFKhE"
    },
    {
      "id": "q8zoXAbmJdI",
      "title": "Rethinking Team Building: how a 30-person Startup serves 50 Million Users — Grant Lee, Gamma",
      "description": "The central thesis of this talk is that in the rapidly evolving age of AI, startups and tech companies should reject the traditional \"blitzscaling\" model of hyper-growth and specialized roles. Instead, they should focus on building lean, agile teams of generalists and \"player coaches\" who can adapt quickly to change. Grant Lee argues that investing in brand and culture from day one is a more scalable and sustainable way to build a company than simply hiring more people.\n\nTimestamps\n\n00:00:00 - Introduction to Gamma and its \"content-first\" philosophy.\n\n00:01:55 - Shifting focus from product innovation to organizational innovation.\n\n00:04:19 - The case for hiring generalists over specialists.\n\n00:06:48 - Introducing the \"player coach\" leadership model.\n\n00:08:57 - The importance of scaling with brand and culture.\n\n00:12:04 - Q&A session begins.\n\nAbout Grant Lee\nGrant has spent the past 10+ years building tech startups and has a background in finance and operations. He was interim CFO at Optimizely and the COO of Clearbrain, two YC startups. He grew up in the bay area and studied at Stanford, where he received his B.S. and M.S. in mechanical engineering. He is currently building Gamma, an AI-powered platform to create presentations, websites, and more.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-15T17:04:13Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M6S",
      "viewCount": 5465,
      "likeCount": 104,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/q8zoXAbmJdI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/q8zoXAbmJdI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/q8zoXAbmJdI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/q8zoXAbmJdI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/q8zoXAbmJdI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=q8zoXAbmJdI"
    },
    {
      "id": "Qw9P1zvCupE",
      "title": "Building a 10 person unicorn - Max Brodeur-Urbas, Gumloop",
      "description": "An overview of how Gumloop is scaling automation across companies like Instacart, Webflow and Shopify with less than 10 people.\n\nAbout Max Brodeur-Urbas\nex-microsoft engineer, started Gumloop in my bedroom and scaled to millions in ARR with a hyper-lean team\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-15T17:03:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M3S",
      "viewCount": 4177,
      "likeCount": 69,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Qw9P1zvCupE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Qw9P1zvCupE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Qw9P1zvCupE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Qw9P1zvCupE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Qw9P1zvCupE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Qw9P1zvCupE"
    },
    {
      "id": "gcseUQJ6Gbg",
      "title": "Using OSS models to build AI apps with millions of users — Hassan El Mghari",
      "description": "In this talk, Hassan will go over how he builds open source AI apps that get millions of users like roomGPT.io 2.9 million users, restorePhotos.io 1.1 million users, Blinkshot.io 1 million visitors, and LlamaCoder.io 1.4 million visitors. He'll go over his journey in AI, demo some of the apps that he's built, and dig into his tech stack and code to explain how he builds these apps from scratch. He’ll also go over how to market them and go over his top tips and tricks for building great full-stack AI applications quickly and efficiently.\n\nThis talk will start from first principles and give you a glimpse into Hassan’s workflow of idea - working app - many users. Attendees should come out of this session equipped with the resources to build impressive AI applications and understand some of the behind the scenes of how they’re built and marketed. This will hopefully serve as an educational and inspirational talk that encourages builders to go build cool things.\n\nAbout Hassan El Mghari\nHassan El Mghari is a software engineer based in New York specializing in building full-stack AI applications. His AI applications have a combined user base of over 3 million. He currently leads the developer relations team at Together.ai, where his work includes building example AI apps, creating content, and educating developers on AI development.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-15T17:02:33Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M47S",
      "viewCount": 5778,
      "likeCount": 190,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/gcseUQJ6Gbg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/gcseUQJ6Gbg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/gcseUQJ6Gbg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/gcseUQJ6Gbg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/gcseUQJ6Gbg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=gcseUQJ6Gbg"
    },
    {
      "id": "s8RM8uYxkoY",
      "title": "Bolt.new: How we scaled $0-20m ARR in 60 days, with 15 people — Eric Simons, Bolt",
      "description": "Tiny Teams are the future of how startups are built, and it all comes down to team culture, decision making, tooling choices, and endless grit.\n\nIn this talk, Eric will share the high octane insights & learnings of how the 2nd fastest growing product in history _made it_ with a team of less than 15 people.\n\nAbout Eric Simons\nCEO of Bolt.new\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-15T17:01:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M33S",
      "viewCount": 5180,
      "likeCount": 119,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/s8RM8uYxkoY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/s8RM8uYxkoY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/s8RM8uYxkoY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/s8RM8uYxkoY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/s8RM8uYxkoY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=s8RM8uYxkoY"
    },
    {
      "id": "_BRhRh7mOX0",
      "title": "Prompt Engineering and AI Red Teaming — Sander Schulhoff, HackAPrompt/LearnPrompting",
      "description": "Learn from the creator of Learn Prompting, the internet's 1st Prompt Engineering guide (released 2 months before ChatGPT), and HackAPrompt, the World's 1st AI Red Teaming competition.\n\nMy talk will cover topics ranging from the history of prompt engineering to the most advanced research-backed prompt engineering techniques.\n\nI will also discuss the origins of prompt injection and AI red teaming, as well as the current state of industry and the need for agentic red teaming.\n\nhttps://www.hackaprompt.com\n\nAbout Sander Schulhoff\nI'm Sander Schulhoff, the founder and CEO of HackAPrompt and Learn Prompting. I created the first Prompt Engineering guide on the internet, two months before ChatGPT was released, which has taught 3 million people how to prompt ChatGPT. I also ran, in collaboration with OpenAI, the first AI Red Teaming Hackathon (an event that nearly doubled a similar one by the White House). Today, HackAPrompt partners with the Frontier AI labs to produce research that makes their models more secure. My background is primarily in NLP and deep reinforcement learning. I recently led the team behind The Prompt Report, the most comprehensive study of prompt engineering ever done. Our 76-page survey, co-authored with OpenAI, Microsoft, Google, Princeton, Stanford, and other leading institutions, analyzed 1,500+ academic papers and covered 200+ prompting techniques.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-14T19:00:11Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT2H1M5S",
      "viewCount": 7725,
      "likeCount": 196,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/_BRhRh7mOX0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/_BRhRh7mOX0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/_BRhRh7mOX0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/_BRhRh7mOX0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/_BRhRh7mOX0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=_BRhRh7mOX0"
    },
    {
      "id": "1MVh05GDydE",
      "title": "Survive the AI Knife Fight: Building Products That Win — Brian Balfour, Reforge",
      "description": "If you’ve ever been blocked by vague specs, shifting goals, or chasing “vibes,” things have only gotten messier in the age of AI. Everyone is obsessing over engineers doing PM work and PMs cranking out prototypes—but that skips the hardest question: What should we build, and why will it win? Today’s competitive landscape is a knife-fight. When it’s trivial to ship “something,” true differentiation becomes brutally difficult.\n\nAt Reforge, we built AI agents that analyze user feedback at scale, perform real-time market analysis, model feature impact, and run continuous user research -- pushing us to rethink what \"product work” actually looks like.\n\nIn this talk, we’ll explore:\n\n- How to find a seam within the red ocean of incumbents, well-funded upstarts, and the horde of startups.\n- How to use real-time feedback analysis, competitive monitoring, synthetic users, AI-native research to understand impact before it ships.\n- How to architect workflows where human intuition and machine intelligence ship product side by side.\n\nAbout Brian Balfour\nBrian Balfour, Founder/CEO of Reforge, previously VP Growth @ HubSpot. Prior to Reforge, he has started multiple VC backed companies, and grown user bases to millions of daily active users.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-14T18:59:48Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M10S",
      "viewCount": 13837,
      "likeCount": 369,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1MVh05GDydE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1MVh05GDydE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1MVh05GDydE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1MVh05GDydE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1MVh05GDydE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1MVh05GDydE"
    },
    {
      "id": "AXMdSqdoGHM",
      "title": "Automating Escrow with USDC and AI - Corey Cooper, Circle",
      "description": "This workshop explores how USDC, AI, and smart contracts can streamline escrow by automating fund release based on task or process verification. By using AI to interpret off-chain signals such as document validation, delivery confirmations, or milestone completion, we can trigger secure, programmable USDC payouts without manual intervention. The result is a faster, trust-minimized escrow system ideal for services, trade, and gig economy use cases.\n\nAbout Corey Cooper\nI'm a developer who was once a high school basketball scout, where I built scouting technology to make data more accessible for college coaches. A lifelong Lakers fan from Atlanta, I love basketball and have spent my career building enterprise software. With over 15 years of experience as a solutions engineer, I bring a mix of technical depth, business insight, and hands-on leadership to product launches. Today, I am passionate about the programmability of money, now empowered by smart contracts, and how it is reshaping what is possible in digital finance.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-14T14:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT58M18S",
      "viewCount": 1755,
      "likeCount": 45,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/AXMdSqdoGHM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/AXMdSqdoGHM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/AXMdSqdoGHM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/AXMdSqdoGHM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/AXMdSqdoGHM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=AXMdSqdoGHM"
    },
    {
      "id": "ZuiJjkbX0Og",
      "title": "How LLMs work for Web Devs: GPT in 600 lines of Vanilla JS - Ishan Anand",
      "description": "Don't be intimidated. Modern AI can feel like magic, but underneath the hood are principles that web developers can understand, even if you don't have a machine learning background. In this workshop, we'll explore a complete GPT-2 inference implementation built entirely in Vanilla JS. This JavaScript translation of the popular \"Spreadsheets-are-all-you-need\" approach will let you debug and step through a real LLM line by line without the overhead of learning a new language, framework, or even IDE.\n\nAll the major LLMs, including ChatGPT, Claude, DeepSeek, and Llama, inherit from GPT-2's architecture, making this exploration a solid foundation to understand modern AI systems and comprehend the latest research.\n\nWhile we won't have time to cover everything, you'll gain the essential knowledge to understand the key concepts that matter when building with LLMs, including how they:\n\n- Convert raw text into meaningful tokens\n- Represent semantic meaning through vector embeddings\n- Train neural networks through gradient descent\n- Generate text with sampling algorithms like top-k, top-p, and temperature\n\nThis intense but beginner-friendly workshop is designed specifically for web developers diving into ML and AI for the first time. It’s your \"missing AI degree\" in just two hours. You'll walk away with an intuitive mental model of how Transformers work that you can apply immediately to your own LLM-powered projects.\n\nAbout Ishan Anand\nIshan Anand is an AI consultant and technology executive specializing in Generative AI and LLMs. He created \"Spreadsheets-are-all-you-need,\" an innovative course that demystifies large language models by implementing GPT-2 entirely in Excel. As the former CTO and co-founder of Layer0 (acquired by Edgio), and most recently Vice-President of Product Management for Edgio, he's led teams in developing cutting-edge solutions in web performance, edge computing, and AI/ML for enterprise web applications. Ishan brings deep technical expertise from his dual B.S. degrees in Mathematics and EECS from MIT, combined with a unique ability to make advanced technology accessible to broader audiences.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-13T17:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H41M34S",
      "viewCount": 7399,
      "likeCount": 258,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ZuiJjkbX0Og/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ZuiJjkbX0Og/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ZuiJjkbX0Og/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ZuiJjkbX0Og/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ZuiJjkbX0Og/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ZuiJjkbX0Og"
    },
    {
      "id": "FWlRHPZWyHE",
      "title": "[Workshop] AI Pipelines and Agents in Pure TypeScript with Mastra.ai — Nick Nisi, Zack Proser",
      "description": "This hands-on workshop introduces Mastra.ai, a TypeScript framework that streamlines the development of agentic AI systems compared to traditional approaches using LangChain and vector databases. Participants will learn to build structured AI workflows with composable tools and reliable control, enabling them to create internal AI assistants that can handle requests like data cleaning, email drafting, and document summarization with minimal code. The session covers Mastra installation, running a local MCP server, defining tools and agents in TypeScript, using the Mastra playground, and implementing practical examples such as RAG setups and tool-chaining agents—all designed to equip attendees with the skills to develop scalable AI-driven internal tools based on sound software engineering principles rather than just experimental prompts.\n\nAbout Nick Nisi\nNick Nisi is an elite software engineer who is a veteran of open source web development, a lover of karaoke, an advocate for diversity in tech, a conference organizer extraordinaire, a lover of new experiences, and a beacon of expertise, kindness and hope for his development team.\n\nAbout Zack Proser\nZachary Proser builds AI systems that actually ship. For over thirteen years at Cloudmark, Cloudflare, Gruntwork, Pinecone, and now WorkOS, he’s worked across the stack—from infrastructure to interface—shipping production code.\n\nAt WorkOS, he shares what he learns in the open: creating sample applications and architectures, technical guides, and real-world lessons that make identity, security, and AI accessible. His posts are known for their copy-paste readiness and refusal to hand-wave.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-12T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H51M14S",
      "viewCount": 6652,
      "likeCount": 153,
      "commentCount": 15,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/FWlRHPZWyHE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/FWlRHPZWyHE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/FWlRHPZWyHE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/FWlRHPZWyHE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/FWlRHPZWyHE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=FWlRHPZWyHE"
    },
    {
      "id": "zK9lYrLbjSg",
      "title": "AI Engineering with the Google Gemini 2.5 Model Family - Philipp Schmid, Google DeepMind",
      "description": "Hands on Workshop on learning to use Gemini 2.5 Pro in combination with Agentic tooling and MCP Servers.\n\nAbout Philipp Schmid  \nPhilipp Schmid is a Senior AI Developer Relations Engineer at Google DeepMind working on Gemini, Gemma with the mission to help every developer and builder to create and benefit from AI in a responsible way.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-11T19:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H44M51S",
      "viewCount": 4375,
      "likeCount": 95,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/zK9lYrLbjSg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/zK9lYrLbjSg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/zK9lYrLbjSg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/zK9lYrLbjSg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/zK9lYrLbjSg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=zK9lYrLbjSg"
    },
    {
      "id": "8rABwKRsec4",
      "title": "The New Code — Sean Grove, OpenAI",
      "description": "In an era where AI transforms software development, the most valuable skill isn't writing code - it's communicating intent with precision. This talk reveals how specifications, not prompts or code, are becoming the fundamental unit of programming, and why spec-writing is the new superpower.\n\nDrawing from production experience, we demonstrate how rigorous, versioned specifications serve as the source of truth that compiles to documentation, evaluations, model behaviors, and maybe even code.\n\nJust as the US Constitution acts as a versioned spec with judicial review as its grader, AI systems need executable specifications that align both human teams and machine intelligence. We'll look at OpenAI's Model Spec as a real-world example.\n\nFinally, we'll end on some open questions about what the future of developer tooling looks like in a world where communication once again becomes the most important artifact in engineering.\n\nAbout Sean Grove\nSean Grove works on alignment reasoning at OpenAI, helping translate high‑level intent into enforceable specs and evaluations. Before OpenAI he founded OneGraph, a GraphQL developer‑tools startup later acquired by Netlify. He has delivered dozens of technical talks worldwide on developer tooling, APIs, AI UX and design, and now alignment.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-11T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M36S",
      "viewCount": 818613,
      "likeCount": 15553,
      "commentCount": 1148,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/8rABwKRsec4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/8rABwKRsec4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/8rABwKRsec4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/8rABwKRsec4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/8rABwKRsec4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=8rABwKRsec4"
    },
    {
      "id": "OKs6EO_klBg",
      "title": "Boris explains Claude Code",
      "description": "Boris from Anthropic shows how AI models are getting exponentially better at coding! See Claude Code in action - from GitHub integration to TDD workflows that actually WORK! This is the coding revolution happening live! 🚀💻\n\n#LiveDemo\n#AIRevolution\n#CodingFuture\n#GitHubIntegration\n#TDD\n#DeveloperProductivity\n#BitterLesson\n#RealTimeAI\n#ProgrammingDemo\n#TechInnovation",
      "publishedAt": "2025-07-10T20:30:03Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT56S",
      "viewCount": 10795,
      "likeCount": 232,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/OKs6EO_klBg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/OKs6EO_klBg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/OKs6EO_klBg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/OKs6EO_klBg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/OKs6EO_klBg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=OKs6EO_klBg"
    },
    {
      "id": "L6_NiGIEXZQ",
      "title": "Production software keeps breaking and it will only get worse — Anish Agarwal, Traversal.ai",
      "description": "Software is eating the world. AI is eating software. AI-powered SWE means a whole lot more software is going to be written that powers mission critical systems in the coming years, with hardly any of it written by humans. Hence, when these software systems inevitably break, it’s going to be next to impossible to troubleshoot them. Towards addressing this issue, we’ll do a product launch of Traversal’s AI, a significant step towards self-healing software systems. We will showcase how it is already used to autonomously troubleshoot production incidents in some of the most complex enterprise environments.\n\nAbout Anish Agarwal\nAnish Agrawal is the CEO and Co-founder of Traversal, where he and his team are revolutionizing observability and troubleshooting with AI Agents. A Professor of Computer Science and Operations Research at Columbia University, Anish earned his PhD in Computer Science from MIT, specializing in causal machine learning—teaching AI to understand cause and effect from data. Despite achieving his goal of becoming a professor, Anish pivoted from academia, recognizing a once-in-a-lifetime opportunity to apply his AI research to tackle the industry’s toughest challenges, with autonomous troubleshooting at the forefront. His career also includes roles as a management consultant at BCG and research scientist at Amazon and Microsoft Research.\n\nAbout Matthew Schoenbauer\nMatt Schoenbauer is a founding engineer at Traversal, where he and his team are redefining observability and troubleshooting with AI agents. Previously, he was a systematic trader at Citadel Securities, operating at the core of the world’s largest equities market-making platform, where live troubleshooting in the Linux terminal was a critical part of his work. Before that, he worked in quantitative research at Proof Trading. Matt has published research across cryptography, number theory, and algebraic topology, and holds a master’s degree from Columbia University, where he focused on machine learning systems and causal machine learning.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n00:00 Introduction: The Three Pillars of Software Engineering\n02:10 The Worsening Problem of Troubleshooting\n04:15 Why Current AI/ML Solutions are Failing\n07:08 Traversal.ai's Novel Approach to Autonomous Troubleshooting\n11:35 Case Study: How Traversal.ai helped Digital Ocean\n16:03 The Broader Vision for Traversal.ai",
      "publishedAt": "2025-07-10T16:29:07Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M13S",
      "viewCount": 3306,
      "likeCount": 71,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/L6_NiGIEXZQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/L6_NiGIEXZQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/L6_NiGIEXZQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/L6_NiGIEXZQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/L6_NiGIEXZQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=L6_NiGIEXZQ"
    },
    {
      "id": "8EQo4J2BWKw",
      "title": "Thinking Deeper in Gemini — Jack Rae, Google DeepMind",
      "description": "Progress towards general intelligence has been marked by identifying fundamental intelligence bottlenecks within existing models and developing solutions that improve the architecture or training objective. From this perspective, we discuss our work on Thinking in Gemini as a solution to a bottleneck in test-time compute. We will discuss recent progress in Thinking both from the benefit of capability and steerability, and discuss where our models are headed.\n\nAbout Jack Rae\nLead of Gemini Thinking, co-lead of Gemini Pre-training\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-10T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M13S",
      "viewCount": 28854,
      "likeCount": 580,
      "commentCount": 33,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/8EQo4J2BWKw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/8EQo4J2BWKw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/8EQo4J2BWKw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/8EQo4J2BWKw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/8EQo4J2BWKw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=8EQo4J2BWKw"
    },
    {
      "id": "wE1ZCmCLP5g",
      "title": "A year of Gemini progress + what comes next — Logan Kilpatrick, Google DeepMind",
      "description": "Over the last year, Google and Gemini models have shown rapid progress across all dimensions (model, product, etc). Let's highlight all the work that has happened, how we got the worlds best models, and where we are going next (across both the model landscape and out AI products).\n\nAbout Logan Kilpatrick\nLogan leads product for Google AI Studio and works on the Gemini API. Before Google, Logan led developer relations at OpenAI.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-10T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT11M58S",
      "viewCount": 14651,
      "likeCount": 294,
      "commentCount": 13,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/wE1ZCmCLP5g/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/wE1ZCmCLP5g/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/wE1ZCmCLP5g/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/wE1ZCmCLP5g/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/wE1ZCmCLP5g/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=wE1ZCmCLP5g"
    },
    {
      "id": "I_pICAT8Bhg",
      "title": "The Wild World of AI: 6 Months That Changed Everything",
      "description": "From pelicans on bicycles to $600 billion market crashes - discover the most insane AI developments of the past 6 months! 🤖🚲\n\n#AI\n#MachineLearning\n#LLM\n#TechNews\n#AIRevolution\n#OpenAI\n#DeepSeek\n#TechTalk\n#ArtificialIntelligence\n#TechTrends",
      "publishedAt": "2025-07-10T03:23:09Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1M57S",
      "viewCount": 4478,
      "likeCount": 87,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/I_pICAT8Bhg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/I_pICAT8Bhg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/I_pICAT8Bhg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/I_pICAT8Bhg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/I_pICAT8Bhg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=I_pICAT8Bhg"
    },
    {
      "id": "YpY83-kA7Bo",
      "title": "2025 in LLMs so far, illustrated by Pelicans on Bicycles — Simon Willison",
      "description": "What's changed in the world of LLMs since the AIE World's Fair last year? A lot!\n\nI'll be taking full advantage of my role as a fiercely independent researcher to review the past 12 months of advances in the field and catch everyone up on the latest models, free from any influence of vendors or employers.\n\nAbout Simon Willison\nSimon Willison is the creator of Datasette, an open source tool for exploring and publishing data. He currently works full-time building open source tools for data journalism, built around Datasette and SQLite.\n\nPrior to becoming an independent open source developer, Simon was an engineering director at Eventbrite. Simon joined Eventbrite through their acquisition of Lanyrd, a Y Combinator funded company he co-founded in 2010.\n\nHe is a co-creator of the Django Web Framework, and has been blogging about web development and programming since 2002 at simonwillison.net\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps:\n\n00:00 A review of the last six months in LLMs\n01:08 The \"Pelican Riding a Bicycle\" Benchmark\n02:10 AWS Nova and Llama 3.3 70B\n03:30 DeepSeek and its impact\n05:42 Mistral Small 3 and the rise of local models\n06:45 Claude 3.7 Sonnet and GPT 4.5\n08:44 Gemini 2.5 Pro, GPT-4o, and Llama 4\n11:21 GPT 4.1, O3, and O4 Mini\n12:05 Claude 4 and other recent releases\n14:11 Amusing and concerning LLM bugs\n16:58 The power of tools and reasoning in AI\n17:41 Prompt injection and the \"Lethal Trifecta\"\n18:11 The future of the pelican benchmark",
      "publishedAt": "2025-07-09T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M30S",
      "viewCount": 148236,
      "likeCount": 3689,
      "commentCount": 104,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/YpY83-kA7Bo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/YpY83-kA7Bo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/YpY83-kA7Bo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/YpY83-kA7Bo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/YpY83-kA7Bo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=YpY83-kA7Bo"
    },
    {
      "id": "sRpqPgKeXNk",
      "title": "Trends Across the AI Frontier — George Cameron, ArtificialAnalysis.ai",
      "description": "The entire AI stack is developing faster than ever - from chips to infrastructure to models. How do you sort the signal from the noise? Artificial Analysis an independent benchmarking and insights company dedicated to helping developers and companies pick the right models and technologies for building applications. This talk will walk through the state of the frontier across the AI stack.\n\nAbout George Cameron\nCPO of Artificial Analysis\n\nAbout Micah Hill-Smith\nI'm Micah, co-founder and CEO of Artificial Analysis - an independent AI benchmarking company. We help developers understand AI capabliites and make critical decisions about models and technologies. We publish extensive benchmarking results on our public website (including intelligence, performance, cost and more), and develop reports to inform key strategic decisions. I became obsessed with benchmarking AI models initially as an AI engineer building applications, and have previously spent time as a strategy consultant with McKinsey & Company.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps\n[00:00] Introduction to Artificial Analysis: An overview of the company's work in benchmarking AI models across various modalities and metrics.\n\n[01:54] The State of AI Progress: A look at the rapid advancements in AI since the launch of ChatGPT, with a focus on the current leaders in AI intelligence.\n\n[04:06] The Reasoning Models Frontier: An exploration of the trade-offs between the enhanced intelligence of reasoning models and their increased latency and cost.\n\n[08:25] The Open Weights Frontier: A discussion on the closing intelligence gap between open-weights and proprietary models, with a nod to the significant contributions from China-based AI labs.\n\n[10:26] The Cost Frontier: An analysis of the dramatic decrease in the cost of accessing high-level AI intelligence and the implications for application development.\n\n[14:09] The Speed Frontier: A look at the remarkable increase in the output speed of AI models and the technological advancements driving this trend.\n\n[16:34] The Future of Compute Demand: A concluding perspective on why the demand for compute will likely continue to rise despite efficiency gains, driven by larger models, the quest for greater intelligence, and the rise of AI agents.",
      "publishedAt": "2025-07-08T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M52S",
      "viewCount": 12809,
      "likeCount": 231,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/sRpqPgKeXNk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/sRpqPgKeXNk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/sRpqPgKeXNk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/sRpqPgKeXNk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/sRpqPgKeXNk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=sRpqPgKeXNk"
    },
    {
      "id": "PbHm2qKnu10",
      "title": "Training Agentic Reasoners — Will Brown, Prime Intellect",
      "description": "This talk will be a technical deep dive into RL for agentic reasoning via multi-turn tool calling, similar to OpenAI's o3 and Deep Research. In particular, we'll cover:\n\n- When, why, and how\n- GRPO vs PPO vs etc\n- Designing environments and rewards\n- Survey of recent research highlights\n- Results on example tasks\n- Overview of open-source ecosystem (libraries, compute requirements, tradeoffs, etc.)\n\nAbout Will Brown\nWill Brown is a Research Engineering Lead at Prime Intellect, focusing on RL for reasoning and agents. He previously held research roles at Morgan Stanley and AWS, and completed his PhD in Computer Science at Columbia University.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps\n[00:00] Introduction to the idea that reasoning and agents are similar.\n[01:05] The growing effectiveness of Reinforcement Learning (RL) in AI.\n[03:04] The complexities and challenges of implementing RL.\n[04:41] The connection between popular AI products (agents) and RL fine-tuning.\n[07:18] The core process of Reinforcement Learning.\n[10:21] The importance of tools and real-world tasks for agents.\n[12:13] The problem of \"reward hacking\" and how to design better evaluations.\n[14:51] Future directions for agentic systems and a practical toolkit for implementation.",
      "publishedAt": "2025-07-07T17:20:54Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M17S",
      "viewCount": 14508,
      "likeCount": 366,
      "commentCount": 14,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/PbHm2qKnu10/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/PbHm2qKnu10/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/PbHm2qKnu10/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/PbHm2qKnu10/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/PbHm2qKnu10/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=PbHm2qKnu10"
    },
    {
      "id": "P_uhFGH4J9Y",
      "title": "New York Times' Connections: A Case Study on NLP in Word Games — Shafik Quoraishee, NYT Games",
      "description": "This session will examine the interplay between human intuition and artificial intelligence in puzzle-solving, using the popular New York Times Connections game as a practical case study.\n    \n    We'll investigate how gameplay can be systematically evaluated through AI algorithms, exploring machine learning strategies such as clustering, semantic mapping, and natural language processing.\n    \n    Attendees will gain insights into building AI-driven puzzle solvers, learn methods for quantitatively assessing gameplay complexity, and discuss the potential impacts of AI on puzzle game design and player engagement.\n\nTimestamps [00:00]:\n\n[01:45] Introduction to Connections\n\n[03:50] Why Connections is Interesting for AI\n\n[05:18] Human vs. AI Problem Solving\n\n[06:55] AI Analysis and Methodology\n\n[09:26] Semantic Similarity\n\n[10:45] Relational Alignment\n\n[12:16] Multi-dimensional Analysis\n\n[15:44] Graph Neural Networks (GNNs)\n\n[17:42] Motivation and Next Steps",
      "publishedAt": "2025-07-05T22:41:15Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M31S",
      "viewCount": 4279,
      "likeCount": 107,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/P_uhFGH4J9Y/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/P_uhFGH4J9Y/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/P_uhFGH4J9Y/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/P_uhFGH4J9Y/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/P_uhFGH4J9Y/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=P_uhFGH4J9Y"
    },
    {
      "id": "Lue8K2jqfKk",
      "title": "Claude Code & the evolution of agentic coding — Boris Cherny, Anthropic",
      "description": "A ten thousand foot view of the coding space, the UX of coding, and the Claude Code team's approach.\n\nAbout Boris Chemy\nCreated Claude Code. Member of Technical Staff @Anthropic. Prev: Principal Engineer @Meta, Architect @Coatue. Author, OReilly's Programming TypeScript.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-04T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M12S",
      "viewCount": 118667,
      "likeCount": 2362,
      "commentCount": 95,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Lue8K2jqfKk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Lue8K2jqfKk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Lue8K2jqfKk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Lue8K2jqfKk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Lue8K2jqfKk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Lue8K2jqfKk"
    },
    {
      "id": "8kMaTybvDUw",
      "title": "12-Factor Agents: Patterns of reliable LLM applications — Dex Horthy, HumanLayer",
      "description": "Hi, I'm Dex. I've been hacking on AI agents for a while.\n    \n    I've tried every agent framework out there, from the plug-and-play crew/langchains to the \"minimalist\" smolagents of the world to the \"production grade\" langraph, griptape, etc.\n    \n    I've talked to a lot of really strong founders who are all building really impressive things with AI. Most of them are rolling the stack themselves. I don't see a lot of frameworks in production customer-facing agents.\n    \n    I've been surprised to find that most of the products out there billing themselves as \"AI Agents\" are not all that agentic. A lot of them are mostly deterministic code, with LLM steps sprinkled in at just the right points to make the experience truly magical.\n    \n    Agents, at least the good ones, don't follow the \"here's your prompt, here's a bag of tools, loop until you hit the goal\" pattern. Rather, they are comprised of mostly just software.\n    \n    So, I set out to answer:\n    \n    What are the principles we can use to build LLM-powered software that is actually good enough to put in the hands of production customers?\n\n# The Short  Version: The 12 Factors\n\nEven if LLMs continue to get exponentially more powerful, there will be core engineering techniques that make LLM-powered software more reliable, more scalable, and easier to maintain.\n\nHow We Got Here: A Brief History of Software\nFactor 1: Natural Language to Tool Calls\nFactor 2: Own your prompts\nFactor 3: Own your context window\nFactor 4: Tools are just structured outputs\nFactor 5: Unify execution state and business state\nFactor 6: Launch/Pause/Resume with simple APIs\nFactor 7: Contact humans with tool calls\nFactor 8: Own your control flow\nFactor 9: Compact Errors into Context Window\nFactor 10: Small, Focused Agents\nFactor 11: Trigger from anywhere, meet users where they are\nFactor 12: Make your agent a stateless reducer\n\n\n---\n\nhttps://x.com/dexhorthy/\nhttps://github.com/humanlayer/12-factor-agents\nhttps://news.ycombinator.com/item?id=43699271",
      "publishedAt": "2025-07-03T20:50:54Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M6S",
      "viewCount": 172031,
      "likeCount": 4468,
      "commentCount": 144,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/8kMaTybvDUw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/8kMaTybvDUw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/8kMaTybvDUw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/8kMaTybvDUw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/8kMaTybvDUw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=8kMaTybvDUw"
    },
    {
      "id": "FCi4jT86gSw",
      "title": "MCP Is Not Good Yet — David Cramer, Sentry",
      "description": "You’ve heard a lot about MCP, probably been given an AI mandate or two, and are trying to figure out what’s real and what’s make believe. \n\nThis session will give practical advice for how you should be thinking about MCP, the implementation pit falls, and where the speaker thinks things are going. \n\n---related links---\n\nhttps://twitter.com/zeeg\nhttps://cra.mr\nhttps://sentry.io",
      "publishedAt": "2025-07-03T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M41S",
      "viewCount": 7600,
      "likeCount": 168,
      "commentCount": 12,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/FCi4jT86gSw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/FCi4jT86gSw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/FCi4jT86gSw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/FCi4jT86gSw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/FCi4jT86gSw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=FCi4jT86gSw"
    },
    {
      "id": "BS92RdBvI90",
      "title": "Your Personal Open-Source Humanoid Robot for $8,999 — JX Mo, K-Scale Labs",
      "description": "Introducing developer ready robots that are open-source, affordable, and easy to use. https://www.kscale.dev/\n\nAbout Jingxiang Mo \nJingxiang Mo is a founding engineer at K-Scale Labs, where he leads the fast-moving, open-source development of general-purpose humanoid robots. His work spans the full stack—from training end-to-end reinforcement-learning policies on in-house infrastructure to building the robot operating system and shipping mass-manufactured hardware such as the 5 feet tall K-Bot and 1.5 feet tall Z-Bot humanoid robots.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-02T23:40:32Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M26S",
      "viewCount": 31561,
      "likeCount": 903,
      "commentCount": 79,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/BS92RdBvI90/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/BS92RdBvI90/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/BS92RdBvI90/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/BS92RdBvI90/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/BS92RdBvI90/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=BS92RdBvI90"
    },
    {
      "id": "1__V4KTv_Gw",
      "title": "The Build-Operate Divide: Bridging Product Vision and AI Operational Reality",
      "description": "Product leaders see AI possibilities. Operations teams see implementation chaos. That disconnect can kill promising AI features before they ever reach users.\n\nIn this session, Chris Hernandez (Chime) and Jeremy Silva (Freeplay) share an integrated framework that bridges product strategy and operational reality. You'll learn how they transformed fragmented AI workflows into a unified approach—from prototyping and prompt testing to human review loops and model benchmarking.\n\nWe’ll explore how to build evaluation systems that satisfy both technical and business stakeholders, create effective HITL processes from day one, and use QA as a strategic enabler of generative AI quality. Most importantly, we’ll show how product and operations can move beyond friction—working together to deliver AI features that scale responsibly and ship faster, with confidence.\n\nAbout Jeremy Silva\nA seasoned ML engineer with extensive experience building and deploying language models in the healthcare sector, Jeremy currently serves as Product Lead at Freeplay. At Freeplay, he oversees an enterprise-ready platform that empowers teams to run experiments, create evaluations, monitor production systems, and label data—all within a unified environment.\n\nDrawing from hands-on collaboration with Freeplay's enterprise customers, Jeremy brings valuable \"in-the-trenches\" experience building LLM systems at scale. This direct customer engagement has also positioned him as a trusted advisor, helping organizations shape and refine their AI product roadmaps for maximum impact.\n\nJeremy’s unique perspective spans technical implementation and product development making him well-positioned to share insights on effectively bridging the gap between AI capabilities and real-world product outcomes.\n\nAbout Chris Hernandez\nI’m a Manager of Speech Analytics at Chime, where I lead a team in developing and implementing AI-powered insights to enhance member experiences and operational efficiency. With over a decade of experience in leadership, AI, and machine learning, I specialize in designing and scaling AI solutions that drive measurable impact.\n\nAt Chime, we believe that everyone can feel good about their money. We’re proud to be the most loved banking app™, providing millions of members with transparent, easy-to-use tools that help them unlock financial progress. By leveraging AI, my team helps uncover insights that improve quality, efficiency, and overall member satisfaction.\n\nI joined Chime because of its mission and the opportunity to work alongside an incredible team focused on innovation. I’m excited about the future as we continue to push the boundaries of AI-driven quality solutions—and we’re just getting started! 🚀\n\n**The views and opinions expressed here are my own and do not necessarily reflect the official policy or position of Chime.**\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-02T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M50S",
      "viewCount": 2476,
      "likeCount": 47,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1__V4KTv_Gw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1__V4KTv_Gw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1__V4KTv_Gw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1__V4KTv_Gw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1__V4KTv_Gw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1__V4KTv_Gw"
    },
    {
      "id": "pQz-PgA1eJw",
      "title": "The New Lean Startup — Sid Bendre, Oleve",
      "description": "In this session, I will be presenting a case study of Oleve's journey, revealing how we've scaled a profitable multi-product portfolio with a tiny team. I'll walk you through the emergence of \"tiny teams,\" our two-track engineering methodology that has become our blueprint, as well as an inside look at our technical alpha – specifically how we've engineered deterministic AI agents to deliver magical and reliable consumer experiences to millions. You'll learn how we've built internal tools to grow leanly and created operating playbooks to scale operations without traditional headcount requirements. I'll also share our approach to scrappy infrastructure innovation and how our investment in internal tooling has served as a critical force multiplier. Finally, I'll give an overview of parts of the profitable portfolio playbook that keeps us lean, adaptable, and profitable across multiple product lines.\n\nStructure of talk:\n- the tiny teams revolution\n- the two-track engineering approach\n- technical alpha: deterministic ai agents at scale\n- scrappy infrastructure innovation\n- internal tooling as a multiplier\n- the profitable portfolio playbook\n\nAbout Sid Bendre\nSid Bendre is the co-founder of Oleve, a company building a portfolio of iconic consumer software across multiple verticals. With a lean team, Oleve has already launched two virally successful consumer AI products that have amassed over 250 million views across social media platforms. One of their products reached #4 on the App Store's Education charts in 2024 and #5 in 2025, competing alongside giants like Photomath (Google) and Duolingo. Backed by Neo, Cal Henderson (co-founder of Slack), Russell Kaplan (President of Cognition), and Maria Zhang (ex-CTO of Tinder), Oleve is building the AI infrastructure to run a $1B portfolio of consumer software over the next decade. At Oleve, Sid leads technical and AI efforts, running the “Platform” team responsible for the underlying AI infrastructure that powers their lean scaling approach. Before Oleve, Sid led AI experimentation efforts at a startup hedge fund and worked at Slack, Zendesk, and Microsoft.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-01T16:57:59Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M26S",
      "viewCount": 31196,
      "likeCount": 956,
      "commentCount": 28,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/pQz-PgA1eJw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/pQz-PgA1eJw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/pQz-PgA1eJw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/pQz-PgA1eJw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/pQz-PgA1eJw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=pQz-PgA1eJw"
    },
    {
      "id": "gmTHs5T_YAE",
      "title": "Optimizing inference for voice models in production - Philip Kiely, Baseten",
      "description": "How do you get time to first byte (TTFB) below 150 milliseconds for voice models -- and scale it in production? As it turns out, open-source TTS models like Orpheus have an LLM backbone that lets us use familiar tools and optimizations like TensorRT-LLM and FP8 quantization to serve the models with low latency. But client code, network infrastructure, and other outside-the-GPU factors can introduce latency in the production stack. In this talk, we'll cover the basic mechanics of TTS inference, common pitfalls to avoid in integrating them into production systems, and how to extend this high-performance system to serve customized models with voice cloning and fine-tuning.\n\nAbout Philip Kiely\nPhilip Kiely leads Developer Relations at Baseten. Prior to joining Baseten in 2022, he worked across software engineering and technical writing for a variety of startups. Outside of work, you'll find Philip practicing martial arts, reading a new book, or cheering for his adopted bay area sports teams.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-01T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M13S",
      "viewCount": 2409,
      "likeCount": 72,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/gmTHs5T_YAE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/gmTHs5T_YAE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/gmTHs5T_YAE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/gmTHs5T_YAE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/gmTHs5T_YAE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=gmTHs5T_YAE"
    },
    {
      "id": "yASxPZ-tZe0",
      "title": "Conquering Agent Chaos — Rick Blalock, Agentuity",
      "description": "Agent deployments can be dicey, especially at first.  This session goes over all the things that cause headache with deployments from serverless issues to networking issues - and how we fix them.\n\nAbout Rick Blalock\nSeasoned founder with exit. Developer at night and during the day if I can fit it in meetings... Scaled a mobile developer platform from hundreds to 800,000 developers. Successfully started and sold a fisheries platform & app to the world's largest fishing app with 15m+ users, and then led that company as CPO.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-01T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M40S",
      "viewCount": 1190,
      "likeCount": 24,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/yASxPZ-tZe0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/yASxPZ-tZe0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/yASxPZ-tZe0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/yASxPZ-tZe0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/yASxPZ-tZe0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=yASxPZ-tZe0"
    },
    {
      "id": "9iN-cPnp7xg",
      "title": "[Evals Workshop] Mastering AI Evaluation: From Playground to Production",
      "description": "This hands-on workshop will guide participants through the complete AI evaluation lifecycle using Braintrust, from initial prompt testing to production monitoring. Attendees will learn to build evaluation frameworks that ensure their AI applications perform reliably in real-world scenarios. Topics covered include both offline and online evaluation strategies, logging and feedback systems, and human review processes.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-07-01T04:43:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H25M8S",
      "viewCount": 6082,
      "likeCount": 100,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/9iN-cPnp7xg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/9iN-cPnp7xg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/9iN-cPnp7xg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/9iN-cPnp7xg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/9iN-cPnp7xg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=9iN-cPnp7xg"
    },
    {
      "id": "J-9EbJBxcbg",
      "title": "Intro to GraphRAG — Zach Blumenfeld",
      "description": "Learn the foundations of GraphRAG, starting with knowledge graph construction and then common retrieval patterns.\n---\nGraphRAG has gone from nice-to-have to essential as AI solutions have increased in sophistication. \n\nThis workshop will get you started, answering:\n\n- what is GraphRAG, and when do I need it?\n- what's the best way to construct a knowledge graph?\n- how do I combine unstructured and structured data?\n- how do I retrieve the right information?\n\nAbout Zach Blumenfeld\nZach Blumenfeld is a Data Science Product Specialist at Neo4j who helps empower the market with Neo4j’s industry-leading graph data science capabilities. He has first-hand experience with various modern-day DS/ML challenges, including criminal fraud detection, identity resolution, and recommendation systems. Having served in both data science and software developer capacities, Zach has applied graph computing to law enforcement and government entities in support of missions that counter drug trafficking, human smuggling, money laundering, and child exploitation. He has led the development and deployment of full-stack graph systems designed to facilitate broad data science and operational requirements.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-30T22:56:45Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H18M35S",
      "viewCount": 15457,
      "likeCount": 325,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/J-9EbJBxcbg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/J-9EbJBxcbg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/J-9EbJBxcbg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/J-9EbJBxcbg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/J-9EbJBxcbg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=J-9EbJBxcbg"
    },
    {
      "id": "FZoMSupg37E",
      "title": "Securing Agents with Open Standards — Bobby Tiernay and Kam Sween, Auth0",
      "description": "Shipping AI agents that are safe for production means solving some tough identity and authorization challenges that are not always obvious at the prototype stage. In practice, this comes down to a handful of deeply technical questions:\n- How do you make sure agents are only acting for the right user?\n- How do you prevent over-broad API access or data leaks?\n- How do you handle user approvals when there is no UI, or you need a human in the loop?\n- And how do you avoid the usual pain points like manual credential sharing, stale keys, or unpredictable scopes without writing a lot of brittle, custom code?\n\nThis talk digs into the real technical trade-offs behind building secure, user-aware AI agents. We will go beyond what to do and explain why, sharing the architectural decisions, open standards, and hard lessons learned from integrating OAuth, OIDC, RAR, and async authorization into agent-driven workflows.\n\nYou will see a hands-on demo using an open-source Node.js agent and open protocols, with a focus on practical integration and no magic. The session will show how these solutions have shaped our approach to identity in GenAI and where we see the field heading next.\n\nIf you are an engineer building AI apps that need real guardrails, not just a happy-path demo, we hope to leave you with some practical patterns, design rationale, and a clear view of the trade-offs for making your own agents production ready.\n\nAbout Bobby Tiernay\nBobby has spent eight years at Okta as an architect working on Auth0 and Okta Platform products. He's passionate about generative AI and loves experimenting with new tech in his free time. At work, he helps teams develop AI solutions that improve both internal tools and customer products. With a background in data security and AI governance, Bobby connects research ideas to real-world applications. He's driven by a simple goal: making identity security easier and more secure for the people who use Auth0. When tackling complex challenges, he keeps things straightforward, collaborative, and (hopefully 🤞) fun.\n\nAbout Kam Sween\nKam is a Staff Engineer at Auth0 (an Okta company), where he transforms regulation-heavy legacy systems into lean, cloud-native platforms—and builds the tools that make tomorrow’s tech possible today. As the tech lead for the AI Frameworks & Services team, Kam architects the SDKs and frameworks that help developers harness AI responsibly (and without accidentally scripting Skynet).\n\nWith over a decade of experience building secure, compliant platforms around some of the most sensitive data legally storable in the cloud, Kam brings a rare blend of deep technical fluency and regulatory savvy. His career spans the full stack—from low-level infrastructure to high-level developer experience—making him a natural prototyper of what’s next.\n\nWhether navigating contradictory compliance regimes or designing future-forward architectures, Kam is driven by a simple principle: scalability isn’t a buzzword—it’s a survival tactic. And speed? That’s just what happens when you build things the right way.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-30T22:55:54Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M41S",
      "viewCount": 997,
      "likeCount": 20,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/FZoMSupg37E/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/FZoMSupg37E/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/FZoMSupg37E/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/FZoMSupg37E/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/FZoMSupg37E/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=FZoMSupg37E"
    },
    {
      "id": "F_RyElT_gJk",
      "title": "The emerging skillset of wielding coding agents — Beyang Liu, Sourcegraph / Amp",
      "description": "It's raining coding agents! But while many are saying they're feeling the AGI, others say they're not that useful for serious programming. How much is hype and how much is a skill issue? We'll share empirical observations that help explain the divergence of developer opinion. And we'll cover emergent strategies uncovered by users of Amp, a new coding agent in research preview, that can help you employ agents to complete more complex tasks in production codebases.\n\nAbout Beyang Liu\nBeyang is the co-founder and CTO of Sourcegraph, the company behind Sourcegraph Code Search and Amp. Beyang started his career working on software for some of the largest banks as an engineer at Palantir, where he brought a background in machine learning and data analysis at Stanford.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps\n\nIntroduction & The State of AI in Coding\n[00:14] Current Discourse: The talk begins by acknowledging the polarized debate on AI's role in coding. While some elite programmers are skeptical, many developers find significant value in AI tools, suggesting a disconnect between top-tier and mainstream experience. Liu frames the discussion by referencing opinions from figures like Jonathan Blow and Eric S. Raymond, highlighting the varied perspectives in the field.\n\n[03:01] Paradigm Shift: The most significant mistake developers make is using new agents with old mental models. Liu emphasizes that we are in a \"step function transition\" in model capabilities, meaning that strategies from even six months ago are already outdated for leveraging the full power of today's agents.\n\nThe Three Eras of AI Coding Tools\n[05:06] GPT-3 Era (2022): This era was defined by text completion models. The primary application was \"copilot\" or \"autocomplete,\" where the AI would suggest the next few lines of code based on the preceding context.\n\n[05:24] ChatGPT Era (2023): The introduction of instruct-tuned models like GPT-3.5 led to the rise of chatbots. In the coding world, this manifested as \"ragbots,\" which combined a chat interface with a retrieval engine to answer questions about a codebase.\n\n[06:11] Agent Era (Present): The current era is defined by models capable of tool use and autonomous operation. This requires a new application architecture where the agent can directly edit files, run commands, and interact with external services to accomplish a goal.\n\nControversial Design Philosophy for Agents\n[07:27] Autonomous Edits\n[09:55] Unix Philosophy\n[10:24] New Applications\n\nLive Demo: Sourcegraph's Amp Agent\n[13:15] The Task\n[14:30] Tool Use\n[15:53] Sub-Agents\n[17:56] Planning & Execution\n[19:46] Nuanced Problem Solving\n\nBest Practices from Power Users\n[23:21] Detailed Prompts\n[24:21] Feedback Loops\n[28:03] Code Understanding\n[28:36] Code Reviews\n\nAnti-Patterns and Future Outlook\n[30:35] Micromanagement\n[30:46] Under-prompting\n[31:52] Parallel Agents\n[33:18] High-Ceiling Skill",
      "publishedAt": "2025-06-30T22:54:36Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT35M6S",
      "viewCount": 19486,
      "likeCount": 421,
      "commentCount": 17,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/F_RyElT_gJk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/F_RyElT_gJk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/F_RyElT_gJk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/F_RyElT_gJk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/F_RyElT_gJk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=F_RyElT_gJk"
    },
    {
      "id": "px2e2OOS2Sk",
      "title": "Agents, Access, and the Future of Machine Identity — Nick Nisi (WorkOS) + Lizzie Siegle (Cloudflare)",
      "description": "AI agents are calling APIs, submitting forms, and sending emails—but how do you control what they’re allowed to do? As agents act on behalf of users or organizations, traditional patterns like OAuth, session tokens, and role-based access often fall short.\nIn this talk, we’ll explore how machine identity is evolving to meet this new landscape. You’ll learn:\n\n- How to think about authentication for agents (not just humans)\n- What it means to authorize an action when the actor is an LLM or headless service\n- Real-world strategies from WorkOS and Cloudflare for assigning, managing, and revoking agent identity and access\n\nBy the end, you’ll walk away with practical tools and mental models to build agent-powered systems that are secure, auditable, and scalable.\n\nAbout Nick Nisi\nNick Nisi is an elite software engineer who is a veteran of open source web development, a lover of karaoke, an advocate for diversity in tech, a conference organizer extraordinaire, a lover of new experiences, and a beacon of expertise, kindness and hope for his development team.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-30T22:52:45Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M17S",
      "viewCount": 756,
      "likeCount": 20,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/px2e2OOS2Sk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/px2e2OOS2Sk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/px2e2OOS2Sk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/px2e2OOS2Sk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/px2e2OOS2Sk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=px2e2OOS2Sk"
    },
    {
      "id": "blrovBxxN9o",
      "title": "Turning Fails into Features: Zapier’s Hard-Won Eval Lessons — Rafal Willinski, Vitor Balocco, Zapier",
      "description": "Every agent failure can be a roadmap to your next breakthrough. This talk reveals how Zapier's evaluation system transforms frustrating user experiences into targeted improvements, creating a data flywheel that continuously strengthens our agents. You'll learn practical approaches for building the data flywheel, detecting implicit feedback signals, building solid evals, prioritizing metrics that actually matter, and why your most reliable evals might secretly be sabotaging your performance.\n\nAbout Rafal Wilinski\nRafal Wilinski is the AI Tech Lead for Zapier Agents, where he builds intelligent systems that enable workflow automation for millions of users. I'm passionate about bringing products to life from 0 to 1. Began my career with an interest for AWS cloud, where I've spent my first decade helping startups and enterprises build robust infrastructure. When not working, I'm most likely climbing or drinking whiskey (but not simultaneously).\n\nAbout Vitor Balocco\nVitor is a Staff Software Engineer on the AI R&D team at Zapier, involved in most of Zapier's AI initiatives:\n- Co-creator of Zapier Agents\n- Co-creator of Zapier MCP\n- Creator of the AI Zap builder (natural language to automation)\n- Co-creator of AI custom actions\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-30T17:15:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M15S",
      "viewCount": 3123,
      "likeCount": 75,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/blrovBxxN9o/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/blrovBxxN9o/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/blrovBxxN9o/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/blrovBxxN9o/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/blrovBxxN9o/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=blrovBxxN9o"
    },
    {
      "id": "iXhba366fQc",
      "title": "Building voice agents with OpenAI — Dominik Kundel, OpenAI",
      "description": "We'll walk through the differences between chained and speech-to-speech powered voice agents, how to approach them, best practices and transform a text-based agent into our first voice-enabled agent\n\nAbout Dominik Kundel\nDominik is a developer and product leader with a passion for Developer Experience and Generative AI. He's currently working on Developer Experience & SDKs at OpenAI. Previously he lead Product & Design for Twilio's Emerging Tech & Innovation organization where his team worked on customer-aware AI agents. Dominik loves tinkering with anything that can run JavaScript, from front-end servers to CLIs and coffee machines. You can find him tweeting @dkundel and in his spare time he's working on cocktails, food and photography.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\n\nTimestamps [0:00:00] :\n\nPart 1: High-Level Summary and Timestamps\nThe video is a presentation by Dominic from OpenAI on building voice agents. The main thesis is that voice agents are the future of accessible and information-dense technology, acting as an API to the real world. The presentation introduces the new OpenAI Agents SDK for TypeScript and dives deep into the architectures, best practices, and hands-on-building of these voice agents.\n\n[00:16] Introduction to voice agents.\n\n[01:28] Overview of the OpenAI Agents SDK for TypeScript.\n\n[03:27] The case for why voice agents are important.\n\n[04:21] A look at different architectures for voice agents.\n\n[01:00:16] Best practices for building voice agents.\n\n[01:17:31] A hands-on guide to building a voice agent.\n\n[38:07] Q&A session with the audience.\n\nPart 2: Detailed Technical Summary\nIntroduction to Voice Agents: Dominic defines voice agents as systems that can accomplish tasks independently for users, which are composed of a model, instructions, access to tools, and a runtime [01:04]. He emphasizes that these agents are designed to be autonomous and helpful.\n\nOpenAI Agents SDK for TypeScript: A new TypeScript SDK has been launched, mirroring the Python SDK, to provide a structured way to build agents based on OpenAI's best practices [01:35]. The SDK includes features like handoffs, guardrails, streaming I/O, tool support, built-in tracing, human-in-the-loop support with resumability, and native voice agent support [01:58].\n\nWhy Voice Agents?: Voice agents make technology more accessible [03:34] and are more information-dense due to the nuances of tone and voice [03:47]. A key advantage is their ability to act as an API to the real world, for instance, by calling a business that lacks a formal API [04:02].\n\nVoice Agent Architectures:\n\nChained Approach (Text-based): This architecture follows a speech-to-text to text-based agent to text-to-speech pipeline [04:34]. While easier to start with and offering more control, it suffers from challenges like turn detection, increased latency, and a loss of audio context [05:33].\n\nSpeech-to-Speech Approach: Here, the model is trained directly on audio for a more seamless conversational experience and tool usage [06:30]. This approach boasts lower latency and a more contextual understanding of tone and voice, leading to a more natural flow [06:47]. However, it is harder to integrate with existing text-based systems and struggles with complex decision-making [07:01].\n\nDelegation Approach: This hybrid approach uses a front-line agent for user interaction which then delegates complex tasks to more powerful reasoning models like GPT-4 mini or GPT-3 via tool calls [07:45]. A demo shows the agent effectively handling interruptions and delegating tasks such as checking the weather or processing refunds [08:00].\n\nBest Practices for Building:\n\nStart Small: Begin with a small and clear goal to make performance measurement and iteration more manageable [01:12:40].\n\nEarly Evaluations: Implement evaluations and guardrails early in the development process to ensure reliability and manage complexity as the agent grows [01:13:33].\n\nGenerative Tone: Leverage generative models to create a specific tone and personality for your agent by prompting for emotions and roles, for example using openai.fm [01:14:14].\n\nDescriptive Flows: Use JSON structures to guide the model through conversational flows, much like a human agent's script, to improve the processing of steps [01:16:46].\n\nHands-on Building: The presentation includes a live coding session where Dominic builds a voice agent from scratch [01:17:31]. He demonstrates setting up the agent, adding tools, and connecting it to a real-time browser session using Next.js and WebRTC. The demo showcases real-time interaction, interruption handling, conversation transcripts, debugging with the traces dashboard, human-in-the-loop tool execution approval, and agent handoffs for specialized tasks [01:30:29, 01:50:00].",
      "publishedAt": "2025-06-29T22:30:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H25M35S",
      "viewCount": 18857,
      "likeCount": 474,
      "commentCount": 13,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/iXhba366fQc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/iXhba366fQc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/iXhba366fQc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/iXhba366fQc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/iXhba366fQc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=iXhba366fQc"
    },
    {
      "id": "bUBF5V6oDKw",
      "title": "Containing Agent Chaos — Solomon Hykes, Dagger",
      "description": "AI agents promise breakthroughs but often deliver operational chaos. Building reliable, deployable systems with unpredictable LLMs feels like wrestling fog – testing outputs alone is insufficient when the underlying workflow is opaque and flaky. How do we move beyond fragile prototypes?\n\nThis talk, from the creator of Docker, argues the solution lies outside the model: engineering reproducible execution workflows built on rigorous architectural discipline. Learn how containerization, applied not just to deployment but to each individual step of an agent's workflow, provides the essential isolation and environmental consistency needed.\n\nDiscover how combining this granular container approach with patterns like immutable state management allows us to contain agent chaos, unlock effective testing, simplify debugging, and bring essential control and predictability back to building powerful AI agents you can actually ship with confidence.\n\nAbout Solomon Hykes\nSolomon Hykes is best known as the creator of Docker, the open-source platform that revolutionized software development and deployment through containerization. His work fundamentally changed how applications are built, shipped, and run by standardizing their execution environments. Drawing on his deep experience tackling complexity at the infrastructure level, Solomon is now Founder and CEO of Dagger, focusing on the foundational challenges of building and operating reliable, scalable AI agent systems. He is passionate about applying platform engineering principles to the emerging AI landscape, helping engineers navigate this technological shift and build more dependable systems.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-28T16:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT23M48S",
      "viewCount": 11192,
      "likeCount": 257,
      "commentCount": 27,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/bUBF5V6oDKw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/bUBF5V6oDKw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/bUBF5V6oDKw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/bUBF5V6oDKw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/bUBF5V6oDKw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=bUBF5V6oDKw"
    },
    {
      "id": "bk0TmxoZlUY",
      "title": "Evals 101 — Doug Guthrie, Braintrust",
      "description": "This hands-on workshop guides participants through the full AI evaluation lifecycle with Braintrust, from initial prompt testing to production monitoring. Attendees will build evaluation frameworks, practice offline and online strategies, and implement logging systems.\n\nAbout Doug Guthrie\nDoug Guthrie is a solutions engineer at Braintrust. Previously, he helped customers deploy data infrastructure at dbt Labs. He is also a proud girl dad.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:53:13Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT48M31S",
      "viewCount": 9201,
      "likeCount": 151,
      "commentCount": 11,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/bk0TmxoZlUY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/bk0TmxoZlUY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/bk0TmxoZlUY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/bk0TmxoZlUY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/bk0TmxoZlUY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=bk0TmxoZlUY"
    },
    {
      "id": "jJ45Yz1lJao",
      "title": "Why should anyone care about Evals? — Manu Goyal, Braintrust",
      "description": "An introduction to the evals track\n\nAbout Manu Goyal\nManu Goyal is the founding engineer at Braintrust. Previously, he developed autonomous systems at Nuro. He has an 8 year old Pomeranian named Hendrix.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:51:45Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M41S",
      "viewCount": 12142,
      "likeCount": 96,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/jJ45Yz1lJao/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/jJ45Yz1lJao/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/jJ45Yz1lJao/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/jJ45Yz1lJao/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/jJ45Yz1lJao/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=jJ45Yz1lJao"
    },
    {
      "id": "spvXj9tnWAQ",
      "title": "Engineering Better Evals: Scalable LLM Evaluation Pipelines That Work — Dat Ngo, Aman Khan, Arize",
      "description": "As LLM-powered products become more sophisticated, the need for scalable, reliable evaluation pipelines has never been more critical. This session dives deep into advanced LLM evaluation strategies that move beyond toy benchmarks and toward real-world production impact.\n\nWe’ll explore how to architect and implement evaluation pipelines that work across both online and offline environments—reducing dev complexity and accelerating iteration. The session will cover:\n\n- LLM-as-a-judge frameworks\n- Human-in-the-loop evaluation\n- How hybrid approaches unlock more robust and nuanced performance assessments\n\nWe’ll break down technical architectures, share real implementation patterns, and examine trade-offs between evaluation techniques to help engineers make informed choices.\nWhether you’re building from scratch or refining existing workflows, this talk offers practical strategies for crafting efficient, scalable, and accurate eval pipelines tailored to custom LLM products.\n\nAbout Dat Ngo\nI'm Dat Ngo, Director of AI Solutions at Arize, where I work with the world's largest companies to build and optimize AI applications for their business. With nearly a decade of experience in the AI space, I specialize in helping organizations tackle their biggest challenges around AI evaluation, observability, and making AI systems work reliably at scale.\n\nAt Arize, we partner with industry leaders including Reddit, Booking.com, Siemens, Roblox, and hundreds of other companies to solve the most complex problems in AI deployment and monitoring. This gives me unique insight into what it really takes to build production AI systems that deliver business value.\n\nMy passion for AI extends beyond the office—I eat, live, and breathe AI. I'm deeply engaged with the AI community through speaking, learning, and connecting with fellow practitioners who are pushing the boundaries of what's possible with artificial intelligence.\n\nAs a speaker, I bring real-world expertise from the trenches of enterprise AI deployment, sharing practical insights on evaluation frameworks, observability strategies, and the operational realities of making AI work at scale.\n\nAbout Aman Khan\nAman is Director of Product, LLM at Arize AI. Prior to Arize, Aman was the PM on the Jukebox Feature Store in the ML Platform team at Spotify across ~50 data science teams. Aman was also PM for ML Evaluation frameworks across data science and engineering teams for self-driving cars at Cruise, which helped launch the first self-driving car service in an urban environment. Aman studied Mechanical Engineering at UC Berkeley and lived in the SF Bay Area for 9 years before moving to NYC.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:49:38Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT24M46S",
      "viewCount": 2853,
      "likeCount": 44,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/spvXj9tnWAQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/spvXj9tnWAQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/spvXj9tnWAQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/spvXj9tnWAQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/spvXj9tnWAQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=spvXj9tnWAQ"
    },
    {
      "id": "6NIr_cYPglk",
      "title": "To the moon! Navigating deep context in legacy code with Augment Agent — Forrest Brazeal, Matt Ball",
      "description": "Shortened presentation-only version of our Apollo 11 workshop!\n\nAbout Forrest Brazeal\nForrest Brazeal is an author, tech educator, cartoonist, and Pwnie Award-winning songwriter. He left Google in 2024 to found the technical media company Freeman & Forrest. His community initiative, the Cloud Resume Challenge, has helped thousands of nontraditional learners take their first steps toward a career in tech.\n\nAbout Matt Ball\nMatt is passionate about empowering developers. At Postman, Matt was the first Solutions Architect where he helped build the go-to-market strategy. Matt previously led Professional Services Engineering at Qubit.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:46:59Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M24S",
      "viewCount": 1352,
      "likeCount": 31,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/6NIr_cYPglk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/6NIr_cYPglk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/6NIr_cYPglk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/6NIr_cYPglk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/6NIr_cYPglk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=6NIr_cYPglk"
    },
    {
      "id": "knH3fmGAteQ",
      "title": "Serving Voice AI at Scale — Arjun Desai (Cartesia) & Rohit Talluri (AWS)",
      "description": "Real-Time Voice AI applications demand the lowest possible latencies to enhance user experiences with more advanced reasoning and agentic capabilities. AWS is hosting Arjun Desai, co-founder of Cartesia, in a fireside chat for a technical deep dive into learnings and best practices for building a state-of-the-art inference stack that serves global enterprise customers.\n\nAbout Arjun Desai\nCofounder @ Cartesia | Prev. Stanford ML PhD\n\nAbout Rohit Talluri\nAmazon Web Services (AWS) Generative AI ML Frameworks, focusing on Foundation Model Training & Inference.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:46:13Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M5S",
      "viewCount": 1186,
      "likeCount": 23,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/knH3fmGAteQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/knH3fmGAteQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/knH3fmGAteQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/knH3fmGAteQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/knH3fmGAteQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=knH3fmGAteQ"
    },
    {
      "id": "HT4l0DeP69I",
      "title": "Ship it! Building Production Ready Agents — Mike Chambers, AWS",
      "description": "Explore the practical challenges and solutions for deploying AI agents in real-world production environments. Through detailed technical analysis and practical examples, we'll examine strategies for building and orchestrating agent systems at scale. We'll cover critical infrastructure decisions, scalability frameworks, and best practices for creating robust, production-ready agent architectures.\n\nAbout Mike Chambers\nMike is a passionate developer advocate and expert in the fields of machine learning, AI, and generative AI. With a strong background in cloud computing, he brings a unique blend of technical knowledge and communication skills to engage and inspire audiences. Join Mike in exploring the possibilities and shaping the future of these transformative technologies.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:45:16Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M37S",
      "viewCount": 1965,
      "likeCount": 27,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/HT4l0DeP69I/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/HT4l0DeP69I/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/HT4l0DeP69I/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/HT4l0DeP69I/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/HT4l0DeP69I/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=HT4l0DeP69I"
    },
    {
      "id": "Q3NreEAdKMc",
      "title": "Introducing Strands Agents, an Open Source AI Agents SDK — Suman Debnath, AWS",
      "description": "Building AI agents used to require complex orchestration, extensive scaffolding, and months of tuning. With Strands Agents, an open source SDK from AWS. You can now build, test, and deploy intelligent agents in just a few lines of code. This session introduces the model-driven approach behind Strands, where a model, a prompt, and a set of tools are all you need to create powerful, production-ready agents. Learn how Strands leverages modern foundation models to handle reasoning, tool use, and reflection, reducing development time from months to days.\n\nAbout Suman Debnath\nSuman Debnath is a Principal Machine Learning Advocate at Amazon Web Services. Currently, his focus is on Supervised Learning, Natural Language Processing (NLP), Large Language Models (LLMs), and Retrieval Augmented Generation (RAG). Suman is committed to leveraging open-source tools like LangChain, PyTorch, Numpy, and Pandas for advancing machine learning. He has developed performance benchmarking and monitoring tools for distributed storage systems. Suman has spoken at over 100 global events, including AWS re:Invent, AI Engineer Summit, PyCon, PyData, ODSC, and meetups across multiple countries.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:44:12Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M26S",
      "viewCount": 4076,
      "likeCount": 65,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Q3NreEAdKMc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Q3NreEAdKMc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Q3NreEAdKMc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Q3NreEAdKMc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Q3NreEAdKMc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Q3NreEAdKMc"
    },
    {
      "id": "ROfHHJmumcc",
      "title": "Data is Your Differentiator: Building Secure and Tailored AI Systems — Mani Khanuja, AWS",
      "description": "As  organizations seek to harness their proprietary data while maintaining  security and compliance, Amazon Bedrock provides a comprehensive framework  for building tailored AI applications. Using Amazon Bedrock Knowledge Bases  and Amazon Bedrock Data Automation, organizations can create AI solutions  that truly understand their unique business context, terminology, and  requirements. Combined with Amazon Bedrock Guardrails, these capabilities  enhance the accuracy and relevance of AI-generated responses, while ensuring  that sensitive information remains protected within the organization's  control - enabling businesses to build secure and compliant enterprise-grade  generative AI solutions that accelerate time to value.\n\nAbout Mani Khanuja\nMani Khanuja is a Principal Generative AI Specialist SA, and an author of the book Applied Machine Learning and High Performance Computing on AWS. She leads machine learning projects in various domains such as computer vision, natural language processing, and generative AI. She speaks at internal and external conferences such AWS re:Invent, Women in Manufacturing West, YouTube webinars, and GHC 23. In her free time, she likes to go for long runs along the beach.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:42:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M10S",
      "viewCount": 480,
      "likeCount": 12,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ROfHHJmumcc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ROfHHJmumcc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ROfHHJmumcc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ROfHHJmumcc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ROfHHJmumcc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ROfHHJmumcc"
    },
    {
      "id": "6YdPI9YbjbI",
      "title": "How to build world-class AI products — Sarah Sachs (AI lead @ Notion) &  Carlos Esteban (Braintrust)",
      "description": "Join us for a hands-on workshop where you'll learn practical strategies to evaluate AI applications throughout their lifecycle—from initial testing of prompts to ongoing monitoring in production. We’re excited to host Sarah Sachs, AI Lead at Notion, who will share insights into how Notion built their acclaimed Notion AI.\n\nAbout Carlos Esteban\nCarlos Esteban is a Solutions Engineer at Braintrust. Previously, he helped enterprises secure and scale infrastructure at HashiCorp. He’s also a former tennis player turned yoga enthusiast, still auditioning his next full-time sport.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:40:32Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H43M46S",
      "viewCount": 2368,
      "likeCount": 36,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/6YdPI9YbjbI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/6YdPI9YbjbI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/6YdPI9YbjbI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/6YdPI9YbjbI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/6YdPI9YbjbI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=6YdPI9YbjbI"
    },
    {
      "id": "tzRvcTEapzo",
      "title": "From Mixture of Experts to Mixture of Agents with Super Fast Inference - Daniel Kim & Daria Soboleva",
      "description": "Our hands-on workshop will walk you through how to build your own Mixture of Agents (MoA) system using the fastest, and most capable open models available: Qwen3-32B and Llama 3.3-70B. MoA is an emerging architecture that combines the strengths of multiple large language models in a layered, agent-based design. This approach delivers superior performance by enabling specialized agents to collaborate across layers—outperforming today’s frontier models in both accuracy and efficiency.\n\nTo ground this new paradigm in its roots, we’ll also explore how Mixture of Experts (MoE) architectures continue to push the boundaries of scale and specialization. Learn how Cerebras trains state-of-the-art MoEs from Daria Soboleva, Head Research Scientist.\n\nAbout Daniel Kim\nI'm currently the Head of Growth at Cerebras Systems, the world's fastest provider of AI Inference built on the Cerebras Wafer-Scale Engine. I live in sunny and foggy San Francisco, CA. You can find me relaxing in the park, eating spicy noodles, and recently running!\n\nAbout Daria Soboleva\nDaria Soboleva is a Head Research Scientist at Cerebras working on efficient AI systems. Prior to Cerebras, Daria worked at Google, building expertise in research and engineering. She's the creator of SlimPajama (627B token dataset with 1M+ downloads) and BTLM-3B-8K, a model achieving 7B-level performance with less compute. Daria specializes in optimizing LLM architectures with focus on mixture-of-experts models and hardware-efficient training.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:38:41Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT53M15S",
      "viewCount": 3638,
      "likeCount": 75,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/tzRvcTEapzo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/tzRvcTEapzo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/tzRvcTEapzo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/tzRvcTEapzo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/tzRvcTEapzo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=tzRvcTEapzo"
    },
    {
      "id": "lArgRvBV3tQ",
      "title": "Forget RAG Pipelines—Build Production Ready Agents in 15 Mins: Nina Lopatina, Rajiv Shah, Contextual",
      "description": "Want to take advantage of your data, but don't want to reinvent RAG infrastructure? Join our workshop and see how you can deploy Agentic RAG in minutes using Contextual AI's managed RAG solution. We'll explore how Contextual handles intelligent parsing and chunking of your data, retrieves information with state of the art accuracy, and generates responses with a multi layered set of guardrails against hallucinations. Together, we'll build an end-to-end Agentic RAG pipeline and demonstrate its integration with Claude Desktop via MCP, so you can see how this could plug into your existing ecosystem.\n\nBy the end of this session, you'll have a functioning Agentic RAG prototype that you can easily customize and deploy to production for your specific use cases, even with complex, unstructured documents.\n\nAbout Nina Lopatina\nNina Lopatina is Lead Developer Advocate at Contextual AI, the fastest way for developers to build accurate, scalable RAG agents. She focuses on enabling developers to transform unstructured data into applications by connecting product, content, and community. Nina has worked as a developer and leader in the NLP and language for the last 7 years. She began her tech career after applying machine learning techniques to neural data throughout her PhD and postdoctoral research focused on reinforcement learning and decision-making. When she is not working, Nina is likely chasing fresh snow on the slopes or camping and hiking with her family.\n\nAbout Rajiv Shah\nRajiv Shah is the Chief Evangelist at Contextual AI with a passion and expertise in Practical AI. He focuses on enabling enterprise teams to succeed with AI. Rajiv has worked on GTM teams at leading AI companies, including Hugging Face in open-source AI, Snorkel in data-centric AI, Snowflake in cloud computing, and DataRobot in AutoML. He started his career in data science at State Farm and Caterpillar.\n\nRajiv is a widely recognized speaker on AI, published over 20 research papers, been cited over 1000 times, and received over 20 patents. He holds a PhD in Communications and a Juris Doctor from the University of Illinois at Urbana Champaign. You find him on social media with his short videos, @rajistics, that have received over ten million views.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:35:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H15M43S",
      "viewCount": 9164,
      "likeCount": 167,
      "commentCount": 16,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/lArgRvBV3tQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/lArgRvBV3tQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/lArgRvBV3tQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/lArgRvBV3tQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/lArgRvBV3tQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=lArgRvBV3tQ"
    },
    {
      "id": "fWY1FQwpWkY",
      "title": "Milliseconds to Magic: Real‑Time Workflows using the Gemini Live API and Pipecat",
      "description": "The Gemini Live API GA  is now powered by Google's best cost-effective thinking model Gemini 2.5 Flash. We will do a deep dive on the capabilities that the Gemini Live API combined with Pipecat unlock for devs with special focus on session management, turn detection, tool use (including async function calls), proactivity, multilinguality and integration with telephony and other infra. We will demo some of the more innovative capabilities. We will also talk through some customer use cases - especially how customers can use Pipecat to extend these realtime multimodal capabilities to client side applications such as customer support agents, gaming agents, tutoring agents etc. In addition, we also have an experimental version of the Live API powered by with Google's native audio offering that can be tried in an experimental capacity . This experimental model  can communicate with seamless, emotive, steerable, multilingual dialogue and enhances use cases where more natural voices can be a big differentiator.\n\nAbout Kwindla Kramer\nKwin works on large-scale WebRTC infrastructure at Daily. He is the originator of Pipecat, the widely used, open source, vendor neutral voice agent framework supported by NVIDIA, Google, AWS and used by hundreds of startups. Before co-fonding Daily, Kwin built the sci-fi user interfaces in Minority Report and Iron Man.\n\nAbout Shrestha Basu Mallick\nShrestha Basu Mallick is Group Product Manager and product lead for Gemini API at Google DeepMind. Prior to this, Shrestha led product development for AI assistance across all Google coding surfaces. Shrestha’s first role in Alphabet was at X, the Moonshot Factory, as Head of Product for a materials discovery platform that has since graduated to become its own startup. Before Google, Shrestha has had various roles in product and strategy at Salesforce Einstein, McKinsey, and Docusign. Shrestha holds a PhD in Applied Physics from Stanford.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:31:41Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M43S",
      "viewCount": 1348,
      "likeCount": 23,
      "commentCount": 9,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/fWY1FQwpWkY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/fWY1FQwpWkY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/fWY1FQwpWkY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/fWY1FQwpWkY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/fWY1FQwpWkY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=fWY1FQwpWkY"
    },
    {
      "id": "ujt0da9Z29Q",
      "title": "Realtime Conversational Video with Pipecat and Tavus — Chad Bailey and Brian Johnson, Daily & Tavus",
      "description": "Tavus shipped the world's first realtime video avatar platform last year. Developers use Tavus' conversational video APIs to create education, social, and customer support agents. The Tavus team built their innovative product using the Pipecat open source framework and Daily's global WebRTC infrastructure. Join us for a technical deep dive into conversational video.\n\nAbout Char Bailey\nChad Bailey started his career testing software for the Space Shuttle. After many years of building web apps, he's spent the last several working on real-time communication at Daily. Most recently, he's been building the Pipecat framework, and a series of increasingly ridiculous voice bots to show it off.\n\nAbout Brian Johnson\nBrian Johnson is a Staff Engineer at Tavus, a market-leading generative AI video research company building foundational models and operating systems for human-AI interaction. With a background in electrical engineering and law, he brings decades of experience building and scaling systems across frontend, backend, and ML infrastructure. At Tavus, Brian leads development of real-time AI systems that power lifelike digital humans. His work focuses on combining technical precision with human-centered design to push the boundaries of conversational video AI.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:30:54Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M46S",
      "viewCount": 968,
      "likeCount": 16,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ujt0da9Z29Q/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ujt0da9Z29Q/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ujt0da9Z29Q/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ujt0da9Z29Q/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ujt0da9Z29Q/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ujt0da9Z29Q"
    },
    {
      "id": "YrUBFXa1KUY",
      "title": "Vector Search Benchmark[eting] - Philipp Krenn, Elastic",
      "description": "Every vector database out there is both faster and slower than any other competitor — if you believe all the benchmarketing out there.\nLet's turn the marketing into useful benchmarks that actually help you:\n1. How not to benchmark (spoiler: don’t trust the glossy charts).\n2. What’s uniquely tricky about benchmarking vector search.\n3. How to build meaningful benchmarks tailored to your use case.\n\nPS: Yes, you will have to get your hands dirty. Never believe a benchmark that you haven't tweaked yourself.\n\nAbout Philipp Krenn\nPhilipp leads Developer Relations at Elastic — the company behind the Elasticsearch, Kibana, Beats, and Logstash. Based in San Francisco, he lives to demo interesting technology and solve challenging problems — all with a smile and a terminal window.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:28:48Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M10S",
      "viewCount": 636,
      "likeCount": 7,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/YrUBFXa1KUY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/YrUBFXa1KUY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/YrUBFXa1KUY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/YrUBFXa1KUY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/YrUBFXa1KUY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=YrUBFXa1KUY"
    },
    {
      "id": "xJXm4Wcw4m8",
      "title": "Taming Rogue AI Agents with Observability-Driven Evaluation — Jim Bennett, Galileo",
      "description": "LLM agents often drift into failure when prompts, retrieval, external data, and policies interact in unpredictable ways. This session introduces a repeatable, metric-driven framework for detecting, diagnosing, and correcting these undesirable behaviors in agentic systems at production scale.\n\nAbout Jim Bennett\nJim is the worlds most energetic dev rel, and a Principal Developer Advocate at Galileo, focusing on enabling AI developers to be more productive by monitoring and evaluating LLMs and AI agents. He’s British, so sounds way smarter than he actually is, and lives in the Pacific North West of the USA. In the past he’s lived in 4 continents working as a developer in the mobile, desktop, and scientific space. He's spoken at conferences and events all around the globe, organised meetup groups and communities, and written books on mobile development and IoT. He is currently a Microsoft MVP for AI and Developer Tools.\n\nHe also hates and is allergic to cats, but has a 12-year-old who loves cats, so he has 2 cats.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:27:15Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M14S",
      "viewCount": 862,
      "likeCount": 17,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/xJXm4Wcw4m8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/xJXm4Wcw4m8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/xJXm4Wcw4m8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/xJXm4Wcw4m8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/xJXm4Wcw4m8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=xJXm4Wcw4m8"
    },
    {
      "id": "d9rsC6_VLoA",
      "title": "Building agent fleet architectures your CISO doesn't hate — Lou Bichard, Gitpod",
      "description": "Security is the biggest blocker for agent orchestration adoption in regulated industries for SWE agents. Gitpod's agent orchestration went from an originally self-hosted kubernetes architecture to the current 'bring your own cloud' model that enables deployment our SWE agent orchestration platform in secure environments. The architecture allows customers to securely connect their foundational models and agent memory solutions and comes with features like auto-suspend and resume for agent fleets. In this talk we deep dive into the architecture to share our years of learnings in how to secure agent workloads at scale in secure and regulated environments.\n\nAbout Lou Bichard   \nLou is Product Manager at Gitpod, a platform for secure development environments for both humans and agents powering some of the world's largest financial, insurance, and health care providers. Lou was previously Principal Engineer for developer experience at DAZN building a platform for ~15M global users in 150+ markets.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:25:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M52S",
      "viewCount": 246,
      "likeCount": 2,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/d9rsC6_VLoA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/d9rsC6_VLoA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/d9rsC6_VLoA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/d9rsC6_VLoA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/d9rsC6_VLoA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=d9rsC6_VLoA"
    },
    {
      "id": "H6MrR5NbTZA",
      "title": "Don’t get one-shotted: Use AI to test, review, merge, and deploy code — Tomas Reimers, Graphite",
      "description": "As AI tools like GitHub Copilot and ChatGPT help engineers generate code at an unprecedented rate, the “outer loop”—reviewing, testing, merging, and deploying—becomes more vital than ever. Studies have shown that up to half of AI-generated solutions contain bugs or vulnerabilities, underscoring the continued importance of thorough, human-in-the-loop reviews. In this talk we'll take a look at how next-gen developer tools can harness AI not just for generating code, but also reviewing it. By thoughtfully integrating AI into that fully understands your entire codebase, teams can accelerate velocity without sacrificing quality.\n\nAttendees will learn real-world strategies and best practices for establishing an “outer loop” that safely and efficiently deploys high volumes of AI-assisted code,  without compromising reliability. We’ll also discuss pitfalls to avoid when integrating AI into existing pipelines.\n\nAbout Tomas Reimers\nTomas Reimers, Forbes 30u30 class of ‘23, is the CPO and Co-founder of Graphite, the NYC DevTools startup that’s revolutionizing how the fastest-moving engineers build and ship software. Prior to co-founding Graphite, Tomas was a dev-tools engineer at Meta, developing a framework that supported the work of 200+ product teams and more than 1000 developers. He is passionate about all things software and will enthusiastically debate best engineering and architecture practices with you for hours.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:25:04Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M45S",
      "viewCount": 410,
      "likeCount": 3,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/H6MrR5NbTZA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/H6MrR5NbTZA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/H6MrR5NbTZA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/H6MrR5NbTZA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/H6MrR5NbTZA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=H6MrR5NbTZA"
    },
    {
      "id": "72XxWkd8Jrk",
      "title": "Effective agent design patterns in production — Laurie Voss, LlamaIndex",
      "description": "At LlamaIndex we see a lot of agents built every day, and we've got a sense of what works and what doesn't. We've distilled those learnings down into a series of patterns and best practices for building real-world, production agents, and we're here to share them. You'll learn patterns for applying structure and guidance to famously nondeterministic LLMs and get concrete instruction on how to implement them.\n\nAbout Laurie Voss\nLaurie has been a web developer for 27 years, and along the way he co-founded npm, Inc.. He cares passionately about making technology accessible to everyone by demystifying complex technology topics.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:22:56Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M38S",
      "viewCount": 10330,
      "likeCount": 254,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/72XxWkd8Jrk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/72XxWkd8Jrk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/72XxWkd8Jrk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/72XxWkd8Jrk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/72XxWkd8Jrk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=72XxWkd8Jrk"
    },
    {
      "id": "l614N5W60ls",
      "title": "Foundry Local: Cutting-Edge AI experiences on device with ONNX Runtime/Olive — Emma Ning, Microsoft",
      "description": "About Emma Ning \nEmma Ning is a Principal PM in the Microsoft AI Framework team, focusing on AI model operationalization and acceleration with ONNX Runtime/Olive for open and interoperable AI. She has more than five years of product experience in search engines taking advantage of machine learning techniques and spent more than six years exploring AI adoption among various businesses. She is passionate about bringing AI solutions to solve business problems as well as enhancing product experience.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:21:41Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT22M52S",
      "viewCount": 328,
      "likeCount": 2,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/l614N5W60ls/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/l614N5W60ls/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/l614N5W60ls/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/l614N5W60ls/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/l614N5W60ls/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=l614N5W60ls"
    },
    {
      "id": "EAfP8pDs7h4",
      "title": "[Full Workshop] Vibe Coding at Scale: Customizing AI Assistants for Enterprise Environments",
      "description": "\"Vibe coding\" often falters in complex enterprise environments. Drawing from real implementations, this talk demonstrates systematic approaches to customizing AI assistants for challenging codebases. We'll explore specialized techniques for navigating complex architectures, evidence-based strategies for undocumented legacy systems, methodologies for maintaining context across polyglot environments, and frameworks for standardizing AI usage while preserving developer autonomy. Through case studies from finance and healthcare, we'll present a comprehensive evaluation framework that bridges the gap between AI's theoretical capabilities and practical enterprise implementation, enabling true flow-state collaboration even within the most complex development ecosystems.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:19:00Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H20M38S",
      "viewCount": 825,
      "likeCount": 12,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/EAfP8pDs7h4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/EAfP8pDs7h4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/EAfP8pDs7h4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/EAfP8pDs7h4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/EAfP8pDs7h4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=EAfP8pDs7h4"
    },
    {
      "id": "C1NivhYS1sI",
      "title": "Unlocking AI Powered DevOps Within Your Organization — Jon Peck, GitHub",
      "description": "Software development is a team sport, with many different roles, where eveyone can win. But success isn't guaranteed; it depends on specific practices, policies, and tools which enable minimally-siloed, AI-accelerated collaboration across all parts of the DevOps process, from PM to development to CI/CD and security.\n\nDiscover the patterns and tools which lead to success, methods for changing the status quo, and perhaps a few horror stories. We'll touch on innersourcing, cloud development, AI, automation, governance, security, scaling and more -- with actionable learnings for everyone from small maintainer communities to F500 Enterprises.\n\nAbout Jon Peck\nAn Enterprise Advocate (and occasional manager) at GitHub, Jon Peck meets daily with maintainers, startups, and F500 executives to familiarize them with industry best practices, policy suggestions, and product capabilities across DevOps and AI. With 25+ years of experience as a fullstack developer, architect, and advocate, he aims to to bring engaging, real-world learnings to both boardrooms and global conferences.\n\n- Speaker (conferences): Dev Exec World 2025, STARWEST 2024, InnerSource Summit 2023, GitHub Galaxy 2023, DevWeek Management 2023, Startup Grind 2022, GitHub InFocus 2022, DeveloperWeek 2018-20, SeattleJS, Global AI Conf 2018-19, AI Next 2019-20, MLOps World, Data Innovation Summit, Nordic APIs 2018-19 (keynote), ODSC East+West, API World, O'Reilly AI, OSCON\n- Speaker (tech schools): Galvanize, CodeFellows, Metis, Epicodus, Alchemy\n- Organizer: Seattle Building Intelligent Applications Meetup\n- Educator: Cascadia College, Seattle C&W, consultant\n- Lead Developer: Empower Engine, Giftstarter, Mass General Hospital, Cornell University\n- Technical Advocate: Algorithmia, GitHub\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:17:04Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT22M13S",
      "viewCount": 519,
      "likeCount": 10,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/C1NivhYS1sI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/C1NivhYS1sI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/C1NivhYS1sI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/C1NivhYS1sI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/C1NivhYS1sI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=C1NivhYS1sI"
    },
    {
      "id": "i1uPAN6uW4s",
      "title": "Vibe Coding at Scale: Customizing AI Assistants for Enterprise Environments - Harald Kirshner,",
      "description": "\"Vibe coding\" often falters in complex enterprise environments. Drawing from real implementations, this talk demonstrates systematic approaches to customizing AI assistants for challenging codebases. We'll explore specialized techniques for navigating complex architectures, evidence-based strategies for undocumented legacy systems, methodologies for maintaining context across polyglot environments, and frameworks for standardizing AI usage while preserving developer autonomy. Through case studies from finance and healthcare, we'll present a comprehensive evaluation framework that bridges the gap between AI's theoretical capabilities and practical enterprise implementation, enabling true flow-state collaboration even within the most complex development ecosystems.\n\nAbout Harold Kirshner\nI'm Harald Kirschner, a Principal Product Manager at Microsoft working on Visual Studio Code and GitHub Copilot, supporting over 40 million active developers code faster and more efficiently across virtually any programming language. Before Microsoft, I led Developer Experience at Mozilla, where I led Firefox DevTools and helped deliver Firefox Quantum, which doubled browser performance. My background in software engineering, including early work on MooTools, gives me hands-on insight into the challenges developers face daily. When I'm not working, I enjoy hiking California's coastal trails and experimenting with generative art. As a speaker at the AI Engineer Summit, I'm excited to share insights from our work on AI coding tools and Model Context Protocol to help developers achieve flow state even in complex environments.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:15:59Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M26S",
      "viewCount": 586,
      "likeCount": 11,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/i1uPAN6uW4s/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/i1uPAN6uW4s/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/i1uPAN6uW4s/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/i1uPAN6uW4s/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/i1uPAN6uW4s/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=i1uPAN6uW4s"
    },
    {
      "id": "tHJSZ1-ZqcA",
      "title": "The Agent Awakens: Collaborative Development with Copilot - Christopher Harrison, GitHub",
      "description": "About Christopher Harrison\nChristopher is a long-time geek who's spent the bulk of his career training, supporting and upskilling developers. He's a web developer at heart with passions which span from Python to DevOps to TypeScript to AI. In his current role as an Enterprise Advocate for GitHub he seeks to help organizations improve their DevOps process and culture. When not found writing code he can be found running, playing Civilization, or spending time with his partner and their four-legged child (a rescue mutt).\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:11:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H4M6S",
      "viewCount": 485,
      "likeCount": 7,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/tHJSZ1-ZqcA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/tHJSZ1-ZqcA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/tHJSZ1-ZqcA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/tHJSZ1-ZqcA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/tHJSZ1-ZqcA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=tHJSZ1-ZqcA"
    },
    {
      "id": "JhJKgRAmfIU",
      "title": "AI Red Teaming Agent: Azure AI Foundry — Nagkumar Arkalgud & Keiji Kanazawa, Microsoft",
      "description": "In the age of autonomous AI agents, ensuring their safety and reliability is paramount. But how can we proactively uncover vulnerabilities before they impact real-world scenarios? Enter Azure AI Evaluation SDK’s Red Teaming Agent—a cutting-edge tool designed to rigorously challenge your AI agents, exposing hidden risks and unexpected behaviors. This session will guide you through the powerful capabilities of Azure’s Red Teaming Agent, demonstrating how it simulates adversarial scenarios, stress-tests agentic decision-making, and ensures your applications remain robust, ethical, and safe. You’ll learn practical techniques for systematically identifying weaknesses, interpreting evaluation results, and integrating safety checks into your development lifecycle. Join us to explore how embracing adversarial testing not only mitigates risks but strengthens trust in your AI solutions—keeping you ahead in the rapidly evolving landscape of responsible AI.\n\nAbout Nagkumar Arkalgud\nNagkumar Arkalgud is a Senior Software Engineer at Microsoft, working on the Azure AI Evaluation SDK. With 10 years of experience in software engineering, he designed and built the SDK that enables red teaming for GenAI applications. Nagkumar focuses on advancing AI evaluation methodologies to optimize tools for AI applications.\n\nAbout Keiji Kanazawa\nProduct lead working on a world class machine learning / artificial intelligence platform at Microsoft. Proven product leader with over 20 years deep technical expertise building web scale services and API platforms.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:07:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M31S",
      "viewCount": 458,
      "likeCount": 7,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/JhJKgRAmfIU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/JhJKgRAmfIU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/JhJKgRAmfIU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/JhJKgRAmfIU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/JhJKgRAmfIU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=JhJKgRAmfIU"
    },
    {
      "id": "G1hhmz6mXT0",
      "title": "Collaborating with Agents in your Software Dev Workflow - Jon Peck & Christopher Harrison, Microsoft",
      "description": "GitHub Copilot's agentic capabilities enhance its ability to act as a peer programmer. From the IDE to the repository, Copilot can generate code, run tests, and perform tasks like creating pull requests using Model Context Protocol (MCP). This instructor-led lab will guide you through using agent capabilities on both the client and the server: Key takeaways include:\nUnderstanding how to bring agents into your software development workflow\nIdentifying scenarios where agents can be most impactful, as well as tips and tricks to provide the right context to lead to success\nDiscovering how Model Context Protocol provides access to an additional set of external tools and capabilities that the agent can use\nRecommended practices to accelerate your development while maintaining code quality.\n\nAbout Jon Peck\nAn Enterprise Advocate (and occasional manager) at GitHub, Jon Peck meets daily with maintainers, startups, and F500 executives to familiarize them with industry best practices, policy suggestions, and product capabilities across DevOps and AI. With 25+ years of experience as a fullstack developer, architect, and advocate, he aims to to bring engaging, real-world learnings to both boardrooms and global conferences.\n\n- Speaker (conferences): Dev Exec World 2025, STARWEST 2024, InnerSource Summit 2023, GitHub Galaxy 2023, DevWeek Management 2023, Startup Grind 2022, GitHub InFocus 2022, DeveloperWeek 2018-20, SeattleJS, Global AI Conf 2018-19, AI Next 2019-20, MLOps World, Data Innovation Summit, Nordic APIs 2018-19 (keynote), ODSC East+West, API World, O'Reilly AI, OSCON\n- Speaker (tech schools): Galvanize, CodeFellows, Metis, Epicodus, Alchemy\n- Organizer: Seattle Building Intelligent Applications Meetup\n- Educator: Cascadia College, Seattle C&W, consultant\n- Lead Developer: Empower Engine, Giftstarter, Mass General Hospital, Cornell University\n- Technical Advocate: Algorithmia, GitHub\n\nAbout Christopher Harrison\nChristopher is a long-time geek who's spent the bulk of his career training, supporting and upskilling developers. He's a web developer at heart with passions which span from Python to DevOps to TypeScript to AI. In his current role as an Enterprise Advocate for GitHub he seeks to help organizations improve their DevOps process and culture. When not found writing code he can be found running, playing Civilization, or spending time with his partner and their four-legged child (a rescue mutt).\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:05:42Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H4M6S",
      "viewCount": 573,
      "likeCount": 7,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/G1hhmz6mXT0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/G1hhmz6mXT0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/G1hhmz6mXT0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/G1hhmz6mXT0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/G1hhmz6mXT0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=G1hhmz6mXT0"
    },
    {
      "id": "J4vPq2i0QzE",
      "title": "Agentic Excellence: Mastering AI Agent Evals w/ Azure AI Evaluation SDK — Cedric Vidal, Microsoft",
      "description": "As AI agents transition from experimental assistants to critical components of enterprise workflows, reliably evaluating their performance becomes essential. But how do you systematically measure an AI agent’s capabilities, contextual understanding, and accuracy across diverse scenarios?\n\nIn this talk, we'll dive deep into the Azure AI Evaluation SDK, an innovative tool designed to rigorously assess agentic applications. Learn how to create powerful evaluations using structured test plans, scenarios, and advanced analytics that pinpoint strengths and expose hidden weaknesses. Through practical examples and real-world case studies, you'll discover how companies are already leveraging this SDK to enhance agent trustworthiness, reliability, and performance.\n\nWhether you're developing conversational agents, data-driven decision-makers, or autonomous workflow orchestrators, this session equips you with the techniques and insights needed to ensure your AI solutions deliver exceptional value and exceed user expectations.\"\n\nAbout Cedric Vidal\nCedric Vidal is a Principal AI Advocate at Microsoft, specializing in Generative AI 🤖, and the startup 🚀 and research 🔬 ecosystems. He is dedicated to promoting AI in startups and facilitating the transition of research and startup products to the market. If you're an AI Startup Founder or Engineer, I'd like to feature your work, come talk to me. Before his current role, Cedric spent 4 years as an Engineering Manager in the AI data labeling space for the self-driving 🚕 industry at Argo AI (now re-spawned as Latitude AI). He also served as the CTO of the Fintech AI SAAS startup Quicksign and worked as a software engineering services consultant for major Fintech enterprises for 10 years.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:04:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M1S",
      "viewCount": 1169,
      "likeCount": 13,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/J4vPq2i0QzE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/J4vPq2i0QzE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/J4vPq2i0QzE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/J4vPq2i0QzE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/J4vPq2i0QzE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=J4vPq2i0QzE"
    },
    {
      "id": "N4vCBM5YbN0",
      "title": "Building Code First AI Agents with Azure AI Agent Service — Cedric Vidal, Microsoft",
      "description": "This workshop offers a hands-on introduction to developing Large Language Model (LLM)-powered AI agents using Microsoft’s Azure AI Agent Service. Participants will build a conversational agent capable of analyzing sales data, generating visualizations, and delivering actionable insights.\n\nThe session takes a code-first approach using the Azure AI Foundry SDK for Python, and demonstrates how to integrate core Azure services including Azure OpenAI, Azure AI Search, and Azure Storage.\n\nAttendees will explore key concepts such as function calling, document grounding, and leveraging code interpreters to generate diagrams. The workshop also covers how to connect agents to external data sources like SQL databases (e.g., SQLite), enabling access to legacy relational systems.\n\nBy the end of the session, participants will have a solid foundation for building and deploying intelligent, code-first AI agents with Azure AI Agent Service—ready to power real-world applications.\n\nAbout Cedric Vidal\nCedric Vidal is a Principal AI Advocate at Microsoft, specializing in Generative AI 🤖, and the startup 🚀 and research 🔬 ecosystems. He is dedicated to promoting AI in startups and facilitating the transition of research and startup products to the market. If you're an AI Startup Founder or Engineer, I'd like to feature your work, come talk to me. Before his current role, Cedric spent 4 years as an Engineering Manager in the AI data labeling space for the self-driving 🚕 industry at Argo AI (now re-spawned as Latitude AI). He also served as the CTO of the Fintech AI SAAS startup Quicksign and worked as a software engineering services consultant for major Fintech enterprises for 10 years.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:03:21Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H54M6S",
      "viewCount": 794,
      "likeCount": 17,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/N4vCBM5YbN0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/N4vCBM5YbN0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/N4vCBM5YbN0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/N4vCBM5YbN0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/N4vCBM5YbN0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=N4vCBM5YbN0"
    },
    {
      "id": "DeFF3J8T5Pk",
      "title": "How fast are LLM inference engines anyway? — Charles Frye, Modal",
      "description": "Open weights models and open source inference servers have made massive strides in the year since we last got together at AIE World's Fair.\n\nWhere once we had only pirated LLaMA 2 weights and Transformers, we now have an embarrassment of riches. In fact, we have too many choices! What's an AI engineer looking to self-host inference to do?\n\nIn this session, we'll share our benchmarking results from hundreds of runs across models, frameworks, and hardware. We'll also share tips and tricks from working with teams deploying LLM inference at scale.\n\nAbout Charles Frye\nCharles teaches people to build data, ML, and AI applications. He got his PhD from the University of California, Berkeley, in 2020 for work on the geometry of neural network optimization. He has since worked as an educator and evangelist for neural network applications at Weights & Biases, Full Stack Deep Learning, and now Modal Labs.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T10:01:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M7S",
      "viewCount": 765,
      "likeCount": 14,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/DeFF3J8T5Pk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/DeFF3J8T5Pk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/DeFF3J8T5Pk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/DeFF3J8T5Pk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/DeFF3J8T5Pk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=DeFF3J8T5Pk"
    },
    {
      "id": "W_CYk2ogcDI",
      "title": "RAG in 2025: State of the Art and the Road Forward — Tengyu Ma, MongoDB (acq. Voyage AI)",
      "description": "The talk will have three parts\n1.Roadmap debate: RAG vs. finetuning vs. long-context\n2.RAG today: benefits, challenges, and current solutions\n3.RAG tomorrow: AI models do more work\n\nAbout Tengyu Ma\nTengyu Ma is the Chief AI Scientist @ MongoDB and an Assistant Professor @ Stanford. He was the co-founder and CEO of Voyage AI before the acquisition by MongoDB.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:59:45Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M48S",
      "viewCount": 3173,
      "likeCount": 59,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/W_CYk2ogcDI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/W_CYk2ogcDI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/W_CYk2ogcDI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/W_CYk2ogcDI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/W_CYk2ogcDI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=W_CYk2ogcDI"
    },
    {
      "id": "pIPtpBZ6TKk",
      "title": "The State of AI Powered Search and Retrieval — Frank Liu, MongoDB (prev Voyage AI)",
      "description": "In this talk, we examine the state-of-the-art in AI-powered search and retrieval. We detail techniques for enhancing performance beyond base embedding models, including hybrid search, reranking strategies, query decomposition and document enrichment, the use of domain-specific and fine-tuned embeddings, custom data processing pipelines (ETL), and contextualized chunking methods.\n\nAbout Frank Liu\nFrank Liu is Staff Product Manager at MongoDB. He has over a decade of industry experience in machine learning and hardware engineering and presents at major industry events like the Open Source Summit Open Data Science Conference. In his spare time, he enjoys experimenting with and training models. Frank holds MS and BS degrees in Electrical Engineering from Stanford University.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:57:57Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M35S",
      "viewCount": 658,
      "likeCount": 16,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/pIPtpBZ6TKk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/pIPtpBZ6TKk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/pIPtpBZ6TKk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/pIPtpBZ6TKk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/pIPtpBZ6TKk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=pIPtpBZ6TKk"
    },
    {
      "id": "W2HVdB4Jbjs",
      "title": "Architecting Agent Memory: Principles, Patterns, and Best Practices — Richmond Alake, MongoDB",
      "description": "In the rapidly evolving landscape of agentic systems, memory management has emerged as a key pillar for building intelligent, context-aware AI Agents. Inspired by the complexity of human memory systems—such as episodic, working, semantic, and procedural memory—this talk unpacks how AI agents can achieve believability, reliability, and capability by retaining and reasoning over past experiences.\n\nWe’ll begin by establishing a conceptual framework based on real-world implementations from memory management libraries and system architectures:\nMemory Components representing various structured memory types (e.g., conversation, workflow, episodic, persona)\nMemory Modes reflecting operational strategies for short-term, long-term, and dynamic memory handling\n\nNext, the talk transitions to practical implementation patterns critical for effective memory lifecycle management:\n\nMaintaining rich conversation history and contextual awareness\nPersistence strategies leveraging vector databases and hybrid search\nMemory augmentation using embeddings, relevance scoring, and semantic retrieval\nProduction-ready practices for scaling memory in multi-agent ecosystems\nWe’ll also examine advanced memory strategies within agentic systems:\nMemory cascading and selective deletion\nIntegration of tool use and persona memory\nOptimizing performance around memory retrieval and LLM context window limits\nWhether you're developing autonomous agents, chatbots, or complex workflow orchestration systems, this talk offers knowledge and tactical insights for building AI that can remember, adapt, and improve over time.\nThis session is ideal for:\nAI engineers and agent framework developers\nArchitects designing Agentic RAG or multi-agent systems\nPractitioners building contextual, personalized AI experiences\nBy the end of the session, you’ll understand how to leverage memory as a strategic asset in agentic design—and walk away ready to build agents that not only act and reason but also remember. \n\n\n---related links---\n\nhttps://www.linkedin.com/in/richmondalake/",
      "publishedAt": "2025-06-27T09:56:46Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M37S",
      "viewCount": 78786,
      "likeCount": 2296,
      "commentCount": 47,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/W2HVdB4Jbjs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/W2HVdB4Jbjs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/W2HVdB4Jbjs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/W2HVdB4Jbjs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/W2HVdB4Jbjs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=W2HVdB4Jbjs"
    },
    {
      "id": "640KMYtxCeI",
      "title": "Building Multimodal AI Agents From Scratch — Apoorva Joshi, MongoDB",
      "description": "In this hands-on workshop, you will build a multimodal AI agent capable of processing mixed-media content—from analyzing charts and diagrams to extracting insights from documents with embedded visuals. Using MongoDB as a vector database and memory store, and Google's Gemini for multimodal reasoning, you will gain hands-on experience with multimodal data processing pipelines and agent orchestration patterns by implementing core components directly, using good ol' Python.\n\n---\nIn this hands-on workshop, you will build a multimodal AI agent capable of processing mixed-media content—from analyzing charts and diagrams to extracting insights from documents with embedded visuals. Using MongoDB as a vector database and memory store, and Google's Gemini for multimodal reasoning, you will gain hands-on experience with multimodal data processing pipelines and agent orchestration patterns by implementing core components directly, using good ol' Python.\n\nYou will be provided with a GitHub repository consisting of learning materials and resources required to successfully execute the hands-on portions of the workshop.\n\n---related links---\n\nhttps://www.linkedin.com/in/apoorvajoshi95/",
      "publishedAt": "2025-06-27T09:54:32Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT36M58S",
      "viewCount": 88758,
      "likeCount": 1560,
      "commentCount": 27,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/640KMYtxCeI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/640KMYtxCeI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/640KMYtxCeI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/640KMYtxCeI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/640KMYtxCeI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=640KMYtxCeI"
    },
    {
      "id": "CbiR9xS2skQ",
      "title": "Why Your Agent’s Brain Needs a Playbook: Practical Wins from Using Ontologies - Jesús Barrasa, Neo4j",
      "description": "You're trying to guide how your agents think and act. Code-orchestrated workflows are too rigid, but LLMs charting their own course feel too chaotic. When you need a middle ground, it’s time to reach for the secret weapon: ontologies. These graph-shaped fragments of actionable knowledge can fill in critical gaps.\n\nIn this talk, we’ll explore together how ontologies bring structure, semantics, and sanity to GenAI-powered applications. You’ll learn when they’re useful, how to apply them, and what kinds of problems they help solve. Through practical examples, we’ll show how ontologies (1) guide knowledge graph construction, (2) add a semantic layer for more efficient and accurate retrieval (GraphRAG), and (3) encode domain logic you don’t want to leave up to the LLM.\n\nAbout Jesús Barrasa\nDr. Jesús Barrasa is the AI Field CTO at Neo4j, where he works with organisations combining the power of GenAI with Knowledge Graphs. He co-authored \"Building Knowledge Graphs\" (O'Reilly 2023) and is cohost of the monthly Going Meta live webcast (https://goingmeta.live/) since 2022.\nJesús holds a Ph.D. in Artificial Intelligence/Knowledge Representation and is an active thought leader in the KG and AI space",
      "publishedAt": "2025-06-27T09:53:52Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M54S",
      "viewCount": 747,
      "likeCount": 19,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/CbiR9xS2skQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/CbiR9xS2skQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/CbiR9xS2skQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/CbiR9xS2skQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/CbiR9xS2skQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=CbiR9xS2skQ"
    },
    {
      "id": "gsedOXz8FX4",
      "title": "Memory Masterclass: Make Your AI Agents Remember What They Do! — Mark Bain, AIUS",
      "description": "Are you ready to give your AI agents a memory upgrade?\nJoin us for a fast-paced workshop exploring how memory can transform your agents.\n\nWhat You'll Do:\nLearn Leading Memory Solutions: Gain practical experience with open-source tools like Neo4j, Cognee, Graphiti, and Mem0.\nExplore Memory Types: Understand the theory behind long-term, short-term, episodic, semantic, and other memory types.\nDiscover Memory Benefits: Learn how memory improves recall, contextual awareness, and reasoning in autonomous agents.\nCompare Implementations: Get a snapshot of how different solutions implement memory—what’s built-in, flexible, and experimental. We'll also demonstrate GraphRAG memory solutions and a GraphRAG chat implemented with Google ADK.\nWhether you’re working on AI copilots, agentic workflows, or research prototypes, this workshop will help you embed real memory into your AI stack.\n\n\nAbout Mark Bain\nI'm a deep tech founder building a private research lab: AIUS Technologies. We're on a mission to develop artificial life through R&D of long-term memory.\n\nPreviously I led a cybersecurity lab and an edtech startup. Worked with defense and national security clients, banks and Fortune 500 clients.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:51:20Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT51M25S",
      "viewCount": 8320,
      "likeCount": 166,
      "commentCount": 19,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/gsedOXz8FX4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/gsedOXz8FX4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/gsedOXz8FX4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/gsedOXz8FX4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/gsedOXz8FX4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=gsedOXz8FX4"
    },
    {
      "id": "GGxAQVbwBL4",
      "title": "Graph Intelligence: Enhance Reasoning and Retrieval Using Graph Analytics - Alison & Andreas, Neo4j",
      "description": "Advanced GraphRAG techniques apply graph ML and algorithms, wrapped into tidy notebooks.\n\nAbout Alison Cossette \nAlison Cossette is a dynamic Data Science Strategist, Educator, and Podcast Host. As a Developer Advocate at Neo4j specializing in Graph Data Science, she brings a wealth of expertise to the field. With her strong technical background and exceptional communication skills, Alison bridges the gap between complex data science concepts and practical applications. Alison’s passion for responsible AI shines through in her work. She actively promotes ethical and transparent AI practices and believes in the transformative potential of responsible AI for industries and society. Through her engagements with industry professionals, policymakers, and the public, she advocates for the responsible development and deployment of AI technologies. She is currently a Volunteer Member of the US Department of Commerce - National Institute of Standards and Technology's Generative AI Public Working Group Alison’s academic journey includes Masters of Science in Data Science studies, specializing in Artificial Intelligence, at Northwestern University and research with Stanford University Human-Computer Interaction Crowd Research Collective. Alison combines academic knowledge with real-world experience. She leverages this expertise to educate and empower individuals and organizations in the field of data science. Overall, Alison Cossette’s multifaceted background, commitment to responsible AI, and expertise in data science make her a respected figure in the field. Through her role as a Developer Advocate at Neo4j and her podcast, she continues to drive innovation, education, and responsible practices in the exciting realm of data science and AI.\n\nAbout Andreas Kollegger\nAndreas is a technological humanist. Starting at NASA, Andreas designed systems from scratch to support science missions. Then in Zambia, he built medical informatics systems to apply technology for social good. Now with Neo4j, he is democratizing graph databases to validate and extend our intuitions about how the world works. Everything is connected.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:49:33Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H41M16S",
      "viewCount": 607,
      "likeCount": 16,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/GGxAQVbwBL4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/GGxAQVbwBL4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/GGxAQVbwBL4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/GGxAQVbwBL4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/GGxAQVbwBL4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=GGxAQVbwBL4"
    },
    {
      "id": "c5qJHr3DnT4",
      "title": "GraphRAG methods to create optimized LLM context windows for Retrieval — Jonathan Larson, Microsoft",
      "description": "Jonathan Larson is a Senior Principal Data Architect at Microsoft Research working in Special Projects.  He currently leads a research team focused on the intersection of graph machine learning, LLM memory representations, and LLM orchestration. \n\nHis research has led to shipping new features in Bing, Viva, PowerBI. He also shipped new tools to combat tech fraud. Many of the supporting libraries have been open sourced in collaboration on GitHub. Prior to joining Microsoft, Jonathan was Chief Scientist and Technical Fellow at Sotera Defense Solutions on assignment to DARPA, and led a variety of research across several programs. Jonathan has also led large-scale data science efforts at Google, Zillow, and the US Army. Early in his career, he also worked several startups and incubators.\n\nAbout Jonathan Larson\nJonathan Larson is a Senior Principal Data Architect at Microsoft Research working in Special Projects. He currently leads a research team focused on the intersection of graph machine learning, LLM memory representations, and LLM orchestration. \n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:48:38Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M9S",
      "viewCount": 1672,
      "likeCount": 59,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/c5qJHr3DnT4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/c5qJHr3DnT4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/c5qJHr3DnT4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/c5qJHr3DnT4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/c5qJHr3DnT4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=c5qJHr3DnT4"
    },
    {
      "id": "CzM3cW6FdBs",
      "title": "Agentic GraphRAG: Simplifying Retrieval Across Structured & Unstructured Data — Zach Blumenfeld",
      "description": "Agentic workflows often become complex, brittle, and hard to maintain when they need to retrieve and reason across both structured data (typically requiring precise query execution) and unstructured data (commonly handled via vector search in RAG). In this talk, we’ll explore how mapping key information into a knowledge graph can simplify these workflows and improve retrieval quality. You’ll learn core concepts behind GraphRAG, how to integrate it into agent tools, and get access to end-to-end code examples so you can start building right away.\n\nAbout Zach Blumenfeld\nZach Blumenfeld is an AI/ML graph specialist at Neo4j who helps engineers, data scientists, and business leaders leverage graph technology for analytics and intelligent applications. His expertise spans several dynamic fields, including GraphRAG and AI systems, criminal fraud detection, entity resolution, and recommendation engines.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:44:52Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M25S",
      "viewCount": 3000,
      "likeCount": 79,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/CzM3cW6FdBs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/CzM3cW6FdBs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/CzM3cW6FdBs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/CzM3cW6FdBs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/CzM3cW6FdBs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=CzM3cW6FdBs"
    },
    {
      "id": "1C3sZbaxOmw",
      "title": "Revenue Engineering: How to Price (and Reprice) Your AI Product — Kshitij Grover, Orb",
      "description": "You’ve trained the model—now it’s time to train the business. This talk dives into the engineering behind pricing systems that can evolve as fast as your AI stack.\n\nOrb CTO Kshitij Grover will walk through how leading AI companies design infrastructure to support experimentation, scale, and real-world monetization constraints.\n\nTopics include:\n- How to meter usage and map it to pricing with accuracy and auditability\n- Factoring in margins and underlying costs when designing pricing strategy\n- Handling complexity across motions: self-serve vs. enterprise, pay-as-you-go vs. committed contracts\n- How to test pricing changes safely (and roll them back when needed)\n\nWhether you’re bootstrapping a pricing system from scratch or replacing a brittle V1, you’ll leave with architectural patterns and mental models to make pricing a first-class engineering concern.\n\nAbout Kshitij Grover\nI’m Kshitij Grover, Co-Founder and CTO of Orb, where we’re building billing infrastructure that gives AI and SaaS teams the tools to treat pricing as a product. My focus is on designing systems that are correct, real-time, and intuitive for developers—because billing should be as thoughtfully engineered as the applications it supports. At Orb, we work closely with engineering teams to help them ship pricing changes with speed and confidence. I’m passionate about the intersection of infrastructure, data, and developer experience. As a speaker at the AI Engineering Summit, I’m excited to share what we’ve learned about building billing systems that scale with modern AI workloads.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:41:55Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M39S",
      "viewCount": 476,
      "likeCount": 10,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1C3sZbaxOmw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1C3sZbaxOmw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1C3sZbaxOmw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1C3sZbaxOmw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1C3sZbaxOmw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1C3sZbaxOmw"
    },
    {
      "id": "1nOTQsfe1RU",
      "title": "\"Data readiness\" is a Myth: Reliable AI with an Agentic Semantic Layer — Anushrut Gupta, PromptQL",
      "description": "The rapid progress in LLM capability has not translated to increased reliability for business critical AI use cases. The root-cause? Data is \"\"not ready\"\".\nConversational analytics doesn't go beyond the analyst team because it's hard to verify if the generated queries are actually doing what they are supposed to.\nRAG based systems often fail to handle the breadth and depth of real world use-cases because it requires a prohibitive amount of preparation & maintenance of an underlying knowledge graph.\n\nAgentic AI systems need to hard-code specific workflows to work reliably and end up looking more like software engineering with LLM calls instead of delivering on the promise of truly agentic workflows.\n\nIn all of these failure modes, the common culprit is that the planning or reasoning done by the LLM fails to accurately capture the user's intent or the domain's context aka the lack of a well prepared semantic data layer.\n\nEnterprise data is silo-ed and vastly varying levels of quality and the perfect \"\"semantic layer\"\" and \"\"metadata\"\" is a moving target. New data is continuously being created and business definitions are rapidly changing and often entirely on-demand.\nIn this talk we'll share how you can build and maintain a semantic data layer that is maintained entirely by AI, and show (with live examples) how that dramatically improves reliability of the AI system that needs dynamic access to data.\nWe'll demonstrate how this sufficiently augments existing RAG, text-to-SQL and tool calling techniques and starts opening the door to reliable AI deployments.\n\n\n\n---related links---\n\nhttps://www.linkedin.com/in/anushrut-gupta/\nhttps://promptql.hasura.io/",
      "publishedAt": "2025-06-27T09:40:39Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M2S",
      "viewCount": 434,
      "likeCount": 8,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1nOTQsfe1RU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1nOTQsfe1RU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1nOTQsfe1RU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1nOTQsfe1RU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1nOTQsfe1RU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1nOTQsfe1RU"
    },
    {
      "id": "vRFqbEzzDsI",
      "title": "Building Agentic Applications w/ Heroku Managed Inference and Agents — Julián Duque & Anush Dsouza",
      "description": "In this workshop, you’ll learn how to use Heroku Managed Inference and Agents to build agentic applications. We’ll cover how to provision and deploy LLM models to your app, run untrusted code securely in Python, Node.js, Go, and Ruby using built-in tools, and use the Model Context Protocol (MCP) to connect tools and actions that extend your agents' capabilities.\n---\nAgentic applications are reshaping how developers approach automation and AI integration. In this workshop, you’ll learn how to use Heroku’s new Managed Inference and Agents platform to create applications that can reason, make decisions, and trigger actions, all while staying fully integrated with your app logic and infrastructure.\n\nWe’ll walk through how to provision and deploy LLMs, run untrusted code securely in multiple languages, and extend your agents with the Model Context Protocol (MCP). Whether you're building internal tools, developer assistants, or customer-facing AI features, this workshop will give you the technical foundation to get started.\n\nYou’ll learn how to:\n\n- Deploy and manage LLMs using Heroku Managed Inference and Agents\n- Safely run untrusted code in Python, Node.js, Go, and Ruby using Heroku’s built-in tools\n- Use the Model Context Protocol (MCP) to extend your agent capabilities\n\nBy the end of this session, you’ll know how to build and deploy agentic applications on Heroku using production-ready infrastructure.\n\n---related links---\n\nhttps://twitter.com/julian_duque\nhttps://www.linkedin.com/in/juliandavidduque/\nhttps://julianduque.co/\nhttps://www.heroku.com/\n\n## timestamps\n\nIntroduction to Heroku AI [00:00]\nCore Mission: The product's goal is to make every software engineer an AI engineer. Anush Dsouza, the Product Manager, states Heroku wants to make it “simple to attach agents and AI to your application.” [04:24]\n\nAgentic Control Loop: Heroku provides an \"agentic control loop\" running on its platform. This loop gives AI models access to tools like code execution and data access, all secured under Heroku's trust layer. [05:01]\n\nAI Primitives: Heroku AI is built on key primitives. These include inference for accessing curated models, the Model Context Protocol (MCP) for extending app functionality, and PG Vector for handling embeddings. [06:25]\n\nTrusted Compute: Heroku's trusted compute layer, Dynos, runs first-party tools. They plan to expand this with tools for web search and memory, and users can bring their own tools via MCP. [07:08]\n\nProvisioning and Usage\nManaged Inference: This service allows you to run AI models directly within your Heroku infrastructure. This keeps your data within your application's network for enhanced security. [13:23]\n\nSupported Models: The platform supports text-to-text models from Anthropic (Claude 3.5, 3.7, and 4), embeddings from Cohere Embed, and image generation with Stable Image Ultra. [14:38]\n\nChat Completions API: The basic chat completions endpoint is designed to be highly compatible with the OpenAI and Anthropic APIs. The presenter notes it's “95% compatible with the OpenAI API,” allowing the use of the OpenAI SDK. [50:51] It supports standard parameters like temperature and max_tokens, as well as streaming responses. [21:29]\n\nHeroku Tools and Agents\nServerless Execution: Tools run on one-off Dynos, which scale to zero after execution. This means you “only pay for the compute that you use.” [17:57]\n\nDyno Run Command: This powerful tool allows the LLM to execute Unix commands or pre-deployed scripts on a Heroku Dyno. This gives the agent access to real-time information and the ability to interact with the file system. [25:08]\n\nDatabase Querying: The agent can interact with your PostgreSQL database through two tools:\n\npostgres-get-schema: This retrieves the database schema, which helps prevent the LLM from hallucinating incorrect table or column names. [25:45]\n\npostgres-run-query: This tool generates and executes SQL queries based on the provided schema and the user's natural language request. [25:52]\n\nCode Execution: The agent can generate and run code in Python, Node, Ruby, and Go on a one-off Dyno. It even supports installing dependencies on the fly. [27:02]\n\nExtending with Model Context Protocol (MCP)\nBring Your Own Tools: You can extend the agent's capabilities by deploying your own tools as MCPs to Heroku. [37:38]\n\nDeployment: MCPs are deployed by configuring a Procfile with an mcp process type. This makes your custom tool discoverable by the Heroku agent. [46:19]\n\nExample MCP: The workshop demonstrates a \"Brave Search MCP\" that allows the agent to perform web searches, showcasing how to add external knowledge to the agent. [43:42]",
      "publishedAt": "2025-06-27T09:38:08Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT52M35S",
      "viewCount": 432,
      "likeCount": 8,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/vRFqbEzzDsI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/vRFqbEzzDsI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/vRFqbEzzDsI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/vRFqbEzzDsI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/vRFqbEzzDsI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=vRFqbEzzDsI"
    },
    {
      "id": "KJ9eZYTWS1Y",
      "title": "Events are the Wrong Abstraction for Your AI Agents - Mason Egger, Temporal.io",
      "description": "AI Agents are distributed systems. Agents need to connect and communicate with tools, data repositories, other agents, etc., all over a network. Event-Driven Architecture is a common pattern for facilitating this connectivity, using Events as the communication abstraction. However, this pattern introduces complexities as well, such as fragmented logic, increased latency, decreased observability, and more. But what if there were a way to get the benefits of Event-Driven Architecture without the complexities? Enter Durable Execution. In this talk, we'll discuss the pitfalls of Event-Driven Architecture, how Durable Execution solves these issues, and why Durable Execution, not Events, is the correct abstraction for building AI Agents.\n\nAbout Mason Egger\nMason is currently a Senior Developer Advocate at Temporal Technologies who specializes in building community, developer-focused educational content, distributed systems, and Python. Prior to his work at Temporal he worked in Developer Relations at DigitalOcean and as a backend engineer at various companies. He’s an avid programmer, speaker, educator, and writer/blogger. He is President of the PyTexas Foundation, Conference Chair of the PyTexas Conference, and a founding organizer of the PyTexas Meetup.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:35:48Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M40S",
      "viewCount": 678,
      "likeCount": 16,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/KJ9eZYTWS1Y/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/KJ9eZYTWS1Y/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/KJ9eZYTWS1Y/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/KJ9eZYTWS1Y/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/KJ9eZYTWS1Y/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=KJ9eZYTWS1Y"
    },
    {
      "id": "jvKf6zXrNO4",
      "title": "Prompt Engineering is Dead — Nir Gazit, Traceloop",
      "description": "Manual prompt crafting doesn't scale. In this session, we'll explore how to replace it with a test-driven, automated approach. You'll see how to define output evaluators, write minimal prompts, and let agents iterate toward optimal performance—all without manual tweaking. If you're still hand-tuning prompts, you're doing it wrong.\n\nAbout Nir Gazit\nCEO @ traceloop; ex-chief architect @ Fiverr, ex-tech lead @ Google; OpenTelemetry contributor\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:34:55Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M19S",
      "viewCount": 22177,
      "likeCount": 425,
      "commentCount": 38,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/jvKf6zXrNO4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/jvKf6zXrNO4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/jvKf6zXrNO4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/jvKf6zXrNO4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/jvKf6zXrNO4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=jvKf6zXrNO4"
    },
    {
      "id": "jUv5WSPo9fk",
      "title": "The Eyes Are The (Context) Window to The Soul: How Windsurf Gets to Know You — Sam Fertig, Windsurf",
      "description": "Sometimes it seems like Windsurf knows you a little too well. It's one thing to generate generic code, but to predict your next intent? From matching existing code patterns and styles to tracking how local changes affect the larger codebase, this talk digs into the technical challenges of context awareness and why simply indexing code falls short. Relive our journey tackling the core issue in the AI IDE space : balancing retrieval quality with latency constraints and scaling effectively as codebases grow. For those curious about the infrastructure behind context-aware AI, this talk offers insights into our approach of turning massive codebases into collections of useful context.\n\nAbout Sam Fertig\nSam Fertig is a Deployed Engineer at Windsurf, where he helps deliver cutting-edge software solutions in complex operational environments. Prior to Windsurf, he worked at C3 AI, gaining experience at the intersection of data, engineering, and enterprise AI. Sam holds a degree in Computer Science and Politics from Oberlin College. Outside of work, he’s passionate about MMA and Jiu Jitsu, and enjoys playing guitar in his free time.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:34:15Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M37S",
      "viewCount": 534,
      "likeCount": 9,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/jUv5WSPo9fk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/jUv5WSPo9fk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/jUv5WSPo9fk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/jUv5WSPo9fk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/jUv5WSPo9fk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=jUv5WSPo9fk"
    },
    {
      "id": "W_5tzQY-hVs",
      "title": "Mastering Engineering Flow with Windsurf - Eashan Sinha, Windsurf",
      "description": "As experienced engineers, especially senior and staff engineers, our focus shifts towards complex problem-solving, architectural decisions, and mentoring. While AI tools promise productivity gains, Windsurf offers more than just code completion and chat assistance – it's an agentic IDE built to enhance engineering flow. This talk explores how experienced engineers can leverage Windsurf's deep contextual awareness, structured guidance, and automated workflows to tackle sophisticated and complex tasks. We'll demonstrate practical strategies for accelerating feature development, automating code maintenance and reviews, and ultimately freeing up cognitive load to focus on high-impact engineering challenges. Learn how to move beyond basic AI assistance and truly partner with Windsurf to excel in your role.\n\nAbout Eashan Sinha  \nGraduating from Georgia Tech with his bachelors and masters in computer science, Eashan specializes in AI and ML and has a strong foundation in building GenAI products. Eashan spent time as an engineer at TikTok and founded his own generative AI based company that was accepted into Y Combinator prior to joining Windsurf as a Deployed Engineer. Currently, Eashan is focused on enhancing AI agent efficiency and performance with large codebases and enterprise use cases.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:32:38Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M20S",
      "viewCount": 1026,
      "likeCount": 23,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/W_5tzQY-hVs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/W_5tzQY-hVs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/W_5tzQY-hVs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/W_5tzQY-hVs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/W_5tzQY-hVs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=W_5tzQY-hVs"
    },
    {
      "id": "0MqYA52iWQU",
      "title": "(possible dupe but better sound) What does Enterprise Ready MCP mean? — Tobin South, WorkOS",
      "description": "Everyone is building MCP servers: from Slack integrations to personal data tools. They're good demos, but not ready to turn into production. So, what does it take to make MCP *enterprise-ready?*\n\nWe're going to cover the end-to-end process of getting a hacky MCP server authenticated, permissioned, and secure. We'll talk about registries, SSO, audit logs, agent identifiers, autonomy for agents, and oversight. Oh and we'll use MCP to buy some stuff.\n\nCome learn the stack needed to scale your MCP to the enterprise and some fun hacks along the way.\n\n---\n\nTobin is a PhD from MIT, a fellow at Stanford as the research lead of the Safe and Useful AI Agents initiative, and the head of AI agents for WorkOS.  He's an experienced speaker having presented at events from AI conferences through the world economic forum.",
      "publishedAt": "2025-06-27T09:31:18Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M53S",
      "viewCount": 2246,
      "likeCount": 45,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/0MqYA52iWQU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/0MqYA52iWQU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/0MqYA52iWQU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/0MqYA52iWQU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/0MqYA52iWQU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=0MqYA52iWQU"
    },
    {
      "id": "WXy8Yy9xGss",
      "title": "CI in the Era of AI: From Unit Tests to Stochastic Evals — Nathan Sobo, Zed",
      "description": "Software engineers have long understood that high-quality code requires comprehensive automated testing. For decades, our industry has relied on deterministic tests with clear pass/fail outcomes to ensure reliability.\n\nHigh-quality software depends on automated testing. That's certainly true at Zed, where we're building a next-generation native IDE in Rust. Zed runs at 120 frames per second, but it would also crash once a second if we didn't maintain and run a comprehensive suite of unit tests on every change.\n\nBut what happens when AI enters the equation?\n\nIn this talk, we'll explore how continuous integration evolves when working with AI components. \"Evals\" - parlance from the machine learning field - are fundamentally a continuation of the software testing tradition, but with a critical difference: they're inherently stochastic.\n\nZed's traditional CI goes to extreme lengths to eliminate non-determinism, as nobody likes having their pull requests blocked by flaky builds. We've even fully simulated network interactions with a deterministic random scheduler. AI components, however, forced us to confront a fundamental paradigm shift—uncertainty isn't a bug but an intrinsic feature of these systems, compelling us to embrace what we couldn't avoid.\n\nWe'll share our journey of reconceptualizing evals as \"stochastic unit tests\" - still verifying system behavior, but without binary pass/fail grades.\n\nWe'll discuss practical approaches to:\n- Thoughtfully building test suites for AI components\n- Shifting from red/green outcomes to \"shades of gray\"\n- Replacing build gates with trend analysis and performance monitoring\n- Maintaining engineering confidence despite statistical variance\n\nWhether you're incorporating AI into existing systems or building new AI-powered tools, this talk will provide practical insights into maintaining quality when determinism gives way to probability.\n\nAbout Nathan Sobo\nNathan joined GitHub in late 2011 to build the Atom text editor, and he led the Atom team until 2018.\n\nHe also co-led development of Teletype for Atom, pioneering one of the first production uses of conflict-free replicated data types for collaborative text editing.\n\nHe's been dreaming about building the world's best text editor since he graduated from college, and is excited to finally have the knowledge, tools, and resources to achieve this vision.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-27T09:22:37Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M50S",
      "viewCount": 608,
      "likeCount": 16,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/WXy8Yy9xGss/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/WXy8Yy9xGss/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/WXy8Yy9xGss/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/WXy8Yy9xGss/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/WXy8Yy9xGss/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=WXy8Yy9xGss"
    },
    {
      "id": "84Vtz2IL1Ug",
      "title": "Fun stories from building OpenRouter and where all this is going - Alex Atallah, OpenRouter",
      "description": "How the first LLM aggregator got started, some of the weird moments in its early growth, architecture challenges, and where we'll be taking it down the road.\n\nOpenRouter has just raised $40m from a16z and others: https://x.com/xanderatallah/status/1937957937692938292\n\n---\nThe Genesis of OpenRouter [00:00]\nInitial Question [01:16]: The story begins in early 2023 with the founder, Alex Atallah, pondering if the AI inference market would be dominated by a single player. He noticed the emergence of new models beyond OpenAI and a growing desire from developers to understand the nuances of different models, including their moderation policies [01:48].\n\nThe Rise of Open Source [02:35]: The video highlights the beginning of the open-source AI race, with early models like Bloom 176B and OPT from Facebook [02:46]. A pivotal moment was the release of Meta's Llama 1 in February, which surprisingly outperformed GPT-3 on many benchmarks [03:28], signaling a shift in the landscape.\n\nThe Alpaca Moment [04:38]: A major breakthrough occurred in March 2023 with the distillation of Alpaca. Stanford researchers demonstrated that by fine-tuning Llama 1 with outputs from GPT-3, they could transfer the style and knowledge of a larger model to a smaller one for less than $600. This proved that creating powerful, specialized models no longer required massive budgets [04:58].\n\nFrom a Chrome Extension to a Marketplace\nWindow AI [06:43]: Before OpenRouter, Atallah launched Window AI, an open-source Chrome extension that empowered users to select their preferred LLM for any web application. This project laid the groundwork for what was to come.\n\nThe Launch of OpenRouter [07:18]: OpenRouter was co-founded with Lewis, the creator of the framework that Window AI was built on. Initially, it was a simple aggregator to collect models in one place.\n\nGrowth and Evolution [07:57]: OpenRouter quickly evolved into a marketplace, driven by the proliferation of model providers with varying prices, performance, and features. The platform has seen impressive growth, with a 10-100% month-over-month increase for two years. It now offers a single API for over 400 models from more than 60 providers [08:07].\n\nMarketplace Dynamics [08:57]: The transition to a marketplace was a response to the complexity of the growing AI ecosystem. By aggregating providers, OpenRouter helps developers achieve better uptime for both open-source and closed-source models and provides valuable data on latency and throughput [10:27].\n\nThe Future of OpenRouter\nExpanding Modalities [17:02]: The future vision for OpenRouter includes incorporating models that can generate images and \"transfusion models\" that allow for conversations with images.\n\nSmarter Routing [17:51]: The platform plans to implement more sophisticated routing mechanisms, including geographical routing and enterprise-level optimizations for GPU allocation.\n\nEnhanced Discovery [18:07]: To help developers find the best models for their needs, OpenRouter aims to improve prompt observability, introduce more granular model categorization, and continue to offer competitive pricing.\n\nAbout Alex Atallah\nCofounder & CEO of OpenRouter, the first LLM aggregator and distributor. Cofounder of OpenSea, the first NFT marketplace.\n\nHelped grow OpenSea to over $4B in monthly volume from 2017 to 2022.\n\nFounded OpenRouter in early 2023, which processes over 2 trillion tokens weekly across over 400 unique language models, as of May 2025.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-25T19:47:43Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M47S",
      "viewCount": 5881,
      "likeCount": 131,
      "commentCount": 13,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/84Vtz2IL1Ug/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/84Vtz2IL1Ug/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/84Vtz2IL1Ug/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/84Vtz2IL1Ug/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/84Vtz2IL1Ug/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=84Vtz2IL1Ug"
    },
    {
      "id": "jVGCulhBRZI",
      "title": "Building AI Agents that actually automate Knowledge Work - Jerry Liu, LlamaIndex",
      "description": "Agents are all the rage in 2025, and every single b2b SaaS startup/incumbent promises AI agents that can \"automate work\" in some way.\n\nBut how do you actually build this? The answer is two fold:\n1. really really good tools\n2. carefully tailored agent reasoning over these tools that range from assistant-to-automation based UXs.\n\nThe main goal of this talk is to a practical overview of agent architectures that can automate real-world work, with a focus on document-centric tasks. Learn the core building blocks of best-in-class \"tools\" around processing, manipulating, and indexing/retrieving PDFs to Excel spreadsheets. Also learn the range of agent architectures suited for different tasks, from chat assistant-based UXs with high human-in-the-loop, to automation UXs that rely on encoding a business process into an end-to-end task solver. These architectures have to be generalizable but also highly accurate as agents get increasingly better at reasoning and code-writing.\n\nAbout Jerry Liu\nJerry is the co-founder/CEO of LlamaIndex, the most accurate and flexible way to automate your document workflows with AI agents. Before this, he led the ML monitoring team at Robust Intelligence, did self-driving AI research at Uber ATG and worked on recommendation systems at Quora.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-24T00:16:46Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M57S",
      "viewCount": 102059,
      "likeCount": 1888,
      "commentCount": 23,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/jVGCulhBRZI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/jVGCulhBRZI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/jVGCulhBRZI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/jVGCulhBRZI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/jVGCulhBRZI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=jVGCulhBRZI"
    },
    {
      "id": "JfaLQqfXqPA",
      "title": "RFT, DPO, SFT: Fine-tuning with OpenAI — Ilan Bigio, OpenAI",
      "description": "Full workshop covering all forms of fine-tuning and prompt engineering, like SFT, DPO, RFT, prompt engineering / optimization, and agent scaffolding.\n\nAbout Ilan Bigio\nIlan Bigio is a founding member of OpenAI’s Developer Experience team where he explores model capabilities, builds demos and developer tools, and shares his learnings through talks and docs.\n\nHis work includes creating the AI phone ordering demo showcased at DevDay 2024, leading technical development for Swarm, the precursor to the Agents SDK, and contributing to Codex CLI. Prior to that, he was a Solutions Architect at OpenAI, partnering with companies like Cursor, Khan Academy, and Klarna to shape their AI products. Before OpenAI, he was a full-stack Software Engineer at Google, building for YouTube at scale.\n\nIlan’s journey started as a hobby hacker, diving into operating systems and reverse engineering, before shifting to language models in 2020. He created projects like ShellAI—an open-source, AI-powered terminal assistant—and is passionate about sharing knowledge. With a multidisciplinary background spanning web development, AI/ML, and operating systems, he’s designed and taught courses at Brown and continues to share his expertise through in-depth technical OpenAI guides on topics like Function Calling, Latency Optimization, and Agent Orchestration.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-23T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H46M15S",
      "viewCount": 9989,
      "likeCount": 245,
      "commentCount": 9,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/JfaLQqfXqPA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/JfaLQqfXqPA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/JfaLQqfXqPA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/JfaLQqfXqPA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/JfaLQqfXqPA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=JfaLQqfXqPA"
    },
    {
      "id": "JVuNPL5QO8Q",
      "title": "Windsurf everywhere, doing everything, all at once - Kevin Hou, Windsurf",
      "description": "In this video, we explore the evolution of Windsurf, its core philosophy, and its ambitious vision for the future of AI in software development.\n\nHere's what you'll learn:\n\n00:00 - Introduction to Windsurf: Discover the rapid growth and key features of this AI Engineer World's Fair product, including web search, MCP support, auto-generated memories, and parallel agents.\n02:18 - The Core Philosophy: Learn about the \"secret sauce\" behind Windsurf's intuitive, mind-reading AI, which creates a shared timeline between humans and AI.\n03:46 - Windsurf Everywhere: See the vision for Windsurf to ingest context from all developer tools, including Google Docs, Figma, GitHub, Notion, and Linear.\n06:21 - Windsurf Doing Everything: Explore how the AI will expand beyond coding to interact with third-party services, write design documents, and more.\n08:40 - Windsurf On All the Time: Understand the goal of creating a nearly autonomous AI that works in the background to assist developers.\n11:17 - Introducing SWE-1: Get a first look at the new software engineering model trained for entire workflows.\n11:36 - Benchmarking Success: Learn about the End-to-End Task Benchmark and Conversational SWE Task Benchmark, showcasing Windsurf's impressive results.\n13:32 - The Data Flywheel: Understand the feedback loop that drives Windsurf's continuous improvement.\n14:49 - The Future of AI Products: Hear Kevin's thoughts on the harmony of model, data, and application needed to build successful AI products in 2025.\n\n\nAbout Kevin Hou\nKevin is the head of product engineering at Windsurf, where he builds AI-powered developer tools. He has spent much of his career in AI, previously working as a tech lead manager at Nuro, an autonomous vehicle startup, as well as other companies like Airbnb & Salesforce. Kevin enjoys photography, playing basketball, and woodworking. He studied computer science & ML at Princeton University.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-23T15:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M3S",
      "viewCount": 6843,
      "likeCount": 137,
      "commentCount": 15,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/JVuNPL5QO8Q/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/JVuNPL5QO8Q/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/JVuNPL5QO8Q/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/JVuNPL5QO8Q/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/JVuNPL5QO8Q/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=JVuNPL5QO8Q"
    },
    {
      "id": "sn79oS4MZFI",
      "title": "Case Study + Deep Dive: Telemedicine Support Agents with LangGraph/MCP - Dan Mason",
      "description": "We've all seen website chat bots which can look up an order or answer a basic question -- but what does it take to build autonomous agents which manage long, delicate processes like multi-day medical treatments?\n\nIn this workshop, we'll explore a workflow Stride built in partnership with Avila (https://avilascience.com/) that helps patients self-administer medication regimens at home. The stack includes LangGraph/LangSmith, Claude, MCP, Node.js, React, MongoDB, and Twilio, and rests on a foundation of treatment \"blueprints\" which LLM-powered agents use to guide patients to good outcomes.\n\nYou'll learn how to: -Build a hybrid system of code and prompts that leverages LLM decisioning to drive a web application, message queue and database -Design and maintain flexible agentic workflow blueprints, with no special tools (just Google Docs!) -Create an agent evaluation system, which uses LLM-as-a-judge to evaluate the complexity of each interaction and escalate to human support when needed\n\nWe'll also talk about the prompt engineered guidelines and guardrails which helps agents adhere to protocol as much as possible, while gracefully handling curveballs from the patient. Please bring questions -- we look forward to sharing our learnings on how to make agentic systems like this work in the real world!\n\nAbout Dan Mason\nDan is a product and technology leader with unusually broad experience -- in 20+ years at companies like ESPN, Shutterstock, Viacom, NBCUniversal and a variety of startups and scaleups, he’s accumulated a wealth of knowledge about how digital product development works (and doesn’t), and is excited to apply those insights to reimagining teams and products in the age of LLMs.   He is an engineer turned product manager with strong technical skills, and the teams he leads are highly cross-functional -- often including product, technology, design, PMO and data science.\n\nDan leads Stride’s AI/LLM practice and is focused on thought leadership, code generation, workflow automation, and shaping and leading generative AI client engagements. He is also an active product coach and consultant, and a member of Docker’s Technical Advisory Group. Dan lives in New Jersey with his wife and three busy teenagers, and holds a BA in Computer Science and English Literature from Williams College.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-22T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H56M13S",
      "viewCount": 6693,
      "likeCount": 208,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/sn79oS4MZFI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/sn79oS4MZFI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/sn79oS4MZFI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/sn79oS4MZFI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/sn79oS4MZFI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=sn79oS4MZFI"
    },
    {
      "id": "hlcAZ2lX_ZI",
      "title": "Veo 3 for Developers — Paige Bailey, Google DeepMind",
      "description": "This talk will briefly trace the history of video generation models before diving into Veo 3, Google DeepMind's latest state-of-the-art model that marks a significant leap by generating video with synchronized audio—including dialogue, sound effects, and music—all from text and image prompts. We'll show how it can understanding intricate details, maintain coherence over longer sequences, and simulate realistic physics and camera movements.\n\nFor developers, Veo 3, accessible via Vertex AI (preview), unlocks many new capabilities. We'll discuss how its advanced capabilities, such as semantic context rendering and cinematic control, can empower innovation in filmmaking, game development, education, and more. This session will cover how developers can integrate Veo 3 into their workflows, or test it out today in the Gemini App, Flow, and via the Gemini APIs on Google Cloud.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-21T20:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M37S",
      "viewCount": 4626,
      "likeCount": 96,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/hlcAZ2lX_ZI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/hlcAZ2lX_ZI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/hlcAZ2lX_ZI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/hlcAZ2lX_ZI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/hlcAZ2lX_ZI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=hlcAZ2lX_ZI"
    },
    {
      "id": "wFTVEDYVJT0",
      "title": "Building Agents with Amazon Nova Act and MCP - Du'An Lightfoot, Amazon (Full Workshop)",
      "description": "In this 2-hour workshop, participants will gain practical hands-on experience building sophisticated AI agents using Amazon's agent technologies. You'll learn to build agents that can navigate the web like humans, perform complex multi-step tasks, and leverage specialized tools through natural language commands. You’ll explore Amazon Nova Act for reliable web navigation, Model Context Protocol (MCP) for connecting agents to external data sources and APIs, and Amazon Bedrock Agents for orchestrating complex workflows. Through guided exercises, you'll create agents capable of retrieving information and taking action across web applications, all through natural language interactions. By the end of this workshop, you'll have the practical skills to build AI agents that can browse websites, interact with web interfaces, and solve multi-step problems by combining these powerful Amazon technologies.\n\nAbout Du'An Lightfoot\nDu’An is an Air Force veteran and Sr. Developer Advocate at AWS. He has 10+ years of designing, implementing, and supporting enterprise infrastructures. At AWS he uses his experience and knowledge to help customers learn and build on AWS.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-21T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H26M20S",
      "viewCount": 2509,
      "likeCount": 73,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/wFTVEDYVJT0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/wFTVEDYVJT0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/wFTVEDYVJT0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/wFTVEDYVJT0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/wFTVEDYVJT0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=wFTVEDYVJT0"
    },
    {
      "id": "DNw_Vrkoohc",
      "title": "Large Scale AI on Apple Silicon — Alex Cheema, EXO Labs",
      "description": "The hardware lottery: when a research idea wins because it is better suited to current hardware and software, and not because it is universally superior.\n\nMachine learning researchers often treat hardware as a fixed constraint and stop exploring beyond it. Yet historically, breakthroughs have come from algorithms that best align with the dominant hardware-software stack - neural networks being a classic example.\n\nIn this talk, EXO Labs co-founder Alex Cheema will share recent algorithmic improvements for running large scale AI workloads on Apple Silicon.\n\nAlex will demonstrate how the EXO Framework enables inference, fine-tuning, and training of large ML models on Apple Silicon, from the scale of one MacBook locally to clusters of colocated M3 Ultra Mac Studios.\n\nAbout Alex Cheema\nAlex is one of the co-founders of EXO Labs. He has a background in Physics from Oxford University and distributed systems engineering.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-20T22:52:47Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M29S",
      "viewCount": 3432,
      "likeCount": 92,
      "commentCount": 11,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/DNw_Vrkoohc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/DNw_Vrkoohc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/DNw_Vrkoohc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/DNw_Vrkoohc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/DNw_Vrkoohc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=DNw_Vrkoohc"
    },
    {
      "id": "YRGjll7uu5w",
      "title": "The Web Browser Is All You Need - Paul Klein IV, Browserbase",
      "description": "With the rise of MCP servers, A2A, and our trusty friend, OpenAPI, it turns out the web browser may be the default MCP server for the rest of the internet.\n\nIn this talk, we'll walk through how a web browsing tool is probably the only tool you'll need to enable production AI Agents.\n\nAbout Paul Klein IV\nPaul Klein IV is a San‑Francisco‑based serial entrepreneur and engineer. After honing his chops at Twilio during it's IPO and founding Stream Club—a live‑streaming platform acquired by Mux in 2021 he launched Browserbase in 2024 to give developers and AI agents fast, reliable, multi‑region headless‑browser infrastructure. In its first 12 months, Klein raised $27.5 million (a $6.5 M seed and a $21 M Series A led by CRV and Kleiner Perkins with Okta Ventures) . He views Browserbase as the “last‑mile” interface between large language models and the web, enabling end‑to‑end workflow automation far beyond traditional scraping \n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-20T21:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M31S",
      "viewCount": 14394,
      "likeCount": 265,
      "commentCount": 24,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/YRGjll7uu5w/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/YRGjll7uu5w/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/YRGjll7uu5w/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/YRGjll7uu5w/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/YRGjll7uu5w/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=YRGjll7uu5w"
    },
    {
      "id": "Lcqat4iP_lE",
      "title": "The State of MCP observability: Observable.tools — Alex Volkov and Benjamin Eckel, W&B and Dylibso",
      "description": "AI Engineers deserve observable tools!\n\nMCP getting adoption means that less and less of your agents code is running under your control, and this has DX and observability challenges, let's fix that!\n\nJoin Alex Volkov from Weights & Biases and Steve Manual from mcp.run on this recap of the current state of MCP observability, including the observable.tools initiative, a recap of where the field stands and what to look forward to + a practical example of MCP tool usage evaluation framework from mcp.run!\n\nAbout Alex Volkov\nAlex Volkov is an AI Evangelist at Weights & Biases as well as the founder and host of ThursdAI, a weekly newsletter and podcast that explores the latest innovations in AI, their practical applications, and the open-source AI community. Alex is an AI startup founder with 20 years of full-stack software engineering experience, offering a deep well of insights into AI innovation. He’s celebrated for his ability to clarify and summarize the complexities of the rapid AI advances and advocating for its beneficial uses.\n\nAbout Benjamin Eckel\nBenjamin has over a decade of experience as a software engineer and is the co-founder and CTO of Dylibso. He previously led DX at Recurly and worked on integrations and edge observability at Datadog.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-20T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M56S",
      "viewCount": 2090,
      "likeCount": 55,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Lcqat4iP_lE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Lcqat4iP_lE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Lcqat4iP_lE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Lcqat4iP_lE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Lcqat4iP_lE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Lcqat4iP_lE"
    },
    {
      "id": "PHBGhUKAM-w",
      "title": "Building Protected MCP Servers — Den Delimarsky and Julia Kasper, MCP Steering Committee & Microsoft",
      "description": "Join us to see how VS Code and GitHub Copilot's expanding suite of AI features can match or even surpasses the benefits of other popular AI developer tools. We'll focus on practical scenarios to ensure immediate applicability and work through live demos of Copilot features such as: Code generation using Edits, Planning/problem solving using Chat, Inline terminal command generation, Boilerplate code generation using Agent mode, Improving boilerplate with custom instructions and then refactoring using Agent mode and Edits, Improving test generation and code reviews with custom instructions, as well as an Introduction to MCP.\n\nAbout Den Delimarsky \nI am a Principal Product Engineer, currently working at Microsoft, where I help build developer tools and AI-powered experiences that make engineers more productive. You can learn more @ den.dev/about.\n\nAbout Julia Kasper\nJulia Kasper is a member of the Microsoft Developer Division focusing on the developer experience for the Microsoft Power Platform. She is passionate about scenarios where you extend the Power Platform with Azure services and have the best possible end-to-end experience.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-20T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M13S",
      "viewCount": 729,
      "likeCount": 34,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/PHBGhUKAM-w/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/PHBGhUKAM-w/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/PHBGhUKAM-w/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/PHBGhUKAM-w/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/PHBGhUKAM-w/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=PHBGhUKAM-w"
    },
    {
      "id": "Zz4QjZsYWK0",
      "title": "The Geopolitics of AI Infrastructure - Dylan Patel, SemiAnalysis",
      "description": "As AI reshapes the global balance of power, the infrastructure behind it—chips, data centers, power, and supply chains—has become a new arena for geopolitical competition. This talk explores how nations are racing to secure critical AI hardware, control compute capacity, and assert influence over the technologies and talent that define the future.\n\nAbout Dylan Patel\nDylan is the founder, CEO, and Chief Analyst for SemiAnalysis, the preeminent authority on all things AI and semiconductors. Through Dylan’s unwavering commitment to excellence, he has built the firm from the ground up as the thought leader from the semiconductor supply chain to the cloud ecosystem, machine learning models, and all things in between. Since 2020, SemiAnalysis has transformed its business from a solo venture into a cohesive and focused team to provide breaking news and in-depth analysis for the most strategic, complex, and escalating challenges in the semiconductor industry.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-19T23:10:59Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M29S",
      "viewCount": 23701,
      "likeCount": 595,
      "commentCount": 26,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Zz4QjZsYWK0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Zz4QjZsYWK0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Zz4QjZsYWK0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Zz4QjZsYWK0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Zz4QjZsYWK0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Zz4QjZsYWK0"
    },
    {
      "id": "0NHCyq8bBcM",
      "title": "Remote MCPs: What we learned from shipping — John Welsh, Anthropic",
      "description": "We recently released remote MCP support for both claude.ai and the Anthropic API. This talk will cover architectural decisions we made in our implementation, remote MCP authentication, supporting engineers who are building out agentic AI tools, implementing custom internal transports, and whatever else we can fit into 18 minutes of your time.\n\nAbout John Welsh\nI'm John Welsh, a software engineer who's been building large scale systems for the past 20 years. I'm currently at Anthropic, where I've been building our public API and defining how internal systems communicate with MCP servers and other integrations.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-19T16:52:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M12S",
      "viewCount": 6689,
      "likeCount": 184,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/0NHCyq8bBcM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/0NHCyq8bBcM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/0NHCyq8bBcM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/0NHCyq8bBcM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/0NHCyq8bBcM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=0NHCyq8bBcM"
    },
    {
      "id": "x-8pBqWiTzk",
      "title": "MCP: Origins and Requests For Startups — Theodora Chu, Model Context Protocol PM, Anthropic",
      "description": "Learn more about the latest updates on MCP and get ideas for what startups to build.\n\nAbout Theodora Chu\nTheo is a product manager at Anthropic, focused on bringing knowledge to models. She works on the Anthropic API as well as MCP. Prior to Anthropic, she spent much of her career building zero-to-one products at her own startup as well as at Stripe. She's come full circle since dropping out of her master's in NLP at Stanford.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter",
      "publishedAt": "2025-06-18T22:55:21Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M45S",
      "viewCount": 12769,
      "likeCount": 333,
      "commentCount": 12,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/x-8pBqWiTzk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/x-8pBqWiTzk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/x-8pBqWiTzk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/x-8pBqWiTzk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/x-8pBqWiTzk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=x-8pBqWiTzk"
    },
    {
      "id": "n6wHJDqlS1I",
      "title": "How to Build Trustworthy AI — Allie Howe",
      "description": "Trust is a multifaceted outcome that results when product and engineering teams work together to build AI that is aligned, explainable, and secure. Learn strategies for how to build trustworthy AI and why trust is paramount for AI systems.\n\nTrustworthy AI = AI Security + AI Safety\n\nLearn about the differences between AI Security and AI Safety and how the three focus areas of MLSecOps + AI Red Teaming + AI Runtime Security can help you achieve both and ultimately build Trustworthy AI. \n\nTrustworthy AI Issues in the news:\nhttps://x.com/syddiitwt/status/1923427722241487297\nhttps://fingfx.thomsonreuters.com/gfx/legaldocs/egvblxokkvq/Walters%20v%20OpenAI%20-%20order.pdf?ref=claritasgrc.ai\n\nMLSecOps Resources\nModelscan https://github.com/protectai/modelscan\nCommunity: mlsecops.com\n\nAI Red Teaming Resources:\nhttps://azure.github.io/PyRIT/\nhttps://ashy-coast-00aeb501e.6.azurestaticapps.net/MS_AIRT_Lessons_eBook.pdf\n\nAI Runtime Security Resources:\nhttps://www.pillar.security/solutions#ai-detection\nhttps://noma.security/\n\nShowcasing Trustworthy AI to Customers/Prospects\nhttps://www.vanta.com/collection/trust/what-is-a-trust-center",
      "publishedAt": "2025-06-16T20:29:50Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT24M22S",
      "viewCount": 2678,
      "likeCount": 58,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/n6wHJDqlS1I/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/n6wHJDqlS1I/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/n6wHJDqlS1I/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/n6wHJDqlS1I/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/n6wHJDqlS1I/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=n6wHJDqlS1I"
    },
    {
      "id": "uFPAtKIN-FQ",
      "title": "Exposing Agents as MCP servers with mcp-agent: Sarmad Qadri",
      "description": "In this talk, we will show that agents can be represented as MCP servers, allowing them to be run from any MCP client (such as Claude, Cursor and other applications).\n\nThis is made possible with [mcp-agent](https://github.com/lastmile-ai/mcp-agent), a simple, composable framework to build agents using [Model Context Protocol](https://modelcontextprotocol.io/introduction).\n\n## Overview\n\nCurrently \"agentic\" behavior exists only on the MCP client side – clients like Claude or Cursor use MCP servers, which are often simple tool APIs, to solve tasks.\n\nHowever, if Agents are MCP servers themselves, then any MCP client can invoke, coordinate and orchestrate agents the same way it does with any other MCP server.\n\nThis paradigm shift enables: \n1. **Agent Composition**: Build complex multi-agent systems over the same base protocol (MCP).\n 2. **Platform Independence**: Use your agents from any MCP-compatible client \n3. **Scalability**: Run agent workflows on dedicated infrastructure, not just within client environments \n4. **Customization**: Develop your own agent workflows and reuse them across any MCP client.\n\n## Background\n\nmcp-agent was inspired by 2 foundational updates that Anthropic introduced for AI application developers:\n\n1. [Model Context Protocol](https://www.anthropic.com/news/model-context-protocol) - a standardized interface to let any software be accessible to AI assistants via MCP servers.\n\n2. [Building Effective Agents](https://www.anthropic.com/research/building-effective-agents) - a seminal writeup on simple, composable patterns for building production-ready AI agents.\n\n`mcp-agent` puts these two foundational pieces into an AI application framework:\n\n1. It handles the pesky business of managing the lifecycle of MCP server connections.\n\n2. It implements every pattern described in Building Effective Agents, and does so in a _composable_ way, allowing you to chain these patterns together.\n\nNow as MCP continues to grow adoption, we are exploring advanced agent architectures that allow for sophisticated workflows in simple ways.",
      "publishedAt": "2025-06-11T16:57:37Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M5S",
      "viewCount": 6789,
      "likeCount": 183,
      "commentCount": 9,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/uFPAtKIN-FQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/uFPAtKIN-FQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/uFPAtKIN-FQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/uFPAtKIN-FQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/uFPAtKIN-FQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=uFPAtKIN-FQ"
    },
    {
      "id": "jqyWZ19d1hg",
      "title": "Surfacing Semantic Orthogonality Across Model Safety Benchmarks — Jonathan Bennion",
      "description": "Various AI safety datasets have been developed to measure LLMs against evolving interpretations of harm. Our evaluation of five recently published open-source safety benchmarks reveals distinct semantic clusters using UMAP dimensionality reduction and kmeans clustering (silhouette score: 0.470). We identify six primary harm categories with varying benchmark representation. GretelAI, for example, focuses heavily on privacy concerns, while WildGuardMix emphasizes self-harm scenarios. Significant differences in prompt length distribution suggests confounds to data collection and interpretations of harm as well as offer possible context. Our analysis quantifies benchmark orthogonality among AI benchmarks, allowing for transparency in coverage gaps despite topical similarities. Our quantitative framework for analyzing semantic orthogonality across safety benchmarks enables more targeted development of datasets that comprehensively address the evolving landscape of harms in AI use, however that is defined in the future.",
      "publishedAt": "2025-06-11T15:40:41Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT26M38S",
      "viewCount": 783,
      "likeCount": 9,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/jqyWZ19d1hg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/jqyWZ19d1hg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/jqyWZ19d1hg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/jqyWZ19d1hg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/jqyWZ19d1hg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=jqyWZ19d1hg"
    },
    {
      "id": "2Jom-4Brg6Q",
      "title": "Beyond Conversation: Why Documents Transform Natural Language into Code - Filip Kozera",
      "description": "Natural language is quickly becoming our most powerful programming abstraction, perfectly suited to capture the inherent fuzziness and complexity of real-world problems. But despite the power of AI chatbots, endlessly brainstorming in conversational interfaces rarely leads to clarity or reliable results.\n\nThis session explores how structured, document-based natural language is uniquely positioned as the ultimate interface for humans to precisely describe complex systems. We'll discuss why conversational interfaces often fail at forcing clarity, and how shifting to a document-driven model ensures that humans articulate their intent clearly and rigorously.\n\nAttendees will learn:\n\nWhy natural language (not code) is the most intuitive way to describe complex systems\n\nHow documents inherently force clarity, rigor, and structured thinking compared to chatbots\n\nReal-world examples of document-based programming for building reliable, deployable AI systems\n\nPractical insights into transitioning from conversational brainstorming to structured document-driven workflows",
      "publishedAt": "2025-06-10T17:30:11Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT10M57S",
      "viewCount": 2016,
      "likeCount": 48,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/2Jom-4Brg6Q/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/2Jom-4Brg6Q/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/2Jom-4Brg6Q/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/2Jom-4Brg6Q/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/2Jom-4Brg6Q/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=2Jom-4Brg6Q"
    },
    {
      "id": "3YRrBFeQ1aw",
      "title": "Why Bolt.new Won and Most DevTools AI Pivots Failed - Victoria Melnikova",
      "description": "Everyone's pivoting to AI—but most are doing it wrong. After conducting in-depth interviews with leaders at 17 developer tools startups that attempted to \"add AI\" to their roadmap, I've uncovered the patterns that led to either spectacular success or painful failure. This isn't abstract theory—it's battle-tested wisdom from companies that bet their future on AI and lived to tell the tale.\n\nYou'll learn:\n- The three most common AI pivot traps that led otherwise promising startups to burn through runway with nothing to show for it\n- Why adding an AI feature doesn't constitute a real AI transformation (and what actually does)\n- The counterintuitive \"backward pivot\" strategy that worked for 5 of the most successful transitions\n- A practical framework for evaluating if your existing developer tooling can meaningfully evolve in the AI era or needs to be reimagined from scratch",
      "publishedAt": "2025-06-10T17:30:11Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M45S",
      "viewCount": 1630,
      "likeCount": 38,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/3YRrBFeQ1aw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/3YRrBFeQ1aw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/3YRrBFeQ1aw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/3YRrBFeQ1aw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/3YRrBFeQ1aw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=3YRrBFeQ1aw"
    },
    {
      "id": "5s6Q-y42ZZA",
      "title": "The Many Ends of Programming - Ray Myers",
      "description": "AI will reshape Software Engineering – but how remains an open question. Will the developers’ role evolve, or vanish entirely? Are we heading toward an Innovator’s Paradise or an Infinite Pile of Garbage?\n\nVisions of the future are so wildly divergent that we struggle to even agree on terms, let alone direction. In this talk, we’ll cut through the noise by exploring six distinct “endgames” for programming in the age of AI. Each offers a different lens on what we build, how we build, and who (or what) is doing the building.\n\nBy naming and examining these futures, we gain a clearer view of what’s ahead and a chance to choose our destination.",
      "publishedAt": "2025-06-10T17:30:11Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT27M12S",
      "viewCount": 1926,
      "likeCount": 47,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/5s6Q-y42ZZA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/5s6Q-y42ZZA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/5s6Q-y42ZZA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/5s6Q-y42ZZA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/5s6Q-y42ZZA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=5s6Q-y42ZZA"
    },
    {
      "id": "J3oJqan2Gv8",
      "title": "MCPs are Boring (or: Why we are losing the Sparkle of LLMs) - Manuel Odendahl",
      "description": "With the mainstream spread especially in coding and with agents, we are starting to imprison ourselves in little cargo culted boxes of what llms and agents are.\n\nI’ll hopefully show you a couple of ideas so you can delve deeper and learn to unleash and harness the shoggoth.\n\nYou’re absolutely right – this is the talk you don’t want to miss!\n\nhttps://x.com/ProgramWithAi/status/1929226124019564993",
      "publishedAt": "2025-06-10T17:30:11Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT28M32S",
      "viewCount": 9576,
      "likeCount": 249,
      "commentCount": 30,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/J3oJqan2Gv8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/J3oJqan2Gv8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/J3oJqan2Gv8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/J3oJqan2Gv8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/J3oJqan2Gv8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=J3oJqan2Gv8"
    },
    {
      "id": "Qvp9vw4jJQ8",
      "title": "Break It 'Til You Make It: Building the Self-Improving Stack for AI Agents - Aparna Dhinakaran",
      "description": "Building and shipping an AI agent is just the beginning. In real-world systems, the real work starts after deployment — when agents drift, fail silently, or underperform in edge cases no one anticipated.\n\nThis talk is about building the full monitoring and improvement stack that keeps agents reliable, efficient, and improving over time. We’ll walk through how to connect evals, tracing, observability, experimentation, and optimization into a virtuous cycle — one where agents not only perform, but learn and adapt in production.\n\nDrawing on real-world deployments, I’ll cover:\n\n- Composing evaluation layers that surface meaningful failure modes\n-Tracing and instrumentation for deep visibility into agent behavior\n-Running experiments that actually improve outcomes\n-Closing the loop with feedback-driven optimization\n- People know to improve the agents application, but do they also know they need to improve their evals in tandem?\n\nIf you’re scaling agents beyond the prototype phase, this is the talk that helps you move from working once to working continuously.",
      "publishedAt": "2025-06-10T17:30:11Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M25S",
      "viewCount": 1944,
      "likeCount": 48,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Qvp9vw4jJQ8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Qvp9vw4jJQ8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Qvp9vw4jJQ8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Qvp9vw4jJQ8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Qvp9vw4jJQ8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Qvp9vw4jJQ8"
    },
    {
      "id": "lp0pswT_FEI",
      "title": "Just do it. (let your tools think for themselves) - Robert Chandler",
      "description": "There's a new type of wrapper in town. The MCP API wrapper. \n\nMake them thin and you'll be wondering why your chatbot is struggling to even send a Slack message (true story). But make them _agentic_ and the world is unlocked. \n\nIn this talk I'll demonstrate the drawbacks using low level APIs as MCPs and show the magic that happens when your 'tools' are actually other agents. It's prompts all the way down baby!",
      "publishedAt": "2025-06-10T17:30:11Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT6M50S",
      "viewCount": 1359,
      "likeCount": 35,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/lp0pswT_FEI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/lp0pswT_FEI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/lp0pswT_FEI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/lp0pswT_FEI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/lp0pswT_FEI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=lp0pswT_FEI"
    },
    {
      "id": "utxVvGJ4bcg",
      "title": "Supercharging developer workflow with Amazon Q Developer - Vikash Agrawal",
      "description": "Supercharging Developer Workflow with Amazon Q Developer\n\nTired of repetitive coding tasks? What if AI could handle coding, testing, documentation, and deployment for you? In this session, we’ll build the classic 2048 game from scratch using Amazon Q Developer, demonstrating how AI can streamline the development workflow.\n\nKey highlights:\n✅ /dev – AI-powered code generation\n✅ /test – Automated unit test creation\n✅ /doc – Instant documentation generation\n✅ /review – AI-assisted code review\n✅ Amazon Q Developer in CLI\n✅ /dev – Deployment script generation\n✅ Deploy & Debug – Seamless AWS deployment & debugging in CloudWatch\n\nBy the end of this session, you’ll see firsthand how Amazon Q Developer can boost productivity, reduce boilerplate, and help you ship faster. Let’s build smarter, not harder! 🚀",
      "publishedAt": "2025-06-10T17:30:11Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M22S",
      "viewCount": 1381,
      "likeCount": 24,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/utxVvGJ4bcg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/utxVvGJ4bcg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/utxVvGJ4bcg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/utxVvGJ4bcg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/utxVvGJ4bcg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=utxVvGJ4bcg"
    },
    {
      "id": "Vqsfn9rWXR8",
      "title": "AI Engineer World's Fair 2025 - Evals",
      "description": "",
      "publishedAt": "2025-06-06T10:30:09Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT3H59M12S",
      "viewCount": 8254,
      "likeCount": 132,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Vqsfn9rWXR8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Vqsfn9rWXR8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Vqsfn9rWXR8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Vqsfn9rWXR8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Vqsfn9rWXR8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Vqsfn9rWXR8"
    },
    {
      "id": "-9E9_21tx04",
      "title": "AI Engineer World’s Fair 2025 - Reasoning + RL",
      "description": "Timestamps\n\n0:00:00 intro\n0:11:53 Will Brown - Training Agentic Reasoners\n\n24:00 Greg Kamradt - Measuring AGI: Interactive Reasoning Benchmarks\n\n42:53 Aakanksha Chowdhery - Post-Training Open Models with RL for Autonomous Coding\n\n1:04:44 Ryan Marten - OpenThoughts: Data Recipes for Reasoning Models\n\n2:48:41 Afternoon Welcome\n\n2:49:16 Kyle Corbitt - How to Train Your Agent: Building Reliable Agents with RL\n\n3:09:08 Nathan Lambert - A taxonomy for next-generation reasoning models\n\n3:29:03 Christian Szegedy - Towards Verified Superintelligence\n3:32:36 Extremely low audio from Zoom\n3:41:45 audio quality improved\nChristian Szegedy/Former co-founder of xAI\nTowards Verified Superintelligence",
      "publishedAt": "2025-06-06T10:24:50Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT3H54M58S",
      "viewCount": 8218,
      "likeCount": 162,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/-9E9_21tx04/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/-9E9_21tx04/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/-9E9_21tx04/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/-9E9_21tx04/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/-9E9_21tx04/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=-9E9_21tx04"
    },
    {
      "id": "U-fMsbY-kHY",
      "title": "AI Engineer World’s Fair 2025 - Day 2 Keynotes & SWE Agents track",
      "description": "see schedule https://ai.engineer/schedule \n\ntimestamps:\n0:00:00 - start\n0:13:40 - Laurie Voss - Keynotes Intro\n0:15:35 - AI Education Summit announcement\n0:20:17 - Logan Kilpatrick (GDM) - Gemini 2.5 Pro 06-05 Launch - A Year of Shipping and What Comes Next\n0:32:23 - Jack Rae (GDM) - Thinking Deeper in Gemini\n0:51:05 - Manu Goyal (Braintrust) - The Importance of Evals\n0:57:05 - Solomon Hykes (Dagger) - Containing Agent Chaos (use-container launch)\n1:20:45 - Jesse Han (Morph) - Infrastructure for the Singularity\n2:28:00 - Vibhu Sapra - SWE Agent Intro\n2:29:00 - Scott Wu (Cognition) - Devin 2.0 and the Future of SWE\n2:45:30 - Rustin Banks (Google Jules) - Your Coding Agent Just Got Cloned\n3:00:12 - Christopher Harrison (GitHub Copilot) - The Agent Awakens\n3:19:37 - Tomas Reimers (Graphite) - Don't get one-shotted\n5:13:45 - Boris Cherny (Anthropic) - Claude Code & the evolution of Agentic Coding\n5:32:25 - Robert Brennan (Allhands) - Software Dev Agents: What Works & What Doesn't\n5:51:30 - Josh Albrecht (Imbue Sculptor) - Beyond the Prototype\n6:10:50 - Eno Reyes (Factory) - Ship Production Software in Minutes, Not Months\n7:14:25 - Laurie Voss - Keynotes Intro\n7:15:31 - George Cameron (Artificial Analysis) - Trends across the AI Frontier\n7:33:25 - Ankur Goyal (Braintrust) - Evals Closer\n7:38:30 - Barr Yaron (Amplify) - State of AI Engineering 2025\n7:51:38 - Alex Atallah (OpenRouter) - fun stories\n8:10:25 - Sean Grove (OpenAI) - The New Code\n8:31:25 - Ben & swyx: AI Engineer Official Hackathon\n\n\nsee schedule https://ai.engineer/schedule",
      "publishedAt": "2025-06-06T01:22:00Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT9H8M7S",
      "viewCount": 26986,
      "likeCount": 419,
      "commentCount": 11,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/U-fMsbY-kHY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/U-fMsbY-kHY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/U-fMsbY-kHY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/U-fMsbY-kHY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/U-fMsbY-kHY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=U-fMsbY-kHY"
    },
    {
      "id": "a0TyTMDh1is",
      "title": "AI Engineer World’s Fair 2025 - Retrieval + Search",
      "description": "",
      "publishedAt": "2025-06-05T22:21:03Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT4H34S",
      "viewCount": 6288,
      "likeCount": 94,
      "commentCount": 9,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/a0TyTMDh1is/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/a0TyTMDh1is/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/a0TyTMDh1is/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/a0TyTMDh1is/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/a0TyTMDh1is/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=a0TyTMDh1is"
    },
    {
      "id": "xhKgTkzSmuQ",
      "title": "AI Engineer World’s Fair 2025 - Tiny Teams",
      "description": "",
      "publishedAt": "2025-06-05T10:29:55Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT3H37M25S",
      "viewCount": 5802,
      "likeCount": 87,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/xhKgTkzSmuQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/xhKgTkzSmuQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/xhKgTkzSmuQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/xhKgTkzSmuQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/xhKgTkzSmuQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=xhKgTkzSmuQ"
    },
    {
      "id": "z4zXicOAF28",
      "title": "AI Engineer World's Fair 2025 - Day 1 Keynotes & MCP track ft. Anthropic MCP team",
      "description": "full schedule here: https://ai.engineer/schedule\n\nthanks @yashgargk for timestamps:\n\n0:00:00 - start\n0:15:15 - Welcome to AI Engineer - Laurie Voss (LlamaIndex)\n0:22:17 - Designing AI-Intensive Applications - Shawn Wang (Latent Space)\n0:35:46 - Spark to System: Building the Open Agentic Web - Asha Sharma (Microsoft)\n0:59:02 - State of Startups and AI 2025 - Sarah Guo (Conviction)\n1:24:44 - 2025 in LLMs so far - Simon Willison (Datasette)\n1:43:20 - Agentic GraphRAG - Stephen Chin (Neo4j), Andreas Kollegger (Neo4j)\n1:47:58 - Track Intros - Laurie Voss (LlamaIndex)\n1:51:00 - Break\n2:29:26 - MCP Track Intro - Henry Mao (Smithery)\n2:31:16 - MCP Origins & RFS - Theodora Chu (Anthropic)\n2:49:47 - What we learned from shipping remote MCP support at Anthropic - John Welsh (Anthropic)\n3:03:51 - Full Spectrum MCP: Uncovering Hidden Servers and Clients Capabilities - Harald Kirschner (VS Code, Microsoft)\n3:18:54 - MCP isn’t good, yet - David Cramer (Sentry)\n3:36:34 - Break\n5:08:05 - MCP is all you need - Samuel Colvin (Pydantic)\n5:25:43 - Observable tools - the state of MCP observability - Alex Volkov (Weights & Biases), Benjamin Eckel (Dylibso)\n5:43:00 - The rise of the agentic economy on the shoulders of MCP - Jan Curn (Apify)\n6:02:05 - Break\n7:08:00 - Buffer\n7:09:28 - Closing thoughts on Agentic GraphRAG + Demo - Stephen Chin (Neo4j), Andreas Kollegger (Neo4j)\n7:15:22 - Building Agents at Cloud-Scale - Antje Barth (AWS)\n7:34:26 - Windsurf everywhere, doing everything, all at once - Kevin Hou (Windsurf)\n7:50:31 - Buffer\n7:51:30 - #define AI Engineer - Greg Brockman (OpenAI), Shawn Wang (Latent Space)",
      "publishedAt": "2025-06-05T00:54:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT8H37M51S",
      "viewCount": 81398,
      "likeCount": 1104,
      "commentCount": 40,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/z4zXicOAF28/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/z4zXicOAF28/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/z4zXicOAF28/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/z4zXicOAF28/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/z4zXicOAF28/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=z4zXicOAF28"
    },
    {
      "id": "RR5le0K4Wtw",
      "title": "AI Engineer World’s Fair 2025 — GraphRAG",
      "description": "",
      "publishedAt": "2025-06-04T22:57:46Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT4H8M5S",
      "viewCount": 4626,
      "likeCount": 82,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/RR5le0K4Wtw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/RR5le0K4Wtw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/RR5le0K4Wtw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/RR5le0K4Wtw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/RR5le0K4Wtw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=RR5le0K4Wtw"
    },
    {
      "id": "3k4a0PemMu4",
      "title": "AI Engineer World’s Fair 2025 - LLM Recommendation Systems (RecSys)",
      "description": "",
      "publishedAt": "2025-06-04T22:54:39Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT4H6M11S",
      "viewCount": 6170,
      "likeCount": 87,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/3k4a0PemMu4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/3k4a0PemMu4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/3k4a0PemMu4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/3k4a0PemMu4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/3k4a0PemMu4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=3k4a0PemMu4"
    },
    {
      "id": "9u6xvcNJaxc",
      "title": "The 4 Patterns of AI Native Development — Patrick Debois",
      "description": "AI is fundamentally reshaping software development roles and activities. While the change is obvious, understanding the actual shifts taking place on the individual developer remains challenging. \n\nIn this talk, we introduce the four AI Native Dev patterns that are currently emerging:\n- From producer to manager: we say what AI needs to do\n- From implementation to intent: we care less on the how but focus on the why\n- From delivery to discovery: we experiment and learn\n- From content creation to knowledge: capture knowhow to get better\n\nWe backup these patterns by showcasing features in tools that support these shift.\n\nThe aim of the patterns is to help grasp how to position you and your team members 's career effectively in this changing landscape.",
      "publishedAt": "2025-06-04T07:21:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M11S",
      "viewCount": 7523,
      "likeCount": 181,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/9u6xvcNJaxc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/9u6xvcNJaxc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/9u6xvcNJaxc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/9u6xvcNJaxc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/9u6xvcNJaxc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=9u6xvcNJaxc"
    },
    {
      "id": "ZB7l4uxW3Yo",
      "title": "Breaking the Chain: Agent Continuations for Resumable AI Workflows - Greg Benson",
      "description": "AI agents are powerful—but brittle. Once an agent chain starts, you either let it run or you tear it down and lose state. Agent Continuations change that contract. Borrowing from programming‑language continuations, we capture an agent’s entire call stack—tools, goals, partial responses—in a compact JSON blob combined with the familiar messages array. The result is a protocol‑level \"Agent State\" that lets you:\n\n- Pause anytime for human-in-the-loop approval gates, rate‑limit resets, or progressive UI updates.\n\n- Migrate agents across nodes, clouds, even different agent execution platforms\n\n- Checkpoint long‑running multi‑agent plans using off‑the‑shelf storage and enable restarting in the presence of agent failure\n\n- Resume seamlessly through standard LLM function‑calling APIs, so every framework that speaks OpenAI JSON can speak continuations.\n\nOur approach works with single-level agent loops and multi-level agents in which agents can call subagents.\n\nAttendees will leave with open‑source Python snippets and a mental model that turns “monolithic” agents into restart‑able, human‑aware services—shrinking failure windows and unlocking new UX patterns for AI products.\n\n**Key Takeaways**\n\n- Why Continuations are a good construct for Agent State\n- Protocol spec and reference JSON examples and a - Python implementation\nLive demo: suspend a three‑layer agent with suspending for human approval\n\n** Links **\n\nhttps://github.com/SnapLogic/agent-continuations\nhttps://agentcreator.com",
      "publishedAt": "2025-06-03T22:31:07Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT27M2S",
      "viewCount": 2249,
      "likeCount": 56,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ZB7l4uxW3Yo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ZB7l4uxW3Yo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ZB7l4uxW3Yo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ZB7l4uxW3Yo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ZB7l4uxW3Yo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ZB7l4uxW3Yo"
    },
    {
      "id": "0ZPAvzhpGjw",
      "title": "The Agent Native Company — Rick Blalock, Agentuity",
      "description": "Are you just using AI—or are you building a company around it?\n\nIn this talk, I break down what it means to be an agent-native company—a business designed from the ground up with AI agents at the core of operations, culture, and product. Drawing from my own founder experience (building 14 months of product in 8 weeks with just 6 people and a stack of agents), I’ll walk you through the real-world shift happening right now across tech.\n\n🔍 What you'll learn:\n\nThe difference between AI-enhanced vs. AI-native orgs\n\nWhy the future of hiring is about AI fluency, not just professional networks or credentials\n\nThe rise of new job titles like “Agent Manager” (yes, that’s a real job)\n\nHow lean teams can use AI agents to achieve 10x—or even 100x—impact\n\nWhat “culture is the new stack” really means when humans and AI work together\n\n🧠 Featuring real-world examples, practical hiring insights, and a peek into how workflows and job roles are changing fast.\n\n📈 Whether you’re a founder, tech leader, or just curious about the future of work, this is your guide to scaling smart—with AI at the wheel.",
      "publishedAt": "2025-06-03T22:23:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M58S",
      "viewCount": 1165,
      "likeCount": 25,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/0ZPAvzhpGjw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/0ZPAvzhpGjw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/0ZPAvzhpGjw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/0ZPAvzhpGjw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/0ZPAvzhpGjw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=0ZPAvzhpGjw"
    },
    {
      "id": "9mzfioh1Zag",
      "title": "Grounded Reasoning Systems for Cloud Architecture - Iman Makaremi",
      "description": "As LLMs move into enterprise workflows, developers face a new kind of architecture challenge: how do you build reliable, interpretable systems powered by agents and reasoning?\n\nThis talk unpacks how we designed and implemented an AI orchestration framework for enterprise architecture — combining LangGraph for multi-agent workflows, Flyte for distributed execution, and AWS Bedrock for LLM inference using Claude 3. The product: an AI copilot for enterprise architects, deeply rooted in your tech stack context.\n\nAt the core of this system is a domain-specific **knowledge graph** that acts as long-term memory for the agents. It enables persistent, structured representations of architectural state, system dependencies, and business context — giving the agents the grounding they need to generate accurate recommendations, translate natural language into SQL or code, and maintain continuity across workflows.\n\nWe’ll also cover how we’ve integrated observability practices — including planned OpenTelemetry instrumentation — to trace and debug autonomous AI systems in production.\n\nIf you’re a developer or AI engineer thinking beyond the chatbot and looking to embed reasoning into complex system design and data tasks, this talk offers an end-to-end blueprint — from orchestration and grounding to production monitoring.",
      "publishedAt": "2025-06-03T22:23:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT26M5S",
      "viewCount": 713,
      "likeCount": 16,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/9mzfioh1Zag/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/9mzfioh1Zag/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/9mzfioh1Zag/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/9mzfioh1Zag/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/9mzfioh1Zag/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=9mzfioh1Zag"
    },
    {
      "id": "A0PxE39xaMc",
      "title": "GPU-less, Trust-less, Limit-less: Reimagining the Confidential AI Cloud - Mike Bursell",
      "description": "What happens when private AI models or sensitive data need to run in the public cloud?\n\nCan we still maintain control – without relying on blind trust?\nCan we eliminate that blind trust and make infrastructure verifiable by design?\n\nIn this talk, you’ll discover what a “GPU-less” future really means: not the absence of acceleration, but the freedom to collaborate and deploy private AII workloads in a confidential, self-sovereign AI cloud – with open, on-chain guarantees that centralized clouds simply can’t offer. \n\nNo GPU-provider lock-in. No black-box execution. Just algorithmic, sovereign infrastructure – where the confidential cloud is a protocol, not a service.\n\nYou’ll learn the foundations of Confidential AI and see real-world results powered by it. \nThen, through four demos on Super Protocol, you’ll learn how to:\n\n1. AI Marketplace & Confidentiality Check – Deploy models in a few clicks and verify on-chain they’re running inside hardware-backed confidential environments.\n2. n8n Healthcare AI Workflow – Build and run agentic automations for sensitive data – entirely within confidential environments.\n3. Distributed vLLM Inference – Parallelize LLM inference across multiple GPU servers– with zero data exposure and no dependency on any single provider.\n4. Provable Medical-Data Training & On-Chain Reporting – Train on multiple sensitive datasets inside confidential environments – no data or IP exposed to participants, infrastructure providers, or Super Protocol – and generate verifiable on-chain proofs of exactly what ran, where, and how.\n\nJoin us to discover how you can leverage Confidential AI today – and unlock new possibilities.\n\nExtra resources:\n- NVIDIA on Super Protocol: https://developer.nvidia.com/blog/exploring-the-case-of-super-protocol-with-self-sovereign-ai-and-nvidia-confidential-computing\n- Website  https://superprotocol.com/\n- Super AI Marketplace: https://marketplace.superprotocol.com/\n- Documentation: https://docs.superprotocol.com/",
      "publishedAt": "2025-06-03T22:23:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT43M41S",
      "viewCount": 4631,
      "likeCount": 688,
      "commentCount": 15,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/A0PxE39xaMc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/A0PxE39xaMc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/A0PxE39xaMc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/A0PxE39xaMc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/A0PxE39xaMc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=A0PxE39xaMc"
    },
    {
      "id": "fcPUqxfrE6Y",
      "title": "Why the Best AI Agents Are Built Without Frameworks (Primitives over Frameworks) — Ahmad Awais, CHAI",
      "description": "Cursor, v0, chai.new, lovable, bolt — what do they all have in common? They weren’t built on AI frameworks—they're built using primitives optimized for speed, scale, and flexibility.\n\nLLMs are evolving fast—like, literally every week. New standards pop up (looking at you, MCP), and APIs change faster than you can keep track. Frameworks just can't move at this speed.\n\nIn this talk, I'll challenge conventional engineering wisdom, sharing my real-world experience scaling thousands of AI agents to handle over 100 million monthly runs.\n\nYou'll discover how using AI primitives can dramatically speed up iteration, provide bigger scale, and simplify maintenance. \n\nI'll share eight practical agent architectures—covering memory management, auto tool integration, and simple serverless deployment—to help you quickly build reliable and scalable AI agents.\n\nBy the end of this session, you'll clearly see why we must rethink and rebuild our infrastructure and focus on AI-native primitives instead of heavy, bloated, and quickly outdated frameworks. \n\nI wonder if we need another S3-moment but for the AI agent infrastructure.",
      "publishedAt": "2025-06-03T22:23:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT27M6S",
      "viewCount": 22955,
      "likeCount": 546,
      "commentCount": 72,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/fcPUqxfrE6Y/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/fcPUqxfrE6Y/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/fcPUqxfrE6Y/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/fcPUqxfrE6Y/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/fcPUqxfrE6Y/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=fcPUqxfrE6Y"
    },
    {
      "id": "tOou_GJ9Ddk",
      "title": "Are MCPs Overhyped? A Rant about MCPs — Henry Mao, Smithery",
      "description": "AI agents are becoming smarter but lack the broad capability to take action in practice. At Smithery, we believe the missing link is an AI orchestration layer—a unified interface that gives agents context, action, and a way to learn from real interactions. This talk explores the problem space in the Model Context Protocol (MCP) ecosystem and how we're tackling it at Smithery.",
      "publishedAt": "2025-06-03T22:23:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7M29S",
      "viewCount": 4394,
      "likeCount": 77,
      "commentCount": 11,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/tOou_GJ9Ddk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/tOou_GJ9Ddk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/tOou_GJ9Ddk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/tOou_GJ9Ddk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/tOou_GJ9Ddk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=tOou_GJ9Ddk"
    },
    {
      "id": "d7ds6m7fbqg",
      "title": "Agentic Enterprise - What your CEO must know about AI -  Hubert Misztela",
      "description": "How large organizations will be transformed by AI?\nWhat people and organizations are scared of because of AI?\nWhat people do not know about AI Agents?\nWhat enterprises need?\nWhy we might be wrong about Agents and LLMs impact all together? \n\nWorkflows optimization. \nAI beyond LLMs and Agents: Representation Learning + GenAI + New Interfaces.\nContext is the new oil, not the data.\n\nYour CEO has to pivot. Now.",
      "publishedAt": "2025-06-03T22:22:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT28M4S",
      "viewCount": 2472,
      "likeCount": 64,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/d7ds6m7fbqg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/d7ds6m7fbqg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/d7ds6m7fbqg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/d7ds6m7fbqg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/d7ds6m7fbqg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=d7ds6m7fbqg"
    },
    {
      "id": "nnktgWtfJHE",
      "title": "Blender MCP and The Future Of Creative Tools - Siddharth Ahuja",
      "description": "A dive into the Blender MCP to see how it was made, what use cases for creators it unlocks, and how the future might look for creators.",
      "publishedAt": "2025-06-03T22:22:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M50S",
      "viewCount": 4559,
      "likeCount": 166,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/nnktgWtfJHE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/nnktgWtfJHE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/nnktgWtfJHE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/nnktgWtfJHE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/nnktgWtfJHE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=nnktgWtfJHE"
    },
    {
      "id": "pSqpC7fFLZA",
      "title": "The Robots are coming for your job, and that's okay - Elmer Thomas and Maria Bermudez",
      "description": "In a world where AI is revolutionizing API documentation, many wonder: “Why can’t we just use AI to write the docs?” At Twilio, we’ve explored this question deeply. Our Developer Education team found that while generative AI is powerful, it still carries too much risk to be used as an autonomous customer-facing agent. Instead, we use AI to amplify our small team’s impact by automating repetitive tasks, freeing us to focus on high-value, accuracy-critical work.\n\nThis talk shares our journey building and deploying AI agents to streamline documentation workflows, support over 100 product managers, and empower less-technical colleagues to contribute. Attendees will learn practical strategies for integrating agentic AI into documentation processes, how to balance automation with human oversight, and ideas for taking their own docs to the next level. This session is ideal for anyone interested in the intersection of AI, APIs, and documentation, especially those on short-staffed teams seeking scalable solutions.",
      "publishedAt": "2025-06-03T22:22:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT8M57S",
      "viewCount": 836,
      "likeCount": 30,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/pSqpC7fFLZA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/pSqpC7fFLZA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/pSqpC7fFLZA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/pSqpC7fFLZA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/pSqpC7fFLZA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=pSqpC7fFLZA"
    },
    {
      "id": "sXXl3YMU7ZI",
      "title": "Building Reliable Support Agents Using the Effect Typescript Library - Michael Fester",
      "description": "In this video, we walk through how our team built production-ready support agents using the Effect TypeScript library. The video includes a demo of the agent in action, along with a breakdown of the architecture and design decisions behind it.\n\nWe cover what worked well, what was challenging, and why we are continuing to invest in Effect for future development. If you’re building internal tools, working with LLMs, or automating customer support, this talk shares practical lessons on creating robust systems with strong guarantees.\n\nTopics include:\nArchitectural patterns for agent-based systems\nTradeoffs in developer experience\nTechniques for reliability and fault tolerance\n\nFeel free to reach out or share your thoughts:\nTwitter: x.com/michaelfester\nLinkedIn: linkedin.com/in/michaelfester",
      "publishedAt": "2025-06-03T22:22:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7M22S",
      "viewCount": 889,
      "likeCount": 20,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/sXXl3YMU7ZI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/sXXl3YMU7ZI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/sXXl3YMU7ZI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/sXXl3YMU7ZI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/sXXl3YMU7ZI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=sXXl3YMU7ZI"
    },
    {
      "id": "tYCu_57jzL8",
      "title": "The Knowledge Graph Mullet: Trimming GraphRAG Complexity - William Lyon",
      "description": "There are typically two approaches to working with graphs: property graphs and RDF. These systems are often thought of as different knowledge graph paradigms optimized for different workflows. This talk examines how combining property graph interfaces with RDF triple storage creates an optimal foundation for GraphRAG systems. We'll show how to build and use knowledge graphs using the Dgraph graph database and how knowledge graphs are the foundation of building AI Agents.\n\nResources:\n\n* Dgraph docs: https://docs.hypermode.com/dgraph/overview\n* Hypermode: https://hypermode.com\n* hyper-news GitHub repo: https://github.com/johnymontana/hyper-news\n* Hypermode Agents early access: https://hyp.foo/agents",
      "publishedAt": "2025-06-03T22:22:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT32M52S",
      "viewCount": 1441,
      "likeCount": 35,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/tYCu_57jzL8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/tYCu_57jzL8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/tYCu_57jzL8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/tYCu_57jzL8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/tYCu_57jzL8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=tYCu_57jzL8"
    },
    {
      "id": "u825uxb7LnA",
      "title": "The Coherence Trap: Why LLMs Feel Smart (But Aren’t Thinking) - Travis Frisinger",
      "description": "Why AI engineers must rethink what intelligence means in the age of large language models.\n\nLLMs aren’t thinking.\nNo awareness. No reasoning. No plan.\nAnd yet—they feel smart. Shockingly so.\n\nThis talk introduces coherence reconstruction, a mental model that explains why LLMs are so useful despite their lack of true understanding. You’ll learn how they generate meaning through latent coherence—a kind of internal gravity that pulls language into alignment with context.\n\nWe’ll break down:\n\n+ Why hallucinations happen—and why you can’t fully eliminate them.\n+ How prompts act like force vectors, shaping behavior in structured ways.\n+ What this all means for reasoning tasks, evaluation practices, and agent design.\n\nIf you’re building tools, agents, or workflows with LLMs, this talk will reframe how you think about reliability, cognition, and what \"understanding\" even means.\n\n🔗 Additional resources:\nBlog: https://aibuddy.software/\nAI Decision Loop Paper: https://aibuddy.software/papers/2500_chatgpt_conversations_case_study.pdf\nAI Decision Loop Git Repo: https://github.com/T-rav/gpt-chat-analysis\nAI Coherence Paper: https://aibuddy.software/papers/AI_Coherence_A_Theory_of_Utility_in_Large_Language_Models.pdf\nCat Metal Album: https://www.youtube.com/watch?v=gdV5l0JvdNo&list=PL0X82GOpevvYfPLM-JibRJEizHqCJ6U4H&index=7",
      "publishedAt": "2025-06-03T22:22:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M47S",
      "viewCount": 1822,
      "likeCount": 56,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/u825uxb7LnA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/u825uxb7LnA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/u825uxb7LnA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/u825uxb7LnA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/u825uxb7LnA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=u825uxb7LnA"
    },
    {
      "id": "wAQK7O3WGEE",
      "title": "Agents reported thousands of bugs, how many were real? - Ian Butler and Nick Gregory",
      "description": "Ever had an AI-generated tweak unexpectedly break your entire project? Agentic software development has impressive promise, but the reality still falls short. In this talk we introduce SM-100, a groundbreaking benchmark designed specifically to evaluate autonomous agents on software maintenance tasks.\n\nWe're also excited to announce Bismuth, a generalist software agent with strong performance on such maintenance tasks.\n\nhttps://bismuth.sh & https://sm100bench.com",
      "publishedAt": "2025-06-03T22:22:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M39S",
      "viewCount": 594,
      "likeCount": 14,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/wAQK7O3WGEE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/wAQK7O3WGEE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/wAQK7O3WGEE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/wAQK7O3WGEE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/wAQK7O3WGEE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=wAQK7O3WGEE"
    },
    {
      "id": "wHhlvcQgi9M",
      "title": "7 Habits of Highly Effective Generative AI Evaluations - Justin Muller",
      "description": "Evaluations are the single most reliable indicator of the health and long term viability of any gen AI project.  As a Principal Applied AI Architect for AWS, I've had the opportunity to look at over 100 different attempts at evaluation frameworks over the last few years. \nIn this talk I share some stories about the best and worst, and then distill the 7 most common elements I've seen in successful evaluations.  \n\nSlides at https://d2ot4ns4zf41bm.cloudfront.net/slides/7+Habits+AI+World's+Fair.pptx",
      "publishedAt": "2025-06-03T22:22:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT25M39S",
      "viewCount": 4490,
      "likeCount": 199,
      "commentCount": 20,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/wHhlvcQgi9M/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/wHhlvcQgi9M/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/wHhlvcQgi9M/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/wHhlvcQgi9M/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/wHhlvcQgi9M/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=wHhlvcQgi9M"
    },
    {
      "id": "wsFd22SL1s8",
      "title": "Arrakis: How To Build An AI Sandbox From Scratch - Abhishek Bhardwaj",
      "description": "Arrakis (https://github.com/abshkbh/arrakis) provides MicroVM-based secure sandboxes for code execution and full computer use. It features first-class support for backtracking, a Python SDK, and a Model Context Protocol (MCP) server.\n\nIn this talk, we go under the hood to explore how to architect an AI sandbox from the ground up. We’ll also dive into why sandboxes are becoming essential infrastructure for AI models and agents — enabling the next big unlock in intelligence.\n\nLinks -\nSlides for the talk available here - https://tinyurl.com/arrakis-aie\nVibe coding with Claude and Arrakis -https://x.com/abshkbh/status/1907480355529203809",
      "publishedAt": "2025-06-03T22:22:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT40M18S",
      "viewCount": 4046,
      "likeCount": 140,
      "commentCount": 14,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/wsFd22SL1s8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/wsFd22SL1s8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/wsFd22SL1s8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/wsFd22SL1s8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/wsFd22SL1s8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=wsFd22SL1s8"
    },
    {
      "id": "y9YQc9a3gNw",
      "title": "The Voice-First AI Overlay: Designing Conversational Co-Pilots - Gregory Bruss",
      "description": "This talk introduces the concept of the 'Voice-First AI Overlay': an AI agent assisting conversations directly within the communication interface, operating either single-sidedly or mediating between participants.\n\nI dive into the engineering and design of such a system. We'll cover how overlays fit into the broader agent orchestration landscape, UI principles, and address the voice-first UX problem: how to design AI overlays that genuinely assist without disrupting the primary human interaction\n\nSee a live demo transforming messy, real-time captions into helpful conversational hints in the context of a language lesson.",
      "publishedAt": "2025-06-03T22:22:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M44S",
      "viewCount": 913,
      "likeCount": 20,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/y9YQc9a3gNw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/y9YQc9a3gNw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/y9YQc9a3gNw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/y9YQc9a3gNw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/y9YQc9a3gNw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=y9YQc9a3gNw"
    },
    {
      "id": "Ghc-qalQFLw",
      "title": "My AI Thinks I'm Eating My Feelings (and Other Nutritional Insights) - Rami Alhamad",
      "description": "Eating well shouldn't require an advanced degree or hours decoding nutrition labels. Alma leverages cutting-edge AI to turn complex nutritional science into straightforward, personalized advice. \n\nIn this talk, we'll dive into how we're using large language models and real-world user data to reshape how people track, understand, and improve their diets. We'll share insights on building user-friendly AI experiences, practical lessons from Alma's journey, and how we're making nutrition advice smarter, simpler, and genuinely helpful—one meal at a time.",
      "publishedAt": "2025-06-03T22:22:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT9M59S",
      "viewCount": 324,
      "likeCount": 8,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Ghc-qalQFLw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Ghc-qalQFLw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Ghc-qalQFLw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Ghc-qalQFLw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Ghc-qalQFLw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Ghc-qalQFLw"
    },
    {
      "id": "HIGpxVjGFBw",
      "title": "From PM at Stripe to Building an AI startup, a recent founder's journey - Mounir Mouawad",
      "description": "I spent a bunch of time building products in Big Tech, most recently at Stripe but before that at Google and Amazon. In this short talk I am sharing the highs and lows of building a business in AI and how that differs from building products in Big Tech. May this be an inspiration to would-be founders or useful commiseration material for fellow founders :)",
      "publishedAt": "2025-06-03T22:22:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT11M59S",
      "viewCount": 589,
      "likeCount": 16,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/HIGpxVjGFBw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/HIGpxVjGFBw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/HIGpxVjGFBw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/HIGpxVjGFBw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/HIGpxVjGFBw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=HIGpxVjGFBw"
    },
    {
      "id": "Nqb7JTx0Pqo",
      "title": "MCP Agent Fine tuning Workshop - Ronan McGovern",
      "description": "This is a hands on workshop where students will run an agent with access to MCP servers (a playwright browser, although others can be added), generate high quality reasoning traces, and then train a Qwen3 model on those traces.\n\nStudents will learn:\n- How to generate high quality MCP agent reasoning traces, via an OpenAI style endpoint\n- How to save tools and multi-turn traces\n- Fine-tune a Qwen3 model on those traces with unsloth\n- Run the fine-tuned model",
      "publishedAt": "2025-06-03T22:22:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT35M30S",
      "viewCount": 2007,
      "likeCount": 69,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Nqb7JTx0Pqo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Nqb7JTx0Pqo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Nqb7JTx0Pqo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Nqb7JTx0Pqo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Nqb7JTx0Pqo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Nqb7JTx0Pqo"
    },
    {
      "id": "RVN9HWKmkNU",
      "title": "Will Agent evaluation via MCP Stabilize Agent Networks? - Ari Heljakka",
      "description": "Exposing complex AI Evaluation frameworks to AI agents via MCP allows for a new paradigm of agents to self-improve in a controllable manner. Unlike the often unstable straight-forward self-criticism loops, the MCP-accessible evaluation frameworks can provide the persistence layer that stabilizes and standardizes the measure of progress towards plan fulfillment with agents. \n\nIn this talk, we show how MCP-enabled evaluation engine already allows agents to self-improve in a way that is independent of agent architectures and frameworks, and holds promise to become a cornerstone of rigorous agent development.",
      "publishedAt": "2025-06-03T22:22:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M11S",
      "viewCount": 382,
      "likeCount": 12,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/RVN9HWKmkNU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/RVN9HWKmkNU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/RVN9HWKmkNU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/RVN9HWKmkNU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/RVN9HWKmkNU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=RVN9HWKmkNU"
    },
    {
      "id": "UcW_s4BmuD0",
      "title": "The Demo I Wish I'd Had: OpenAI's Agents SDK... serverless! - Brook Riggio",
      "description": "Deploying and orchestrating significant AI workflows on serverless platforms like Vercel presents unique infrastructure challenges, like managing time limits and persistent state, handling task failures, and achieving reliable execution. As an engineer exploring OpenAI's powerful new Agents SDK on Vercel, I initially struggled with fitting sizeable jobs within the limits of our serverless platform.\n\nIn this highly practical, hands-on session, you'll experience the demo I wish I'd had—showing exactly how to use Inngest's native integration with Vercel to run OpenAI's Agents SDK for robust orchestration and execution of complex, long-running AI workflows. We'll cover practical solutions for retries, state preservation, and seamless orchestration within the constraints of Vercel's serverless platform.\n\nYou'll leave this talk equipped with clear, actionable strategies for implementing production-ready AI infrastructure on Vercel, including essential best practices for monitoring, observability, and robust error handling. Whether you're building your first AI system or enhancing existing workflows, this demo-driven talk provides the tools and insights needed for resilient, scalable AI deployments on Vercel.\n\nComplete demo repo: https://github.com/brookr/serverless-agents \n\nPlease fork this, build your own examples, and send a PR to link to your work!",
      "publishedAt": "2025-06-03T22:22:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M51S",
      "viewCount": 3309,
      "likeCount": 87,
      "commentCount": 17,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/UcW_s4BmuD0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/UcW_s4BmuD0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/UcW_s4BmuD0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/UcW_s4BmuD0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/UcW_s4BmuD0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=UcW_s4BmuD0"
    },
    {
      "id": "Ywl4LsvHKzU",
      "title": "RAG Evaluation Is Broken! Here's Why (And How to Fix It) - Yuval Belfer and Niv Granot",
      "description": "Optimizing local benchmarks, chunking strategies, perfect retrieval scores. If you just nodded along, you're one of many developers building RAG systems optimized for metrics that don't matter in the real world.\n\nBut what if our entire approach to evaluating retrieval-augmented generation is fundamentally flawed? The uncomfortable truth is that current RAG benchmarks reward systems that fail spectacularly on realistic information retrieval tasks.\n\nIn this talk, I'll expose the critical gaps in how we evaluate RAG systems today, from the chunking catch-22 to the myth of perfectly contained information. Using examples like the \"Seinfeld Test,\" we'll explore why high benchmark scores often lead to disappointed users.\n\nYou'll learn practical strategies for meaningful RAG evaluation that reflects how information actually works in the wild, helping you build systems that impress not just benchmark leaderboards, but actual humans.\n\nTo learn more, check out the full episode on RAG evaluation on YAAP: https://youtu.be/RsSkwpTmn8o?si=9gIR6EeIzPgbqY4O",
      "publishedAt": "2025-06-03T22:22:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT10M58S",
      "viewCount": 691,
      "likeCount": 14,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Ywl4LsvHKzU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Ywl4LsvHKzU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Ywl4LsvHKzU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Ywl4LsvHKzU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Ywl4LsvHKzU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Ywl4LsvHKzU"
    },
    {
      "id": "_-oIuRH4oGA",
      "title": "How agents broke app-level infrastructure - Evan Boyle",
      "description": "LLMs have completely broken our assumptions about app-level workloads. Compared to querying a database, LLMs are extremely flakey and slow. In web 2.0, p99 latency was just a few hundred milliseconds - anything higher and the on call is getting paged. \n\nBut today any API that uses LLMs has a p1 latency of a couple of seconds. Yet, the infrastructure we build on top of hasn't caught up with these new assumptions. There isn't a single serverless provider that supports running code for more than a few minutes!\n\nIn this session we'll take about infrastructure patterns that used to be niche, but today require attention from anyone building on top of LLMs:\n\n- Durable execution\n- Long running workflows and APIs\n- Durable execution\n- Agent-scoped storage",
      "publishedAt": "2025-06-03T22:22:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M32S",
      "viewCount": 540,
      "likeCount": 13,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/_-oIuRH4oGA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/_-oIuRH4oGA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/_-oIuRH4oGA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/_-oIuRH4oGA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/_-oIuRH4oGA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=_-oIuRH4oGA"
    },
    {
      "id": "aDj9sY2RoG8",
      "title": "The End of Awkward AI Transcriptions - Travis Bartley and Myungjong Kim",
      "description": "NVIDIA is setting the new global standard for speech AI—with 6 top-ten models on the Hugging Face ASR leaderboard and blazing a trail with models like Parakeet2. In this talk, we’ll pull back the curtain on what it takes to build the world’s fastest, most accurate conversational AI, from open-source research to enterprise-ready NIM microservices that scale across any infrastructure.\n\nWe hear you, developers: Whether you’re building call center agents, video dubbing tools, or digital humans, NVIDIA’s ecosystem is designed for you. With Python-first frameworks, intuitive configurators, and a thriving open-source community, we’re making rapid iteration and seamless integration a reality—so you can launch faster, cut costs, and innovate boldly.\n\nReal-world impact is already here. Enterprises are deploying multilingual, noise-robust, and highly customizable voice agents at scale, while our digital human blueprint lets you create interactive avatars. But the real story is the underlying conversational AI stack that’s transforming customer experience, accessibility, and global communication.\n\nJoin us to see why developers and industry leaders alike are calling NVIDIA’s speech AI “a game-changer”—and how you can be part of the next wave of conversational intelligence.",
      "publishedAt": "2025-06-03T22:22:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M24S",
      "viewCount": 482,
      "likeCount": 11,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/aDj9sY2RoG8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/aDj9sY2RoG8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/aDj9sY2RoG8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/aDj9sY2RoG8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/aDj9sY2RoG8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=aDj9sY2RoG8"
    },
    {
      "id": "Th5e4h-oVmc",
      "title": "Real AI Agents Need Planning, Not Just Prompting - Yuval Belfer",
      "description": "AI agents that actually deserve the name - do they even exist? Despite the hype, most \"agents\" today are just LLMs with fancy prompt engineering tricks, lacking true agency capabilities.\n\nHere's a deeper issue: it's 2025, and LLMs still struggle with basic instruction following. Weird when one of the first big models was literally called \"InstructGPT,\" right? Benchmarks are saturated but meaningless, and without genuine planning abilities, these systems will keep hitting the same walls.\n\nIn this session we will go through:\n- Why conventional agent frameworks like ReAct miss the mark on true agency\n- How dynamic planning creates agents that actually follow complex instructions\n- Tips to improve instruction following in any AI system you build",
      "publishedAt": "2025-06-03T22:22:27Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7M58S",
      "viewCount": 889,
      "likeCount": 16,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Th5e4h-oVmc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Th5e4h-oVmc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Th5e4h-oVmc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Th5e4h-oVmc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Th5e4h-oVmc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Th5e4h-oVmc"
    },
    {
      "id": "bbq0b_FpYEY",
      "title": "Rust is the language of the AGI - Michael Yuan",
      "description": "In the Latent Space podcast, Bret Taylor argued that strongly and statically-typed programming languages, such as Rust, could be especially well suited for AI coding, since the generated code can be validated by compilers for real-time feedback and reinforcement learning. However, unlike weakly or dynamically typed JavaScript or Python, there are few examples of Rust code in LLMs’ training corpora, and hence limiting the LLM's capability in generating Rust code. \n\nIn this talk, we will discuss the open-source Rust Coder project, which provides an integrated agentic framework based on the MCP protocol for generating complete and valid Rust projects. The Rust Coder framework enables the following functionalities for coding LLMs (e.g., Qwen Coder or Codestral).\n\n* Provides Rust example code, explanations, and tutorials relevant to the user’s request within the LLM query context.\n* Generates and parses generated code artifacts into Rust Cargo projects.\n* Compiles and executes generated Rust Cargo projects.\n* Executes the compiled project against test cases.\n* Provides coding LLM feedback based on compiler and testing outputs.\n* Runs continuously until all issues are fixed.\n\nWe will demonstrate how the Rust Coder project works, how to integrate it into your agents, and ways to contribute to the open-source effort. We will also discuss pilot results from a large Rust coding camp (1000+ college students) using the Rust Coder tool.\n\nThe Rust Coder is supported by two Linux Foundation Mentorship grants, as well as content provided by the Rust Foundation.",
      "publishedAt": "2025-06-03T22:22:27Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT29M14S",
      "viewCount": 11143,
      "likeCount": 384,
      "commentCount": 35,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/bbq0b_FpYEY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/bbq0b_FpYEY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/bbq0b_FpYEY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/bbq0b_FpYEY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/bbq0b_FpYEY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=bbq0b_FpYEY"
    },
    {
      "id": "0uj9lMI-sIo",
      "title": "Luminal - Search-Based Deep Learning Compilers - Joe Fioti",
      "description": "Luminal is a deep learning compiler for CPUs, GPUs, and ASICs that takes a search-first approach to discovering efficient kernels, such as flash attention, automatically.",
      "publishedAt": "2025-06-03T22:22:26Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT24M35S",
      "viewCount": 453,
      "likeCount": 22,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/0uj9lMI-sIo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/0uj9lMI-sIo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/0uj9lMI-sIo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/0uj9lMI-sIo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/0uj9lMI-sIo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=0uj9lMI-sIo"
    },
    {
      "id": "2CXn-CByNoo",
      "title": "The RAG Stack We Landed On After 37 Fails - Jonathan Fernandes",
      "description": "Retrieval returning irrelevant results? Can't deploy solutions in the cloud? If these questions keep you up at night, you're likely experiencing the common frustrations of building an effective RAG system. But what if we could systematically optimise each component of the pipeline? \n\nIn this talk, I'll share the insights gained from 37 failed attempts, demonstrating live with documents from a knowledge base and how each optimisation impacts the end result. You'll walk away understanding how to diagnose the weaknesses in your RAG pipeline and apply targeted improvements that dramatically boost performance in real-world applications.",
      "publishedAt": "2025-06-03T22:22:26Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M52S",
      "viewCount": 8875,
      "likeCount": 288,
      "commentCount": 28,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/2CXn-CByNoo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/2CXn-CByNoo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/2CXn-CByNoo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/2CXn-CByNoo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/2CXn-CByNoo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=2CXn-CByNoo"
    },
    {
      "id": "8D_VdU6DBhI",
      "title": "Invisible Users, Invisible Interfaces: Accelerating Design Iteration with AI Simulation - Alex Liss",
      "description": "The genAI explosion has flipped classic software design on its head. Instead of building invisible interfaces, experiences so intuitive they feel second nature, we’ve seen a flood of awkward chatbot overlays and bolt-on features that confuse more than they help. But what if AI could be part of the solution? The path back to seamless design lies in using AI not as a feature, but as a tool for design itself. Through invisible users, like Intelligent Twins for AI-driven audience simulations, and computer use agents for visual evaluation, designers can accelerate needfinding and test interface concepts at scale. This session will explain that by simulating how diverse users experience new interactions, teams can anticipate user needs, reduce friction, and build great interfaces faster. Don’t bolt-on genAI features to existing products and tell people its magic – use AI to design software that actually feels like magic.",
      "publishedAt": "2025-06-03T22:22:26Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M37S",
      "viewCount": 449,
      "likeCount": 11,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/8D_VdU6DBhI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/8D_VdU6DBhI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/8D_VdU6DBhI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/8D_VdU6DBhI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/8D_VdU6DBhI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=8D_VdU6DBhI"
    },
    {
      "id": "CXsbjcrf_5g",
      "title": "Text-to-Speech Data Preparation and Fine-tuning Workshop - Ronan McGovern",
      "description": "By the end of this workshop, you'll have train Sesame's CSM-1B text-to-speech model on a voice from a Youtube video. The workshop will cover data preparation, fine-tuning and evaluation.",
      "publishedAt": "2025-06-03T22:22:26Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT34M",
      "viewCount": 516,
      "likeCount": 23,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/CXsbjcrf_5g/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/CXsbjcrf_5g/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/CXsbjcrf_5g/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/CXsbjcrf_5g/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/CXsbjcrf_5g/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=CXsbjcrf_5g"
    },
    {
      "id": "Djv8Sp11UjI",
      "title": "The Current State of Browser Agents - Jerry Wu and Wyatt Marshall",
      "description": "Browser agents are here. But beyond simple sample use cases (I'm looking at you flight booking demo), are they as good as advertised? \n\nIn this talk, we introduce Web Bench, a new benchmark we've developed that rigorously tests browser agents across 450+ websites on real-world action based objectives such as info extraction, login/auth, form filling, and others. We'll dive into the results, unpack some unexpected discoveries, and discuss broader implications for the future of general purpose agents. \n\nYou'll walk away with practical insights into:\n\n1. data-driven understanding of the capabilities and limitations of state-of-the-art browser agents\n2. how to meaningfully evaluate browser agents \n3. hard-won lessons on designing and launching a benchmark\n\nCome through and see what browser agents can really do.\n\nResources\n\nLeaderboard - https://webbench.ai/\nTechnical Report: https://halluminate.ai/blog/benchmark\nGithub - https://github.com/Halluminate/WebBench\nHuggingface - https://huggingface.co/datasets/Halluminate/WebBench",
      "publishedAt": "2025-06-03T22:22:26Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M13S",
      "viewCount": 557,
      "likeCount": 18,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Djv8Sp11UjI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Djv8Sp11UjI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Djv8Sp11UjI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Djv8Sp11UjI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Djv8Sp11UjI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Djv8Sp11UjI"
    },
    {
      "id": "5_QWh4LGoxg",
      "title": "Cognitive Shield Real Time Real Smart - Rachna Srivastava",
      "description": "This high-energy demonstration unveils Cognitive Shield, a revolutionary three-level defense system that harnesses AI to combat sophisticated financial fraud. Watch as we showcase real-time deepfake detection, graph intelligence for fraud ring visualization, and cross-channel correlation of threats – all integrated within a comprehensive platform that amplifies human expertise rather than replacing it. \n\nLearn how the same AI powering today's most dangerous financial attacks can be turned into our strongest defense.",
      "publishedAt": "2025-06-03T22:22:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT44M58S",
      "viewCount": 249,
      "likeCount": 4,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/5_QWh4LGoxg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/5_QWh4LGoxg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/5_QWh4LGoxg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/5_QWh4LGoxg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/5_QWh4LGoxg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=5_QWh4LGoxg"
    },
    {
      "id": "Bf71xMwd-Y0",
      "title": "Buy Now, Maybe Pay Later: Dealing with Prompt-Tax While Staying at the Frontier - Andrew Thomspson",
      "description": "Frontier LLMs now drop at warp speed. Each upgrade hits you with a Prompt‑Tax: busted prompts, cranky domain experts, and evals that show up fashionably late.\n\nIn this talk I’ll share 18 months of bruises (and wins) from shipping an agentic product for real‑estate lawyers:\n\n• The challenge of an evolving prompt library that breaks every time the model jumps\n\n• The bare‑bones tactics that actually work for faster migrations\n\n•  Our “betting on the model” mantra: ship the newest frontier model even when it’s rough around the edges, then race to close the gaps before anyone else does\n\nWalk away with a playbook to stay frontier‑fresh without blowing up your roadmap or your team’s sanity.",
      "publishedAt": "2025-06-03T22:22:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT25M9S",
      "viewCount": 313,
      "likeCount": 1,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Bf71xMwd-Y0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Bf71xMwd-Y0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Bf71xMwd-Y0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Bf71xMwd-Y0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Bf71xMwd-Y0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Bf71xMwd-Y0"
    },
    {
      "id": "DjUIecgpYAo",
      "title": "Stop Ordering AI Takeout  A Cookbook for Winning When You Build In House - Jan Siml",
      "description": "Forget the multi-agent buffet—this is the home-cooked GenAI playbook that actually drives revenue.\n\nIn this 10-minute lightning talk, Jan Siml shares how a small, in-house team skipped the hype playbook—no multi-agent pipelines with GraphRAG, no monster eval suites—and still turned an internal GenAI assistant into real business impact.\n\n🔑 What you’ll learn\n\n- Go Deep on One Job-to-Be-Done – depth crushes breadth when you own the data and the user.\n\n- Trace Every Click to Dollars – offline evals don’t sign contracts; revenue funnels do.\n\n- Push, Don’t Wait – zero-click Slack/email nudges outperform shiny chat UIs.\n\n- Convert Time-Saved into Time-Well-Spent – guide the next action, not just the answer.\n\n- Data & UX vs Bigger Models – integrations and better flow move the needle; fancy LLMs mostly move the bill.\n\nIf you’re ready to trade Michelin-priced SaaS features for pragmatic, in-house wins—and you like your lessons straight from the kitchen rather than the brochure—hit play. Your AI roadmap (and budget) will thank you.",
      "publishedAt": "2025-06-03T22:22:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT10M44S",
      "viewCount": 307,
      "likeCount": 4,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/DjUIecgpYAo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/DjUIecgpYAo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/DjUIecgpYAo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/DjUIecgpYAo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/DjUIecgpYAo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=DjUIecgpYAo"
    },
    {
      "id": "EnT4Wej5M5k",
      "title": "The Benchmarks Game: Why It's Rigged and How You Can (Really) Win - Darius Emrani",
      "description": "AI benchmarks control billions in investment and shape entire markets - but the game is rigged. In this talk, I'll expose the three \"cheat codes\" companies use to game benchmarks:\n\n* Cherry-picking comparisons (xAI's selective Grok-3 graphs)\n* Buying privileged access (OpenAI's FrontierMath funding)\n* Optimizing for style over substance (Meta's 27 Llama-4 variants on LM Arena)\n\nWhen Andrej Karpathy says \"I don't really know what metrics to look at right now,\" we have a crisis. I'll show you why Goodhart's Law guarantees benchmarks fail when billions are at stake, and more importantly, what to do about it.\n\nYou'll learn:\nHow to spot benchmark manipulation (with real examples)\nWhy 39% of score variance is just writing style\nA 5-step framework to build evaluations that actually matter for YOUR use case\nHow pre-deployment evaluation loops separate reliable AI from constant firefighting\n\nDrawing from my experience building evaluation systems at Waymo, Uber ATG, and SpaceX (where bad evals literally crash), I'll show you how to stop playing the rigged benchmarks game and start measuring what actually matters.",
      "publishedAt": "2025-06-03T22:22:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT11M20S",
      "viewCount": 621,
      "likeCount": 21,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/EnT4Wej5M5k/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/EnT4Wej5M5k/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/EnT4Wej5M5k/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/EnT4Wej5M5k/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/EnT4Wej5M5k/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=EnT4Wej5M5k"
    },
    {
      "id": "eD_6jP1fkKs",
      "title": "Unlocking Africa's Potential with AI — Thabang Ledwaba",
      "description": "As Africa stands at the crossroads of rapid population growth, urbanization, and digital transformation, Artificial Intelligence (AI) presents unprecedented opportunities to tackle some of the continent’s most pressing challenges. This presentation explores how AI can be harnessed as a tool for sustainable development—addressing issues in healthcare, agriculture, education, infrastructure, and governance.\n\nWe’ll delve into real-world applications of AI across African nations, highlight innovative local solutions, and discuss how ethical and inclusive AI development can empower communities, bridge data gaps, and foster economic growth. The session will also examine the importance of homegrown talent, policy frameworks, and cross-sector collaboration in shaping an AI-powered future tailored to Africa’s unique context.\n\nIt is time we reimagine the continent’s future through the lens of AI—one that is driven by innovation, equity, and resilience.",
      "publishedAt": "2025-06-03T07:00:37Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT26M17S",
      "viewCount": 616,
      "likeCount": 22,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/eD_6jP1fkKs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/eD_6jP1fkKs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/eD_6jP1fkKs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/eD_6jP1fkKs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/eD_6jP1fkKs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=eD_6jP1fkKs"
    },
    {
      "id": "EyZiAp0pelw",
      "title": "Letting AI Interface with your App with MCP — Kent C Dodds",
      "description": "We are entering a new era of user interaction. It's being built right before our very eyes and changing rapidly. As crazy as it sounds, soon each one of us will get our own Jarvis capable of performing actually useful tasks for us with a completely different user interaction mechanism than we're used to.\n\nBut someone's gotta give Jarvis the tools to perform these tasks, and that's where we come in.\n\nIn this talk, Kent will live code an MCP server and use it with an AI assistant to help us catch the vision of what this future could look like and our role in it.",
      "publishedAt": "2025-06-03T07:00:07Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M54S",
      "viewCount": 7897,
      "likeCount": 263,
      "commentCount": 14,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/EyZiAp0pelw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/EyZiAp0pelw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/EyZiAp0pelw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/EyZiAp0pelw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/EyZiAp0pelw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=EyZiAp0pelw"
    },
    {
      "id": "dvft0Gp9sEE",
      "title": "Analyzing 10,000 Sales Calls With AI In 2 Weeks — Charlie Guo",
      "description": "AKA: The Data Goldmine You’re Probably Ignoring\n\nMost companies are sitting on mountains of customer data: sales calls, customer support tickets, product reviews, user feedback, and social media interactions. But the truth is that most of this valuable data remains untouched - or worse, unusable.\n\nIn this case study, I'll share how our team leveraged Claude to analyze 10,000 sales call transcripts in a handful of days, extracting deep customer insights at scale. We'll cover the AI engineering challenges we faced, including model selection tradeoffs, reducing hallucinations with retrieval-augmented generation (RAG), and optimizing prompt caching to dramatically cut costs and latency (by up to 90% in some cases).\n\nThis isn't theoretical - it's a practical blueprint with concrete ROI metrics.\nPerfect for AI engineers, data scientists, and anyone sitting on mountains of unstructured customer data they can't analyze at scale.\n\nRead more at https://www.ignorance.ai/",
      "publishedAt": "2025-06-03T07:00:07Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT9M49S",
      "viewCount": 1990,
      "likeCount": 76,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/dvft0Gp9sEE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/dvft0Gp9sEE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/dvft0Gp9sEE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/dvft0Gp9sEE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/dvft0Gp9sEE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=dvft0Gp9sEE"
    },
    {
      "id": "0tVu-V3_fFw",
      "title": "Designing AI To Scale Human Thought — Jun Yu Tan, Tusk",
      "description": "Forget the hype of AI automation replacing jobs. The future lies in human augmentation — revealing blind spots, sparking creativity, and amplifying thoughtful decision-making. In this talk, we’ll explore the principles that distinguish augmentation from automation in AI UX design, covering interaction patterns, design principles, and trust-building feedback loops. Drawing from real-world experiences building AI-powered tools and beyond, we’ll dive into concepts for crafting interfaces that empower users to think smarter, not just work faster. Expect practical insights and a fresh perspective on AI’s role as a collaborative partner.\n\nAI Augmentation: https://jytan.net/blog/2025/ai-augmentation/\nTusk: https://www.usetusk.ai/",
      "publishedAt": "2025-06-03T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M24S",
      "viewCount": 907,
      "likeCount": 23,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/0tVu-V3_fFw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/0tVu-V3_fFw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/0tVu-V3_fFw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/0tVu-V3_fFw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/0tVu-V3_fFw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=0tVu-V3_fFw"
    },
    {
      "id": "1cQlnfwmIdU",
      "title": "open-rag-eval: RAG Evaluation without \"golden\" answers — Ofer Mendelevitch, Vectara",
      "description": "Open-RAG-Eval is an open-source framework that revolutionizes RAG evaluation by harnessing the power of LLM judges for scalable, automated evaluation without the need for golden answers or golden chunks. Building on pioneering research from the University of Waterloo, this framework integrates innovative tools like UMBRELA for reference-free relevance scoring and AutoNuggetizer for automated fact-checking. Designed with a flexible connectors architecture, it seamlessly plugs into any RAG pipeline while delivering fast, transparent, and interpretable metrics on retrieval, generation, and hallucination in RAG.",
      "publishedAt": "2025-06-03T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M3S",
      "viewCount": 1306,
      "likeCount": 29,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1cQlnfwmIdU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1cQlnfwmIdU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1cQlnfwmIdU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1cQlnfwmIdU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1cQlnfwmIdU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1cQlnfwmIdU"
    },
    {
      "id": "6lTxD_oUjXQ",
      "title": "Effective AI Agents Need Data Flywheels, Not The Next Biggest LLM –  Sylendran Arunagiri, NVIDIA",
      "description": "Building effective AI agents isn’t about using the next biggest LLMs in the market  - it’s about creating self-improving systems with data flywheels. By continuously learning from real-world data and agent interactions, these flywheels help evaluate, retrain, and optimize smaller, faster models that match the performance of large LLMs - at a fraction of the cost and compute.\n\nIn this video, learn how NVIDIA uses data flywheels and NeMo microservices to run efficient AI agents with lower TCO and faster inference. Explore a thoughtful framework on building a data flywheel for your own AI agent systems.\n\n#aiagents #dataflywheel #generativeai #modeldistillation #nvidia",
      "publishedAt": "2025-06-03T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M41S",
      "viewCount": 1453,
      "likeCount": 39,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/6lTxD_oUjXQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/6lTxD_oUjXQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/6lTxD_oUjXQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/6lTxD_oUjXQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/6lTxD_oUjXQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=6lTxD_oUjXQ"
    },
    {
      "id": "y6L5RkEqQ8g",
      "title": "ChatGPT is poorly designed. So I fixed it",
      "description": "Let's fix ChatGPT's greatest design sins. We'll design and build a working app that makes ChatGPT multi-modal and multi-model. And no, you don't need to know what those words mean to use it.\n\nDownload the source code: https://github.com/bholmesdev/fixgpt\n\nReferences from this video:\n- Try https://warp.dev to vibe code your own solution\n- Watch Scott and Mark's podcast episode, \"how to not ship the org chart:\" https://www.youtube.com/watch?v=Z1yYcUFzH2A\n- Read \"Why is AI marketing so, so bad?\" by Evan Armstrong at The Leverage: https://www.gettheleverage.com/p/why-is-ai-marketing-so-so-bad",
      "publishedAt": "2025-06-03T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M21S",
      "viewCount": 7352,
      "likeCount": 78,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/y6L5RkEqQ8g/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/y6L5RkEqQ8g/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/y6L5RkEqQ8g/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/y6L5RkEqQ8g/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/y6L5RkEqQ8g/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=y6L5RkEqQ8g"
    },
    {
      "id": "b0xlsQ_6wUQ",
      "title": "The Future of Qwen: A Generalist Agent Model — Junyang Lin, Alibaba Qwen",
      "description": "Since Alibaba launched the Qwen series of large models in 2023, the Qwen series of large language models and multimodal large models have been continuously updated and improved. This presentation will introduce the latest developments in the Qwen series of models, including the large language model Qwen3, vision-language large model Qwen2.5-VL, omni model Qwen2.5-Omni, etc. Additionally, this presentation will also cover the future development directions of the Qwen series.",
      "publishedAt": "2025-06-03T01:08:22Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT25M14S",
      "viewCount": 6887,
      "likeCount": 172,
      "commentCount": 11,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/b0xlsQ_6wUQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/b0xlsQ_6wUQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/b0xlsQ_6wUQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/b0xlsQ_6wUQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/b0xlsQ_6wUQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=b0xlsQ_6wUQ"
    },
    {
      "id": "1XvN5EBDnDw",
      "title": "Creating Agents that Co-Create — Karina Nguyen, OpenAI",
      "description": "In this talk, I will share my thoughts on how two major scaling paradigms in AI are transforming frontier product research——shifting our perspective of AI from narrow, task-focused tools to collaborative agents that meaningfully contribute to real-world innovation. Drawing on lessons learned from my contributions to ChatGPT and Claude, I will explore how AI increasingly handles tasks once reserved for skilled builders, fundamentally altering the fabric of the Internet and the nature of learning. Where, then, are we headed as creators, and what should we be building—and why—if AI increasingly does the work once left to us?\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025",
      "publishedAt": "2025-04-30T07:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT24M22S",
      "viewCount": 38711,
      "likeCount": 937,
      "commentCount": 27,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1XvN5EBDnDw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1XvN5EBDnDw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1XvN5EBDnDw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1XvN5EBDnDw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1XvN5EBDnDw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1XvN5EBDnDw"
    },
    {
      "id": "3j1dHivahFQ",
      "title": "How to Build Your Own AI Data Center in 2025 — Paul Gilbert, Arista Networks",
      "description": "This presentation talks to AI Executives who are tasked with building self managed AI Networks. It will talk about some new terminology that is used, list the key considerations around power to the racks, new hardware (GPU servers) and software (workload managers, GPU management and programming) that's required, there are specific storage requirements, multi-tenancy options, uptime, telemetry and visibility. It will then drill down into the details of the differences between the Data Center networks we build today versus what's required for the next generation of AI Networking.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Paul\n\nPaul Gilbert has spent over 30 years in technology. He worked at Cisco Systems for over 25 years reaching the title of Distinguished Systems Engineer, the first one in North America. In 2022 he left Cisco and joined an AI startup, he was there 1 year then moved onto Arista Networks. He is a tech lead at Arista and focuses on AI and Data Center.",
      "publishedAt": "2025-04-27T06:59:22Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT23M",
      "viewCount": 8199,
      "likeCount": 255,
      "commentCount": 15,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/3j1dHivahFQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/3j1dHivahFQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/3j1dHivahFQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/3j1dHivahFQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/3j1dHivahFQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=3j1dHivahFQ"
    },
    {
      "id": "KUEmEb71vzQ",
      "title": "Function Calling is All You Need — Full Workshop, with Ilan Bigio of OpenAI",
      "description": "Let's talk about Function Calling for o1/o3, Agent SDK (fka Swarms), Realtime API...)\n\nIlan Bigio is a founding member of OpenAI’s Developer Experience team, where he built the 2024 AI phone ordering demo showcased at DevDay and was also the technical lead for Swarm, a framework for multi-agent orchestration and the precursor to the Agents SDK. Prior to that, he was a Solutions Architect at OpenAI, partnering with companies like Cursor, Khan Academy, and Klarna to shape their AI products. Before OpenAI, he was a full-stack Software Engineer at Google, building for YouTube at scale. Ilan’s journey started as a hobby hacker, diving into operating systems and reverse engineering, before shifting to language models in 2020. He created projects like ShellAI—an open-source, AI-powered terminal assistant—and is passionate about sharing knowledge. With a multidisciplinary background spanning web development, AI/ML, and operating systems, he’s designed and taught courses at Brown and continues to share his expertise through in-depth technical OpenAI guides on topics like Function Calling and Latency Optimization.\n\nhttps://www.twitter.com/ilanbigio\n\nTimestamps\n\n0:00:00 – 0:01:44 Intro\n0:01:44 – 0:10:19 History of Function Calling\n0:10:19 – 0:25:00 Agent Loop Setup\n0:25:00 – 0:34:11 Memory\n0:34:11 – 0:54:06 Delegation\n0:54:06 – 1:01:56 Async Delegation\n1:01:56 – 1:17:14 Misc Questions\n1:17:14 – 1:27:01 Dynamic Agent-Written Tools\n1:27:01 – 1:43:06 [end] More Misc\n\nThe special code from the last part of the talk - Dynamic Agent-Written Tools\n\nfrom swarm import Agent\nfrom swarm.repl import run_demo_loop\n\nagent = Agent(\nname=\"Bootstrap\",\ninstructions=\"\",\nfunctions=[],\n)\n\ndef parse_function(code_str):\nnamespace = {}\nexec(code_str, namespace)\nfn_name = next(k for k in namespace if not k.startswith(\"__\"))\nreturn namespace[fn_name]\n\ndef add_tool(python_implementation: str):\nfunction_obj = parse_function(python_implementation)\nagent.functions.append(function_obj)\nreturn \"success\"\n\nagent.functions = [add_tool]\n\nrun_demo_loop(agent)",
      "publishedAt": "2025-04-23T16:00:26Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H42M54S",
      "viewCount": 28338,
      "likeCount": 640,
      "commentCount": 24,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/KUEmEb71vzQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/KUEmEb71vzQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/KUEmEb71vzQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/KUEmEb71vzQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/KUEmEb71vzQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=KUEmEb71vzQ"
    },
    {
      "id": "OC04sP_QgTI",
      "title": "Ensure AI Agents Work: Evaluation Frameworks for Scaling Success — Aparna Dhinkaran, CEO Arize",
      "description": "Turning AI agents into reliable, production-ready tools that deliver tangible business results requires more than just great models. It demands robust evaluation frameworks that ensure agents perform at scale, align with organizational objectives, and continuously improve in dynamic environments.\n\nThis session provides an executive-level perspective on evaluating AI agents at scale. We’ll explore practical strategies for designing evaluation processes that drive measurable impact, identifying and mitigating performance bottlenecks, and implementing observability practices to maintain reliability over time. Through insights from real-world deployments, we’ll highlight common pitfalls, share best practices for iterative improvement, and demonstrate how effective evaluation frameworks can transform experimental agents into enterprise-grade solutions.\n\nWhether you're shaping your organization’s GenAI strategy or looking to unlock the full potential of AI agents, this talk offers actionable insights to ensure your agents work—and scale—successfully.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Aparna\n\nAparna Dhinakaran is the Co-Founder and Chief Product Officer at Arize AI, a pioneer, and early leader in machine learning (ML) observability. A frequent speaker at top conferences and thought leader in the space, Dhinakaran was recently named to the Forbes 30 Under 30. Before Arize, Dhinakaran was an ML engineer and leader at Uber, Apple, and TubeMogul (acquired by Adobe). During her time at Uber, she built several core ML Infrastructure platforms, including Michelangelo. She has a bachelor’s from Berkeley's Electrical Engineering and Computer Science program, where she published research with Berkeley's AI Research group. She is on a leave of absence from the Computer Vision Ph.D. program at Cornell University.",
      "publishedAt": "2025-04-23T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M28S",
      "viewCount": 26526,
      "likeCount": 591,
      "commentCount": 23,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/OC04sP_QgTI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/OC04sP_QgTI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/OC04sP_QgTI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/OC04sP_QgTI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/OC04sP_QgTI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=OC04sP_QgTI"
    },
    {
      "id": "xq9sz5MksVI",
      "title": "The missing pieces of workflow automation — Shirsha Chaudhuri, Thomson Reuters Labs",
      "description": "Gen AI is cool, but what does that mean for your function? This is a talk on when AI hit the road, and where it missed and why. 2024 has been such a confusing year! Tech giants vs startups, established service providers vs internal redefinition of tool stack, trials to licenses, and more. As a functional leader for any org, how do you know the state of AI for your business processes? 2024 has been the year we experimented to find that answer. We tried out lots of vendors, open source, even in-house solutions for AI driven workflow automation and business processes across different functions in our enterprise. Join me as we describe the potential for Agentic workflows, learning from our narrative of what worked in 2024, and what we want changing in 2025.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Shirsha\n\nShirsha heads the co-innovation team in TR Labs that builds solutions for the Editorial and Internal teams in Thomson Reuters. She is passionate about successful operationalizing and sustenance of AI solutions. She works with communities on AI for good, societal impact projects and in the tech for D&I space. She loves to network with people who are using AI and modern tech for building a better world that is more inclusive, more digital and together a better tomorrow.",
      "publishedAt": "2025-04-23T16:00:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M37S",
      "viewCount": 487,
      "likeCount": 21,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/xq9sz5MksVI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/xq9sz5MksVI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/xq9sz5MksVI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/xq9sz5MksVI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/xq9sz5MksVI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=xq9sz5MksVI"
    },
    {
      "id": "VZzUhELgYk4",
      "title": "The Devops Engineer Who Never Sleeps — Diamond Bishop, Datadog",
      "description": "Operate services without getting paged, and not because you phone ran out of batter. Ever get woken up in the middle of the night because a service has gone down, stumbling around looking for your laptop. What if there was an oncall engineer who didn’t need to sleep, always ready to handle issues instead, letting you sleep. In this talk we’ll share how we’re using AI Agents at Datadog to handle alerts and incidents for you, and what we’ve learned building agents to use Datadog and handle DevOps like a human would.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Diamond\n\nA survivor of the long AI winter, Diamond currently directs AI Engineering at Datadog, spearheading their AI agents initiative. His journey spans 15 years of work in AI/ML, including the early days of AI assistants at Amazon (Alexa) and Microsoft (Cortana), as well as working on PyTorch at Meta, and co-founding Augmend—an AI startup focused on DevOps automation (acquired by Datadog). Diamond is a perpetual techno-optimist who also keeps a close eye on Roko's basilisk.\n\nWhen not building AI assistants, he's raising his own budding intelligence (human toddler), participating in the ocasional drone fighting, and building hobby electronics. It's time to build.",
      "publishedAt": "2025-04-22T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M18S",
      "viewCount": 6376,
      "likeCount": 157,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/VZzUhELgYk4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/VZzUhELgYk4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/VZzUhELgYk4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/VZzUhELgYk4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/VZzUhELgYk4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=VZzUhELgYk4"
    },
    {
      "id": "pPvoLjYj_mY",
      "title": "Evaluating Domain Specific LLMs for Real World Finance — Waseem Alshikh, Writer",
      "description": "In today's rapidly evolving financial landscape, AI applications and agents are transforming high-value workflows, like risk assessment, fraud detection, and customer service. As financial institutions increasingly integrate AI into their operations, the reliability and trustworthiness of these systems – and the underlying LLMs – are paramount. The consequences of inaccurate outputs in finance can be significant, ranging from financial losses to reputational damage, underscoring the need for models that are tailored for industry-specific challenges like nuanced terminology and complex regulatory requirements. In this session, Waseem AlShikh, CTO and Co-founder of Writer, will challenge the scaling narrative around general-purpose models and demonstrate how domain-specific LLMs, particularly within the high-stakes finance industry, are delivering state-of-the-art performance, without the need for endless pre-training budgets and resources.Waseem will also introduce a groundbreaking financial benchmark that evaluates the performance of AI systems under the complexities and pressures of the financial domain. Drawing on real-world financial applications, Waseem will demonstrate how to evaluate systems that deliver real ROI in complex, mission-critical scenarios.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Waseem\n\nWaseem Alshikh is the Chief Technology Officer and Co-founder of Writer, the full-stack generative AI platform trusted by the world’s leading enterprises to solve mission-critical business challenges and unleash people’s best work.  An accomplished tech executive with deep expertise in artificial intelligence, machine learning, and natural language processing, Waseem has led Writer to become one of the fastest-growing companies in enterprise generative AI, chosen by hundreds of global leaders like Accenture, Intuit, L’Oreal, Uber, and Vanguard.  Under Waseem’s leadership, Writer has developed a fully integrated solution to build and deploy secure and reliable generative AI applications and agents across the enterprise. Writer’s Palmyra family of large language models (LLMs) is recognized for state-of-the-art performance, topping leaderboards in natural language understanding and generation, and Writer’s novel approach to graph-based RAG leads industry benchmarks.  Founded in 2020, Writer is backed by strategic investors, including ICONIQ Growth, Insight Partners, WndrCo, Balderton Capital, and Aspect Ventures. Waseem has been recognized for his contributions to the tech industry, earning numerous awards and accolades. He holds degrees in Electronics from Beirut Arab University and Damascus Polytechnic University.",
      "publishedAt": "2025-04-22T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M1S",
      "viewCount": 9228,
      "likeCount": 209,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/pPvoLjYj_mY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/pPvoLjYj_mY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/pPvoLjYj_mY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/pPvoLjYj_mY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/pPvoLjYj_mY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=pPvoLjYj_mY"
    },
    {
      "id": "Iw_3cRf3lnM",
      "title": "Self Coding Agents — Colin Flaherty, Augment Code",
      "description": "What if you built an AI coding agent that…built itself? It sounds like science fiction, but AI coding startup Augment Code built an AI agent that not only writes code, but continuously improves its own codebase - including performance optimizations and system architecture. This level of AI autonomy raises fascinating questions about the future of software engineering, where human engineers may shift from writing code to orchestrating multiple self-improving AI agents working in parallel.\n\nIn this talk, Augment Founding Researcher Colin Faherty will explore:\n\n- What does it look like to supervise AI coding agents at scale?\n- How far can we push AI coding agents - what tasks are out of scope?\n- What might unlock when AI handles complexity and humans drive innovation?\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Colin\n\nColin Flaherty is a founding researcher at Augment working on AI agents and retrieval systems. Before that, he was a researcher at Facebook AI Research, where he coauthored a paper in Science on \"Cicero\"—an AI that mastered the game of Diplomacy, widely considered the next grand challenge in AI for games after Chess, Go, and Poker.",
      "publishedAt": "2025-04-21T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M23S",
      "viewCount": 42845,
      "likeCount": 984,
      "commentCount": 48,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Iw_3cRf3lnM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Iw_3cRf3lnM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Iw_3cRf3lnM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Iw_3cRf3lnM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Iw_3cRf3lnM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Iw_3cRf3lnM"
    },
    {
      "id": "kDlqpN1JyIw",
      "title": "Vercel AI SDK Masterclass: From Fundamentals to Deep Research",
      "description": "Full workshop presented by Nico Albanese from Vercel, at the 2025 AI Engineer Summit in New York, Feb 2025: https://x.com/nicoalbanese10 and https://github.com/nicoalbanese\n\nworkshop content/guidebook: https://aie-feb-25.vercel.app/docs \n\nOrganizers note: We somehow screwed up and experienced a total loss of the original workshop video. Nico was incredibly gracious about it and rerecorded the whole thing for you! thank you Nico! Please give him a shoutout: https://x.com/nicoalbanese10",
      "publishedAt": "2025-04-20T21:39:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT59M52S",
      "viewCount": 26162,
      "likeCount": 920,
      "commentCount": 48,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/kDlqpN1JyIw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/kDlqpN1JyIw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/kDlqpN1JyIw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/kDlqpN1JyIw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/kDlqpN1JyIw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=kDlqpN1JyIw"
    },
    {
      "id": "BWqB6aatreE",
      "title": "Frontier Feud: Anthropic, Google DeepMind, Meta FAIR, Thinking Machines — Barr Yaron, Amplify",
      "description": "Get ready for a battle of epic proportions at the Frontier Feud showdown, where teams from leading AI frontier labs will go head-to-head in a battle of wits. Hosted by Barr Yaron, Partner at Amplify Partners!\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Barr\n\nBarr is a data scientist turned investment partner at Amplify Partners, where she focuses on devtools, infrastructure and AI",
      "publishedAt": "2025-04-19T18:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT22M26S",
      "viewCount": 2821,
      "likeCount": 56,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/BWqB6aatreE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/BWqB6aatreE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/BWqB6aatreE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/BWqB6aatreE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/BWqB6aatreE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=BWqB6aatreE"
    },
    {
      "id": "E0k9Ppq6yXY",
      "title": "Stateful Agents — Full Workshop with Charles Packer of Letta and MemGPT",
      "description": "A cornerstone of human intelligence is the ability to learn: as humans interact with the world, we form new memories and can adapt from experience. In this workshop, participants will learn about “stateful agents”: agents that live indefinitely, and can form new memories by learning from data and experience. The workshop will cover best practices for context and state management for agents, as well as how to avoid common challenges with agents (e.g. context overflow errors, memory loss, and lack of user personalization). \n\n\nIn this workshop you will:\n\n- Learn the principles behind context and memory management from the lead author of the MemGPT paper\n- Learn about stateful agents in practice and deployment (scaling to hundreds of thousands of agents)\n- Get hands on experience building stateful agents with the Letta framework and ADE (Agent Development Environment)\n\nNotebook materials: https://github.com/letta-ai/tutorials/tree/main/python\n\nCharles: https://x.com/charlespacker\nLetta: https://x.com/letta_ai",
      "publishedAt": "2025-04-19T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H19M34S",
      "viewCount": 8305,
      "likeCount": 183,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/E0k9Ppq6yXY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/E0k9Ppq6yXY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/E0k9Ppq6yXY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/E0k9Ppq6yXY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/E0k9Ppq6yXY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=E0k9Ppq6yXY"
    },
    {
      "id": "G7aSH6N7qY4",
      "title": "AI + Security & Safety — Don Bosco Durai",
      "description": "Multi-agent systems are revolutionizing industries, driving innovation with autonomous agents that collaborate in dynamic environments. But with great complexity comes great vulnerability.  \nIf you’ve ever worried about adversarial behaviors, privacy breaches, or data leakages in these systems, you’re not alone. These threats can erode trust and jeopardize the integrity of even the most cutting-edge applications.  \nWhat if there were ways to safeguard these systems without stifling innovation? Enter a balanced approach that combines robust security frameworks with adaptive, innovation-friendly strategies.  \nIn this talk, we’ll explore how to identify and mitigate the unique risks inherent in multi-agent systems while fostering an environment where creativity thrives. Learn practical techniques for maintaining security, ensuring safety, and enabling innovation in these transformative systems.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Bosco\n\nBosco is an entrepreneur and thought leader in enterprise security, known for his work in Security, Compliance, and Governance. He co-created Apache Ranger, an open-source project widely considered the gold standard in Big Data security.\n\nCurrently, as the CTO and co-founder of Privacera, Bosco is leading the effort to open-source PAIG.ai, a project dedicated to security, safety, and governance for Generative AI applications and AI Agents.",
      "publishedAt": "2025-04-19T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M13S",
      "viewCount": 1334,
      "likeCount": 40,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/G7aSH6N7qY4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/G7aSH6N7qY4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/G7aSH6N7qY4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/G7aSH6N7qY4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/G7aSH6N7qY4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=G7aSH6N7qY4"
    },
    {
      "id": "2p2ErKRELHM",
      "title": "Voice Agent Engineering — Nik Caryotakis, SuperDial",
      "description": "Does your AI voice agent really need to be able to laugh? …Cry? If the answer is no, then you’re probably better off staying a version behind. In 2025, we’ve seen leaps of progress in the Voice AI Stack – particularly with the release of voice to voice models (e.g. the OpenAI Realtime API). At Superdial however, where we’re automating millions of back-office healthcare phone calls, we’ve learned that what’s special about our product isn’t our realistic voices or natural interruption handling – it’s our conversations. By leveraging open source Voice AI orchestration tooling along with the “old school” STT/LLM/TTS sequenced approach, we’re able to build reliable voice agents that navigate phone trees, conduct sensitive healthcare conversations, and learn from human examples. In this talk, you'll learn our blueprint to navigate the Voice AI vendor landscape, avoid common scaling pitfalls, and design conversations that matter.\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Nik\n\nNik is a staff engineer at Superdial, a platform for automating inbound and outbound healthcare phonecalls with Voice AI. Superdial's agents call your insurance company, navigate their phone trees, wait on hold, and get all your questions asked, answered, and returned to you via API or EHR integrations.\n\nPrior to Superdial, Nik graduated from Stanford University with a BS & MS in Computer Science, where he contributed to research in automated literature mining and competed on the varsity water polo team. Today, Nik is based in NYC and continues to play water polo, but has recently ventured into endurance running events.",
      "publishedAt": "2025-04-18T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M7S",
      "viewCount": 7230,
      "likeCount": 191,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/2p2ErKRELHM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/2p2ErKRELHM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/2p2ErKRELHM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/2p2ErKRELHM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/2p2ErKRELHM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=2p2ErKRELHM"
    },
    {
      "id": "d5EltXhbcfA",
      "title": "Building and evaluating AI Agents — Sayash Kapoor, AI Snake Oil",
      "description": "Is 2025 the year of AI agents? Will reasoning models allow agents to solve challenging open problems? From software engineering to web task automation, it has been claimed that agents will solve challenging open problems. Unfortunately, current agents suffer from many shortcomings that reduce their utility in real-world tasks — look no further than Rabbit R1 and the Humane Pin. In this talk, we will explore how current agents fall far short of their claimed performance in the real world and understand best practices for improving agent evaluation. Learn how to avoid known pitfalls and build AI agents that actually matter.\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nSayash Kapoor is a Senior Fellow at Mozilla, a Laurance S. Rockefeller Graduate Prize Fellow in the University Center for Human Values, and a computer science Ph.D. candidate at Princeton University's Center for Information Technology Policy. He is a coauthor of AI Snake Oil, a book that provides a critical analysis of artificial intelligence, separating the hype from the true advances. He has written for outlets like WIRED and The Wall Street Journal, and his work has been featured in The New York Times, The Atlantic, Washington Post, Bloomberg, and many others. Kapoor has been recognized with various awards, including TIME’s inaugural list of the 100 most influential people in AI.",
      "publishedAt": "2025-04-17T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M",
      "viewCount": 176346,
      "likeCount": 4338,
      "commentCount": 188,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/d5EltXhbcfA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/d5EltXhbcfA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/d5EltXhbcfA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/d5EltXhbcfA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/d5EltXhbcfA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=d5EltXhbcfA"
    },
    {
      "id": "n9rjuBuShko",
      "title": "Building LinkedIn's GenAI Platform — Xiaofeng Wang",
      "description": "In this talk, we will offer insights into building LinkedIn’s GenAI Platform team from the perspective of a first-line manager. We will explore the journey of developing a scalable and adaptable GenAI technology stack in a rapidly evolving tech landscape, seamlessly integrating AI-first principles into LinkedIn’s predominantly Java-based ecosystem, and achieving significant advancements in multi-agent system architectures.\nThe presentation will highlight LinkedIn's GenAI platform innovations, including a centralized registry for dynamic skill-sharing, contextual memory for agent interactions, seamless integration with existing infrastructure, and a balanced approach to leveraging both in-house solutions and popular open-source libraries. Attendees will gain practical insights into fostering collaboration, cultivating a developer-friendly environment, aligning agile execution with long-term platform goals, and identifying the critical talent and skills essential for success. This talk is designed to inspire and guide leaders as they build foundational GenAI teams in dynamic, fast-changing environments.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Xiaofeng\n\nXiaofeng Wang leads a full-stack AI engineering team at LinkedIn, spearheading the development of cutting-edge Generative AI technologies. Their team focuses on LLM post-training optimization, crafting application frameworks, agent architectures, and researching the latest advancements in post-training techniques. They bring innovative solutions to production, empowering agentic applications and products that transform user experiences at LinkedIn.",
      "publishedAt": "2025-04-16T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M53S",
      "viewCount": 5760,
      "likeCount": 106,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/n9rjuBuShko/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/n9rjuBuShko/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/n9rjuBuShko/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/n9rjuBuShko/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/n9rjuBuShko/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=n9rjuBuShko"
    },
    {
      "id": "q_ixa5EW8DY",
      "title": "Insights on Building AI Teams — Heath Black, SignalFire",
      "description": "Market trends and people data. In a world with inflating salaries, it's more important now than ever to ensure you're using the proper filtering, timing, and narrative to find and hire the best possible engineering teams in the new AI era. In this talk, we'll share and discuss data sourced from SignalFire’s Beacon AI platform. Whether building a team or expanding one, we'll examine the information and processes we use to give our portfolio companies an edge, and a framework for setting themselves apart from the competition.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Heath\n\nHeath Black joined Signalfire as Head of Product in 2021 to lead Beacon Talent and other machine-learning initiatives that help make our portfolio companies' lives better.\n\nBefore joining SignalFire, Heath was a senior product manager at Facebook (2017-2021), where he worked in the Facebook Reality Labs organization on various machine learning products for the Facebook + Rayban smart glasses collaboration. Before joining Facebook, Heath worked at several startups across Seed to Series A– Appstores, Chirpify, and Imzy. He also worked at Reddit from 2014-16, where he focused on building out new business lines to monetize the site. His favorite product at Reddit was the subscription box he worked on for cat owners. The box people received could be refolded into a tiny cat house.\n\nHeath received a B.A. from Oklahoma Wesleyan University, where he studied English, with history and communications minors. He received his M.A. from DePaul University in English with a focus on Modern Irish Literature. He's a published poet, avid golfer, bookworm, NBA enthusiast, and father of two rambunctious boys.",
      "publishedAt": "2025-04-15T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M30S",
      "viewCount": 6176,
      "likeCount": 139,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/q_ixa5EW8DY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/q_ixa5EW8DY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/q_ixa5EW8DY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/q_ixa5EW8DY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/q_ixa5EW8DY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=q_ixa5EW8DY"
    },
    {
      "id": "ySYLsoAhXmg",
      "title": "AI Engineers: The Next Generation — Stefania Druga, Google Gemini",
      "description": "Links for more info: https://stefania11.github.io/\nSign-up for early access here http://cognimatescopilot.com\n\nThis talks explores all the ways in which we can push the boundaries of our learning and creativity by using a myriad of open-source multimodal agents that are proactive and nudge you to explore different topics, dimensions, approaches to your learning workflow while also pointing certain cognitive biases or misconceptions you might have. I will show some examples of mobile agents I created in Math learning using our math misconceptions benchmark, also examples in science using the Mozart misconceptions benchmark, an a series of reasoning and logical puzzles where a mobile proactive agent can support us to learn or sometimes un-learn ( for inspiration see all the experiments of Daniel Kahneman and Amos Tversky)\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Stefania\n\nHi! I am Stef. I am currently a research scientist in Google Gemini team working on real-world applications for multimodal language models. I was a principal researcher at the Center of Applied AI Research at the University of Chicago and graduated with a Ph.D. in Creative AI Literacies 🎓 at the University of Washington Information School. In the past I worked with Microsoft’s Human-AI eXperience Team, X Moonshot Factory, Fixie.ai.\n\nI also enjoy designing and building an AI coding plaftorm for kids which started as my master project at MIT (cognimates.me). When I am not coding & writing papers 👩🏽‍💻 I love trail running and rocket yoga.",
      "publishedAt": "2025-04-13T19:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M47S",
      "viewCount": 42435,
      "likeCount": 1118,
      "commentCount": 30,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ySYLsoAhXmg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ySYLsoAhXmg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ySYLsoAhXmg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ySYLsoAhXmg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ySYLsoAhXmg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ySYLsoAhXmg"
    },
    {
      "id": "89aQ7T6cMwA",
      "title": "How to Fail at AI Strategy: Hamel Husain & Greg Ceccarelli",
      "description": "Want to guarantee your AI initiatives are great boardroom presentations but don't actually work? This talk explores the most reliable ways to waste time, money, and resources while building AI strategies. One proven method? Cultivate the perfect disconnect between those building AI solutions and the executives charting the strategic direction. \n\n For business leaders, navigating the AI space is overwhelming. There's a sea of advice on how to allocate resources, hire and execute on AI, but much of it comes from sources that aren't hands-on with the technology. Without practical experience, it's challenging to separate fact from fiction and make informed decisions. On the flip side, AI practitioners who are in the trenches often struggle to communicate their knowledge in a way that resonates with executives. They tend to think and speak in technical terms, which can be off-putting or confusing for those focused on business outcomes.  \nAfter showing you common failure modes, Hamel and Greg will discuss how to overcome and avoid them by drawing on their experience helping 30+ companies develop and execute successful AI projects.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Hamel\n\nHamel Husain started working with language models five years ago when he led the team that created CodeSearchNet, a precursor to GitHub CoPilot. Since then, he has seen many successful and unsuccessful approaches to building LLM products. Hamel is also an [active open source maintainer and contributor](https://hamel.dev/oss/opensource.html) of a wide range of ML/AI projects.  Hamel is currently an [independent consultant](https://hamel.dev/hire.html).\n\nAbout Greg\n\nGreg is an operator with two decades of experience helping companies create competitive advantage with data. Prior to co-founding SpecStory he was the Chief Product Officer at Pluralsight. And previously had data leadership roles at GitHub, Dropbox and Google.",
      "publishedAt": "2025-04-13T16:19:16Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M3S",
      "viewCount": 4620,
      "likeCount": 123,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/89aQ7T6cMwA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/89aQ7T6cMwA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/89aQ7T6cMwA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/89aQ7T6cMwA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/89aQ7T6cMwA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=89aQ7T6cMwA"
    },
    {
      "id": "VhPfM_aGBVc",
      "title": "Anthropic in the Enterprise — Alexander Bricken & Joe Bayley",
      "description": "Enterprise AI implementation often fails due to overengineering, poor data infrastructure, or lack of testing - despite pitfalls many industry leaders across finance, customer support, and productivity sectors have achieved transformative results with Claude. This session will dissect Anthropic's Applied AI approach across multiple deployment models (API, cloud partnerships, and enterprise solutions), revealing how to build effective AI roadmaps while avoiding these common pitfalls. Drawing from real-world case studies of frontier model deployment, we'll demonstrate practical strategies for cross-functional collaboration, developing robust evaluation frameworks, and making informed build-vs-buy decisions that align with your organization's AI maturity and safety requirements.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Alexander\n\nAlexander Bricken is a member of the Applied AI Product Engineering Team at Anthropic, leading technical implementation for Financial Services. He specializes in building production-grade Claude solutions, working directly with customers while collaborating with the Product Research team. Before Anthropic, he spent 2 years at Palantir, where he balanced his responsibilities as an AI Engineer and Account Strategist, specifically working with North American Insurance customers. He has a background in machine learning, data science, and mathematics as one of the founding students of Minerva University.",
      "publishedAt": "2025-04-13T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M55S",
      "viewCount": 7858,
      "likeCount": 151,
      "commentCount": 11,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/VhPfM_aGBVc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/VhPfM_aGBVc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/VhPfM_aGBVc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/VhPfM_aGBVc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/VhPfM_aGBVc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=VhPfM_aGBVc"
    },
    {
      "id": "zM9RYqCcioM",
      "title": "Finetuning: 500m AI agents in production with 2 engineers — Mustafa Ali & Kyle Corbitt",
      "description": "Method Financial has run AI financial agents in production for over 18 months, handling hundreds of thousands of interactions daily. In this talk we'll review some of the \"battle scars\" we gained while deploying and scaling this system. We'll discuss specific techniques we've found critical to keeping this system operational and effective including fine tuning, realtime guardrails and \"sanity checks\", observability platforms, and intelligent caching.\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Mustafa\nMustafa is a founding & senior engineer at Method Financial, a financial platform that makes it easy for fintechs, banks, and lenders to interface with consumer debt. At Method, Mustafa leads their efforts around building robust and scalable real-time data integration systems with top financial institutions. \n\nPrior to Method, Mustafa worked on product-facing and on-chain applications for the Topl protocol.\n\nAbout Kyle\nKyle Corbitt is the co-founder and CEO of OpenPipe, the easiest way to train fine-tuned models and deploy them to production. OpenPipe has fine-tuned thousands of customer models, and serves tens of millions of inference requests every day. Before founding OpenPipe, Kyle led the Startup School team at Y Combinator, which was responsible for the product and content that YC produces for early-stage companies. Prior to that he worked in engineering at Google and studied ML at school.",
      "publishedAt": "2025-04-12T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M44S",
      "viewCount": 22405,
      "likeCount": 482,
      "commentCount": 29,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/zM9RYqCcioM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/zM9RYqCcioM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/zM9RYqCcioM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/zM9RYqCcioM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/zM9RYqCcioM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=zM9RYqCcioM"
    },
    {
      "id": "0vBKv9yAQi4",
      "title": "The Agent Development Life Cycle — Zack Reneau-Wedeen, Sierra",
      "description": "Compared to traditional software, LLMs are creative, flexible, unpredictable, expensive, and slow. A new kind of software demands a new approach to development. At Sierra, we’ve built industrial grade AI agents for consumer brands like Sonos, ADT, and SiriusXM, serving millions of consumers. Every day, their agents are reasoning through complex workflows and helping customers set up speakers, order equipment, and refresh in-car radios. As we’ve scaled with our early customers, we’ve developed a unique methodology to enable Sierra agents to be reliable, testable, and incredibly capable. We've turned scale into an asset that helps align goals, enforce guardrails, and enable continuous self-improvement, even and especially as new models, price points, modalities, and paradigms like reasoning have added complexity and made new experiences possible.\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Zack\n\nI've been a product manager, executive, and software engineer for over ten years at Google and other technology companies focused primarily on consumer products. I started working with neural networks in 2015, when we were building the first version of Google Lens, and I had no idea that language models would play such a central role in the future. Now I'm building conversational AI agents at Sierra.",
      "publishedAt": "2025-04-11T16:30:26Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M40S",
      "viewCount": 33682,
      "likeCount": 839,
      "commentCount": 12,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/0vBKv9yAQi4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/0vBKv9yAQi4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/0vBKv9yAQi4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/0vBKv9yAQi4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/0vBKv9yAQi4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=0vBKv9yAQi4"
    },
    {
      "id": "kPL-6-9MVyA",
      "title": "RAG Agents in Prod: 10 Lessons We Learned — Douwe Kiela, creator of RAG",
      "description": "The latest generation of LLMs is demonstrating impressive test time reasoning capabilities.  However, to be truly valuable in an enterprise setting requires those agentic capabilities to be applied to the right enterprise data. In all the excitement around AI agents, many of us have somehow forgotten the timeless adage “garbage in; garbage out” – language models can only do their job if they are contextualized properly. In this talk, Douwe Kiela will share lessons learned from deploying enterprise RAG systems at scale and how to design a system robust enough for the Fortune 500.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Douwe\n\nDouwe Kiela is the CEO and Co-Founder of Contextual AI. He is also an Adjunct Professor in Symbolic Systems at Stanford University. Previously, he was the Head of Research at Hugging Face and a Research Lead at Meta’s Fundamental AI Research (FAIR) team, where he pioneered Retrieval-Augmented Generation (RAG) among other key AI breakthroughs. His work in multimodality, alignment, and evaluation has set new standards in the field of AI and has made systems safer, more reliable, and more accurate.",
      "publishedAt": "2025-04-10T19:47:37Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M56S",
      "viewCount": 140056,
      "likeCount": 3800,
      "commentCount": 77,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/kPL-6-9MVyA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/kPL-6-9MVyA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/kPL-6-9MVyA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/kPL-6-9MVyA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/kPL-6-9MVyA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=kPL-6-9MVyA"
    },
    {
      "id": "MWTJIAwAAnk",
      "title": "Trust, but Verify: Knowledge Agents for Finance Workflows - Mike Conover",
      "description": "Join us for a deep dive into the engineering and interaction design patterns that power the automated creation of high-signal, information-dense investment research reports. Distilling accurate, actionable insights from vast, multimodal data sources requires a thoughtful approach to both the underlying models and the product affordances that give users granular visibility into a system’s reasoning across thousands of pages of material. We’ll explore how these design considerations foster trust, clarity, and effectiveness in modern financial workflows.\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Mike\n\nMike Conover is the CEO and co-founder of Brightwave, the AI research and diligence platform purpose-build for investment professionals. A pioneer in the field of artificial intelligence, prior to Brightwave Mike led LLM engineering efforts at Databricks where he created Dolly, one of the first open-source models to exhibit instruction following behavior.\n\n\nMike has built AI systems & products for more than fifteen years, including tours of duty at Workday as Director of Financials Machine Learning, SkipFlag (acquired by Workday), and LinkedIn. He has a Ph.D. in complexity science from Indiana University, and his work has been featured in Bloomberg, The Wall Street Journal, The New York Times, TechCrunch, Hacker News, Nature Communications, MIT Technology Review and on NPR.",
      "publishedAt": "2025-04-09T15:30:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M10S",
      "viewCount": 27589,
      "likeCount": 697,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/MWTJIAwAAnk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/MWTJIAwAAnk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/MWTJIAwAAnk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/MWTJIAwAAnk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/MWTJIAwAAnk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=MWTJIAwAAnk"
    },
    {
      "id": "UXOLprPvr-0",
      "title": "Building AI Agents with Real ROI in the Enterprise SDLC: Bruno (Booking.com) & Beyang (Sourcegraph)",
      "description": "Is your CEO asking, \"What is the measurable ROI of AI coding agents in our enterprise?\" One way to answer is to tackle a 10-year migration project to replatform the entire enterprise codebase. This is what Booking.com, the largest travel site in the world, is undertaking, using Sourcegraph as its platform for AI automation throughout the SDLC.\n\nIn this talk, we'll cover agents for large-scale code migration, code review, and internal dev tools. We'll walk through a case study of how a large, established engineering org is pushing the frontiers of what AI can do, driving efficiency gains for devs in a way that demonstrates business impact to executive stakeholders. We'll share tips and tricks we've uncovered while building these agents, and how we're rolling lessons learned into an agents platform that will make it seamless for every enterprise to automate the toil—but not the developer—out of the SDLC.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Bruno\n\nI’m Bruno Passos, a Group Product Manager with 15 years of experience in the tech industry. I lead Developer Experience and GenAI initiatives at Booking.com, focusing on leveraging AI to enhance developer productivity and innovation. I’m passionate about crafting solutions that drive both efficiency and creativity and re-platforming large-scale businesses like Booking.com, leveraging GenAI to accelerate that journey. When I’m not working, I’m most likely cycling or spending time with my family. As a speaker \n\nAbout Beyang\n\nBeyang Liu is the co-founder and CTO of Sourcegraph, a company that is industrializing software development at scale. Sourcegraph accelerates millions of developers working in large, complex codebases like those of Databricks, Reddit, Uber, Canva, Redfin, Palo Alto Networks and the U.S. government. Sourcegraph's tech combines AI with compilers and semantic search to make AI much more effective in big, collaborative codebases. Beyang began his career working on software for some of the largest banks as a dev at Palantir using his education in machine learning and data analysis at Stanford.",
      "publishedAt": "2025-04-08T17:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M56S",
      "viewCount": 13436,
      "likeCount": 213,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/UXOLprPvr-0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/UXOLprPvr-0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/UXOLprPvr-0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/UXOLprPvr-0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/UXOLprPvr-0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=UXOLprPvr-0"
    },
    {
      "id": "OpVkWc3YnFc",
      "title": "Anchoring Enterprise GenAI with Knowledge Graphs: Jonathan Lowe (Pfizer), Stephen Chin (Neo4j)",
      "description": "As enterprises have embraced GenAI architectures the biggest gap is connecting all of the structured and unstructured datasets across your organization. Knowledge graphs are a natural representation of connected data that allows you to enable higher accuracy and more explainable retrieval using GraphRAG. In this session we will talk about how to build organizational support for a connected data architecture that is the fuel for the current and future GenAI applications of your company.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Stephen\n\nStephen Chin is VP of Developer Relations at Neo4j, member of the LF AI & Data Foundation and Open AI Alliance, and author of several titles with O'Reilly, Apress, and McGraw Hill. He has keynoted numerous conferences around the world including AI DevSummit, Devoxx, DevNexus, JNation, JavaOne, Shift, Joker, swampUP, and Open Source India. Stephen is an avid motorcyclist who has done evangelism tours in Europe, Japan, and Brazil, interviewing developers in their natural habitat. When he is not traveling, he enjoys teaching kids how to do AI, embedded, and robot programming together with his daughters.\n\nAbout Jonathan\n\nAnalytics strategist-builder with 30 years of hands-on technical and leadership experience. Envisions, sells, builds and manages fresh approaches to data-driven decision making for biopharma, agriculture, supply chain and telecom clients. Unlocks value rapidly by bridging business and technical cultures. Thrives when growing new teams.",
      "publishedAt": "2025-04-07T17:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M59S",
      "viewCount": 19597,
      "likeCount": 438,
      "commentCount": 14,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/OpVkWc3YnFc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/OpVkWc3YnFc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/OpVkWc3YnFc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/OpVkWc3YnFc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/OpVkWc3YnFc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=OpVkWc3YnFc"
    },
    {
      "id": "jMoAaZP_Kkw",
      "title": "Personal, Local, Private AI Agents: Soumith Chintala",
      "description": "AI Agents are being worked upon by lots of people. But can they run locally, fast, keep your information access in your control and help you trust them with your most intimate information? We'll try to take a stab at answering these questions.\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Soumith\n\nSoumith Chintala is a Scientist-Engineer focused on AI and Robotics, leading influential AI work such as PyTorch, DCGAN and Torch-7; work which is used by several top institutions including NASA, Meta, Google, Tesla, Microsoft, Disney, Genentech, and numerous other Fortune-500 companies and in the curriculum of top-ranked universities such as Stanford, Harvard, Oxford and MIT. He currently leads PyTorch and other AI projects at Meta, is a Visiting Professor at New York University, and maintains advisory roles at various institutions.",
      "publishedAt": "2025-04-06T16:30:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M32S",
      "viewCount": 29188,
      "likeCount": 675,
      "commentCount": 20,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/jMoAaZP_Kkw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/jMoAaZP_Kkw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/jMoAaZP_Kkw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/jMoAaZP_Kkw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/jMoAaZP_Kkw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=jMoAaZP_Kkw"
    },
    {
      "id": "D7_ipDqhtwk",
      "title": "How We Build Effective Agents: Barry Zhang, Anthropic",
      "description": "Recorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Barry:\n\nBarry is a member of technical staff on Anthropic's Applied AI team, focusing on developing agentic systems with enterprises and startups. Previously, he was a tech lead on the Monetization genAI team at Meta, where he claimed the inaugural 'AI Engineer' title. He holds degrees in Computer Science and Industrial Engineering from Northwestern",
      "publishedAt": "2025-04-04T18:46:36Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M9S",
      "viewCount": 311993,
      "likeCount": 7202,
      "commentCount": 83,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/D7_ipDqhtwk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/D7_ipDqhtwk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/D7_ipDqhtwk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/D7_ipDqhtwk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/D7_ipDqhtwk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=D7_ipDqhtwk"
    },
    {
      "id": "b2GqTDWtg6s",
      "title": "Scaling Agents for Gen AI Products - Anju Kambadur, Bloomberg Head of AI Engineering",
      "description": "Recorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Anju\n\nDr. Prabhanjan (Anju) Kambadur is the Head of the AI Engineering group at Bloomberg, which consists of 400+ researchers responsible for building financial solutions, including search and conversational systems, high-precision extraction pipelines, and time-series forecasts, as well as the firm’s underlying AI infrastructure. The members of his group are active in the academic community, where they have published more than 100 peer-reviewed papers in the last three years. Anju is one of the authors of the BloombergGPT research paper. He was also recognized on Insider's \"AI 100\" list of the top 100 people in artificial intelligence in 2023.\n\nBefore Bloomberg, Anju was a research staff member at IBM Research’s Thomas J. Watson Research Center, where he worked on problems in machine learning, such as matrix completion and sketching, sparse coding, genome-wide association studies, temporal causal modeling, and high performance computing.",
      "publishedAt": "2025-04-01T15:06:35Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M38S",
      "viewCount": 37576,
      "likeCount": 830,
      "commentCount": 16,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/b2GqTDWtg6s/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/b2GqTDWtg6s/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/b2GqTDWtg6s/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/b2GqTDWtg6s/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/b2GqTDWtg6s/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=b2GqTDWtg6s"
    },
    {
      "id": "0ML7ZLMdcl4",
      "title": "AI Engineering at Jane Street - John Crepezzi",
      "description": "Programmers using mainstream languages enjoy a wealth of intelligent coding assistants and tools. At Jane Street, where we primarily use OCaml, we faced the challenge of building these tools for a powerful but low-resource functional programming language. This talk explores our journey in creating custom assistants and editor tooling for OCaml, tackling everything from data collection and model training to seamless editor integrations. We'll dive into our end-to-end process: gathering quality training data, developing meaningful evaluations for custom-trained models, building out underlying infrastructure, and creating tools that fit how we work.\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout John\n\nJohn Crepezzi is an engineer at Jane Street, where he works on building LLM-powered coding assistants and the infrastructure to enable others to create applications leveraging large language models. His work focuses on enhancing developer productivity, particularly in Jane Street's OCaml-centric environment.\n\nBefore joining Jane Street, John was a Principal Software Engineer at GitHub, where he contributed to several impactful projects in the developer productivity space, including Codespaces, Merge Queues, and Contribution Graphs. With a career dedicated to improving how developers work, John is passionate about creating tools that empower engineers to solve complex problems more effectively",
      "publishedAt": "2025-03-28T15:04:44Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M57S",
      "viewCount": 52975,
      "likeCount": 999,
      "commentCount": 32,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/0ML7ZLMdcl4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/0ML7ZLMdcl4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/0ML7ZLMdcl4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/0ML7ZLMdcl4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/0ML7ZLMdcl4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=0ML7ZLMdcl4"
    },
    {
      "id": "eJOjdjO45Sc",
      "title": "How Deep Research Works - Mukund Sridhar & Aarush Selvan, Google DeepMind",
      "description": "You’re doing research all the time, we just don't always call it that. From figuring out the right summer camp options for your kids to running due-diligence on an investment opportunity, there are plenty of tasks that take up hours of your day and dozens of chrome tabs. Gemini Deep Research is our initiative to turbocharge this process. In this talk we’ll discuss how we built it, learnings along the way and our vision for the future of personal research assistants.\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Aarush\nAarush Selvan is a Product Manager at Google working on Gemini App. He leads Gemini Deep Research, which enables Gemini to act as your personal research assistant. Before kicking off Deep Research, he led the Gemini Extensions platform which connects Gemini with apps and services (like GMail, Google Maps, YouTube) to provide more helpful responses.\n\nPrior to this, Aarush has been lucky enough to work on products at every part of the machine learning stack - from next generation ASICS to compilers and frameworks and even Speech and NLP technology for the Google Assistant. He's originally from the UK and lives in New York (though you can often find him in the Bay Area!). He has a BS and MS in Symbolic Systems from Stanford University.\n\nAbout Mukund\nStaff ML SWE / TLM at Google Deepmind",
      "publishedAt": "2025-03-26T19:41:41Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M15S",
      "viewCount": 14777,
      "likeCount": 345,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/eJOjdjO45Sc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/eJOjdjO45Sc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/eJOjdjO45Sc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/eJOjdjO45Sc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/eJOjdjO45Sc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=eJOjdjO45Sc"
    },
    {
      "id": "5N33E9tC400",
      "title": "Why Agent Engineering — swyx",
      "description": "Swyx explains why we are all in on Agent Engineering in 2025.\n\nSlides: https://docs.google.com/presentation/d/1SWoBIvTQu__uNEvSawmNcROiUx-n86O_fP0arZcTGb8/edit?usp=sharing\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout swyx\nswyx (Shawn Wang) is Editor of Latent.Space. As a developer experience leader and angel investor, swyx led developer tooling at AWS, Two Sigma, and three devtool unicorns (Netlify, Temporal, Airbyte). He is also the founder of Smol AI, the LLM data pipeline company that produces AI News, the widely-read AI industry newsletter that was 99% created by customizable research agents.",
      "publishedAt": "2025-03-24T19:15:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT11M45S",
      "viewCount": 14512,
      "likeCount": 355,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/5N33E9tC400/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/5N33E9tC400/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/5N33E9tC400/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/5N33E9tC400/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/5N33E9tC400/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=5N33E9tC400"
    },
    {
      "id": "-rsTkYgnNzM",
      "title": "Rethinking how we Scaffold AI Agents - Rahul Sengottuvelu, Ramp",
      "description": "Diagrams, algorithms, and handcrafted heuristics have long played a role in constructing AI agents, but are these traditional scaffolding techniques holding us back? Many current approaches lean too heavily on manual design, neglecting the “bitter lesson” that history has taught us: leveraging massive computation and generic methods often trumps tailored engineering. What if we could rethink our scaffolding strategies for AI agents—aligning them with decades of insight from the broader AI research community? In this talk, Rahul Sengottuvelu, Head of Applied AI at Ramp and co-founder of Cohere.io, will explore how embracing the bitter lesson can transform our approach to building AI agents. Attendees will gain actionable strategies to design more robust, scalable systems that minimize over-engineering while maximizing the power of general-purpose learning.\n\nRecorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Rahul\n\nRahul Sengottuvelu is the Head of Applied AI at Ramp. Before that, he co-founded Cohere.io, a customer support automation platform that used advanced AI to resolve support tickets more accurately. Cohere.io was acquired by Ramp in May 2023. He is also the author of Jsonformer, a constrained decoding library for LLMs.",
      "publishedAt": "2025-03-19T17:09:54Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M32S",
      "viewCount": 33214,
      "likeCount": 851,
      "commentCount": 25,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/-rsTkYgnNzM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/-rsTkYgnNzM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/-rsTkYgnNzM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/-rsTkYgnNzM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/-rsTkYgnNzM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=-rsTkYgnNzM"
    },
    {
      "id": "HS5a8VIKsvA",
      "title": "Navigating AI’s Frontier in 2025 - Grace Isford, Lux Capital",
      "description": "Lux Capital Partner Grace Isford discusses the AI Frontier in NYC, sharing 10 'hot takes' on where the industry is going from a technical perspective. She covers key considerations for technical leaders building agentic systems, as well as the second-degree implications of LLMs for human behavior.\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Grace\n\nAs a Partner based in our New York City office, Grace invests in companies innovating at the nexus of the computational sciences – data, AI and ML infrastructure, open source software, network infrastructure, developer tools, vertical software applications and more.\n\nBefore joining Lux, Grace was a principal at Canvas Ventures where she sourced 10 investments. She got her start as a campus scout while attending Stanford University.\n\nPrior to Canvas, Grace worked on the LP side at the Stanford Management Company, in product at edtech startup Handshake, and in growth equity at Stripes Group. She earned a Bachelors of Science and a Masters of Science in Management Science and Engineering from Stanford, where she was a Mayfield Fellow and served as Co-President of Stanford Women in Business, the campus’s largest pre-professional organization for women. In addition, she is on the board of the Stanford Technology Ventures Program, the university’s entrepreneurship center, and is an active member of All Raise, focused on accelerating the success of female and non-binary founders and funders.\n\nGrace is originally from Connecticut, although has lived in Tokyo, Japan, and aspires to re-learn Japanese. She’s an avid runner and cyclist.",
      "publishedAt": "2025-03-13T17:06:55Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M55S",
      "viewCount": 6030,
      "likeCount": 161,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/HS5a8VIKsvA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/HS5a8VIKsvA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/HS5a8VIKsvA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/HS5a8VIKsvA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/HS5a8VIKsvA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=HS5a8VIKsvA"
    },
    {
      "id": "bVNNvWq6dKo",
      "title": "How Windsurf writes 90% of your code with an Agentic IDE - Kevin Hou, head of product eng",
      "description": "Recorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Kevin\n\nKevin is the head of product engineering at Codeium, where he builds AI-powered developer tools. He has spent much of his career in AI, previously working as a tech lead manager at the Nuro, an autonomous vehicle startup, as well as other companies like Airbnb & Salesforce. Kevin enjoys photography, playing basketball, and woodworking. He studied computer science & ML at Princeton University.",
      "publishedAt": "2025-03-11T19:17:46Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M50S",
      "viewCount": 78153,
      "likeCount": 1509,
      "commentCount": 94,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/bVNNvWq6dKo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/bVNNvWq6dKo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/bVNNvWq6dKo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/bVNNvWq6dKo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/bVNNvWq6dKo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=bVNNvWq6dKo"
    },
    {
      "id": "JIsgyk0Paic",
      "title": "Reinforcement Learning for Agents - Will Brown, ML Researcher at Morgan Stanley",
      "description": "Recorded live at the Agent Engineering Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025\n\nAbout Will\nHi! I’m a machine learning researcher based in New York City.\n\nI am a member of Morgan Stanley’s Machine Learning Research group, where I have been primarily working on projects related to language models and sequential prediction. I completed my PhD (CS) at Columbia, where I was fortunate to be co-advised by Christos Papadimitriou and Tim Roughgarden.\n\nBefore that, I was an undergrad (CS + philosophy) and masters (DS) student at Penn, and I’ve spent time in research and engineering roles at AWS, Two Sigma, MongoDB, and AmFam",
      "publishedAt": "2025-03-07T16:45:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M17S",
      "viewCount": 81816,
      "likeCount": 2084,
      "commentCount": 36,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/JIsgyk0Paic/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/JIsgyk0Paic/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/JIsgyk0Paic/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/JIsgyk0Paic/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/JIsgyk0Paic/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=JIsgyk0Paic"
    },
    {
      "id": "joHR2pmxDQE",
      "title": "OpenAI for VP's of AI + Advice for Building Agents",
      "description": "Deploying transformative solutions in today's fast-evolving AI landscape is challenging. In this session, we'll share how OpenAI's Technical Success team partners with customers to accelerate AI adoption, mitigate deployment risks, and deliver transformative outcomes through hands-on collaboration and a proven engagement framework. We'll share real-world case studies, explore key insights from our customer partnerships and leave plenty of time for open Q&A. Join us!\n\nRecorded live at the Leadership Track Session Day from the AI Engineer Summit 2025 in New York. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025 \n\nAbout Prashant\nPrashant Mital is a Solutions Architect at OpenAI, where he helps customers build and deploy AI applications using OpenAI’s platform. Before OpenAI, Prashant was one of the first Deployed Engineers at Retool, where he helped grow key enterprise accounts and later founded the company’s Professional Services function. Earlier in their career, they trained as an applied physicist and worked on distributed systems and data infrastructure across various industries.\n\nAbout Toki\nToki Sherbakov leads the Solutions Architecture team at OpenAI. His team is responsible for ensuring enterprises are successful in building scalable and high-impact production applications with the OpenAI API platform. Prior to OpenAI, Toki spent 2 years growing and leading the Deployment team at Peregrine Technologies (technology startup serving state and local government customers in the US), and 5 years prior to that at Palantir Technologies driving GTM efforts.\n\n00:00 Opener\n00:17 Intro and overview\n00:40 How OpenAI is structured\n1:44 Enterprise AI customer journey\n3:02 AI as part of your business strategy\n6:54 Morgan Stanley case study \n8:00 2025 is the year of agents\n9:00 Defining Agents\n9:54 Lessons OpenAI learned building Agents in the field\n9:56 Lessons: Abstraction is a tool, not a crutch\n11:43 Lessons:: Start Simple\n13:00 Lessons: Use a network of agents for complex tasks\n14:52 Lessons: Keep prompts simple; use guardrails to handle edge cases\n16:05 Recap",
      "publishedAt": "2025-03-05T15:56:48Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M52S",
      "viewCount": 11188,
      "likeCount": 270,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/joHR2pmxDQE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/joHR2pmxDQE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/joHR2pmxDQE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/joHR2pmxDQE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/joHR2pmxDQE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=joHR2pmxDQE"
    },
    {
      "id": "kQmXtrmQ5Zg",
      "title": "Building Agents with Model Context Protocol - Full Workshop with Mahesh Murag of Anthropic",
      "description": "The Model Context Protocol is a universal, open standard for connecting AI systems with data sources, replacing fragmented integrations with a single protocol. This workshop from Anthropic -- the creators of MCP -- talks about the philosophy behind MCP, its impact on the broader ecosystem since launch, and how developers can use it to build context-rich AI apps and agentic experiences.\n\n00:00 What is MCP? \n9:39 Building with MCP \n26:25 MCP & Agents \n1:13:15 What's next for MCP? \n\nRecorded live at workshop day from the AI Engineer Summit 2025 in NY. Learn more at https://ai.engineer and purchase tickets to our next event, the AI Engineer World's Fair, in SF June 3 - 5 here: https://ti.to/software-3/ai-engineer-worlds-fair-2025 \n\nAbout the instructor\nMahesh is a Member of Technical Staff on Anthropic's Applied AI team, focused on Model Context Protocol, agents, and helping make Claude more useful to enterprises. He was previously a Product Manager at Scale AI & Tecton and did research at UC Berkeley on how self-driving cars impact traffic systems.",
      "publishedAt": "2025-03-01T16:59:35Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H44M12S",
      "viewCount": 283130,
      "likeCount": 4821,
      "commentCount": 102,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/kQmXtrmQ5Zg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/kQmXtrmQ5Zg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/kQmXtrmQ5Zg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/kQmXtrmQ5Zg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/kQmXtrmQ5Zg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=kQmXtrmQ5Zg"
    },
    {
      "id": "U3MVU6JpocU",
      "title": "AI Agents, Meet Test Driven Development",
      "description": "Deploying agentic workflows in production is tough—bugs, hallucinations, and unexpected behavior can quickly turn a promising system into a support nightmare. But there’s a pattern we’ve seen across hundreds of companies: teams that embrace test-driven development (TDD) build stronger, more reliable AI systems.\n\nIn this talk, Anita from Vellum will break down how TDD can be applied to AI agents, sharing real-world strategies for testing and improving reliability. She’ll also explore different types of agentic behavior, what’s possible to build today, and where the innovation is heading. To bring it all together, Anita will demo her own SEO agent—an agentic workflow that automates a big chunk of her content-writing process.\n\nIf you're building AI-powered workflows and want them to actually work, this session is for you!\n\nRelated links:\n\nDeepSeek-R1 training process: https://www.vellum.ai/blog/the-training-of-deepseek-r1-and-ways-to-use-it\nAgentic Workflows: Emerging architectures: https://www.vellum.ai/blog/agentic-workflows-emerging-architectures-and-design-patterns\nFour pillars of building AI systems in production: https://www.vellum.ai/blog/the-four-pillars-of-building-a-production-grade-ai-application\nEverything you need to know on Chain of Thought prompting: https://www.vellum.ai/blog/chain-of-thought-prompting-cot-everything-you-need-to-know\nReasoning models are indecisive parrots: https://www.vellum.ai/reasoning-models",
      "publishedAt": "2025-02-22T22:05:15Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT29M10S",
      "viewCount": 11807,
      "likeCount": 311,
      "commentCount": 27,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/U3MVU6JpocU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/U3MVU6JpocU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/U3MVU6JpocU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/U3MVU6JpocU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/U3MVU6JpocU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=U3MVU6JpocU"
    },
    {
      "id": "2cEGQEllBGc",
      "title": "Don't just slap on a chatbot: building AI that works before you ask",
      "description": "Everyone's racing to add chatbots to their products, but is that REALLY the best way to integrate AI? In this talk, Arthur Objartel from Evil Martians challenges the status quo of AI integration and shares product design insights from building Tegon, an AI-powered issue tracker. While most companies are making more reactive AI assistants and waiting for user commands, we took a completely different approach. This begs the question: should the future of AI be more proactive? For instance, remember Clippy from MS Word? While everyone loved to hate on that thing, we'll explore how its core concept was revolutionary — just 25 years too early! So, that means we’ve got questions: how AI can now enhance user workflows …without a chat interface? How to build AI that knows what users need before they ask? What are the practical principles to make AI truly useful in your products? Watch Arthur’s talk because he has the answers!\n\nhttps://evilmartians.com/chronicles/dont-just-slap-on-a-chatbot-building-ai-that-works-before-you-ask",
      "publishedAt": "2025-02-22T20:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M46S",
      "viewCount": 1572,
      "likeCount": 73,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/2cEGQEllBGc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/2cEGQEllBGc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/2cEGQEllBGc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/2cEGQEllBGc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/2cEGQEllBGc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=2cEGQEllBGc"
    },
    {
      "id": "In7K-4JZKR4",
      "title": "The Price of Intelligence - AI Agent Pricing in 2025",
      "description": "AI agents are reshaping industries, but pricing them is one of the hardest decisions startups face. Get it wrong, and you’ll either leave money on the table or burn cash subsidizing your heaviest users. This talk dives into how AI agent companies are evolving their pricing models—from OpenAI’s API price cuts to Jasper’s unlimited plans to Clay's prospecting credits.\n\nIf you’re building an AI agent—or thinking about how to price one—you need to understand not just what to charge, but why pricing must evolve as your product, costs, and market mature. This talk gives you a clearer framework for pricing AI agents sustainably while staying competitive in an industry where costs, value, and expectations are constantly shifting.",
      "publishedAt": "2025-02-22T20:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M38S",
      "viewCount": 4837,
      "likeCount": 111,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/In7K-4JZKR4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/In7K-4JZKR4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/In7K-4JZKR4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/In7K-4JZKR4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/In7K-4JZKR4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=In7K-4JZKR4"
    },
    {
      "id": "pzmbleiOfCM",
      "title": "Voice Agents: the good, the bad, and the ugly",
      "description": "AI voice agents seem to be everywhere. But what does it actually take to move from proof of concept to production? This talk walks you through the process of building an AI voice agent that's now conducting hundreds of consulting-style research interviews.\n\nWhat once required hours of consultant time and weeks of scheduling can now be done in a single day with the voice agent.\n\nBut getting there wasn’t exactly smooth sailing. We’ll skip the hype and dive into the real challenges: wrangling hallucinations, designing evaluation metrics that actually matter, determining the right human/AI handoff, and troubleshooting unexpected surprises (like the agent randomly switching from English to Korean).\n\nYou’ll leave with a no-nonsense playbook for getting voice agents into production.",
      "publishedAt": "2025-02-22T20:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M48S",
      "viewCount": 4245,
      "likeCount": 95,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/pzmbleiOfCM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/pzmbleiOfCM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/pzmbleiOfCM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/pzmbleiOfCM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/pzmbleiOfCM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=pzmbleiOfCM"
    },
    {
      "id": "r0AG44qYKsI",
      "title": "This video was edited with AI agent. But how?",
      "description": "The talk is about world’s first open-source video editing agent!\n\nDiffusion Studio x Re-Skill technology proposal:\n\nOur Python-based agent starts a browser session using Playwright and opens operator.diffusion.studio.\n\nThis web app is a video editing UI optimized for agents, providing access to Diffusion Studio Core—a JavaScript-based engine that renders videos directly in the browser using WebCodecs (fully hardware-accelerated).\n\n🖥 How it works:\n1️⃣ A VideoEditingTool generates code based on user prompts and runs it in the browser.\n2️⃣ If additional context is needed, DocsSearchTool uses RAG to pull information from operator.diffusion.studio/llms.txt.\n3️⃣ After each execution step, the composition is sampled (currently 1 frame per second) and analyzed using VisualFeedbackTool via a multi-modal model.\n4️⃣ The feedback system decides whether to proceed with rendering or refine further.\n\n📡 File transfers between the browser and Python happen via Chrome DevTools Protocol, and for scalability, the agent can connect to a GPU-accelerated remote browser session via WebSocket (WIP: wss://chrome.diffusion.studio).\n\n---\n\nhttps://github.com/diffusionstudio/agent\n\nhttps://re-skill.io/\n\nslides: https://docs.google.com/presentation/d/1eipINYiwx3vjwvJXrv4QA0-9t4-uIVPuh112X9pElkM/edit?usp=sharing",
      "publishedAt": "2025-02-22T20:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M",
      "viewCount": 3934,
      "likeCount": 116,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/r0AG44qYKsI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/r0AG44qYKsI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/r0AG44qYKsI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/r0AG44qYKsI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/r0AG44qYKsI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=r0AG44qYKsI"
    },
    {
      "id": "wJwTlvb_TSo",
      "title": "WTF do people use Open Models for??",
      "description": "from Eugene Cheah, CEO, Featherless.ai\n\nCovering the open weights landscape. What’s being downloaded. What’s being used.\n\nThe heritage and what’s to come next",
      "publishedAt": "2025-02-22T20:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT28M1S",
      "viewCount": 2371,
      "likeCount": 34,
      "commentCount": 17,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/wJwTlvb_TSo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/wJwTlvb_TSo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/wJwTlvb_TSo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/wJwTlvb_TSo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/wJwTlvb_TSo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=wJwTlvb_TSo"
    },
    {
      "id": "kjSGc7uwDo8",
      "title": "Beyond APIs: How AI Web Agents Are Automating the \"Long Tail\" of Knowledge Work",
      "description": "AI Web Agents, such as rtrvr.ai, that can autonomously take actions on the web, scrape data, create graphs, and call API's with just natural language represent a fundamental reimagination of what we can do with the browser.\n\nhttps://www.rtrvr.ai/blog/introducing-rtrvr-ai",
      "publishedAt": "2025-02-22T20:00:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M44S",
      "viewCount": 1052,
      "likeCount": 16,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/kjSGc7uwDo8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/kjSGc7uwDo8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/kjSGc7uwDo8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/kjSGc7uwDo8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/kjSGc7uwDo8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=kjSGc7uwDo8"
    },
    {
      "id": "y2Drx0SDZLo",
      "title": "Agent Evals: Finally, With The Map",
      "description": "A systematic and principled map of the key aspects of AI Agent Evaluation is presented. Agent Evals are often approached as a laundry list of ad hoc metrics, making it hard to plan ahead towards a comprehensive quality assurance for your agents. In contrast, this presentation directly provides you with a solid foundation for your agent evaluation roadmap, towards making your agents reliable, effective and safe. \nhttps://rootsignals.ai/agentevals",
      "publishedAt": "2025-02-22T19:00:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M31S",
      "viewCount": 2808,
      "likeCount": 47,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/y2Drx0SDZLo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/y2Drx0SDZLo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/y2Drx0SDZLo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/y2Drx0SDZLo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/y2Drx0SDZLo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=y2Drx0SDZLo"
    },
    {
      "id": "3jwClx0Ft2E",
      "title": "Your Evals Are Meaningless (And Here’s How to Fix Them)",
      "description": "After working with hundreds of AI teams, I discovered a concerning pattern: most real-world evals are practically meaningless. Drawing from my experience at HoneyHive, I'll reveal why popular evaluation methods are failing us, why traditional testing methods don't work for agents, and most importantly, how to fix it. Finally, I'll share practical strategies I've seen work across startups and Fortune 100 companies to build evaluation systems that actually map to real-world performance.",
      "publishedAt": "2025-02-22T19:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M50S",
      "viewCount": 2861,
      "likeCount": 49,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/3jwClx0Ft2E/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/3jwClx0Ft2E/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/3jwClx0Ft2E/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/3jwClx0Ft2E/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/3jwClx0Ft2E/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=3jwClx0Ft2E"
    },
    {
      "id": "cZ5ZJy19KMo",
      "title": "Mission-Critical Evals at Scale (Learnings from 100k medical decisions)",
      "description": "So you've built your LLM product, have paying customers and your LLM throughput is increasing. Great! But scale introduces its own problems: it'll uncover new edge case user inputs and failure cases that your current evaluations don't capture.\n\nAnd what if you just can't afford to make mistakes? (At Anterior, our product helps health insurers make decisions around approving medical treatment - this is mission-critical, with no room for error!)\n\nThe solution? A scalable and self-auditing reference-free evaluation system (rolls off the tongue, right?).\n\nIn this talk, we'll explain how to build one, why it should run real-time and how building this system provides company defensibility.\n\nFor further details and discussion, see: https://chrislovejoy.me/mission-critical-evals",
      "publishedAt": "2025-02-22T19:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M15S",
      "viewCount": 2904,
      "likeCount": 88,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/cZ5ZJy19KMo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/cZ5ZJy19KMo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/cZ5ZJy19KMo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/cZ5ZJy19KMo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/cZ5ZJy19KMo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=cZ5ZJy19KMo"
    },
    {
      "id": "KVgbERRPU4M",
      "title": "OpenLLMetry is all you need",
      "description": "OpenLLMetry (https://github.com/traceloop/openllmetry) is an open-source project for tracing and monitoring GenAI agents and apps anywhere you want - whether it's Datadog, New Relic, Dynatrace, Grafana, or even Langsmith.",
      "publishedAt": "2025-02-22T19:00:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT9M12S",
      "viewCount": 1510,
      "likeCount": 31,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/KVgbERRPU4M/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/KVgbERRPU4M/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/KVgbERRPU4M/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/KVgbERRPU4M/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/KVgbERRPU4M/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=KVgbERRPU4M"
    },
    {
      "id": "Hp4MzVTXcKw",
      "title": "The Model Isn’t Wrong—You’re Just Bad at Prompting",
      "description": "LLMs aren’t failing—you just need better prompts. This talk covers Chain of Thought, Few-Shot, and Meta Prompting, plus key differences when working with reasoning models. Learn when simple beats complex, when to avoid few-shot prompting, and how to fine-tune your approach with free tools. Stop blaming the model—fix your prompts.\n\nRESOURCES\n\nPrompt Engineering Substack\nhttps://prompthub.substack.com\n\nPromptHub Blog\nhttps://www.prompthub.us/blog\n\nPrompt Engineering with Reasoning Models\nhttps://www.prompthub.us/blog/prompt-engineering-with-reasoning-models\n\n\nChain of Thought Prompting Guide\nhttps://www.prompthub.us/blog/chain-of-thought-prompting-guide\n\n\nThe Few Shot Prompting Guide\nhttps://www.prompthub.us/blog/the-few-shot-prompting-guide\n\nPROMPT TEMPLATES AND COLLECTIONS\n\nAutoReason\nhttps://app.prompthub.us/community/playground/5316\n\nDeepSeek-R1 training template\nhttps://app.prompthub.us/community/playground/5788\n\nReasoning prompts collection\nhttps://app.prompthub.us/community/group/361\n\nTOOLS\n\nPromptHub Prompt enhancers\nhttps://www.prompthub.us/features/enhancers",
      "publishedAt": "2025-02-22T18:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT8M54S",
      "viewCount": 2514,
      "likeCount": 64,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Hp4MzVTXcKw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Hp4MzVTXcKw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Hp4MzVTXcKw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Hp4MzVTXcKw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Hp4MzVTXcKw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Hp4MzVTXcKw"
    },
    {
      "id": "UOsOfLnAX3Y",
      "title": "How to Improve Your Agents: Academic Lit Review",
      "description": "In this video, I dive into the capabilities of Arklex AI's agent framework, highlighting how AI agents can collaborate with human agents to enhance productivity. Compared to LangChain, CrewAI, etc, Arklex is enterprise-focused and strikes a balance between control and intelligence.  Arklex open-source empowers developers to build their own agents. Besides open-source, Arklex also offers an enterprise version with built-in enterprise-friendly tools and an optimized ML infra layer. Reach out if you're interested at Arklex.ai.",
      "publishedAt": "2025-02-22T18:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT39M2S",
      "viewCount": 3626,
      "likeCount": 93,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/UOsOfLnAX3Y/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/UOsOfLnAX3Y/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/UOsOfLnAX3Y/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/UOsOfLnAX3Y/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/UOsOfLnAX3Y/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=UOsOfLnAX3Y"
    },
    {
      "id": "VTJHR7rQ2KI",
      "title": "Stop Guessing: Build Robust AI with Layered CoT",
      "description": "In “Stop Guessing: Build Robust AI with Layered CoT,” we dive deep into a revolutionary approach that transforms the way AI reasons and makes decisions. Rather than relying on a single, monolithic system that often guesses its way through complex problems, we explore how Layered Chain-of-Thought prompting and Multi-Agent Systems can work together to build AI that is transparent, accurate, and self-correcting.\n\nIn this talk, you’ll learn how breaking down AI reasoning into a series of verifiable steps—each confirmed against a knowledge base—can significantly boost robustness and repeatability. \n\nWe’ll provide concrete technical examples that demonstrate how Multi-Agent Systems break down complex tasks into specialized components using Layered Chain-of-Thought prompting. You’ll see how each agent generates an initial thought, verifies its accuracy against trusted knowledge bases, and then collaboratively builds a robust, self-correcting chain of reasoning. This layered approach not only overcomes the limitations of traditional methods but also paves the way for more transparent and scalable AI systems.\n\nResearch Paper on arXiv: https://arxiv.org/abs/2501.18645\n\nJoin us as we challenge the status quo of AI design and explore how building intelligence one verified, collaborative step at a time can lead to truly robust and explainable systems.",
      "publishedAt": "2025-02-22T18:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT10M16S",
      "viewCount": 462,
      "likeCount": 11,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/VTJHR7rQ2KI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/VTJHR7rQ2KI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/VTJHR7rQ2KI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/VTJHR7rQ2KI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/VTJHR7rQ2KI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=VTJHR7rQ2KI"
    },
    {
      "id": "_pBfv1rbLBU",
      "title": "Privacy First Enterprise AI: Building AI Agents that Never Leave Your Security Boundary",
      "description": "Steven Moon, founder of Aech AI Inc., discusses a new vision for Enterprise AI deployment that leverages existing enterprise infrastructure rather than building parallel systems. He argues that AI agents should operate within established security boundaries, follow security policies, use approved systems, and be monitored and audited, just like human employees.\n\nKey points covered in this video:\n\n* *The limitations of traditional SaaS interfaces* and the shift towards AI agents as the primary way to interact with business systems.\n* *How enterprises already possess the necessary infrastructure* (secure compute environments, identity management, data governance) to deploy AI agents securely.\n* *The idea of IT departments evolving into HR departments for AI agents* , managing onboarding, access permissions, and monitoring through familiar systems.\n* *The potential for AI agents to communicate and collaborate via email* , creating a framework for observable and controllable AI systems at enterprise scale.\n* *The importance of enhancing existing systems* with AI agents instead of building new interfaces.\n* *The end of mandatory translation layers* between humans and machines, and the beginning of direct understanding and seamless AI collaboration.\n\nThis video offers a different perspective on Enterprise AI, emphasizing the use of existing infrastructure to ensure security, compliance, and seamless integration. Learn how to leverage the systems your organization already trusts to unlock the power of AI agents.",
      "publishedAt": "2025-02-22T18:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7M10S",
      "viewCount": 694,
      "likeCount": 17,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/_pBfv1rbLBU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/_pBfv1rbLBU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/_pBfv1rbLBU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/_pBfv1rbLBU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/_pBfv1rbLBU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=_pBfv1rbLBU"
    },
    {
      "id": "zuMw0pkPXpU",
      "title": "Tool Calling Is Not Just Plumbing for AI Agents — Roy Derks",
      "description": "Tool calling is more than just a technical detail—it’s the most important piece of how AI agents get things done. It allows agents to connect to systems, access data, and perform all sorts of tasks. Building good tools is very similar to building good APIs, as they need good design for things like authentication and security. In this session, we’ll explore how tool calling works, why it matters, and how to do it right. You’ll learn different ways to build tools that help agents connect to APIs, databases, and other resources, making them smarter and more useful.\n\nBuild a MCP server: https://hackteam.io/blog/build-your-first-mcp-server-with-typescript-in-under-10-minutes/\nTool Calling platform: https://github.com/IBM/wxflows",
      "publishedAt": "2025-02-22T17:00:24Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT25M18S",
      "viewCount": 5994,
      "likeCount": 149,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/zuMw0pkPXpU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/zuMw0pkPXpU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/zuMw0pkPXpU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/zuMw0pkPXpU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/zuMw0pkPXpU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=zuMw0pkPXpU"
    },
    {
      "id": "62U6FLUCPWs",
      "title": "The Hidden Costs of Building Your Own RAG Stack — Ofer Vectara",
      "description": "The rise of RAG and Agentic RAG has sparked interest across industries for its potential to build trusted Generative AI applications with reduced hallucinations. While building your own RAG stack may seem like a good idea at first, this approach often hides significant challenges that can lead to inefficiencies, inflated costs, and missed opportunities. In this talk, we will explore some of pitfalls of self-built RAG stacks, including the complexity of integration, scalability issues, and long-term maintenance burdens. By contrasting DIY RAG with turnkey RAG solutions - attendees will gain a clearer understanding of how to achieve optimal results with fewer resources and greater focus on innovation.",
      "publishedAt": "2025-02-22T17:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M14S",
      "viewCount": 1019,
      "likeCount": 25,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/62U6FLUCPWs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/62U6FLUCPWs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/62U6FLUCPWs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/62U6FLUCPWs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/62U6FLUCPWs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=62U6FLUCPWs"
    },
    {
      "id": "xzXdLRUyjUg",
      "title": "Lets Build An Agent from Scratch",
      "description": "Everyone is talking about agents and how powerful they are or will be. But what is an agent anyways? Down with corporate buzzword marketing speak, we are engineers, let’s build!\n\nIn this talk we will build the minimal components needed to call an agent an agent. We will do this in a stepwise manner to see the effect of each additional element.\n\nBy the end of the talk we will have the simplest system that can be called an agent. It will include: planning, memory, tool calling all in a while loop. The goal is for you to leave realizing how simple agents can be. Maybe you have already built one.\n\nPost with code/slides: https://kamlasater.com/talks/agents-2025",
      "publishedAt": "2025-02-22T17:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M29S",
      "viewCount": 6756,
      "likeCount": 187,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/xzXdLRUyjUg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/xzXdLRUyjUg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/xzXdLRUyjUg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/xzXdLRUyjUg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/xzXdLRUyjUg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=xzXdLRUyjUg"
    },
    {
      "id": "ya_9_niq2as",
      "title": "Your LLM Ran Out of Knowledge — Now What?",
      "description": "LLMs are great when there is sufficient training material, but what do we do when there is little or no knowledge to train on?\n\nWe demo a novel framework that enables reasoning LLMs to operate in domains with limited training data by combining domain-specific heuristics, explicit rules, and real-world constraints. This allows us to guide AI decision-making in specialized fields like corporate negotiations, geopolitics, etc, where trainable knowledge is scarce. This methodology opens new possibilities for AI applications in technical domains where traditional training data is scarce.\n\nGithub - https://github.com/agsheves/OracReasoningEngine",
      "publishedAt": "2025-02-22T17:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M51S",
      "viewCount": 628,
      "likeCount": 14,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ya_9_niq2as/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ya_9_niq2as/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ya_9_niq2as/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ya_9_niq2as/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ya_9_niq2as/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ya_9_niq2as"
    },
    {
      "id": "OD13PiXw60o",
      "title": "Building Multi agent Systems with Finite State Machines",
      "description": "State machines and the Actor model are a timeless foundation for designing robust, scalable, and maintainable distributed systems by providing clear abstractions for managing state, concurrency, and message-driven communication. But as foundational AI models grow more intelligent and autonomous, do these tools still have a place?\n\nThis talk explores how State machines and the Actor model can be leveraged alongside LLMs to build Agents that reason, plan, and act with observability, reliability, and control. The Agentic patterns of tool use, feedback, collaboration, orchestration, and chartering are all introduced through the clarifying lens of State Charts.\n\nhttps://github.com/adamterlson/AgenticStateMachines",
      "publishedAt": "2025-02-22T17:00:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M11S",
      "viewCount": 2228,
      "likeCount": 78,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/OD13PiXw60o/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/OD13PiXw60o/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/OD13PiXw60o/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/OD13PiXw60o/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/OD13PiXw60o/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=OD13PiXw60o"
    },
    {
      "id": "EUHx5ooJHuQ",
      "title": "How Coding Agents change Software Development Forever - Hailong Zhang",
      "description": "In this talk, we explore the transformative role of coding agents in modern software development. We'll begin by examining the future software development workflow, highlighting how coding agents streamline processes and enhance productivity. Next, we'll discuss the process of working with an unit test agent (Test Gru) as an example. We'll also share some development experiences with Gru.ai agents to help you better understand how to leverage them to enhance efficiency.\nJoin us to discover how coding agents are shaping the future of development.",
      "publishedAt": "2025-02-22T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT8M50S",
      "viewCount": 736,
      "likeCount": 15,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/EUHx5ooJHuQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/EUHx5ooJHuQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/EUHx5ooJHuQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/EUHx5ooJHuQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/EUHx5ooJHuQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=EUHx5ooJHuQ"
    },
    {
      "id": "FpJ9dPe1qYQ",
      "title": "Reverse Conway's law and GenAI: How agents will take over the organisation - Patrick Debois",
      "description": "Generative AI tools are changing the way we work. Our workflows and processes change, expectations of our roles change, our jobs change... inevitably our organisations must also change. This talk represents research of various models of how people are thinking about the impact of agents in the workforce. A glimpse into possible futures: from Copilot all the way up to running the business !",
      "publishedAt": "2025-02-22T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT28M12S",
      "viewCount": 924,
      "likeCount": 24,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/FpJ9dPe1qYQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/FpJ9dPe1qYQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/FpJ9dPe1qYQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/FpJ9dPe1qYQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/FpJ9dPe1qYQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=FpJ9dPe1qYQ"
    },
    {
      "id": "MExbNNG_VcI",
      "title": "Your AI Agent Isn't an Engineer: The Art of Thoughtful Anthropomorphism",
      "description": "Raise your hand if you've been personally victimized by the question: 'Will AI replace software engineers?'—a question our industry invited by marketing AI agents as 'human engineers' instead of what they really are: tools. \n\nAnthropomorphism—attributing human-like qualities to technology—can make AI feel more familiar, lowering the barrier to adoption. But when we oversell their capabilities, we create unrealistic expectations and lose developer trust. \n\nJoin Rizel as she shares her framework for making agents approachable without misrepresenting their potential. Learn why misrepresentation happens and how to foster trust.\n\nBlog post: https://dev.to/blackgirlbytes/your-ai-agent-isnt-an-engineer-5egf",
      "publishedAt": "2025-02-22T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M20S",
      "viewCount": 694,
      "likeCount": 20,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/MExbNNG_VcI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/MExbNNG_VcI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/MExbNNG_VcI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/MExbNNG_VcI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/MExbNNG_VcI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=MExbNNG_VcI"
    },
    {
      "id": "R2VfIjuWhgw",
      "title": "Where AI is superhuman: The right jobs to automate with LLMs",
      "description": "Ask an LLM system to do any job and it'll give it a try. But not all jobs are made equal – the nature of different work means that LLMs will be much more disruptive in some areas compared to others. If you're a founder deciding where to build, or an executive deciding where to invest, what should you do? In this talk we dive into first principles assessment of what LLMs do best, what types of jobs see the best technology-workflow fit, and which jobs LLMs will disrupt entirely because they're already superhuman in capabilities.",
      "publishedAt": "2025-02-22T16:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT11M53S",
      "viewCount": 692,
      "likeCount": 20,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/R2VfIjuWhgw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/R2VfIjuWhgw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/R2VfIjuWhgw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/R2VfIjuWhgw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/R2VfIjuWhgw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=R2VfIjuWhgw"
    },
    {
      "id": "4J8-D0sgU9A",
      "title": "Cohere: Building enterprise LLM agents that work (Shaan Desai)",
      "description": "Building scalable, safe and seamless LLM agents for enterprise is a difficult task. Not only must developers choose the right frameworks, tools, and models from a panacea of options but they also need to carefully orchestrate them to build fault tolerant agents that meet strict enterprise requirements. In this talk we walk you through the critical decision making process in setting up enterprise agents. Specifically, we discuss the frameworks we love, how we define robust tools and ensure safety via human-in-the-loop, highlight our evaluation criteria and importantly, discuss how we improve model capabilities.",
      "publishedAt": "2025-02-22T15:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M29S",
      "viewCount": 2802,
      "likeCount": 65,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/4J8-D0sgU9A/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/4J8-D0sgU9A/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/4J8-D0sgU9A/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/4J8-D0sgU9A/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/4J8-D0sgU9A/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=4J8-D0sgU9A"
    },
    {
      "id": "YYcNm2RexnY",
      "title": "Lessons from building GenAI based applications — Juan Peredo",
      "description": "Integrate GenAI into your applications to deliver value without hidden complexities or budget surprises. Join us for a fast-paced session packed with hard-won insights.\n\nWe will discuss topics like model hosting dilemmas, cost surprises, and the critical role of validating outputs. We will also talk about strategies to minimize these challenges, including:\n\n- Chatbots to agents: Supercharge your apps with AI chatbots and agents.\n- Cost control: How AI impacts your development cost and tips on how to control them.\n- Pro moves: Prompt management, observability, and evaluations.\n\nPerfect for managers, engineers, and builders: walk away with strategies to ship AI apps faster, cheaper, and smarter. Cut through the hype—let’s talk results.",
      "publishedAt": "2025-02-22T15:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT33M13S",
      "viewCount": 785,
      "likeCount": 14,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/YYcNm2RexnY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/YYcNm2RexnY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/YYcNm2RexnY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/YYcNm2RexnY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/YYcNm2RexnY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=YYcNm2RexnY"
    },
    {
      "id": "ro5HkZvzfiQ",
      "title": "The LLM Triangle: Engineering Principles for Robust AI Applications - Almog Baku:",
      "description": "Let's face it: most LLM App PoCs are a disaster waiting to happen. Hallucinations, inconsistency, and scalability nightmares abound. Enter the LLM Triangle - a framework for building reliable, production-ready AI systems.\n\nI'll present the LLM Triangle Principles, a framework for building robust LLM-native applications. Based on extensive experience, I'll share key insights for bridging the gap between LLM potential and production-grade performance.\n\nWe'll explore:\n- SOPs for consistent LLM performance\n- Strategic model selection balancing capability and cost\n- LLM-native architecture for production\n- Contextual data optimization techniques\n\nUsing real-world implementations, we'll tackle common pitfalls and present innovative solutions. Senior engineers and tech leaders will gain actionable insights to elevate LLM applications from concept to production.\n\nJoin us to gain practical strategies for robust and scalable AI systems.",
      "publishedAt": "2025-02-22T15:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT26M19S",
      "viewCount": 1330,
      "likeCount": 31,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ro5HkZvzfiQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ro5HkZvzfiQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ro5HkZvzfiQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ro5HkZvzfiQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ro5HkZvzfiQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ro5HkZvzfiQ"
    },
    {
      "id": "7MiFIhlkBoE",
      "title": "Patrick Dougherty: How to Build AI Agents that Actually Work",
      "description": "Two years ago, we decided to completely re-engineer our product from scratch for AI Agents. We had no frameworks, no SDKs, and no idea if it would actually work. These are the lessons we learned along the way, before getting acquired in 2024 by https://www.klarity.ai/.",
      "publishedAt": "2025-02-22T15:00:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M44S",
      "viewCount": 11694,
      "likeCount": 368,
      "commentCount": 13,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/7MiFIhlkBoE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/7MiFIhlkBoE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/7MiFIhlkBoE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/7MiFIhlkBoE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/7MiFIhlkBoE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=7MiFIhlkBoE"
    },
    {
      "id": "D6v5rlqUIc8",
      "title": "Keynote: Why people think \"agent\" is a buzzword but it isn't",
      "description": "Chip Huyen's keynote for the AIE Summit Online track",
      "publishedAt": "2025-02-22T14:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT28M7S",
      "viewCount": 9043,
      "likeCount": 247,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/D6v5rlqUIc8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/D6v5rlqUIc8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/D6v5rlqUIc8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/D6v5rlqUIc8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/D6v5rlqUIc8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=D6v5rlqUIc8"
    },
    {
      "id": "qeDPKbWjsuk",
      "title": "Keynote: The AI developer experience doesn't have to suck – why and how we built Modal",
      "description": "Modal provides infrastructure for AI and other compute-heavy applications. In order to deliver the developer experience we wanted, we realized early that we would have to throw out Kubernetes and Docker and start over. This is the story of a deep rabbit hole of how we built our own container system in the quest of a great developer experience.",
      "publishedAt": "2025-02-22T14:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M38S",
      "viewCount": 1244,
      "likeCount": 21,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/qeDPKbWjsuk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/qeDPKbWjsuk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/qeDPKbWjsuk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/qeDPKbWjsuk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/qeDPKbWjsuk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=qeDPKbWjsuk"
    },
    {
      "id": "D7BzTxVVMuw",
      "title": "AI Engineer Summit 2025: Agent Engineering (Day 2)",
      "description": "Timestamps\n0:00:00 - start\n0:15:36 - swyx: Why Agent Engineering\n0:27:23 - AI Snake Oil: Building and evaluating AI Agents\n0:47:17 - Gemini: Going deep on Gemini Deep Research\n1:02:23 - Anthropic: How We Build Effective Agents\n1:17:30 - Sierra: The Agent Development Life Cycle\n1:36:07 - Morgan Stanley: What RL Means for Agents\n2:53:39 - Jane Street: Building AI-Powered Developer Tools at Jane Street\n3:10:51 - Bloomberg: Challenges to Scaling Agents for Generative AI Products\n3:30:29 - Brightwave: Knowledge Agents for Finance Workflows\n5:07:34 - Windsurf:  Agents are built at the fringe: getting from 90 to 100\n5:46:59 - SuperDial: Voice AI: Your Bot Isn't Special\n5:28:06 - Method/OpenPipe: How we scaled 500m AI agents in production with 2 engineers\n6:06:12 - Ramp: AI Agents: the Bitter Lesson\n7:06:33 - OpenAI: Creating Agents that Co-Create\n7:30:48 - Gemini: The Next AI Engineers\n7:52:26 - Meta: What does it take to build a personal, local, private AI Agent that augments you deeply?",
      "publishedAt": "2025-02-21T22:56:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT8H26M36S",
      "viewCount": 92787,
      "likeCount": 1879,
      "commentCount": 16,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/D7BzTxVVMuw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/D7BzTxVVMuw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/D7BzTxVVMuw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/D7BzTxVVMuw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/D7BzTxVVMuw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=D7BzTxVVMuw"
    },
    {
      "id": "L89GzWEILkM",
      "title": "AI Engineer Summit 2025 - AI Leadership (Day 1)",
      "description": "Scheduled Talks (All times EST):\n9:00am - Show opener \n9:07AM - Beyond the Consensus: Navigating AI's Frontier in 2025 - Grace Isford of Lux Capital\n9:28AM - How To Build an AI Strategy That Fails: Hamel Husain of Parlance Labs and Greg Ceccarelli of SpecStory\n9:49AM - Balancing Innovation with Security & Safety - Don Bosco Durai of Privacera\n10:10AM - Building Self-Coding Agents - Colin Flaherty of Augment Code\n10:30AM - Break\n11:00AM - Anchoring Enterprise GenAI with Knowledge Graphs - Stephen Chin of Neo4j and Jonathan Lowe of Pfizer\n11:21AM - Building AI Agents with Real ROI in the Enterprise SDLC - Bruno Passos of Booking.com and Beyang Liu of Sourcegraph\n11:42AM - Building Trust in Enterprise AI: Evaluating Domain-Specific LLMs for Real-World Financial Scenarios - Waseem Alshikh of Writer\n12:03PM - OpenAI for VPs of AI - Prashant Mital of OpenAI\n12:24PM - Break\n1:15PM - Frontier Feud - where teams from leading AI frontier labs will go head-to-head in a battle of wits. Hosted by Barr Yaron, Partner at Amplify Partners\n1:45PM - Missing pieces of workflow automation - Shirsha Chaudhuri of Thomson Reuters\n2:06PM - Ensure AI Agents Work: Evaluation Frameworks for Scaling Success - Aparna Dhinkaran of Arize\n2:27PM - The Devops Engineer Who Never Sleeps - Diamond Bishop of Datadog\n2:48PM - How to Build Your Own AI Data Center in 2025 - Paul Gilbert of Arista Networks\n3:08PM - Anthropic for VPs of AI - Alexander Bricken of Anthropic\n3:30PM - Break\n4:00PM - Insights on Building AI Teams - Heath Black of SignalFire\n4:21PM - Lessons from Building LinkedIn's GenAI Platform - Xiaofeng Wang of LinkedIn\n4:42PM - Specialized RAG Agents - Douwe Kiela of Contextual AI\n\nTimestamps\n00:00:00 - Intro\n00:17:20 - Lux Capital: Trends in 2025\n00:35:11 - Ai-execs: Building an AI Strategy That Fails\n00:52:05 - Privacera: Building with AI Safety and Security\n01:10:07 - Augment Code: Self-Coding Agents\n02:07:32 - Neo4j: Knowledge Graphs\n02:28:27 - booking.com: Agents With Real ROI\n02:49:31 - Writer: Evaluating LLMs for Financial Scenarios\n03:01:34 - OpenAI: OpenAI for VPs\n03:09:47 - OpenAI: Building Agents the Right Way\n04:25:41 - Frontier Feud\n04:51:29 - Reuters:  Missing Pieces of Workflow Automation\n05:06:07 - Arize: Evaluating Agents\nDatadog: Devops Engineer that Never Sleeps 05:28:13\nAstra: How to build an AI Data Center 05:44:41\n06:07:38 - Anthropic: Anthropic for VPs of AI\nHeath Black 07:05:40 - SignalFire: Insights on Building AI Teams\n07:26:07 - LinkedIn: Lessons from Building LinkedIn’s GenAI Platform\n07:43:51 - Contextual AI: 10 Lessons Learned from the Frontier of AI",
      "publishedAt": "2025-02-20T22:19:52Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT8H3M36S",
      "viewCount": 41930,
      "likeCount": 914,
      "commentCount": 12,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/L89GzWEILkM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/L89GzWEILkM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/L89GzWEILkM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/L89GzWEILkM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/L89GzWEILkM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=L89GzWEILkM"
    },
    {
      "id": "lG_8rgQqxfc",
      "title": "Personality Driven Development: Exploring the Frontier of Agents with Attitude",
      "description": "Meet Circuitrix, the sassy robot who schedules meetings, Hootie McHootface, the whimsical owl who transcribes calls, and Zarplo, the sycophantic code-reviewing martian -- AI agents with personalities as unique as their workflows.\n\nIs giving AI agents human-like traits merely a marketing gimmick? Or does it fundamentally transform and improve user adoption and interaction? We'll explore the impact of anthropomorphizing AI agents on user engagement, and share insights from letting end-users completely customize their own agents’ personalities.\n\nDiscover the engineering practices required to develop agents with unique personas, the technical challenges debugging a product with infinite(!) customizability, and why you may never say the phrase \"works on my machine\" ever again. Get ready to rethink the relationship between AI and users in this deep dive into the world of personality-driven agent design.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Benjamin\nBen is a customer-obsessed technology executive and product leader who seamlessly bridges the worlds of business, product, and technology. He has repeated success leading cross-functional teams at multiple lifecycle stages, from 3x startup founder, to scaling through hyper-growth, to managing mature lines of business.\n\nLeadership: In 7 years at Twilio, Ben was GM of multiple business units (Developer Experience, Enterprise), Product Director for text messaging, and Head of R&D for Twilio.org. As CPTO at Arcadia (climate tech unicorn), he led a global team building APIs to decentralize and decarbonize the electrical grid. He cofounded multiple startups including Mobile Commons (acquired by $UPLD), an early platform for SMS marketing; and QuitCarbon, an AI platform to transition 100M homes off fossil fuels.\n\nTech Background: His early experience was building high availability, distributed software for B2B customers with a focus on data and security. At Bloomberg LP, Ben developed on their trading system and first search engine. At ShadowTV he transcoded and streamed 100s of terabytes of video data for government and corporate customers. And as a Visiting Scientist at Cornell, he developed medical imaging software for lung cancer screening.\n\nFun Stuff: Ben earned a BS in Electrical and Biological Engineering and a Master's in Medical Image Processing at Cornell University. His is passionate about fighting the climate crisis and local STEAM education. He lives in Oakland CA with his wife and two sons. In off hours, he can usually be found coding Ruby, biking, playing basketball, solving cryptic crosswords, listening to Audible, or losing at pub trivia.\n\nHe was one of the leading pioneers who shaped how nonprofits use text messaging for advocacy, fundraising, and organizing. He is an investor/advisor at tech startups Art19 (acquired by Amazon), Sesh, Private.ai, Propel Data, Mind-X (acquired by Blackrock), and Earthforce.",
      "publishedAt": "2025-02-17T18:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M",
      "viewCount": 1116,
      "likeCount": 27,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/lG_8rgQqxfc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/lG_8rgQqxfc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/lG_8rgQqxfc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/lG_8rgQqxfc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/lG_8rgQqxfc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=lG_8rgQqxfc"
    },
    {
      "id": "IAdZxqjZ45U",
      "title": "Optimizing LLMs in Insurance with DSPy: Jeronim Morina",
      "description": "In the insurance industry, LLMs promise efficiency but often get bogged down by manual tuning for optimal performance. DSPy changes the game.\n\nTraditional LLM deployment is a high-effort, error-prone process, demanding extensive prompt engineering and fine-tuning across multiple steps.\n\nImagine deploying LLMs where manual optimizations are replaced by DSPy's automated, efficient prompt and weight optimization\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Jeronim\nI'm currently working at AXA, one of the biggest insurers of the world with over 100 billion euro revenue. I build critical Machine Learning infrastructure for AXA Germany to enable hundreds of Data Scientists working effectively every day. I provide core Machine Learning Platform toolings as well as help them deploy Machine Learning models to production reliably and efficiently. I'm also responsible for orchestrating and creating LLM applications that help our customer agents with claims management.\n\nApart from that I have founded my own company bloomed AI in 2023 and help startups with their LLM infrastructure, as well as create a LLM based coverage check tool for customers to see if their insurance provides with with the right coverage and how to write a claim properly.",
      "publishedAt": "2025-02-16T17:15:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M29S",
      "viewCount": 4611,
      "likeCount": 112,
      "commentCount": 16,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/IAdZxqjZ45U/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/IAdZxqjZ45U/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/IAdZxqjZ45U/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/IAdZxqjZ45U/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/IAdZxqjZ45U/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=IAdZxqjZ45U"
    },
    {
      "id": "ePMvfa8vgL8",
      "title": "Customized, production ready inference with open source models: Dmytro (Dima) Dzhulgakov",
      "description": "Recorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Dmytro\nDmytro (Dima) Dzhulgakov is the co-founder and CTO of ‪@fireworksai‬ which focuses on the transition to AI-powered business via interactive experimentation and a production platform centered around PyTorch technologies. Fireworks.ai offers high-performance low-cost LLM inference service that helps to try out and productionize large models.\n\nDmytro is one of PyTorch core maintainers. Previously he helped to bring PyTorch from a research framework to numerous production applications across Meta's AI use cases and broader industry.",
      "publishedAt": "2025-02-16T01:45:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M55S",
      "viewCount": 1446,
      "likeCount": 28,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ePMvfa8vgL8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ePMvfa8vgL8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ePMvfa8vgL8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ePMvfa8vgL8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ePMvfa8vgL8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ePMvfa8vgL8"
    },
    {
      "id": "1B9i7FBsRVQ",
      "title": "Claude plays Minecraft!",
      "description": "Not Chatbots again! Not today, thank you!\n\nImagine a world where AI does more than just chat—it thinks, solves, and acts. Enter the realm of Minecraft, where virtual landscapes become the perfect proving ground for the next generation of autonomous agents.\n\nThis deep dive session takes you on an adventure beyond the ordinary, showcasing how we've engineered an AI entity capable of reasoning, problem-solving, and executing tasks in Minecraft.\n\nLeveraging the power of Amazon's Bedrock, Lambda, SNS, and a suite of AWS serverless technologies, paired with the latest Claude 3 model from Anthropic, we reveal the full potential of AI beyond the confines of chatbots.\n\nDiscover how these serverless solutions empower our AI to interact with, adapt to, and transform its environment in real-time, providing a glimpse into the future of autonomous agents in both virtual and real-world applications. Join us as we navigate the intricacies of serverless AI architecture, demonstrating its practical implications, block by block.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Derek\nDerek is a Developer Advocate for Developer Relations at Amazon Web Services, focused on helping developers across Australia and New Zealand to build their applications on AWS. He is focused on engaging technical audiences like developer, community, and user groups to share the latest AWS cloud services in blog posts, social media, and public speaking. He has a special interest in cloud-native architecture and front-end / mobile development.\n\nIn prior roles he has worked primarily as a Software Developer with over 18 years’ experience designing, architecting and building complex solutions across a range of industries including health, telecommunications, insurance, finance and defence.\n\nHe is currently enjoying the adoption of agile development principles across the industry, that is finally recognizing that it’s critical to release early and frequently to maximize learning and validate assumptions.",
      "publishedAt": "2025-02-15T23:15:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M16S",
      "viewCount": 829,
      "likeCount": 22,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1B9i7FBsRVQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1B9i7FBsRVQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1B9i7FBsRVQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1B9i7FBsRVQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1B9i7FBsRVQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1B9i7FBsRVQ"
    },
    {
      "id": "ckLXb15BnM8",
      "title": "The Adversarial Path to the Personal Assistant: Sumit Agarwal",
      "description": "Despite their trillions of tokens of training data, GPT4 and others models can’t answer a single question about us as unique individuals. The personal AI assistant we all want surely has to know us as individuals, right? Today’s AI assistants either give us generic information, or require significant input from us before providing useful personalized assistance. Isn’t there a better path? Of course there is. In this talk, we’ll discuss our implementation of a personal, private, proactive AI assistant that begins its relationship with you by downloading your transaction logs from major B2C sites (think of Google, Facebook, Amazon, Doordash, Strava, Uber and dozens of others) to your local device. By building a RAG system using this data, our personal AI assistant becomes useful immediately, without requiring significant user input. Learn how a modest amount of very powerful personal data can unlock the power and potential of personal AI assistants.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Sumit\nSumit Agarwal is founder and CEO of Ario AI, which is developing a personal agent built on top of a person's entire online data history. Before Ario, Sumit spent 8 years building Shape Security, the leading security vendor for user data protection. F5 Networks purchased Shape for $1B in Jan 2020. Immediately prior to Shape, Sumit was a Deputy Assistant Secretary of Defense at the Pentagon where he worked on national security issues. Sumit served as a network warfare officer in the United States Air Force Guard and Reserve for 17 years. He started his career with stints at Trilogy, in venture capital, and as a founder of Quova. He also spent 6 years at Google from 2003 to 2009. Sumit holds a BS in Chemical Engineering from MIT.",
      "publishedAt": "2025-02-15T19:30:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M46S",
      "viewCount": 706,
      "likeCount": 12,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ckLXb15BnM8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ckLXb15BnM8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ckLXb15BnM8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ckLXb15BnM8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ckLXb15BnM8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ckLXb15BnM8"
    },
    {
      "id": "_2tZaDs-w5s",
      "title": "RAG at scale: production ready GenAI apps with Azure AI Search",
      "description": "If 2023 was the year of GenAI prototypes, 2024 is the year these apps go into production. In this session we’ll demo how Azure AI Search combines the best RAG capabilities for GenAI apps at any scale, without compromising cost or performance. We will share the latest product updates, including increased storage limits, advanced capabilities for detailed retrieval pipeline control, built-in support for content beyond text, and re-ranking improvements to boost quality of responses.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Pablo\nPablo is a Distinguished Engineer at Microsoft. He works in the Azure AI group where he is both a hands-on engineer and the general manager of Azure AI Search, a state-of-the-art information retrieval system. Pablo currently focuses on knowledge retrieval for generative AI applications and is deeply curious about what LLMs are teaching us about the nature of thought and knowledge.",
      "publishedAt": "2025-02-13T08:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M53S",
      "viewCount": 1524,
      "likeCount": 39,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/_2tZaDs-w5s/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/_2tZaDs-w5s/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/_2tZaDs-w5s/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/_2tZaDs-w5s/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/_2tZaDs-w5s/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=_2tZaDs-w5s"
    },
    {
      "id": "of-SV35YqvY",
      "title": "Training Albatross  An Expert Finance LLM: Leo Pekelis",
      "description": "The challenge with financial agents successfully completing complex workflows like tabular reasoning or sentiment analysis often comes down to the reliability of executing numerous chained tasks together. Establishing the p99s necessary has to happen at the model level, yet most finance domain-specific LLMs are either only pre-training (BloombergGPT) or using supervised fine-tuning (FinBERT).\n\nThis presentation reveals how we transformed an open-source model into Albatross (https://huggingface.co/gradientai/v-alpha-tross), capable of performing at the top of the leaderboard on chat as well as domain-specific tasks. Our journey involved an intensive data pipeline and training regiment, incorporating a combination of continual pre-training, fine-tuning, and preference optimization, to customize the model for the intricacies of financial tasks. We'll share our insights on overcoming the execution hurdle, which is often the downfall of AI projects in specialized domains.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Leo\nAs Gradient's Chief Scientist, Leo leads our research team. Prior to Gradient, Leo led CloudTruck's ML and data science orgs pioneering applied ML to operational challenges. Prior to CloudTrucks, Leo held leadership roles across Opendoor, Optimizely, and Disney. Leo holds a bachelors degree in economics from Stanford, as well as a masters and PhD in statistics from Stanford.",
      "publishedAt": "2025-02-13T08:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M20S",
      "viewCount": 1539,
      "likeCount": 54,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/of-SV35YqvY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/of-SV35YqvY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/of-SV35YqvY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/of-SV35YqvY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/of-SV35YqvY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=of-SV35YqvY"
    },
    {
      "id": "tQTB4MU_z8w",
      "title": "Accelerating Mixture of Experts Training With Rail Optimized InfiniBand Networking in Crusoe Cloud",
      "description": "State-of-the-art machine learning models are increasingly using techniques like mixture of experts that enable larger-scale models to be trained more efficiently by distributing layers of the model across multiple neural networks. This sparse distribution of model state puts increasing pressure on cluster-level networking while training. At Crusoe Cloud, we’ve built a high-performance InfiniBand network that's designed to provide the highest possible performance for these state-of-the-art training techniques. We use a “rail-optimized” design, reducing the number of hops between any set of GPUs in our cluster, accelerating all2all performance, and reducing training time. Learn more about how to utilize Crusoe Cloud rail-optimized networks to accelerate your training workloads.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Ievgen\nIevgen is a product manager at Crusoe, focused on building reliable and scalable AI-cloud infrastructure. He defines and guides the design of large and ultra-large-scale, multi-tenant GPU clusters, enabling customers to use thousands of GPUs simultaneously for ML training and inference. Before joining Crusoe, Ievgen held several different technical and product positions at networking vendors.",
      "publishedAt": "2025-02-12T20:45:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M45S",
      "viewCount": 642,
      "likeCount": 21,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/tQTB4MU_z8w/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/tQTB4MU_z8w/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/tQTB4MU_z8w/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/tQTB4MU_z8w/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/tQTB4MU_z8w/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=tQTB4MU_z8w"
    },
    {
      "id": "gFyBdBm0AGo",
      "title": "System Design for Next-Gen Frontier Models — Dylan Patel, SemiAnalysis",
      "description": "Current and future hardware requirements for next generation frontier models.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Dylan\nDylan Patel is the founder and Chief Analyst of SemiAnalysis, a semiconductor and AI research company. SemiAnalysis has analysts across the US, Japan, Taiwan, Singapore, and France covering the industry from production of materials, equipment, process technology, fabs to design IP and fabless to physical infrastructure of datacenters, networking, and AI models.",
      "publishedAt": "2025-02-11T00:08:26Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M29S",
      "viewCount": 6171,
      "likeCount": 143,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/gFyBdBm0AGo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/gFyBdBm0AGo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/gFyBdBm0AGo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/gFyBdBm0AGo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/gFyBdBm0AGo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=gFyBdBm0AGo"
    },
    {
      "id": "CoaL4JZKsWI",
      "title": "AI Music Generation, From Prompt to Production: Phlo Young",
      "description": "The rise of AI music generation tools has opened up a world of creative possibilities for musicians and non-musicians alike. This workshop will demystify these tools, providing a hands-on introduction to their capabilities and potential. Participants will learn how to use AI to generate musical ideas, create custom loops and samples, and even compose full songs.\n\nIn this workshop we will:\n\nUnderstand the different types of AI music generation tools and their use cases.\nGet hands-on experience with popular AI music platforms like Suno and Udio.\nExplore prompt engineering techniques for generating different musical styles and genres.\nLearn how to refine and customize AI-generated music to your liking.\nDiscuss the ethical and legal considerations surrounding AI music creation.\n\nTakeaway: By the end of the workshop, attendees will have a practical understanding of AI music generation tools and how they can be used to enhance creativity and musical expression. Whether you're a seasoned musician or just starting out, this workshop will equip you with the knowledge and skills to harness the power of AI for making music.\n\nPrerequisites: An account with Suno and Udio (free or paid)\nNo prior musical experience or coding knowledge required (but it helps)\nSkill level: Beginner\n\nAssets: https://aietalk.com/music/\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Phlo\nPhlo is an AI Engineer passionate about the intersection of music and generative AI. He combines years of experience in marketing and music distribution with a foundation in audio engineering (University of Miami) and cutting-edge AI research to explore the future of music creation. Phlo has a proven track record of success, scaling an eCommerce store to half a million dollars in monthly revenue and orchestrating impactful music marketing campaigns. He believes AI-assisted music production will democratize the creative process, making it more accessible for everyone. At the AI Engineer World's Fair, Phlo will be leading a workshop where attendees can experience firsthand the power of AI music generation and discuss its potential impact on the music industry.",
      "publishedAt": "2025-02-11T00:04:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT54M34S",
      "viewCount": 1887,
      "likeCount": 54,
      "commentCount": 20,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/CoaL4JZKsWI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/CoaL4JZKsWI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/CoaL4JZKsWI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/CoaL4JZKsWI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/CoaL4JZKsWI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=CoaL4JZKsWI"
    },
    {
      "id": "heYmh_lsX5s",
      "title": "Giving a Voice to AI Agents: Scott Stephenson, CEO, Deepgram",
      "description": "Voice AI technology has evolved significantly in recent years, transitioning from simple command-response systems to more sophisticated natural conversational agents powered by Large Language Models (LLMs). This progression in voice AI is being driven by advances in core technologies such as foundational AI models, dramatically transforming interactions between humans and machines. Notable improvements include advanced automatic speech recognition and breakthroughs in human-like speech synthesis, all integrated with the deep language comprehension provided by LLMs. These developments have culminated in powerful, autonomous systems that interact through spoken language exclusively. During the session, Scott Stephenson, Founder and CEO of Deepgram, will explore the fundamental principles and best practices for crafting responsive, realistic, and captivating AI agents. He will delve into topics such as natural language processing and the design of multimodal interactions. Attendees will gain insights into the principal design challenges and key considerations involved in developing voice agents capable of managing complex conversations and providing context-sensitive responses on par with human speakers.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Scott\nVoice AI technology has evolved significantly in recent years, transitioning from simple command-response systems to more sophisticated natural conversational agents powered by Large Language Models (LLMs). This progression in voice AI is being driven by advances in core technologies such as foundational AI models, dramatically transforming interactions between humans and machines. Notable improvements include advanced automatic speech recognition and breakthroughs in human-like speech synthesis, all integrated with the deep language comprehension provided by LLMs. These developments have culminated in powerful, autonomous systems that interact through spoken language exclusively.\n\nDuring the session, Scott Stephenson, Founder and CEO of Deepgram, will explore the fundamental principles and best practices for crafting responsive, realistic, and captivating AI agents. He will delve into topics such as natural language processing and the design of multimodal interactions. Attendees will gain insights into the principal design challenges and key considerations involved in developing voice agents capable of managing complex conversations and providing context-sensitive responses on par with human speakers.\n\nScott Stephenson is a dark matter physicist turned Deep Learning entrepreneur. He earned a PhD in particle physics from University of Michigan where his research involved building a lab two miles underground to detect dark matter. Scott left his physics post-doc research position to found Deepgram.",
      "publishedAt": "2025-02-10T23:00:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M8S",
      "viewCount": 1571,
      "likeCount": 41,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/heYmh_lsX5s/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/heYmh_lsX5s/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/heYmh_lsX5s/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/heYmh_lsX5s/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/heYmh_lsX5s/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=heYmh_lsX5s"
    },
    {
      "id": "dRQHikOrH2A",
      "title": "How to build the world's fastest voice bot: Kwindla Hultman Kramer",
      "description": "How to build the world's fastest voice AI bot:\n\nSelf-host speech-to-text, LLM inference, and text-to-speech all together in the same container/cluster.\nRoute audio over the internet using WebRTC and edge networking.\nConfigure timings for voice activity detection, phrase endpointing, and other parts of the pipeline to optimize for latency. (There are trade-offs to doing this!)\nHere's a LLama 3 voice bot that has voice-to-voice response times of ~500ms.\n\nWe used @DeepgramAI 's STT and TTS for this bot, and everything is hosted on @cerebriumai 's serverless GPU infrastructure.\n\nhttps://x.com/kwindla/status/1806129490411900940\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Kwindla \nI am one of the founders of Daily and I serve as the company's CEO. We develop infrastructure and SDKs for video and audio. If you are are creating a product or an app that has video or audio features, we can probably help. The Internet is increasingly a video-first medium, and we think of ourselves as building the infrastructure for the future of our collective digital experience.",
      "publishedAt": "2025-02-10T16:15:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M38S",
      "viewCount": 3892,
      "likeCount": 136,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/dRQHikOrH2A/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/dRQHikOrH2A/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/dRQHikOrH2A/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/dRQHikOrH2A/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/dRQHikOrH2A/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=dRQHikOrH2A"
    },
    {
      "id": "Xmkl27AM2VQ",
      "title": "Unveiling the latest Gemma model advancements: Kathleen Kenealy",
      "description": "Lets cut through the buzzwords and get to the point. In this talk we'll unveil the abilities of Gemma and Gemini models, and discuss how to design and build killer apps with LLMs. We'll cover the essential tools, techniques, and best practices you need to know, without the fluff. We'll explore how developers can use Google Cloud's Vertex AI platform to build safe, secure applications with open models. Using Google's Gemma model, we'll dive into an end-to-end example of model discovery, tuning, and deployment as part of real-world application.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025",
      "publishedAt": "2025-02-09T20:51:56Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M25S",
      "viewCount": 1841,
      "likeCount": 59,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Xmkl27AM2VQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Xmkl27AM2VQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Xmkl27AM2VQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Xmkl27AM2VQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Xmkl27AM2VQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Xmkl27AM2VQ"
    },
    {
      "id": "zHYQZFy0UVk",
      "title": "Fine tune 20 Llama Models in 5 Minutes: Santosh Radha",
      "description": "The complexity and scarcity of deploying GPUs can bring AI development to a standstill. What if there was a better way to train, fine-tune, and serve models on accelerated compute infrastructure entirely in Python? See how during this session where we fine-tune 20 Llama models without doing any infrastructure work. Startups and enterprises can finally gain unprecedented speed and agility to build, iterate, and deploy anything that they can imagine, from multi-agent, multi-modal AI applications, to digital twins for real world simulation. What used to take weeks with dozens of best-in-class engineers can now be accomplished in hours from a single notebook.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Santosh\nSantosh is the Head of Product/Research at Agnostiq, where he plays a pivotal role in shaping the company's product strategy, particularly through the development of Covalent which is designed to significantly enhance the scalability and performance of next-generation AI applications and large-scale scientific simulations across multi-cloud environments. Santosh holds a Ph.D in theoretical physics from Case Western Reserve University.",
      "publishedAt": "2025-02-09T20:51:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT6M26S",
      "viewCount": 1254,
      "likeCount": 28,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/zHYQZFy0UVk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/zHYQZFy0UVk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/zHYQZFy0UVk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/zHYQZFy0UVk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/zHYQZFy0UVk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=zHYQZFy0UVk"
    },
    {
      "id": "-hYqt8M9u_M",
      "title": "The GenAI Maturity Curve or  You Probably Don't Need Fine Tuning: Kyle Corbitt",
      "description": "Simple instruction prompting? Few-shot examples? Fine-tuning? How do you decide when to do each? In this talk we’ll discuss the emerging concept of the GenAI maturity curve and define the steps along it. We’ll also discuss the concrete triggers you should watch for to indicate that you’re ready to move up to the next step.\n\nAt OpenPipe we’ve helped customers fine-tune thousands of models (and redirected thousands more who hadn’t hit the trigger points). Let’s talk about how to speed-run that journey!\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Kyle\nKyle Corbitt is the co-founder and CEO of OpenPipe, the easiest way to train fine-tuned models and deploy them to production. OpenPipe has fine-tuned thousands of customer models, and serves millions of inference requests every day.\n\nBefore founding OpenPipe, Kyle led the Startup School team at Y Combinator, which was responsible for the product and content that YC produces for early-stage companies. Prior to that he worked in engineering at Google and studied ML at school.",
      "publishedAt": "2025-02-09T20:48:19Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M3S",
      "viewCount": 1114,
      "likeCount": 31,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/-hYqt8M9u_M/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/-hYqt8M9u_M/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/-hYqt8M9u_M/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/-hYqt8M9u_M/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/-hYqt8M9u_M/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=-hYqt8M9u_M"
    },
    {
      "id": "idDnpGqJd80",
      "title": "Building an AI assistant that makes phone calls [Convex Workshop]",
      "description": "In this workshop, we'll use a variety of technologies to build a better AI assistant. This workshop leverages a Convex vector database to establish a knowledge base, Google Cloud speech-to-text, GPT-4 API, text-to-speech, Twilio and audio streaming. By the end, we'll have built an AI assistant that can take basic requests by voice, interpret what to do, make a phone call and interact with a human on the other end, then come back with some action to do (like adding an event to a calendar, or sending you an SMS update!).\n\nThis project is written entirely in Typescript, with Node, Express, and Next frameworks. To get started, clone this repo: https://github.com/get-convex/ai-world-fair.git\n\nTo follow along with full functionality, you will need keys for the following services. (Don't worry if you don't have them all! You can still follow along the presentation, and substitute the keys in later, or use entirely different services altogether.)\n\nYou will also need a free ngrok account if you wish to try it out locally.\n\nSee /server/.env.template for the required keys:\n\nOpenAI required to manage the conversation, and for text-to-speech APIs\nOPEN_AI_KEY=\n\nGoogle Cloud credential file (often called service_account.json). Required for speech-to-text translation services. OAUTH client only required for integrating calendar & email. Not required for the workshop.\nGOOGLE_APPLICATION_CREDENTIALS=./service_account.json GOOGLE_OAUTH_CLIENT_ID=\n\nTwilio credentials. Required to make and stream phone calls\nTWILIO_ACCOUNT_SID= TWILIO_AUTH_TOKEN=\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Tom\nTom is the Head of Developer Experience at Convex, which means he's the one to blame if your support tickets takes longer than 5 minutes to get a response. He also spends a lot of time talking with developers in order to better understand how to make Convex the fastest, most reliable and easy-to-use development platform on the planet. If you have any ideas, email him!\n\nTom got into software engineering as a kid, and it's a passion that never left. His free time is spent reading programming books (no joke), and playing covers of 90s pop songs on his guitar while singing extremely loudly and beautifully.",
      "publishedAt": "2025-02-09T16:30:12Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT50M53S",
      "viewCount": 1565,
      "likeCount": 41,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/idDnpGqJd80/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/idDnpGqJd80/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/idDnpGqJd80/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/idDnpGqJd80/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/idDnpGqJd80/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=idDnpGqJd80"
    },
    {
      "id": "2Wtq2GvUicw",
      "title": "LLM Quality Optimization Bootcamp: Thierry Moreau and Pedro Torruella",
      "description": "Lunch & Learn: In this bootcamp we demonstrate how smaller open source models, fine-tuned to excel at specialized tasks (e.g. classification, function calling etc.) can deliver comparable if not improved quality over proprietary state of the art models, resulting in significant cost reduction (over 60x) in your GenAI usage costs.\n\nWe’ll learn how to (1) collect and curate a fine tuning dataset, (2) fine tune an open source model (Llama 3), and (3) deploy the model fine tune into production with OctoAI and OpenPipe.\n\nFollow the prerequisite instructions contained within the collab notebook (takes about 2 mins of setup): https://colab.research.google.com/drive/1DVw6vfEtzYV7QfcVXhmmjTVBOiJiJ02b#scrollTo=fUT1waisoXFs\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Thierry\nThierry Moreau (University of Washington Ph.D.) is a co-founder of OctoAI and firm believer in open source, and spends his time to educating people on how to build more efficient and safer AI systems as OctoAI’s head of DevRel\n\nAbout Pedro\nPedro Torruella is a Senior DevRel Engineer at OctoAI. Pedro started his engineering career in Real Time Video Processing. He has implemented algorithms in both hardware and software, coordinated and led multinational teams, and founded his own startup. He shines on making the bridge between tech and people, and currently focuses on helping others use AI to create products that users love.",
      "publishedAt": "2025-02-08T21:32:17Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT53M5S",
      "viewCount": 1065,
      "likeCount": 31,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/2Wtq2GvUicw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/2Wtq2GvUicw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/2Wtq2GvUicw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/2Wtq2GvUicw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/2Wtq2GvUicw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=2Wtq2GvUicw"
    },
    {
      "id": "GVbPiq3Pet0",
      "title": "Building security around ML: Dr. Andrew Davis",
      "description": "The field of Adversarial ML has been active since at least 2013 and despite over a decade of attempts to make models more robust to imperceptible changes in the input, attack methods still outpace the ability to defend neural networks and other machine learning models. In this talk, we'll get into why adversarial examples are becoming increasingly relevant with the advent of agentic multimodal LLMs and what we can do to defend these models.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Dr. Andrew\nDr. Andrew Davis is Chief Data Scientist at HiddenLayer, where he leads research defending and detecting attacks on ML systems. Coming from a cybersecurity background, Andrew has been interested in the problem of solving adversarial examples since seeing the \"Intriguing Properties of Neural Networks\" poster at the ICLR 2014 workshop.",
      "publishedAt": "2025-02-08T21:31:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT25M1S",
      "viewCount": 385,
      "likeCount": 10,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/GVbPiq3Pet0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/GVbPiq3Pet0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/GVbPiq3Pet0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/GVbPiq3Pet0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/GVbPiq3Pet0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=GVbPiq3Pet0"
    },
    {
      "id": "1oySeF37SZc",
      "title": "GitHub Next Explorations: Rahul Pandita",
      "description": "In this session, we'll talk about current explorations by GitHub Next including Copilot Workspace a copilot native dev environment for getting started with everyday tasks.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Rahul\nI am Rahul Pandita, a Staff Researcher at Github.\n\nMy primary research interests are in data science and automated software engineering. I specifically work in the area of program comprehension targeted towards improving developer/tester/end-user productivity.\n\nPreviously, I worked as a Senior Researcher at Phase Change Software. Before that, I was as a postdoctoral researcher at Department of Computer Science NCSU working with Dr. Laurie Williams and Dr. Munindar Singh. I received my PhD. from NCSU in Computer Science. And I believe that “There is so much more left to be done...”. I strongly believe that there is always room for improvement.",
      "publishedAt": "2025-02-08T21:31:24Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M18S",
      "viewCount": 416,
      "likeCount": 4,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1oySeF37SZc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1oySeF37SZc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1oySeF37SZc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1oySeF37SZc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1oySeF37SZc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1oySeF37SZc"
    },
    {
      "id": "2Ey275TX4ZU",
      "title": "RAG and the MongoDB Document Model: Ben Flast",
      "description": "In this talk, we will explore the cutting-edge techniques for Retrieval Augmented Generation with MongoDB. We will focus on leveraging Vector Search, specifically Atlas Vector Search, over MongoDB data to improve information retrieval and generation processes.\n\nWe will show how to build a RAG system using a Parent Child Retrieval Strategy to enable more efficient and accurate retrieval of relevant information. Additionally, we will show how all of this can be done within the MongoDB document model rather than relying on implementing these relationships in the application layer. And finally, we will introduce the concept of Search Nodes which enable you to serve vector search workloads at scale.\n\nThis talk is aimed at developers, ML engineers, and data scientists interested in building AI powered experiences with RAG. By the end of the session, attendees will have a solid understanding of how Retrieval Augmented Generation, Vector Search, and MongoDB can be leveraged to build innovative and scalable AI-powered applications.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Ben\nBen Flast is a Director of Product at MongoDB focused on Search, Vector Search, and various AI Integrations. He’s been at MongoDB for the past 5 years and is excited about the new wave of real-time AI powered applications that are emerging. With a deep interest in Large Language Models, Embedding Models, and agentic experiences, Ben loves to stay on the pulse of new and emerging AI capabilities.\n\nWhen not immersed in the world of AI, Ben enjoys hitting the slopes skiing, playing strategy games, and a bit of city gardening. He’s based in Brooklyn, New York, and is very excited about the number of AI startups popping up in the city.",
      "publishedAt": "2025-02-08T21:31:24Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M13S",
      "viewCount": 1379,
      "likeCount": 37,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/2Ey275TX4ZU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/2Ey275TX4ZU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/2Ey275TX4ZU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/2Ey275TX4ZU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/2Ey275TX4ZU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=2Ey275TX4ZU"
    },
    {
      "id": "LJa1SjCkYas",
      "title": "Insights from Snorkel AI running Azure AI Infrastructure: Humza Iqbal and Lachlan Ainley",
      "description": "Join us and hear from the Snorkel AI team about their experience and lessons learned using Azure AI infrastructure powered by NVIDIA GPUs. Learn about how Snorkel Researchers were able to run experiments quickly from small projects to large-scale distributed jobs on multiple GPUs reliably and with full monitoring mechanisms.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Humza\nI do research in machine learning robustness. I've developed techniques to make models more robust to distribution shift and adversarial examples as well as understanding the underpinnings of models and understanding why machine learning works. I work at a startup Securiti.ai to help enterprises understand customer data and comply with privacy regulations using machine learning.\n\nAbout Lachlan\nDriven IT marketing and sales professional with extensive experience in Software Applications (ERP, Business Intelligence, CRM, Data Management), Hardware (Server, Storage and Networks), and Cloud based solutions (IaaS, SaaS). \n\nOver 10 years experience with global systems integrator, Fujitsu, and global Software companies Nintex, Microsoft, International across Sydney, Tokyo and Seattle.\n\nI am a team player who leads by example, taking an energetic approach to achieving successful business outcomes. A combination of strong business acumen and exceptional interpersonal skills has regularly served me well in creating a highly productive work environment for my team, regardless of culture, language or geography.\n\nAs a competitor and keen sports enthusiast, I know how to leverage team strengths to achieve collective goals and create win/win environments. My approach to analytical decision making is analytical, I evaluate the information available and learn from collective past experiences.",
      "publishedAt": "2025-02-08T21:31:24Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M46S",
      "viewCount": 177,
      "likeCount": 4,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/LJa1SjCkYas/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/LJa1SjCkYas/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/LJa1SjCkYas/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/LJa1SjCkYas/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/LJa1SjCkYas/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=LJa1SjCkYas"
    },
    {
      "id": "n0qemluQDtQ",
      "title": "Agentic Workflows on Vertex AI: Rukma Sen",
      "description": "Tired of chatbots that can barely answer basic questions? This talk dives deep into Vertex AI's agentic workflows. We'll walk you through the nuts and bolts of designing and building agents that can handle complex tasks, make decisions, and interact with your systems like a pro. You'll leave with the skills and knowledge to automate the boring stuff and unlock new levels of efficiency.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Rukma\nAI Product Marketing, Google",
      "publishedAt": "2025-02-08T21:31:24Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M6S",
      "viewCount": 1775,
      "likeCount": 30,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/n0qemluQDtQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/n0qemluQDtQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/n0qemluQDtQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/n0qemluQDtQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/n0qemluQDtQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=n0qemluQDtQ"
    },
    {
      "id": "utTqdQpe39A",
      "title": "GitHub's AI Powered Security Platform: Sarah Khalife",
      "description": "Join this session to learn more about how GitHub is incorporating GenAI across GitHub Advanced Security (GHAS) in addition to the core platform. Sarah Khalife, Principal Solutions Engineer, will provide an overview of key features including code scanning, secret scanning, and supply chain security, highlighting the latest AI-powered capabilities.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Sarah\nPassionate about creating an environment for organizations to implement best practices and improve their software development lifecycle operations, Sarah is a Principal Solutions Engineer at GitHub. She helps drive innersource, automation and security workflows, and most recently, AI-assisted development for her enterprise customers. Sarah is currently focused on helping customers in the Financial Services Industry to overcome challenges, adopt new solutions, and scale them out across their business. Previously, she worked as a senior software engineer, deploying and operating tools related to Industrial IoT platforms and container services in production with Kubernetes, as well as developing microservices.",
      "publishedAt": "2025-02-08T21:31:24Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT23M45S",
      "viewCount": 268,
      "likeCount": 4,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/utTqdQpe39A/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/utTqdQpe39A/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/utTqdQpe39A/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/utTqdQpe39A/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/utTqdQpe39A/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=utTqdQpe39A"
    },
    {
      "id": "z_Xh2MzqKDM",
      "title": "[Full Workshop] Llama 3 at 1,000 tok/s on the SambaNova AI Platform",
      "description": "In this workshop, you will learn how to build LLM-based apps, such as a question-answering system with RAG, in LangChain using Llama-3 at 1,000 tokens per second on the SambaNova AI Platform.\n\nLevel: Intermediate\n\nAbstract: SambaNova delivers generative AI capabilities to the enterprise. In this workshop, you will learn:\n\n● About SambaNova’s full-stack generative AI platform, powered by the SN40L AI chip and delivering unparalleled performance for training and inference\n\n● Samba-1, a trillion parameter composition of experts (CoE) model, and how it can be used for enterprise settings\n\n● How to build and deploy a question-answering app end-to-end with retrieval augmented generation (RAG) for enterprise search using the following suite: LangChain as framework, Unstructured for pre-processing text documents, E5-large-v2 embedding, ChromaDB vector store, and Llama-3-8B-Instruct running at speed record of 1,000 tokens per second via SambaNova.\n\nThis workshop is designed for tech professionals, engineers, and anyone interested in enterprise generative AI applications.\n\nPrerequisites: Experience programming, ideally in Python, a Github account, and laptop\n\nAssets: We will provide a link to the Github repo with step-by-step instructions on how to install the required libraries and how to run the Jupyter notebooks and Streamlit apps. We will also provide SambaNova API keys for the CoE and Llama-3 endpoints.\n\nGitHub Repo: https://github.com/sambanova/ai-starter-kit/tree/main/workshops/ai_engineer_2024/ Dev Setup for Exercise 1: https://github.com/sambanova/ai-starter-kit/blob/main/workshops/ai_engineer_2024/basic_examples/README.md Dev Setup for Exercise 2: https://github.com/sambanova/ai-starter-kit/blob/main/workshops/ai_engineer_2024/ekr_rag/README.md",
      "publishedAt": "2025-02-07T20:30:30Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H58S",
      "viewCount": 764,
      "likeCount": 20,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/z_Xh2MzqKDM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/z_Xh2MzqKDM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/z_Xh2MzqKDM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/z_Xh2MzqKDM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/z_Xh2MzqKDM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=z_Xh2MzqKDM"
    },
    {
      "id": "sKiTUuEV1rw",
      "title": "[Full Workshop from Microsoft] Github Copilot - The World's Most Widely Adopted AI Developer Tool",
      "description": "GitHub Copilot was introduced as “Your AI pair programmer” in January of 2021. Since then, we have been adding more and more capabilities to increase developer productivity and happiness. We’ve gone from simply leveraging AI to generate code to explaining existing code, generating unit tests, propose fixes for bugs, making code robust / secure, summarizing pull requests, having conversations tailored to your organization’s repositories, providing answers to your questions based on your organization’s knowledge base and so much more! Let's explore how to get started with GitHub Copilot, its ever growing list of capabilities, and how to make the most out of the tool.\n\nAs long as you have a web browser that can access public repositories on GitHub.com then you have all you need. To interact with GitHub Copilot we will be using GitHub Codespaces which you can connect to via a web browser.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Dave\nDave is a Senior DevOps Advocate on the GitHub & Azure DevOps Teams. He is very passionate about DevOps and application modernization. He is a link between the product group and customers. Dave has worked in the software development industry his entire career. Having worked for both startups and large companies, his strength is his view and knowledge of the overall software development lifecycle paired with technical skills which allow him to manage DevOps culture, processes & tools that enable software development teams to become as innovative, efficient and productive as possible.\n\nAbout Alex\nGlobal Engagement Lead, GitHub for Startups - ex-Amazon, ex-Army, and Founder of planeAhead\n\nA first generation Haitian, Alex grew up in the with 3 siblings outside of Chicago as someone who always wanted to create a legacy for his family; past, present and future. He joined the Army as a Intelligence soldier right out of high school and after serving several years he finished his college degree and started his career in tech. 5 years at Amazon and Amazon Web Services, globally, and a couple of other tech stops later, he built his first company, PlaneAhead. In addition to his work at PlaneAhead, he works with GitHub to grow their startup program and does work as a mental health advocate.\n\nAbout Christina\nChristina Warren is a Senior Developer Advocate at GitHub, where she works to make GitHub the best place for developers of all types and experience levels, with tools like Codespaces, GitHub Copilot and GitHub Actions. Before joining GitHub, Christina was a Developer Advocate at Microsoft, where she focused on Linux and open source communities, giving talks, and making video content.\n\nBefore moving into engineering, Christina spent a decade in digital media as an editor, senior reporter, and commentator, with a focus on technology, business, and entertainment. As a journalist, she appeared as an expert or commentator on ABC, NBC, CBS, CNN, CNBC, Fox News, Fox Business, Bloomberg, the BBC, Marketplace Radio, The Today Show, Good Morning America, and many more outlets.\n\nAbout Harald\nExperienced leader in technical product management and strategy. 20 year track record in data analytics, customer-centric development, AI, software engineering, design, and open source. Skillfully connects the dots between stakeholders, customer needs & wants and technology into a comprehensive product vision.",
      "publishedAt": "2025-02-07T20:28:55Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H19M45S",
      "viewCount": 546,
      "likeCount": 10,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/sKiTUuEV1rw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/sKiTUuEV1rw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/sKiTUuEV1rw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/sKiTUuEV1rw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/sKiTUuEV1rw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=sKiTUuEV1rw"
    },
    {
      "id": "k0VIgKAUkP4",
      "title": "[Full Workshop] How to add secure code interpreting in your AI app: Vasek Mlejnsky",
      "description": "In this workshop, I'll show you how to add secure AI code execution that supports any LLM in your AI app using E2B. AI-powered code execution improves reasoning of LLMs and allows you to build AI-based dashboards where users can chat with their data, generative UI, or coding agents like Devin.\n\nWe'll be using a prepared repository with Next.js app from E2B's cookbook: https://github.com/e2b-dev/e2b-cookbook/tree/main/examples/anthropic-power-artifacts\n\nTech stack:\n\nAnthropic's Sonnet 3.5 (get your API key here - https://console.anthropic.com/)\nE2B's Code Interpreter SDK (get your API key here - https://e2b.dev/docs/getting-started/api-key)\nNext.js\nVercel's AI SDK\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Vasek\nVasek is building cloud for AI agents. He is the CEO of E2B.dev, a 100% open-source cloud runtime for AI agents, that he co-founded with his high-school friend Tom. They have been building dev tools together before. E2B has customers from various fields, from bioinformatics, through programming and data analysis, to a big American sport organization. Vasek has always been a big fan of startups - when he needs recharge he rewatches an episode of Silicon Valley Series. He is excited about any new dev tool, and he also relaxes running or playing tennis.",
      "publishedAt": "2025-02-06T21:56:42Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H48M16S",
      "viewCount": 1081,
      "likeCount": 26,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/k0VIgKAUkP4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/k0VIgKAUkP4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/k0VIgKAUkP4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/k0VIgKAUkP4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/k0VIgKAUkP4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=k0VIgKAUkP4"
    },
    {
      "id": "uhoPM-ABuV0",
      "title": "GitHub Copilot: The World's Most Widely Adopted AI Developer Tool",
      "description": "GitHub Copilot was introduced as “Your AI pair programmer” in January of 2021. Since then, we have been adding more and more capabilities to increase developer productivity and happiness. We’ve gone from simply leveraging AI to generate code to explaining existing code, generating unit tests, propose fixes for bugs, making code robust / secure, summarizing pull requests, having conversations tailored to your organization’s repositories, providing answers to your questions based on your organization’s knowledge base and so much more! Let's explore how to get started with GitHub Copilot, its ever growing list of capabilities, and how to make the most out of the tool.\n\nAs long as you have a web browser that can access public repositories on GitHub.com then you have all you need. To interact with GitHub Copilot we will be using GitHub Codespaces which you can connect to via a web browser.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\\\n\nAbout Dave\nDave is a Senior DevOps Advocate on the GitHub & Azure DevOps Teams. He is very passionate about DevOps and application modernization. He is a link between the product group and customers. Dave has worked in the software development industry his entire career. Having worked for both startups and large companies, his strength is his view and knowledge of the overall software development lifecycle paired with technical skills which allow him to manage DevOps culture, processes & tools that enable software development teams to become as innovative, efficient and productive as possible.",
      "publishedAt": "2025-02-06T09:24:03Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT29M49S",
      "viewCount": 1942,
      "likeCount": 8,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/uhoPM-ABuV0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/uhoPM-ABuV0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/uhoPM-ABuV0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/uhoPM-ABuV0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/uhoPM-ABuV0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=uhoPM-ABuV0"
    },
    {
      "id": "x8HbIJh2wpQ",
      "title": "Substrate Launch: the API for modular AI",
      "description": "AI models enable some new and powerful capabilities, but we still need to think of them as functions in larger logical systems, rather than a sort of end-state for software. AI-integrated programs should be built just like any other program: by relating small semantic tasks to each other in order to automate a larger task. Right now, the main problem preventing developers from running 10-20 AI modules on a single user request is an infrastructure one, and that’s what we’re solving. Large companies like Google have built internal infrastructure and SDKs to enable this, but we’re offering this capability to any developer.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Rob\nRob Cheung (Co-Founder, CEO) was the founding engineer at Fin.com, a 2015 AI agent intermediated by a human-in-the-loop workforce. After Fin pivoted away from AI, he became the founding engineer at Substack, and for the last two years has been experimenting with the ideas that have become Substrate.",
      "publishedAt": "2025-02-06T09:24:03Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M20S",
      "viewCount": 416,
      "likeCount": 7,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/x8HbIJh2wpQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/x8HbIJh2wpQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/x8HbIJh2wpQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/x8HbIJh2wpQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/x8HbIJh2wpQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=x8HbIJh2wpQ"
    },
    {
      "id": "T60Tj25J4Zw",
      "title": "Build, Evaluate and Deploy a RAG-Based Retail Copilot with Azure AI: Cedric Vidal and David Smith",
      "description": "Building generative AI applications for production requires a paradigm shift to LLM Ops, with new tools, platforms and processes for orchestrating end-to-end development workflows. In this session, you’ll learn to build, evaluate and deploy an enterprise copilot application end-to-end, using a code-first approach with Azure AI Studio and Prompt flow. From ideating your scenario with your data, to evaluating it for quality locally and on Azure, then deploying it for real-world usage.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Cedric\nCedric Vidal is a Principal AI Advocate at Microsoft, specializing in Generative AI , and the startup and research ecosystems. He is dedicated to promoting AI in startups and facilitating the transition of research and startup products to the market. Before his current role, Cedric spent 4 years as an Engineering Manager in the AI data labeling space for the self-driving industry at Argo AI (now re-spawned as Latitude AI). He also served as the CTO of the Fintech AI SAAS startup Quicksign and worked as a software engineering services consultant for major Fintech enterprises for 10 years.\n\nAbout David\nDavid has extensive product management and developer relations experience, focused on bridging the gap between technical experts and the stakeholders who rely on their expertise. He has a proven track record of growing and nurturing diverse user communities, and building products to serve their needs, in a range of companies from startups to Big Tech.\n \nWith a background in Data Science, David has over 20 years of experience in the applications of Artificial Intelligence and Machine Learning to industries as diverse as pharmaceutical research, financial analysis, manufacturing and healthcare IT. He is also an experienced speaker and presenter, and an early contributor to the open-source R project.\n \nAfter leaving his homeland of Australia for the UK to study for a PhD in Statistics, David joined Insightful Corporation in 1998. As the Director of Product Management in the Seattle headquarters, David oversaw several major software releases leading to its acquisition by TIBCO. From 2006 to 2008, David was the VP of Product Management at startup Zynchros, the pioneering provider of hosted formulary management software for health insurers and pharmacy benefit managers, until its acquisition by SXC Health Solutions. At Revolution Analytics from 2008 to 2015, David dramatically grew the worldwide community of R users and the enterprise market for open source data analysis software, leading to a successful acquisition by Microsoft in 2015.\n \nDavid remained at Microsoft post-acquisition, where he has held roles in program management and developer relations, and is currently a Principal Cloud Advocate leading the AI and Machine Learning team in Developer Relations. He is Microsoft’s representative to the board of the non-profit R Consortium. \n \nDavid holds an Australian passport and a US Green Card, lives in the San Francisco Bay Area with his husband of nearly 20 years, and speaks English and French.",
      "publishedAt": "2025-02-06T09:24:02Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H57M58S",
      "viewCount": 542,
      "likeCount": 13,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/T60Tj25J4Zw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/T60Tj25J4Zw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/T60Tj25J4Zw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/T60Tj25J4Zw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/T60Tj25J4Zw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=T60Tj25J4Zw"
    },
    {
      "id": "8RbTZl7bs5U",
      "title": "EyeLevel Launch: Your RAG is Tripping, Here's the Real Reason Why",
      "description": "95% of RAG hallucinations are generated by the RAG, not the LLM. But why? In this talk, we'll discuss the hard data engineering problems of building highly accurate RAG systems and how to fix them. You'll see how companies like Air France are getting 95% accuracy or better.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Benjamin\nOver a two decade career, Ben has designed CMOS chips for quantum computing, developed VPN architectures for mobile and pioneered consumer AI at IBM Watson and Weather Channel. He has 21 patents and a PhD in physics. In 2019, he launched EyeLevel.ai to help connect the world’s private data to LLMs.",
      "publishedAt": "2025-02-06T09:24:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT6M13S",
      "viewCount": 735,
      "likeCount": 26,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/8RbTZl7bs5U/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/8RbTZl7bs5U/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/8RbTZl7bs5U/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/8RbTZl7bs5U/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/8RbTZl7bs5U/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=8RbTZl7bs5U"
    },
    {
      "id": "Ju9PeKEKb24",
      "title": "Ionic Launch: Opening the economy to AI agents",
      "description": "Ionic Commerce is on a mission to integrate AI agents into the economy, starting with ecommerce. We have created a connective tissue between commerce and large language models designed specifically for agents which allows agents to navigate the digital world effectively and execute complex transactions without navigating UX/UI designed for humans. We are further enhancing the data layer to support decision-making and bringing the transaction layer into the decision process. Ionic Commerce is laying the foundation for AI agents to seamlessly participate in the economy.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Justin\nJustin is the CEO and cofounder of Ionic Commerce which is on a mission to open the economy to AI agents, starting with ecommerce. Previously, Justin was President and cofounder of Bungalow, the largest coliving marketplace in the US. Prior to cofounding Bungalow, Justin led business operations teams at Uber, did a finance stint at Goldman Sachs, and served overseas with the US Army.",
      "publishedAt": "2025-02-06T09:24:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M30S",
      "viewCount": 280,
      "likeCount": 0,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Ju9PeKEKb24/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Ju9PeKEKb24/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Ju9PeKEKb24/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Ju9PeKEKb24/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Ju9PeKEKb24/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Ju9PeKEKb24"
    },
    {
      "id": "NjNEdjDvKu8",
      "title": "Creating and scaling your own custom copilots with Azure AI Studio: Hanchi Wang",
      "description": "Custom copilots are evolving from simple LLM+data retrieval augmented generation (RAG) solutions into more complex solutions with multiple interoperating APIs, models, metaprompts and grounding data. In this session, we’ll talk about these emerging patterns and show how Azure AI Studio and Promptflow empowers developers to build multi-agent copilot solutions. Discover advanced features such as debugging tools and security measures for developing intelligent, scalable, and safe AI solutions\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Hanchi\nHanchi is a seasoned engineer and engineering manager with extensive experience in AI, machine learning, and large-scale data processing. He is currently focused on developing innovative AI tools that empower engineers to efficiently build, evaluate, deploy, and monitor their AI applications.",
      "publishedAt": "2025-02-06T09:24:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT24M21S",
      "viewCount": 260,
      "likeCount": 2,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/NjNEdjDvKu8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/NjNEdjDvKu8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/NjNEdjDvKu8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/NjNEdjDvKu8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/NjNEdjDvKu8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=NjNEdjDvKu8"
    },
    {
      "id": "R3hTescenDw",
      "title": "Which Jobs Can Be Replaced Today:  Fryderyk Wiatrowski and Peter Albert",
      "description": "The founders of Zeta Labs will provide an update on the progress in autonomous agent development, discussing its alignment with the timeline for replacing humans in their current jobs. Additionally, they will highlight how these agents represent a crucial milestone towards achieving Artificial General Intelligence (AGI)\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Fryderyk \nCo-founder of Zeta Labs, focusing on developing autonomous AI agents. Previously worked at Meta and in high-frequency trading (HFT). Graduated with a degree in Mathematics and Computer Science from Oxford University.\n\nAbout Peter\nCo-Founder of Zeta Labs, Previously co-creator of Llama 2 at MetaAI, successful e-commerce entrepreneur.",
      "publishedAt": "2025-02-06T09:24:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M59S",
      "viewCount": 856,
      "likeCount": 17,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/R3hTescenDw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/R3hTescenDw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/R3hTescenDw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/R3hTescenDw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/R3hTescenDw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=R3hTescenDw"
    },
    {
      "id": "YcOrV-TLNyQ",
      "title": "Multi model multimodal and multi agent innovations in Azure AI: Cedric Vidal",
      "description": "Explore GPT-4, multi-modality, and demos integrating sight and language with Dall-E and Whisper. Learn about developer tools, AI assistants, scalable applications, and customization. Focus on responsible AI, data privacy, and security with Azure. Featuring interactive demos and stories, this session is perfect for developers and innovators.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Cedric\nCedric Vidal is a Principal AI Advocate at Microsoft, specializing in Generative AI , and the startup and research ecosystems. He is dedicated to promoting AI in startups and facilitating the transition of research and startup products to the market. Before his current role, Cedric spent 4 years as an Engineering Manager in the AI data labeling space for the self-driving industry at Argo AI (now re-spawned as Latitude AI). He also served as the CTO of the Fintech AI SAAS startup Quicksign and worked as a software engineering services consultant for major Fintech enterprises for 10 years.",
      "publishedAt": "2025-02-06T09:24:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT28M56S",
      "viewCount": 379,
      "likeCount": 3,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/YcOrV-TLNyQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/YcOrV-TLNyQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/YcOrV-TLNyQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/YcOrV-TLNyQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/YcOrV-TLNyQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=YcOrV-TLNyQ"
    },
    {
      "id": "a0WvaMRZ9hc",
      "title": "AI Templates: Gabriela and Aishwarya",
      "description": "Building and deploying generative AI solutions can be challenging and time-consuming, especially for startups with limited resources and expertise. In this workshop, you will learn how to use AI templates and GitHub to quickly prototype and deploy generative AI applications in minutes. AI templates are ready-made solutions that leverage Microsoft Azure Services like Azure OpenAI and GitHub features like GitHub Codespaces.\n\nhttps://aka.ms/aie-workshop\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Gabriela\n15+ years of experience in the data space, Gabriela has worked in research and in several startups from different industries, including Software, Financial, Advertisement, and Health. Throughout her career, she has built diverse teams, created sophisticated data science solutions, engaged with customers and stakeholders to deliver business insights and drive data-centric decisions. She is passionate about building innovative solutions, understanding business gaps, and customer needs, and delivering a flawless experience.\n\nAbout Aishwarya\nAishwarya works in the Microsoft for Startups group within Microsoft as a Senior AI Advocate to help startups build machine learning solutions, leveraging core Microsoft/OpenAI products. Prior to this, Aishwarya was working as a Data Scientist in Google Cloud and before that an AI & ML Innovation Leader at IBM Data & AI, where she was working cross-functionally with the product team, data science team and sales to research AI use-cases for clients by conducting discovery workshops and building assets to showcase the business value of the technology. She is the founder of Illuminate AI, first of its kind non-profit organization for providing resources and mentorship for people who want to build their career in the field of AI. She is an advocate for open-source technologies, presently an open source Developer Advocate for Deepchecks; previously a developer advocate for PyTorch Lightning and a contributor to Scikit Learn.",
      "publishedAt": "2025-02-06T09:24:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H3M20S",
      "viewCount": 267,
      "likeCount": 3,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/a0WvaMRZ9hc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/a0WvaMRZ9hc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/a0WvaMRZ9hc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/a0WvaMRZ9hc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/a0WvaMRZ9hc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=a0WvaMRZ9hc"
    },
    {
      "id": "gL9kfxt6uo0",
      "title": "Accelerate your AI journey with Azure AI model catalog: Sharmila Chokalingam",
      "description": "Learn how the Azure AI model catalog helps you discover and operationalize flagship LLMs and SLMs on Azure and unlocks access to a wide collection of models with enterprise data privacy, content safety compliance, and security built in. Experience live demos of deploying popular LLMs like Mistral, Phi3 & Llama3 and finally, take a deep dive into how the model catalog has enabled organizations to drive innovation, efficiency, and strategic decision-making with real-world examples.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Sharmila:\nExperienced Product Marketing Manager with a good understanding of both hardware and software marketplace and a demonstrated history of working in cutting edge AI technology that spans across Simulation, Industrial Metaverse, IOT, Digital Twins and Gaming. Currently working on AzureML team to bring all the latest and greatest LLMs to the Azure AI ecosystem. Skilled in Go-to-market Strategy, messaging and positioning, Demand gen and growth marketing strategies",
      "publishedAt": "2025-02-06T09:24:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT23M14S",
      "viewCount": 191,
      "likeCount": 3,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/gL9kfxt6uo0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/gL9kfxt6uo0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/gL9kfxt6uo0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/gL9kfxt6uo0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/gL9kfxt6uo0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=gL9kfxt6uo0"
    },
    {
      "id": "nbZzSC5A6hs",
      "title": "Lessons from the Trenches: Building LLM Evals That Work IRL: Aparna Dhinkaran",
      "description": "With nearly two-thirds of enterprise developers planning production deployments of large language models this year, LLM evaluation has never been more important. LLM evaluation is also an area where confusion reigns, starting with ambiguity around what “LLM evals” even means. Often, LLM model evaluation – quantifying general fitness (i.e. on the Hugging Face leaderboard) – is conflated with task-specific LLM system evaluation. And while many foundation model providers offer their own evals, AI engineers building LLM systems designed to plug into many models or tools need a way to objectively evaluate both different foundation models and their own systems with rigorous techniques. In this session, Arize AI founder Aparna Dhinakaran will release research onstage and walk attendees through real life examples of building an LLM Eval from scratch. This session will build on multiple research pieces that have garnered millions of views across social platforms, diving into techniques to build out robust LLM evals and ultimately gain a better understanding of the limits of LLM capabilities. Want to build your own LLM task evals for a specific use case leveraging open source tools? Want to see the latest research on which foundation models your company should be using for specific use cases? You won’t want to miss this session!\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Aparna\nAparna Dhinakaran is the Co-Founder and Chief Product Officer at Arize AI, a pioneer and early leader in AI observability and LLM evaluation. A frequent speaker at top conferences and thought leader in the space, Dhinakaran is a Forbes 30 Under 30 honoree. Before Arize, Dhinakaran was an ML engineer and leader at Uber, Apple, and TubeMogul (acquired by Adobe). During her time at Uber, she built several core ML Infrastructure platforms, including Michelangelo. She has a bachelor’s from Berkeley's Electrical Engineering and Computer Science program, where she published research with Berkeley's AI Research group. She is on a leave of absence from the Computer Vision Ph.D. program at Cornell University.",
      "publishedAt": "2025-02-06T09:24:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M49S",
      "viewCount": 4513,
      "likeCount": 118,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/nbZzSC5A6hs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/nbZzSC5A6hs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/nbZzSC5A6hs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/nbZzSC5A6hs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/nbZzSC5A6hs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=nbZzSC5A6hs"
    },
    {
      "id": "7AYUCAuFYeA",
      "title": "Prompt Engineering Tactics: Dan Cleary",
      "description": "Everything is going well until a prompt that works most of the time, goes off the rails. Does this sound familiar?\nThe inherent fragility and non-deterministic nature of prompts can be challenging, often leading to inconsistent outputs.\n\nIn this session, I'll dive into advanced prompting techniques that are grounded in research and empirical evidence. We'll explore how to tailor methods to specific tasks and how these strategies can significantly enhance output consistency and quality. \n\nRecorded & streamed live for the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Dan\nI'm the co-founder of PromptHub, a platform that makes it easy to iterate, test, and manage prompts. I'm a runner, basketball junkie, and Hubermanlab listener.",
      "publishedAt": "2025-02-05T11:18:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M12S",
      "viewCount": 1277,
      "likeCount": 30,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/7AYUCAuFYeA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/7AYUCAuFYeA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/7AYUCAuFYeA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/7AYUCAuFYeA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/7AYUCAuFYeA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=7AYUCAuFYeA"
    },
    {
      "id": "LksXn4CLC0g",
      "title": "No-code fine-tuning: Mark Hennings",
      "description": "I will explain what fine-tuning is, why it's the next practical step to take from prompt engineering, its benefits for production deployments, and how modern AI Engineers can now do it with zero code.\n\nRecorded & streamed live for the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Mark\nCreator of Simple Booth, bootstrapped to 7 figures revenue and #414 on Inc 500 in 2018.  Now building in AI.",
      "publishedAt": "2025-02-05T11:18:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT9M27S",
      "viewCount": 496,
      "likeCount": 11,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/LksXn4CLC0g/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/LksXn4CLC0g/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/LksXn4CLC0g/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/LksXn4CLC0g/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/LksXn4CLC0g/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=LksXn4CLC0g"
    },
    {
      "id": "PNjMwdCo_YM",
      "title": "BotDojo Launch: Enhancing AI Assistants with Evaluations and Synthetic Data",
      "description": "So you've built an AI assistant, but how do you gain the confidence to deploy it to production? In this live demo we introduce BotDojo, a platform that helps you build and improve LLM applications. We'll demonstrate how it identifies gaps in your assistant's knowledge through targeted evaluations. Then, we'll show how to generate synthetic data from existing documentation and support interactions to improve performance.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Paul\nPaul Henry is the Founder and CEO of BotDojo, an AI enablement platform that assists companies in designing and deploying Large Language Model (LLM) applications. Prior to founding BotDojo, Paul served as the CTO of Auctane, where he led the Engineering team and contributed to the company's growth from 10 to 2,000 employees. During his tenure, he helped develop a logistics platform that now processes over three billion orders annually for more than a million customers, powering products such as ShipStation, ShipEngine, and Stamps.com.\n\nAt BotDojo, Paul draws upon his experience to address the challenges associated with reliably deploying LLM applications to enhance internal operations and customer support. The platform supports the entire lifecycle of AI application development, from design and evaluation to deployment, allowing companies to deploy AI solutions with confidence.",
      "publishedAt": "2025-02-05T11:18:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M47S",
      "viewCount": 572,
      "likeCount": 9,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/PNjMwdCo_YM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/PNjMwdCo_YM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/PNjMwdCo_YM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/PNjMwdCo_YM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/PNjMwdCo_YM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=PNjMwdCo_YM"
    },
    {
      "id": "fiXjTif1nS4",
      "title": "Best Practices for Evaluating Large Language Model Applications with llmeval: Niklas Nielsen",
      "description": "Recorded & streamed live for the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Niklas Nielsen\nNik was most recently Head of Product at MosaicML (acq. Databricks for $1.3B). Prior to that he worked at Intel and Mesosphere on building Distributed Systems, and at Adobe on the Virtual Machines and Compilers team. He co-founded CustomerDB, a startup applying AI to product management.",
      "publishedAt": "2025-02-05T11:18:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT9M33S",
      "viewCount": 425,
      "likeCount": 2,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/fiXjTif1nS4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/fiXjTif1nS4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/fiXjTif1nS4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/fiXjTif1nS4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/fiXjTif1nS4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=fiXjTif1nS4"
    },
    {
      "id": "pijYURicI1Y",
      "title": "Building efficient hybrid context query for LLM grounding: Simrat Hanspal",
      "description": "Natural language queries have opened new doors for improving customer experiences. But not all queries can be issued directly on LLMs. Many require supporting context for LLM grounding.\nFetching relevant context can range from simple to complex. Let us understand this with an example of e-commerce. \n\n1. Simple - Semantically similar text from vector db \nEx: vibrant red with glitter and versatile for travel\n2. Slightly complex - Semantically similar text from vector db, which belongs to an entity \nEx: vibrant red shoes with glitter and versatile for travel\n3. Highly complex - Semantically similar text from vector db, which belongs to an entity with structured filters\n(vibrant red shoes with glitter and versatile for travel within the price range of $500-1000)\n\nHandling such queries would require mapping of vector data to existing data models. Highly complex queries would also require issuing multiple queries to relational and vector db. Finally, the results would be put together with intersection operation.\nThis small engineering effort explodes into the project of its own very soon with more data sources. What a mess! \n\nIn this talk, I will be explaining how Hasura's GraphQL API provides an efficient solution to multi-source queries for GenAI applications.\n\nRecorded & streamed live for the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Simrat\nData Scientist with a curious engineering mind. Currently working as Technical Evangelist at Hasura. Helping the community build better data products with Hasura.\nPrior to Hasura, worked for 12+ years as an Applied Data scientist building intelligent products and solutions ground up.",
      "publishedAt": "2025-02-05T11:18:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT11M35S",
      "viewCount": 251,
      "likeCount": 4,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/pijYURicI1Y/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/pijYURicI1Y/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/pijYURicI1Y/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/pijYURicI1Y/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/pijYURicI1Y/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=pijYURicI1Y"
    },
    {
      "id": "pj_hKFhnJCw",
      "title": "How to evaluate a model for your use case: Emmanuel Turlay",
      "description": "Fine-tuning LLMs requires a lot of resources, both memory and GPU, which are notoriously costly. In this talk, I will describe five ways to minimize resource usage, and to find the cheapest resources out there to fine-tune LLMs with a tight budget.\n\nRecorded & streamed live for the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Emmanuel\nI started my career in academia 15 years ago doing particle physics research at CERN. I moved to the US in 2014 and joined Instacart as a Sr. Software Engineer. I lead teams around payments, orders, and MLOps. In 2018 I joined Cruise, where I started the ML Infrastructure team which grew to about 80 engineers. In 2022, I founded Sematic, an open-source ML Infrastructure company.",
      "publishedAt": "2025-02-05T11:18:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7M32S",
      "viewCount": 209,
      "likeCount": 6,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/pj_hKFhnJCw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/pj_hKFhnJCw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/pj_hKFhnJCw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/pj_hKFhnJCw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/pj_hKFhnJCw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=pj_hKFhnJCw"
    },
    {
      "id": "wWRRs2zBr5I",
      "title": "The Rise of the AI Software Engineer: Jesse Han",
      "description": "Programming was once called \"automatic programming\". One day, we'll think about how engineering was once called \"AI engineering\". Along the way, we will command legions of AI software engineers that adapt, evolve, and know our codebases better than we do. I will unveil what we have been working on at Morph Labs to take us into that future.\n\nRecorded & streamed live for the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Jesse\nJesse Han is the CEO and founder of Morph Labs, which is building open-source infrastructure for the personal AI software engineer. He holds a PhD in mathematics and previously worked at OpenAI on theorem proving, synthetic data, and GPT-4.",
      "publishedAt": "2025-02-05T11:18:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT3M48S",
      "viewCount": 1238,
      "likeCount": 42,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/wWRRs2zBr5I/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/wWRRs2zBr5I/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/wWRRs2zBr5I/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/wWRRs2zBr5I/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/wWRRs2zBr5I/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=wWRRs2zBr5I"
    },
    {
      "id": "3E7VAZaTG9M",
      "title": "Scaling AI in Education: A Khanmigo case study: Shawn Jansepar",
      "description": "In this presentation, I will explore Khan Academy's journey to become an AI-first organization, focusing on our AI Tutor and Teacher Assistant, Khanmigo. This case study will cover the strategic evolution from conception, through to launch, and continuous iteration and refinement.\n\nKey Highlights:\n\nStrategic partnership: The collaboration with OpenAI to launch Khanmigo alongside GPT4, going from prototype to fully launched product in 3 months time. I will delve into the why and how behind our decision to partner with OpenAI, and to leverage generative AI in our product.\n\nCultural shift in product development: The transition from our previous, more traditional product development approach to a highly experimental, prototype-driven culture. This section will highlight how we embedded AI across all teams to enhance our mission, moving beyond isolated AI projects to fully integrate AI into our operational fabric.\n\nKhanmigo in action: An in-depth look at Khanmigo's functionality and its solution to real-world challenges faced by students and teachers, coupled with it's impact in real classrooms around the US.\n\nOngoing technical challenges and scaling: An overview of the technical obstacles encountered in scaling and maintaining quality as we continued to add more users.\n\nEthical considerations and AI safety: How we thought of AI safety in the context of the classroom, and delivered on an experience that parents and educators trust.\n\nPilot programs and iterative learning: Insights from our pilot programs across various school districts, focusing on how we've used feedback and data to refine and enhance Khanmigo's capabilities.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Shawn\nShawn Jansepar is Director of Engineering at Khan Academy and product leader of the Khanmigo Platform. Prior to joining Khan Academy, Shawn led Engineering at Mobify in Vancouver, growing it from a small startup to a large team which was eventually acquired by Salesforce. He holds a Bachelor of Science degree in Computer Science from Simon Fraser University.",
      "publishedAt": "2025-02-05T02:56:08Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT22M39S",
      "viewCount": 1867,
      "likeCount": 67,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/3E7VAZaTG9M/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/3E7VAZaTG9M/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/3E7VAZaTG9M/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/3E7VAZaTG9M/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/3E7VAZaTG9M/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=3E7VAZaTG9M"
    },
    {
      "id": "u3NofYYstaY",
      "title": "Cohere for VPs of AI: Vivek Muppalla",
      "description": "Executive briefing and private Q&A for VPs of AI\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/20... & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Vivek\nVivek Raju Muppalla has a diverse work experience in the technology industry. Vivek Raju is currently serving as the Director of Engineering at Cohere, a position they have held since 2023. Prior to that, from 2022 to 2023, they worked as a Director at Scale AI, where they were responsible for starting the company's Synthetic Data Business and focused on the Scale Enterprise Generative AI platform.",
      "publishedAt": "2025-02-05T02:47:56Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M11S",
      "viewCount": 454,
      "likeCount": 8,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/u3NofYYstaY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/u3NofYYstaY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/u3NofYYstaY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/u3NofYYstaY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/u3NofYYstaY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=u3NofYYstaY"
    },
    {
      "id": "9tvJ_GYJA-o",
      "title": "Mastering LLM Inference Optimization From Theory to Cost Effective Deployment: Mark Moyou",
      "description": "LLM inference is not your normal deep learning model deployment nor is it trivial when it comes to managing scale, performance and COST. Understanding how to effectively size a production grade LLM deployment requires understanding of the model(s), the compute hardware, quantization and parallelization methods, KV Cache budgets, input and output token length predictions, model adapter management and much more.\n\nIf you want to deeply understand these topics and their effects on LLM inference cost and performance you will enjoy this talk.\n\nThis talk will cover the following topics:\n\nWhy LLM inference is different to standard deep learning inference\nCurrent and future NVIDIA GPU overview - which GPU(s) for which models and why\nUnderstanding the importance of building inference engines\nDeep recap on the attention mechanism along with different types of popular attention mechanisms used in production\nDeep dive on KV Cache and managing KV Cache budgets to increase throughput per model deployment\nParallelism (reducing latency) - mainly tensor parallelism but data, sequence, pipeline and expert parallelism will be highlighted\nQuantization methods on weights, activations, KV Cache to reduce engine sizes for more effective GPU utilization\nIncreasing throughput with inflight batching and other techniques\nDetailed performance analysis of LLM deployments looking at Time to first token, inter-token latencies, llm deployment characterizations, and more that can help reduce deployment costs\nThe main inference engine referenced in the talk with TRT-LLM and the open-source inference serve NVIDIA Triton.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Mark\nDr. Mark Moyou is a Senior Data Scientist at NVIDIA on the Retail team focused on enabling scalable machine learning for the nation's top Retailers. Before NVIDIA, he was a Data Science Manager in the Professional Services division at Lucidworks, an Enterprise Search and Recommendations company. Prior to Lucidworks, he was a founding Data Scientist at Alstom Transportation where he applied Data Science to the Railroad Industry in the US. Mark holds a PhD and MSc in Systems Engineering and a BSc in Chemical Engineering. On the side, Mark is the host of The AI Portfolio Podcast, The Caribbean Tech Pioneers, Progress Guaranteed Podcast and Director of the Southern Data Science Conference in Atlanta.",
      "publishedAt": "2025-01-01T17:37:56Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT33M39S",
      "viewCount": 17864,
      "likeCount": 559,
      "commentCount": 12,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/9tvJ_GYJA-o/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/9tvJ_GYJA-o/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/9tvJ_GYJA-o/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/9tvJ_GYJA-o/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/9tvJ_GYJA-o/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=9tvJ_GYJA-o"
    },
    {
      "id": "IbJ40EwaNlM",
      "title": "Navigating Challenges and Technical Debt in LLMs Deployment: Ahmed Menshawy",
      "description": "Large Language Models (LLMs) have become essential in advancing AI, enabling remarkable capabilities in natural language processing and understanding. However, the efficient deployment of LLMs in production environments reveals a landscape of challenges and technical debt.\n\nEthically, LLMs face issues such as bias amplification, where they might perpetuate existing stereotypes in their outputs. Misinformation is another concern, with the potential misuse of LLMs to create convincing yet false narratives. Privacy risks emerge from LLMs possibly memorizing and revealing personal data. Moreover, societal challenges include the impact on employment, as LLMs could automate tasks but also lead to job displacement. These challenges highlight the need for careful management and ethical considerations in the deployment of LLMs.\n\nIn this talk, Ahmed will highlight the key challenges and technical debt associated with LLMs' deployment, which demands customization and sophisticated engineering solutions not readily available in broad-use machine learning libraries or inference engines.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Ahmed\nAhmed Menshawy is the Vice President of AI Engineering at Mastercard's Cyber and Intelligence division. In this role, he leads the AI Engineering team, driving the development and operationalization of AI products and addressing the broad range of challenges and technical debts surrounding ML pipelines deployment. Ahmed also leads a team dedicated to creating a number of AI accelerators and capabilities, including Serving engines and Feature stores, aimed at enhancing various aspects of AI engineering.\n\nHe is also the co-author of the famous paper in ACM EuroMLSys, titled \"\"Navigating Challenges and Technical Debt in Large Language Models Deployment,\"\" which mainly focuses on the complexities involved in deploying large language models efficiently.\n\nIn addition, Ahmed is the co-author of \"\"Deep Learning with TensorFlow\"\" and the author of \"\"Deep Learning by Example,\"\" focusing on advanced topics in deep learning. He is also collaborating on an upcoming O'Reilly book, \"\"Graph Learning for the Enterprise,\"\" which aims to guide enterprises in efficiently training and deploying graph learning pipelines at scale.",
      "publishedAt": "2024-12-31T17:33:19Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M15S",
      "viewCount": 1817,
      "likeCount": 52,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/IbJ40EwaNlM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/IbJ40EwaNlM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/IbJ40EwaNlM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/IbJ40EwaNlM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/IbJ40EwaNlM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=IbJ40EwaNlM"
    },
    {
      "id": "jdeMJJ_oNYg",
      "title": "LLM Safeguards: Security Privacy Compliance Anti Hallucination: Daniel Whitenack",
      "description": "Recorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Daniel\nDaniel Whitenack (aka Data Dan) is a Ph.D. trained data scientist and founder of Prediction Guard. He has more than ten years of experience developing and deploying machine learning models at scale, and he has built data teams at two startups and an international NGO with 4000+ staff. Daniel co-hosts the Practical AI podcast, has spoken at conferences around the world (ODSC, Applied Machine Learning Days, O’Reilly AI, QCon AI, GopherCon, KubeCon, and more), and occasionally teaches data science/analytics at Purdue University.",
      "publishedAt": "2024-12-31T17:28:40Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT34M10S",
      "viewCount": 1050,
      "likeCount": 30,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/jdeMJJ_oNYg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/jdeMJJ_oNYg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/jdeMJJ_oNYg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/jdeMJJ_oNYg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/jdeMJJ_oNYg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=jdeMJJ_oNYg"
    },
    {
      "id": "AVjrkXGnF2M",
      "title": "Cooking with fire without burning down the kitchen: Dominik Kundel",
      "description": "Over the last 2 years the capabilities of LLM have been developing at a rapid pace and R&D organizations in almost every industry are expected to determine their \"AI strategy\" while balancing existing non-AI customer needs and a tighter financial environment. For some, recent AI developments might even pose a disruptive shift for their products and company, but how do you balance rapid prototyping and exploration of these disruptive technologies with catering to your current user base to avoid the Innovator's Dilemma? Should you add AI to every product team's roadmap or form a dedicated AI team? How do you experiment with entirely new AI endeavors without risking your current customer base? In other words, how do you cook with fire without burning down the kitchen?\n\nIn this discussion round, Dominik Kundel will share how Twilio has been tackling some of these challenges, their learnings and what changes/iterations they have been going through to address those learnings, followed by an open discussion for others to share their learnings.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Dominik\nDominik leads Product for the Emerging Tech & Innovation organization at Twilio. His team builds next gen prototypes and iterates quickly to help craft the long term product vision and explore the impact of autonomous agents & AGI on customer engagement. Deeply passionate about the Developer Experience, he’s a JavaScript enthusiast who’s integrated it into everything from CLIs to coffee machines. Catch his tweets @dkundel and his side ventures in cocktails, food and photography.",
      "publishedAt": "2024-12-31T17:27:21Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M35S",
      "viewCount": 1422,
      "likeCount": 45,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/AVjrkXGnF2M/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/AVjrkXGnF2M/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/AVjrkXGnF2M/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/AVjrkXGnF2M/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/AVjrkXGnF2M/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=AVjrkXGnF2M"
    },
    {
      "id": "mpzktdYTcdE",
      "title": "E-Values Evaluating the Values of AI: Sheila Gulati and Nischal Nadhamuni",
      "description": "Join us for a thought-provoking session on the future of AI evaluations, led by Sheila Gulati, founder of Tola Capital, and Nischal Nadhamuni, cofounder and CTO of Klarity. We'll delve into the importance of rethinking and innovating evaluations at this pivotal time, highlight the limitations of current methods, and offer practical steps for the AI community. As AI continues to play a significant role in our society, the need to develop the right evaluation tools is more important than ever. Learn how to create smarter, fairer, and more effective AI systems that align with our collective values and societal goals. Sheila will cover the thematic trends of this industry and Nischal will show how his company Klarity applied them as they have grown to serve the largest companies in the world and achieved their recent $70M Series B! This is a unique opportunity to engage with leading experts and shape the future of AI—don't miss out!\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Sheila\nSheila Gulati is the founder and managing director of Tola Capital, a venture capital firm that invests globally in artificial intelligence (AI) and enterprise software. For more than two decades, Sheila has been at the forefront of innovation in software and investing, and her leadership has resulted in some of the most impactful software platform businesses in the world and numerous successful investments and exits across a range of companies.\n\nAt Tola, Sheila combines business acumen with her vision of emerging trends in enterprise software and a sense of partnership and candor to guide forward-thinking founders at every stage – from inception to scaling. Some of her notable portfolio investments include OSISoft (acquired by Schneider), hybris (acquired by SAP), and Clipchamp (acquired by Microsoft).\n\nPrior to founding Tola Capital in 2010, Sheila spent over a decade at Microsoft where, most recently, she led the company’s enterprise IT strategy and launched the company’s cloud platform, Microsoft Azure, now the company’s largest business at $100B in revenue (inclusive of cloud, database, and developer tools). Before that, Sheila had various leadership roles within the Microsoft Developer business unit and spent time on the Corporate Development team where she was responsible for acquisitions and investments. \n\nAbout Nischal\nNischal Nadhamuni is the CTO and Co-Founder of Klarity, a company on a mission to automate document centric workflows. Prior to Klarity, he worked on a AI applications at Airware, Flipkart and Mass General Hospital. \n\nNischal completed his undergrad at the  Massachusetts Institute of Technology. \n\nAfter meeting Harvard Law student, Andrew Antos in an entrepreneurship class at MIT, an idea sparked between the two: automating document review would simplify workflows for millions of workers around the world. In 2017, the two formally launched Klarity.",
      "publishedAt": "2024-12-31T17:25:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT28M13S",
      "viewCount": 619,
      "likeCount": 12,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/mpzktdYTcdE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/mpzktdYTcdE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/mpzktdYTcdE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/mpzktdYTcdE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/mpzktdYTcdE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=mpzktdYTcdE"
    },
    {
      "id": "IxXMKT2FDRk",
      "title": "Hiring & Building an AI Engineering Team: Dr. Bryan Bischof",
      "description": "Recorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Dr. Bryan\nBryan Bischof is the Head of AI at Hex, where he leads the team of engineers building Magic—the data science and analytics copilot. Bryan has worked all over the data stack leading teams in analytics, machine learning engineering, data platform engineering, and AI engineering. He started the data team at Blue Bottle Coffee, led several projects at Stitch Fix, and built the data teams at Weights and Biases. Bryan previously co-authored the book Building Production Recommendation Systems with O’Reilly, and teaches Data Science and Analytics in the graduate school at Rutgers. His Ph.D. is in pure mathematics.",
      "publishedAt": "2024-12-31T17:24:08Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT29M7S",
      "viewCount": 7441,
      "likeCount": 259,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/IxXMKT2FDRk/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/IxXMKT2FDRk/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/IxXMKT2FDRk/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/IxXMKT2FDRk/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/IxXMKT2FDRk/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=IxXMKT2FDRk"
    },
    {
      "id": "KJsUHnwSvTY",
      "title": "RAG for VPs of AI: Jerry Liu",
      "description": "Ask anything about the state of Retrieval Augmented Generation with the CEO of LLamaIndex.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Jerry\nJerry Liu is the CEO & Co-Founder of Llama Index",
      "publishedAt": "2024-12-31T17:23:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT26M51S",
      "viewCount": 5794,
      "likeCount": 116,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/KJsUHnwSvTY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/KJsUHnwSvTY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/KJsUHnwSvTY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/KJsUHnwSvTY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/KJsUHnwSvTY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=KJsUHnwSvTY"
    },
    {
      "id": "5qNXdLbEdew",
      "title": "AI Platform Engineering: Patrick Debois",
      "description": "AI engineers are great, but to scale it out to the organisation you need an AI Platform team.\n\nSimilar to introducing Agile and DevOps companies have pilot projects to release their first genAI features. They would bring in people that have an affinity for both AI and applications together to form the first change agent in a company. Once you have a few teams, you notice that there is shared AI infrastructure, you need enablement and governance across. This pattern has been used to introduce Cloud, Security and Developer Experience.\n\nIn this talk we highlight:\n\nthe shared components of the AI stack: proxies, caching, testing, feedback collection, guardrails, ...\nthe steps (and struggles) to enable this across the whole engineering (hackathons, training, abstractions)\nhow it fits in the existing SDLC workflow and processes (testing , versioning, observability , security)\nhow we can leverage the knowledge of all platform teams together (cloudops, secops , developer experience , data platform and ai platform) for dealing with security , permissions and performance\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Patrick\nPatrick Debois is a versatile technologist with a breadth of experience across Dev, Sec, and Ops. Known for his aptitude in harnessing emerging ideas , he skillfully guides teams and advises businesses ranging from startups to enterprises in their journey. Recognized as a trusted ally among dev, sec, ops communities, and beyond, he is currently immersing himself in the world of AI & Machine Learning continuously pushing the boundaries of his technical expertise.\n\nWhile Patrick’s technical appetite is vast, his affinity for people is equally profound. He possesses the rare ability to bridge perspectives, effortlessly switching between management and individual contributor levels and roles. This unique experience has led him organising the first Devopsdays in 2009. He is attributed to coining the term DevOps and co-author of the widely known Devops Handbook. In the past Patrick has worked together with renowned tech organizations such as Atlassian and Snyk. He currently wears both hats of VP of Engineering and Distinguished Engineer at Showpad.\n\nHe thrives in sharing knowledge, organizing numerous community events, and presenting at many more. He believes in transforming his learnings into shareable lessons, using this feedback loop to hone his skills and broaden his perspectives. Through open sharing and lateral thinking, Patrick is not just enhancing his professional growth but also contributing significantly to the evolution of the field.\n\nYou can enjoy his past talks on his youtube channel https://www.youtube.com/@jedi4ever/videos. Or follow the firehose of learnings he shares on Twitter https://twitter.com/patrickdebois",
      "publishedAt": "2024-12-31T17:20:37Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT28M18S",
      "viewCount": 4952,
      "likeCount": 121,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/5qNXdLbEdew/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/5qNXdLbEdew/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/5qNXdLbEdew/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/5qNXdLbEdew/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/5qNXdLbEdew/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=5qNXdLbEdew"
    },
    {
      "id": "khcMErjUB8k",
      "title": "Real ROI: Lessons from Enterprises that have already succeeded with LLMs at Scale: Raza Habib",
      "description": "I'll share practical insights I've learned from AI leaders at Duolingo, Gusto, Vanta, Filevine, Ironclad and Sourcegraph who have succeeded with LLMs in production. We'll cover the skills your team needs, tips for RAG in production, how to choose evals and what it takes to succeed with agents.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Raza\nRaza Habib is the CEO and Cofounder of Humanloop where he's helped hundreds of companies get AI into production. He has a PhD in Deep Learning from UCL and studied physics at Cambridge. Sifted named him one of Europe's 20 Gen AI power players.",
      "publishedAt": "2024-12-31T17:19:09Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M1S",
      "viewCount": 6796,
      "likeCount": 227,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/khcMErjUB8k/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/khcMErjUB8k/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/khcMErjUB8k/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/khcMErjUB8k/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/khcMErjUB8k/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=khcMErjUB8k"
    },
    {
      "id": "gWLVu9OGvBg",
      "title": "Understanding AI Stakes to Break Production Code: Philip Rathle",
      "description": "When your mindblowing prototype meets the real world, GenAI projects can get stuck on their way to production. Whether the sticking points have to do with accuracy, explainability, compliance, cost, privacy, or something else, depends a lot on what’s at stake. In this round table session, we will explore “getting unstuck” and how that's different depending on project stakes... where \"stakes\" refers to what you have to gain or lose from good & bad answers. Let’s explore the bar for “getting to production” together through this lens--considering things like dollar impact, brand & reputational impact, privacy, bias, health & human safety, regulatory, etc. Bring your examples and questions and learn from each other’s successes and challenges to break the AI production code.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Philip\nPhilip Rathle is CTO of Neo4j, the graph database and analytics leader that enabled the ICIJ to crack the Panama Papers, and NASA to get to Mars two years faster. Neo4j enables thousands of organizations worldwide-- including most of the Fortune 500-- to solve their most pressing & valuable problems through the power of the connections in data. Philip comes from a long career in data & databases. He joined Neo4j in 2012, where he led Product Management for over a decade, helping to pioneer the graph database category and creating one of the world’s leading database & analytics companies.",
      "publishedAt": "2024-12-31T17:17:42Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT23M24S",
      "viewCount": 484,
      "likeCount": 6,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/gWLVu9OGvBg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/gWLVu9OGvBg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/gWLVu9OGvBg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/gWLVu9OGvBg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/gWLVu9OGvBg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=gWLVu9OGvBg"
    },
    {
      "id": "0oTlgBfzNJ0",
      "title": "The ROI of AI: Why you need Eval Framework - Beyang Liu",
      "description": "There has been a ton of hype about AI's applications in software development, but leaders must look beyond the hype to assess the ROI for their organizations. We'll cover some quantitative and qualitative frameworks that have proven useful for our customers, highlight the benefits and drawbacks of popular metrics in use, and share the themes that have emerged as important pillars of the value prop for AI dev tools. I'll also share a vision for where the next 18 months of AI will lead in software development.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nBeyang Liu is CTO and co-founder of Sourcegraph. Sourcegraph is the world's best code search and understanding engine, which enables developers to find and grok code across very large codebases and dependency graphs. Beyang is also the creator of Cody, the context-aware AI coding assistant, which uses Sourcegraph's search and understanding engine to generate code, answer questions, and enable a wide variety of AI automation in the context of your private codebase.\n\nPrior to Sourcegraph, Beyang built large-scale data analysis engines for Fortune 500 companies with complex codebases as an engineer at Palantir Technologies. Beyang's interest in AI sprang from his experience studying computer science at Stanford University, where he first encountered the Chomsky and Norvig models of intelligence and discovered a love for compilers while publishing research as a member of the Stanford AI Lab.",
      "publishedAt": "2024-12-31T17:00:41Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT25M28S",
      "viewCount": 3233,
      "likeCount": 72,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/0oTlgBfzNJ0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/0oTlgBfzNJ0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/0oTlgBfzNJ0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/0oTlgBfzNJ0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/0oTlgBfzNJ0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=0oTlgBfzNJ0"
    },
    {
      "id": "kwnCvA9l-TY",
      "title": "AI Frontiers in Trust and Safety  Combatting Multifaceted Harm on Tinder at Scale: Vibhor Kumar",
      "description": "Harassment, Hate Speech, Pig Butchering Scams, and Underage users. These are just some of the possible categories of the (very) long tail of harm on Tinder. How can we possibly train, serve, and maintain models for all of these, at global, real-time scale? We build off of pre-trained models and an increasingly mature open-source ecosystem. In this talk, we'll cover how we've dramatically accelerated our modeling pipeline with (1) human-AI hybrid dataset generation for different harm vectors, (2) automated parameter-efficient fine-tuning of open-source large language and multimodal models for violation detection, and (3) serving fine-tuned adapters efficiently in real-time and at scale using LoRAX and cascade classification.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Vibhor\nVibhor Kumar is a computer scientist, amateur neuroscientist, and armchair philosopher of science. He likes working at the intersection of the theoretical and applied. His work has been involved in mapping fly brains, catching financial fraud, and generating assets of various types using AI.\n\nHe is currently a software engineer in Trust and Safety at Tinder, a hands-on advisor to AI startups including Togethr.ai, a contributor to open-source AI projects, and an angel investor.",
      "publishedAt": "2024-12-02T20:37:40Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M36S",
      "viewCount": 865,
      "likeCount": 24,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/kwnCvA9l-TY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/kwnCvA9l-TY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/kwnCvA9l-TY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/kwnCvA9l-TY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/kwnCvA9l-TY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=kwnCvA9l-TY"
    },
    {
      "id": "prttz9_1XDc",
      "title": "Enhancing Quality and Security in CI: Gunjan Patel",
      "description": "Learn how AI can enable code to self-improve in readability and security. This session explores the integration of AI into CI/CD pipelines with innovative prompting techniques for improving variable names, automating code comments, adding unit tests, and autonomously identifying and fixing security vulnerabilities. Discover practical methods for integrating AI with developer workflows, resulting in code that evolves and improves with minimal manual intervention. This approach makes software development more efficient and secure. Attendees will walk away with a plug-and-play CI template with a Bring-Your-Own-LLM option that can be integrated into their own CI pipelines.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Gunjan\nGunjan has extensive experience as a developer, architect, developer relations, and engineering leader at both startups and large corporations. He has contributed to open source projects and has expertise in containers, Kubernetes, and the cloud ecosystem. Currently, Gunjan serves as the Director of Engineering at Palo Alto Networks working on integration of AI for Developer Productivity. He is passionate about GenerativeAI and how it can revolutionize development, cloud computing, and security.",
      "publishedAt": "2024-11-27T19:56:40Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M27S",
      "viewCount": 2089,
      "likeCount": 57,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/prttz9_1XDc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/prttz9_1XDc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/prttz9_1XDc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/prttz9_1XDc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/prttz9_1XDc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=prttz9_1XDc"
    },
    {
      "id": "OrtBEBLMXdM",
      "title": "Iterating on LLM apps at scale  Learnings from Discord: Ian Webster",
      "description": "Discover best practices for rapid evaluation and iteration on LLM apps in large-scale applications, with a first-hand account from Discord's engineering team. This talk covers development workflow and evaluation methodology in order to measure model & prompt improvements, mitigate risks, and speed up development. We'll discuss the best practices that we refined and implemented internally, the tooling and automation that got us shipping improvements consistently, and some of the strange and wonderful things that happen with LLMs in the wild\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Ian\nIan Webster is a Senior Staff Engineer at Discord and the maintainer of Promptfoo, a popular LLM evaluation tool. At Discord he leads teams that successfully scaled an AI-based products to millions of users while navigating the many new challenges presented by LLMs.",
      "publishedAt": "2024-11-22T20:27:24Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M26S",
      "viewCount": 3728,
      "likeCount": 115,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/OrtBEBLMXdM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/OrtBEBLMXdM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/OrtBEBLMXdM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/OrtBEBLMXdM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/OrtBEBLMXdM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=OrtBEBLMXdM"
    },
    {
      "id": "AUuktOQPWYg",
      "title": "Decoding Mistral AI's Large Language Models: Devendra Chaplot",
      "description": "In this talk, Devendra Singh Chaplot, Research Scientist at Mistral AI will explore the building blocks and training strategies that power Mistral AI’s large language models. It will feature Mistral AI's open-source models, Mixtral 8x7B and Mixtral 8x22B, which are based on a mixture-of-experts (MoE) architecture and released under the Apache 2.0 license. The presentation will also provide guidance on utilizing Mistral \"La Plateforme\" API endpoints and offer a preview of upcoming features.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Devendra\nDevendra Singh Chaplot is a Research Scientist at Mistral AI working on building the next generation of AI models. Earlier he was a Research Scientist at the Facebook AI Research (FAIR) Lab working at the intersection of Machine Learning, Computer Vision and Robotics. He has led the design of several AI systems which won the CVPR-2019 PointNav and CVPR-2020 ObjectNav, NeurIPS-2022 Rearrangement Habitat Challenges and the Visual-Doom AI Competition 2017. Chaplot is a recipient of the Facebook Fellowship Award and his research has received Best Paper and Best Demo awards at leading AI conferences. His research has also been featured in several popular media outlets such as MIT Technology Review, TechCrunch, Engadget, Popular Science, Kotaku, and Daily Mail. Chaplot received his Ph.D. in Machine Learning from Carnegie Mellon University and Bachelor's degree in Computer Science from IIT Bombay.",
      "publishedAt": "2024-11-21T21:16:38Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M16S",
      "viewCount": 2668,
      "likeCount": 65,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/AUuktOQPWYg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/AUuktOQPWYg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/AUuktOQPWYg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/AUuktOQPWYg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/AUuktOQPWYg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=AUuktOQPWYg"
    },
    {
      "id": "Up6WVA07QdE",
      "title": "The AI emperor has no DAUs  why most devs still don't use code AI: Quinn Slack",
      "description": "Despite the big potential productivity increases proven from several years in the market, the embarrassing truth is that most developers in the world never or rarely use AI while coding. With hundreds of billions of dollars in upstream AI investments betting on insatiable inference demand, this is a big risk—but also a big opportunity that's not yet priced in, if you believe adoption will accelerate. Quinn Slack, the CEO/cofounder of Sourcegraph, presents this problem and shares solutions for other AI application builders and foundation model companies from lessons learned at Sourcegraph building Cody, the AI coding assistant that is #2 in revenue.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Quinn\nI work at Sourcegraph as CEO. I love programming and want to make it so everyone can code. I studied computer science at Stanford. I’m on the boards of Sourcegraph and Hack Club. I live in the San Francisco Bay Area.",
      "publishedAt": "2024-11-20T20:28:33Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M45S",
      "viewCount": 6591,
      "likeCount": 144,
      "commentCount": 14,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Up6WVA07QdE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Up6WVA07QdE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Up6WVA07QdE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Up6WVA07QdE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Up6WVA07QdE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Up6WVA07QdE"
    },
    {
      "id": "Yyg_BoeB2LU",
      "title": "A Practical Guide to Efficient AI: Shelby Heinecke",
      "description": "In the past years, we’ve witnessed a whirlwind of AI breakthroughs powered by extremely large and resource-demanding models. And now, faced with actually deploying these models at scale, AI engineers and builders are left to pick up the pieces on how to improve latency and resource consumption practically. In parallel, the on-device AI movement is heating up, imposing even more physical constraints on AI model deployment. In this talk, we will first identify key sources of inefficiency in AI models. Then, we will discuss techniques and practical tools to improve efficiency, from model architecture selection, to quantization, to prompt optimization.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Shelby\nDr. Shelby Heinecke leads an AI research team at Salesforce. Shelby’s team develops cutting-edge AI for Salesforce products and academic research. Her team's work spans AI agents, LLMs, on-device AI, entity resolution, recommendation systems, and beyond. Shelby earned her Ph.D. in Mathematics from University of Illinois at Chicago, specializing in machine learning theory. She also holds an M.S. in Mathematics from Northwestern and a B.S. in Mathematics from MIT. Website: www.shelbyh.ai",
      "publishedAt": "2024-11-18T20:22:09Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M45S",
      "viewCount": 2560,
      "likeCount": 60,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Yyg_BoeB2LU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Yyg_BoeB2LU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Yyg_BoeB2LU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Yyg_BoeB2LU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Yyg_BoeB2LU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Yyg_BoeB2LU"
    },
    {
      "id": "T7sxvrJLJ14",
      "title": "Moondream: how does a tiny vision model slap so hard? — Vikhyat Korrapati",
      "description": "Psst! Wanna learn how to build an AI model that punches way above its weight? Beats models 4 times its size and competes with the models from Meta, Google and OpenAI? In this talk I’ll spill the beans on how I pulled it off, and how you can too. I’ll share my unexpected journey that led to the creation of Moondream, a tiny open-source vision language model that kicks ass. I’ll share my journey and the technical hurdles that I faced along the way. I’ll also explain why small models are the future of AI. Join me for a story of accidental innovation, the democratization of AI, and how sometimes, thinking small can lead to big results.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Vikhyat\nVik's work focuses on developing efficient AI models that can run on resource-constrained devices without sacrificing performance. His mission is to democratize AI technology, making advanced computer vision accessible to developers and businesses of all sizes. Prior to his current endeavors, Vik spent 9 years at AWS, gaining valuable experience in large-scale computing systems.",
      "publishedAt": "2024-11-14T20:49:19Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M26S",
      "viewCount": 16512,
      "likeCount": 527,
      "commentCount": 23,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/T7sxvrJLJ14/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/T7sxvrJLJ14/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/T7sxvrJLJ14/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/T7sxvrJLJ14/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/T7sxvrJLJ14/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=T7sxvrJLJ14"
    },
    {
      "id": "DId2KP8Ykz4",
      "title": "Navigating RAG Optimization with an Evaluation Driven Compass: Atita Arora and Deanna Emery",
      "description": "Retrieval Augmented Generation (RAG) has become a cornerstone for integrating domain-specific content and addressing hallucinations in AI applications. As the adoption of RAG solutions intensifies across industries, a pressing challenge emerges: understanding and identifying where within the complex RAG framework changes and improvements can be made. This talk delves into the methodology of extracting crucial indicators from your RAG pipeline, empowering informed decision-making during experimentation. Join us as we navigate an end-to-end process for RAG experimentation and evaluation, offering insights into optimizing performance and addressing hurdles along the RAG implementation journey.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Atita\nAtita Arora is a seasoned and esteemed professional in information retrieval systems and has decoded complex business challenges, pioneering innovative information retrieval solutions in her 15-year journey as a Solution Architect / Relevance strategist / Individual Contributor and works as Solution Architect at Qdrant. She has a robust background from her impactful contributions as a committer in various information retrieval projects. She has a keen interest in making revolutionary tech innovations accessible and implementable to solve real-world problems. She is currently actively researching about evaluating RAGs while navigating the world of vectors and LLMs, seeking to uncover insights that can enhance their practical applications and effectiveness.\n\nAbout Deanna\nDeanna is the Founding AI Researcher at Quotient AI, where she is leading research on evaluation of Large Language Models in real-world products and applications. Before Quotient, Deanna was a Principal Data Scientist at Aon, where she led the team building language models for valuation of intellectual property assets. She began her career as a researcher at Harvard-Smithsonian Center for Astrophysics and Caltech LIGO. Deanna has a MS in Machine Learning from UC Berkeley and BA in Physics from Harvard University. She is passionate about diversity and inclusion in STEM; she has conducted research on diversity in named patent inventors, working with companies to measure and address diversity gaps, and she is an active board member at a STEM education non-profit.",
      "publishedAt": "2024-11-12T19:16:46Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M14S",
      "viewCount": 4503,
      "likeCount": 151,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/DId2KP8Ykz4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/DId2KP8Ykz4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/DId2KP8Ykz4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/DId2KP8Ykz4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/DId2KP8Ykz4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=DId2KP8Ykz4"
    },
    {
      "id": "fOtTHWeU6B8",
      "title": "How Zapier Builds AI Products and Features with the Help of Braintrust: Ankur Goyal & Olmo Maldonado",
      "description": "Zapier is the #1 workflow automation platform for small and midsize businesses, connecting to more than 7,000 of the most popular work apps. We were also one of the first companies to build and ship AI features into our core products. We've had the opportunity to work with Braintrust since the early days of the product, which now powers the evaluation and observability infrastructure across our AI features.\n\nWe’ll walk through a couple of our projects – AI Zap Builder and Zapier Copilot – and how we built them from the ground up with evals and observability in mind. Hopefully, you can walk away with a few of our learnings from operating these projects at scale while systematically improving their performance.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Ankur\nAnkur Goyal is the founder & CEO of Braintrust—the developer platform that companies like Zapier, Notion, Instacart, Airtable, and more use to evaluate, log, and ship reliable AI products to millions. He was previously Head of AI platform at Figma, founder and CEO of Impira, and VP Eng at Singlestore. After Figma acquired Impira, he led the AI team there, and saw a number of the same blockers to AI development at Impira, Figma, and other peer companies, which led to founding Braintrust\n\nAbout Olmo\nOlmo Maldonado is a Senior AI Engineer at Zapier, where he develops high-scale AI services aimed at democratizing automation. He leads the team behind the AI Zap Builder and Copilot, and has created shared services that have enabled multiple teams to scale LLM usage to production loads. Under his leadership, Zapier improved AI accuracy by fostering a culture of Eval Driven Development. Olmo is a former Googler and a core developer of MooTools. He holds a Master’s degree in Electrical Engineering from the University of California, Los Angeles. Born in Mexico and raised in the United States, Olmo embraces and celebrates both cultures. He resides in San Antonio, TX, with his family.",
      "publishedAt": "2024-11-07T20:11:02Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M59S",
      "viewCount": 2927,
      "likeCount": 54,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/fOtTHWeU6B8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/fOtTHWeU6B8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/fOtTHWeU6B8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/fOtTHWeU6B8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/fOtTHWeU6B8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=fOtTHWeU6B8"
    },
    {
      "id": "42q8OmAF_Gw",
      "title": "What It Actually Takes to Deploy GenAI Applications to Enterprises: Arjun Bansal and Trey Doig",
      "description": "Join Trey Doig and Arjun Bansal as they recount Echo AI’s journey rolling out its conversational intelligence platform to billion-dollar retail brands. They’ll discuss navigating LLM accuracy issues as well as what needed to happen at the application and infrastructure layers in order to successfully deploy at enterprise scale.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Arjun\nArjun Bansal is an entrepreneur and AI expert focused on understanding and building intelligent systems. He is currently CEO & co-founder of Log10.io, a platform for measuring and improving accuracy of LLM applications and agents. Arjun previously co-founded Nervana Systems (acq. Intel), and XOKind (AI agents for travel). Arjun's career spans research in brain-machine interfaces, building AI processors, and AI sidekicks.\n\nAbout Trey\nTrey Doig is the Co-Founder & CTO at Echo AI, building a GenAI-native Conversation Intelligence platform. Trey has over ten years of experience in the tech industry, having worked as an engineer for IBM, Creative Commons, and Yelp. Trey’s previous startup SeatMe, was acquired by Yelp.com, which still powers their reservation functionality today.",
      "publishedAt": "2024-11-04T20:48:26Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M30S",
      "viewCount": 3350,
      "likeCount": 51,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/42q8OmAF_Gw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/42q8OmAF_Gw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/42q8OmAF_Gw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/42q8OmAF_Gw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/42q8OmAF_Gw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=42q8OmAF_Gw"
    },
    {
      "id": "2DyHW23L6Cs",
      "title": "Knowledge Graphs & GraphRAG: Techniques for Building Effective GenAI Applications: Zach Blumenthal",
      "description": "RAG & LLM Frameworks: Learn about practical graph design patterns and retrieval strategies to more effectively customize GenAI for real-world applications. While GenAI offers great potential, it faces challenges with hallucination and lack of domain knowledge. Graph-powered retrieval augmented generation (GraphRAG) helps overcome these challenges by integrating vector search with knowledge graphs and data science techniques to improve context, semantic understanding, and personalization while facilitating real-time updates. You'll receive detailed coded examples to begin your journey with GenAI and graphs, leaving with practical skills to apply immediately to your own projects.\n\nPrerequisites: This is a hands-on workshop where you can follow along with Jupyter notebooks in Colab. We will provide links to notebooks at the beginning of the workshop. To follow along please:\n\nBring your laptop\nCreate a Google account ahead of time if you don’t have one already so you can run Colab notebooks.\n[Prefered] Bring a working openAI API key. We will provide a key for those that do not have one yet. To make a new key, create an OpenAI account or sign in. Next, navigate to the API key page and \"Create new secret key\". Optionally naming the key. Save this somewhere safe, and do not share it with others. We recommend testing your key to make sure it works - see the OpenAI quickstart tutorial for more details.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Andreas\nAndreas is a technological humanist. Starting at NASA, Andreas designed systems from scratch to support science missions. Then in Zambia, he built medical informatics systems to apply technology for social good. Now with Neo4j, he is democratizing graph databases to validate and extend our intuitions about how the world works. Everything is connected.",
      "publishedAt": "2024-11-01T19:46:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H39M52S",
      "viewCount": 14842,
      "likeCount": 328,
      "commentCount": 13,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/2DyHW23L6Cs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/2DyHW23L6Cs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/2DyHW23L6Cs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/2DyHW23L6Cs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/2DyHW23L6Cs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=2DyHW23L6Cs"
    },
    {
      "id": "eDr0m6R7fI4",
      "title": "AI Engineering Without Borders — swyx",
      "description": "One year into the Rise of the AI Engineer, what do we think we know, and are we so sure?\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025",
      "publishedAt": "2024-10-30T19:23:51Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT10M32S",
      "viewCount": 2047,
      "likeCount": 65,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/eDr0m6R7fI4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/eDr0m6R7fI4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/eDr0m6R7fI4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/eDr0m6R7fI4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/eDr0m6R7fI4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=eDr0m6R7fI4"
    },
    {
      "id": "U9DPRZ0lSIQ",
      "title": "State Space Models for Realtime Multimodal Intelligence: Karan Goel",
      "description": "What are the big breakthroughs required to bring realtime multimodal intelligence to every device in the world? This talk describes the work we're doing at Cartesia on bringing realtime models to life on an entirely new technology stack. I'll describe new research ideas that we developed over the last few years — state space models — that are enabling us to build audio models that are cheaper, faster and higher quality than state of the art approaches.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Karan\nKaran is the Founder / CEO of Cartesia.ai where he builds multimodal models that can be run in real-time on any device. Before founding Cartesia, Karan pursued his PhD from Stanford, where he spent a few years developing the first state space models, building data systems, and researching new methods for robust machine learning. Karan is a recipient of the Siebel Scholarship, graduated from IIT-Delhi and CMU, and is passionate about machine learning, engineering and developer tools.",
      "publishedAt": "2024-10-29T19:15:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M26S",
      "viewCount": 3638,
      "likeCount": 102,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/U9DPRZ0lSIQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/U9DPRZ0lSIQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/U9DPRZ0lSIQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/U9DPRZ0lSIQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/U9DPRZ0lSIQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=U9DPRZ0lSIQ"
    },
    {
      "id": "apZXpgU_klw",
      "title": "Second Order Effects of AI: Cheng Lou",
      "description": "Recorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025",
      "publishedAt": "2024-10-28T19:09:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M46S",
      "viewCount": 3486,
      "likeCount": 87,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/apZXpgU_klw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/apZXpgU_klw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/apZXpgU_klw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/apZXpgU_klw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/apZXpgU_klw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=apZXpgU_klw"
    },
    {
      "id": "IRp7lvBlbHs",
      "title": "Build an AI Research Agent: Apoorva Joshi",
      "description": "In this 2 hour workshop, we will build an AI research agent that can search for research papers, summarize them, and answer questions on topics based on past research. We will use MongoDB as the agent's memory provider and knowledge store, open-source LLMs as the agent’s “brain”, and LangChain to orchestrate the end-to-end agentic workflow.\n\nAttendees will be provided with all the resources required to successfully execute the hands-on portions of the workshop, including a GitHub repository consisting of notebook templates with pseudocode. Attendees will replace the pseudocode with their own code during the workshop.\n\nFor this workshop, attendees will need basic to intermediate knowledge of Python, and a laptop with the latest version of Python installed.\n\nThe preferred environment for running the labs is Google Colab, but for those who would prefer a local setup, instructions can be found here: https://mongodb-developer.github.io/ai-agents-lab/docs/dev-env/dev-setup#local-setup\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Apoorva\nApoorva is a Data Scientist turned Developer Advocate, with 6 years of experience applying Machine Learning to problems in Cybersecurity, including phishing detection, malware protection, and entity behavior analytics. As an AI Developer Advocate at MongoDB, she now helps developers be successful at building AI applications via written content and workshops.",
      "publishedAt": "2024-10-25T21:45:20Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT27M33S",
      "viewCount": 16799,
      "likeCount": 475,
      "commentCount": 14,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/IRp7lvBlbHs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/IRp7lvBlbHs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/IRp7lvBlbHs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/IRp7lvBlbHs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/IRp7lvBlbHs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=IRp7lvBlbHs"
    },
    {
      "id": "qpmZID27t98",
      "title": "The Multimodal Future of Education: Stefania Druga",
      "description": "We will explore how we might use AI models to combine sounds, images, and videos and create new learning activities that support critical, creative and counter-factual thinking. Showcase demos using Generative AI (Vertex API, AI studio, LearnML) to detect misconceptions in math learning, support creative coding, create simulations to test scientific hypotheses, curate and sumarize research & identiy blind spots in one’s thinking. The goal of our demos will be to demonstrate how mights we use multimodal ai to support learning activities where the agency is balanced between learners and AI and we encourage people to discover the limitations of these technologies while developing a critical use of it, know if, when and how to use it when learning new skills.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Stefania\nHi! I am Stef. I am currently a research scientist in Google Gemini team working on real-world applications for multimodal language models. I was a principal researcher at the Center of Applied AI Research at the University of Chicago and graduated with a Ph.D. in Creative AI Literacies 🎓 at the University of Washington Information School. In the past I worked with Microsoft’s Human-AI eXperience Team, X Moonshot Factory, Fixie.ai.\n\nI also enjoy designing and building an AI coding plaftorm for kids which started as my master project at MIT (cognimates.me). When I am not coding & writing papers 👩🏽‍💻 I love trail running and rocket yoga.",
      "publishedAt": "2024-10-24T19:42:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M5S",
      "viewCount": 2555,
      "likeCount": 84,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/qpmZID27t98/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/qpmZID27t98/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/qpmZID27t98/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/qpmZID27t98/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/qpmZID27t98/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=qpmZID27t98"
    },
    {
      "id": "uiq95JYpBGY",
      "title": "Productionizing GenAI Models – Lessons from the world's best AI teams: Lukas Biewald",
      "description": "AI is poised to add $15.7 trillion to the global economy by 2030, with generative AI at the forefront of this revolution, marking a transformative shift across sectors. In his talk, Lukas Biewald will unpack the impact and potential of generative AI models and share practical insights learned from the best ML teams in the world who're building and implementing AI in production. He will share specific insights on deploying GenAI models into real-world applications, emphasizing LLM evaluation, dataset management, model experimentation and optimization. This session is a call to action for ML teams looking to leverage AI's full potential responsibly, and looking to expedite putting AI into production.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Lukas\nI’m Lukas Biewald, I founded CrowdFlower/Figure Eight and Weights and Biases. You can find my projects on twitter and medium and github.  I live and work in San Francisco.",
      "publishedAt": "2024-10-23T19:23:33Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT22M36S",
      "viewCount": 7201,
      "likeCount": 183,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/uiq95JYpBGY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/uiq95JYpBGY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/uiq95JYpBGY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/uiq95JYpBGY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/uiq95JYpBGY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=uiq95JYpBGY"
    },
    {
      "id": "Ve-akpov78Q",
      "title": "Code Generation and Maintenance at Scale: Morgante Pell",
      "description": "AI agents show incredible promise, but have a hard time dealing with existing large-scale codebases. This talk will show examples of how LLMs fail when not given the proper tools and practical demonstrations of how pre-LLM tools already make developers superhuman. Explore a concrete set of challenges around user interfaces for AI and a vision for what superintelligent developer assistants might look like.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Morgante\nMorgante is the founder of Grit, a startup using static analysis and AI to automate common software development tasks with backing from Founders Fund. Before founding Grit, Morgante was a senior staff architect at Google, where he led the development of infrastructure automation tools and worked with dozens of F500 companies on software modernization projects. He is passionate about software architecture, programming languages, and going on long hikes.",
      "publishedAt": "2024-10-17T18:52:20Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M54S",
      "viewCount": 5187,
      "likeCount": 143,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Ve-akpov78Q/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Ve-akpov78Q/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Ve-akpov78Q/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Ve-akpov78Q/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Ve-akpov78Q/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Ve-akpov78Q"
    },
    {
      "id": "i2vBaFzCEJw",
      "title": "The Hierarchy of Needs for Training Dataset Development: Chang She and Noah Shpak",
      "description": "Training and fine-tuning models depends critically on how you construct your dataset. Part art, part science, we’ll share with you practical lessons in dataset construction at Character AI and how to build a data platform to support rapid iterative refinement of training data. For LLMs, data scale is much larger and workloads are more diverse. This is especially true for multimodal datasets. To deal with these challenges, we'll show you how LanceDB is used in production to solve many pain-points around the storage, management, and querying of large scale AI data.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Chang\nChang She is the CEO and cofounder of LanceDB, the developer-friendly, open-source database for multi-modal AI. A serial entrepreneur, Chang has been building DS/ML tooling for nearly two decades and is one of the original contributors to the pandas library. Prior to founding LanceDB, Chang was VP of Engineering at TubiTV, where he focused on personalized recommendations and ML experimentation.\n\nAbout Noah\nNoah is a Research Engineer with a passion for building data systems and ML platforms from the ground up.\n\nHe leads the Data Platform team at Character, focusing on accelerating foundation model research, alignment, and product development through internet-scale data mining, prompting tools, and retrieval systems. Making data go vroom while gpus go brrrr is what makes him (and the team) tic!",
      "publishedAt": "2024-10-15T19:22:42Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M32S",
      "viewCount": 2811,
      "likeCount": 72,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/i2vBaFzCEJw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/i2vBaFzCEJw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/i2vBaFzCEJw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/i2vBaFzCEJw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/i2vBaFzCEJw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=i2vBaFzCEJw"
    },
    {
      "id": "aNmfvN6S_n4",
      "title": "No more bad outputs with structured generation: Remi Louf",
      "description": "JSON, prompt formatting, hallucinations. If you feel uncomfortable, you have probably had to implement complex solutions to circumvent these problems. What if there was a way to increase the reliability of Large Language Models at no cost? Enter structured generation. In this talk we will explore how the output of models can be steered at no extra cost, why this improves their efficiency and accuracy significantly and makes generation less sensitive to the specifics of the prompt. By the end of the talk, we'll understand how we can start benefiting from this breakthrough today by using the open source library Outlines.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Rémi\nRémi is the co-founder and CEO of .txt. After studies in Philosophy and Physics, Remi explored NLP and Bayesian statistics for 7 years. He works from a French castle, enjoys long walks in the nearby forests, reading poetry, playing guitar and spending time with his children.",
      "publishedAt": "2024-10-14T18:51:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M32S",
      "viewCount": 10337,
      "likeCount": 273,
      "commentCount": 9,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/aNmfvN6S_n4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/aNmfvN6S_n4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/aNmfvN6S_n4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/aNmfvN6S_n4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/aNmfvN6S_n4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=aNmfvN6S_n4"
    },
    {
      "id": "himhGiWJXjo",
      "title": "Realtime Data Connectivity for AI: Tanmai Gopal",
      "description": "What if ChatGPT could talk to your realtime data? Your product database? Your salesforce data?\n\n→ Write an email for my top paying customer quoting recent movies they rented →→ What are the genres of the movies here?\n\n→→→ Make it funny using a reference from one of the movies.\n\nAs we hurtle towards AI ubiquity, AI connected to realtime data will become the default user expectation.\n\nJoin me as I unveil Pacha DDN, an AI powered realtime data access layer that securely connects data & business logic spread across multiple sources to your LLM. Pacha DDN provides autonomous explainable multi-step query planning to retrieve data from structured & unstructured data sources and APIs instantly.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Tanmai\nTanmai is the CEO and cofounder at Hasura. Hasura is an open-source technology startup, that provides a GraphQL engine to help application developers work with data in modern app and microservices/serverless environments.Prior to Hasura, Tanmai ran a consultingfirm helping enterprises modernizing their technology stacks, and moving from monolithic to cloud-native environments. He is a full-stack engineer who’s passionate about making it easy to build things. He created and taught one of India’s largest MOOCs on modern application development with over 250,000 students.",
      "publishedAt": "2024-10-11T20:12:04Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7M14S",
      "viewCount": 5025,
      "likeCount": 127,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/himhGiWJXjo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/himhGiWJXjo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/himhGiWJXjo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/himhGiWJXjo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/himhGiWJXjo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=himhGiWJXjo"
    },
    {
      "id": "ib-wTAvCZqg",
      "title": "Architecting and Testing Controllable Agents: Lance Martin",
      "description": "LLM-powered autonomous agents combine (1) Tool calling, (2) Memory, and (3) Planning to autonomously perform tasks. While they hold tremendous promise, agent reliability has been a barrier for large-scale deployment and productionisation. We’ll cover ways to design and build reliable agents using LangGraph, which can support diverse self-corrective applications such as RAG and code generation. But, just as critically, we’ll cover ways to use LangSmith to test your agents, examining both agent's final response as well as agent tool use trajectories. Collectively, we’ll talk about three types of testing loops you can incorporate into your agent design process - at run time, pre-production, and for production monitoring.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Lance Martin\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025",
      "publishedAt": "2024-10-11T18:57:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT2H21M53S",
      "viewCount": 7544,
      "likeCount": 215,
      "commentCount": 11,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ib-wTAvCZqg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ib-wTAvCZqg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ib-wTAvCZqg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ib-wTAvCZqg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ib-wTAvCZqg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ib-wTAvCZqg"
    },
    {
      "id": "gADhNzFjGeI",
      "title": "Breaking AI's 1-GHz Barrier: Sunny Madra (Groq)",
      "description": "It’s been 25 years since Intel broke the 1 Ghz speed barrier for a general purpose microprocessor. What does 1 Ghz AI inference mean? What application capabilities will this enable? How will we achieve it? Groq’s mission is to build the AI computer that will power the next generation of software.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Sunny\nSunny Madra, an experienced entrepreneur, has a track record of successful exits for the startups he founded. These exits include the sales of Autonomic to Ford Xtreme Labs to Pivotal, and most recently Definitive Intelligence to Groq. Currently, Sunny is leading GroqCloud.",
      "publishedAt": "2024-10-10T19:17:25Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M11S",
      "viewCount": 3562,
      "likeCount": 78,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/gADhNzFjGeI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/gADhNzFjGeI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/gADhNzFjGeI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/gADhNzFjGeI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/gADhNzFjGeI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=gADhNzFjGeI"
    },
    {
      "id": "C1CXwRYbwuQ",
      "title": "Making Open Models 10x faster and better for Modern Application Innovation: Dmytro (Dima) Dzhulgakov",
      "description": "Generative AI powers the next generation of real time applications. The key to success of modern application development in the Gen AI era is secure, latency-sensitive and low cost LLM serving solution, which Firework’s enterprise grade deployment provides. Fireworks AI accelerates innovation through its SaaS platform of low latency inference and high quality fine-tuning of 100+ models, across the state of the art LLMs, image/video/audio generation, embedding and multimodality models. These advantages are delivered through Fireworks' proprietary FireAttention technology, 4x-15x faster than the OSS alternatives. To bring the totality of knowledge together, Fireworks tuned their own FireFunction model to integrate hundreds of models and API calling together. Fireworks' adoption is the fastest in the industry and it also enables a software stack capable of extracting the most across different hardware and deployment options.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Dmytro\nDmytro (Dima) Dzhulgakov is the co-founder and CTO of ‪@fireworksai‬ which focuses on the transition to AI-powered business via interactive experimentation and a production platform centered around PyTorch technologies. Fireworks.ai offers high-performance low-cost LLM inference service that helps to try out and productionize large models.\n\nDmytro is one of PyTorch core maintainers. Previously he helped to bring PyTorch from a research framework to numerous production applications across Meta's AI use cases and broader industry.",
      "publishedAt": "2024-10-09T17:07:41Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M55S",
      "viewCount": 1789,
      "likeCount": 30,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/C1CXwRYbwuQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/C1CXwRYbwuQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/C1CXwRYbwuQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/C1CXwRYbwuQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/C1CXwRYbwuQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=C1CXwRYbwuQ"
    },
    {
      "id": "JbyictbPFV0",
      "title": "We accidentally made an AI platform: Jamie Turner",
      "description": "Recorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Jamie\nPrior to Convex, Jamie was a Senior Engineering Director at Dropbox, leading the Business Platform and the Storage / Databases groups. Earlier in his tenure at Dropbox, Jamie was a Principal Engineer, launching several significant projects in synchronization and storage with his Convex co-founders James and Sujay. Over ten years before Dropbox, Jamie held leadership positions at several startups, most recently as the Head of Engineering at Bump, a former top-10 mobile app acquired by Google in 2013.\n\nJamie brings to Convex an enduring obsession with databases, networking, and protocols. Over the course of his career, he’s created dozens of related open-source projects, collectively with thousands of GitHub stars and heavy industry use.",
      "publishedAt": "2024-10-08T19:46:07Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M36S",
      "viewCount": 6968,
      "likeCount": 124,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/JbyictbPFV0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/JbyictbPFV0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/JbyictbPFV0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/JbyictbPFV0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/JbyictbPFV0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=JbyictbPFV0"
    },
    {
      "id": "7_WhRAuP2Wg",
      "title": "Building and Scaling an AI Agent Swarm of low latency real time voice bots: Damien Murphy",
      "description": "Multimodality: AI Agents are becoming more powerful at a rapid pace! In this talk you will learn best practices and considerations to think about when building your AI Agent Swarm. All aspects from low latency Speech to Text, Large Language Model RAG and Fine Tuning and Text to Speech. I will share open source code for how to build an AI Agent you can talk to with sub second latency end to end! You will learn how you can scale your AI Agents to handle 1000s or millions of concurrent conversations.\n\nDeepgram Account\n\nhttps://console.deepgram.com/signup\nRequirements\n\nBrowser\nMicrophone\nSpeaker / Headphones\nDevelopment Tools\n\nNodeJS (http-server)\nJavaScript, CSS, HTML\nRepos\n\nhttps://github.com/DamienDeepgram/deepgram-workshop-client (Required)\nhttps://github.com/DamienDeepgram/deepgram-workshop-server (Optional)\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Damien\nFull stack developer and solutions engineer working with customers, focused on realizing business value from low latency real time AI",
      "publishedAt": "2024-10-08T18:28:46Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H7M23S",
      "viewCount": 2854,
      "likeCount": 69,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/7_WhRAuP2Wg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/7_WhRAuP2Wg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/7_WhRAuP2Wg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/7_WhRAuP2Wg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/7_WhRAuP2Wg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=7_WhRAuP2Wg"
    },
    {
      "id": "5nOLb27hQ5w",
      "title": "The era of unbounded products: Designing for Multimodal IO: Ben Hylak",
      "description": "Everything is converging. ai models can now natively understand the same modalities as you. at the same time, AR technology is getting to a place where we are able to experience virtual worlds like never before. how did we get here, where is this going, and how do we build intuitive experiences in the age of unbounded products.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025",
      "publishedAt": "2024-09-25T20:32:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M32S",
      "viewCount": 4872,
      "likeCount": 137,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/5nOLb27hQ5w/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/5nOLb27hQ5w/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/5nOLb27hQ5w/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/5nOLb27hQ5w/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/5nOLb27hQ5w/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=5nOLb27hQ5w"
    },
    {
      "id": "uLrOI65XbDw",
      "title": "Everything you need to know about Fine-tuning and Merging LLMs: Maxime Labonne",
      "description": "Fine-tuning LLMs is a fundamental technique for companies to customize models for their specific needs. In this talk, we will cover when fine-tuning is appropriate, popular libraries for efficient fine-tuning, and key techniques. We will explore both supervised fine-tuning (LoRA, QLoRA) and preference alignment (PPO, DPO, KTO) methods.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Maxime\nMaxime Labonne is a Senior Staff Machine Learning Scientist at Liquid AI, serving as the head of post-training. He holds a Ph.D. in Machine Learning from the Polytechnic Institute of Paris and is recognized as a Google Developer Expert in AI/ML. An active blogger, he has made significant contributions to the open-source community, including the LLM Course on GitHub, tools such as LLM AutoEval, and several state-of-the-art models like NeuralBeagle and Phixtral. He is the author of the best-selling book “Hands-On Graph Neural Networks Using Python,” published by Packt. Connect with him on X and LinkedIn @maximelabonne.",
      "publishedAt": "2024-09-25T19:03:03Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M52S",
      "viewCount": 25418,
      "likeCount": 863,
      "commentCount": 19,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/uLrOI65XbDw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/uLrOI65XbDw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/uLrOI65XbDw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/uLrOI65XbDw/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/uLrOI65XbDw/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=uLrOI65XbDw"
    },
    {
      "id": "gbM7k3NauNI",
      "title": "LLM Scientific Reasoning: How to Make AI Capable of Nobel Prize Discoveries: Hubert Misztela",
      "description": "Do you remember that feeling when you realized who was Jon Snow's mother? Or who was the Batman really? Those 'aha' moments define scientific reasoning: of many steps and non-obvious.\n\nEven though the scientific discovery using LLMs is becoming more popular recently, there is little if any discussion about high level reasoning process behind breakthroughs in science.\n\nSome of the discoveries like RNA interference required connecting of distanced areas of biology, described in different journals and with distinct vocabulary. In this talk we would like to discuss if LLMs would be able to spot those novel relationships behind phenomenas from distanced areas? What would it take: RAG, Agentic RAG or fully fledged AI agent?\n\nWe will first try to classify problems tackled by RAGs. Then we would define a new family of NLP problems related to the scientific discovery and propose a template for benchmarking of thereof. We would discuss them on the examples of Nobel Prize discoveries. Then the question would be if and how RAGs or more general AI Agents might help us in tackling those problems, so we will try to entertain you with some attempts to solve it.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Hubert\nCryptographer who became Apps Developer, Apps Developer who became a Data Scientist, Data Scientist who became a Consultant, Consultant who became AI Researcher for drug design. AI Researcher who is flirting with AI Engineering.\n\nI have over a decade of experience spanning from programming and research to business stakeholder management. Delivering solutions in AI, software development, mathematics and cryptography across industries: pharma, high-tech, government and education.\n\nFor the last six years I have been at Novartis: first two working on AI applications to commercial activities optimisation in close alignment with region Europe leadership team and the last 4 building AI solutions for small molecule design in collaboration with Microsoft Research.\n\nLecturer, conference speaker, internal trainings organizer.\n\nRecently I have organized an internal company LLM workshop and hackathon with 140+ participants.",
      "publishedAt": "2024-09-23T18:30:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M",
      "viewCount": 3461,
      "likeCount": 121,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/gbM7k3NauNI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/gbM7k3NauNI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/gbM7k3NauNI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/gbM7k3NauNI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/gbM7k3NauNI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=gbM7k3NauNI"
    },
    {
      "id": "eLXF0VojuSs",
      "title": "How to Construct Domain Specific LLM Evaluation Systems: Hamel Husain and Emil Sedgh",
      "description": "Many failed AI products share a common root cause: a failure to create robust evaluation systems. Evaluation systems allow you to improve your AI quickly in a systematic way and unlock superpowers like the ability to curate data for fine-tuning. However, many practitioners struggle with how to construct evaluation systems that are specific to their problems.\n\nIn this talk, we will walk through a detailed example of how to construct domain-specific evaluation systems.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Hamel\nHamel Husain started working with language models five years ago when he led the team that created CodeSearchNet, a precursor to GitHub CoPilot. Since then, he has seen many successful and unsuccessful approaches to building LLM products. Hamel is also an active open source maintainer and contributor of a wide range of ML/AI projects. Hamel is currently an independent consultant.\n\nAbout Emil\nEmil is CTO at Rechat, where he leads the development of Lucy, an AI personal assistant designed to support real estate agents.",
      "publishedAt": "2024-09-19T16:47:24Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M45S",
      "viewCount": 14916,
      "likeCount": 458,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/eLXF0VojuSs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/eLXF0VojuSs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/eLXF0VojuSs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/eLXF0VojuSs/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/eLXF0VojuSs/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=eLXF0VojuSs"
    },
    {
      "id": "Lko9lTGD_9U",
      "title": "From model weights to API endpoint with TensorRT LLM: Philip Kiely and Pankaj Gupta",
      "description": "TensorRT-LLM is the highest-performance model serving framework, but it can have a steep learning curve when you’re just getting started. We run TensorRT and TensorRT-LLM in production and have seen both the incredible performance gains it offers and the hurdles to overcome in getting it up and running. In this workshop, participants will learn how to start using TensorRT-LLM, including selecting a model to optimize, building an engine for it with TensorRT-LLM, setting batch sizes and sequence lengths, and running it on a cloud GPU.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Philip\nPhilip Kiely is a software developer and author based out of Chicago. Originally from Clive, Iowa, he graduated from Grinnell College with honors in Computer Science. Philip joined Baseten in January 2022 and works across documentation, technical content, and developer experience. Outside of work, he's a lifelong martial artist, a voracious reader, and, unfortunately, a Bears fan.\n\nAbout Pankaj\nPankaj Gupta is a co-founder of Baseten, where he leads model performance. Pankaj has spent his career making systems faster and more efficient, from optimizing data processing libraries at Twitter to search infrastructure at Uber and media processing at Adobe. A graduate of IIT Delhi, Pankaj now lives in the Bay Area, where he enjoys gardening and evening walks around his neighborhood.",
      "publishedAt": "2024-09-13T17:27:26Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H40M1S",
      "viewCount": 3622,
      "likeCount": 71,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Lko9lTGD_9U/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Lko9lTGD_9U/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Lko9lTGD_9U/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Lko9lTGD_9U/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Lko9lTGD_9U/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Lko9lTGD_9U"
    },
    {
      "id": "ksgLoPxEQzM",
      "title": "Build enterprise generative AI apps using Llama 3 at 1,000 tokens/s on the SambaNova AI platform",
      "description": "In this workshop, you will learn how to build LLM-based apps, such as a question-answering system with RAG, in LangChain using Llama-3 at 1,000 tokens per second on the SambaNova AI Platform.\n\nLevel: Intermediate\n\nSambaNova delivers generative AI capabilities to the enterprise. In this workshop, you will learn:\n\n● About SambaNova’s full-stack generative AI platform, powered by the SN40L AI chip and delivering unparalleled performance for training and inference\n● Samba-1, a trillion parameter composition of experts (CoE) model, and how it can be used for enterprise settings\n● How to build and deploy a question-answering app end-to-end with retrieval augmented generation (RAG) for enterprise search using the following suite: LangChain as framework, Unstructured for pre-processing text documents, E5-large-v2 embedding, ChromaDB vector store, and Llama-3-8B-Instruct running at speed record of 1,000 tokens per second via SambaNova.\n\nThis workshop is designed for tech professionals, engineers, and anyone interested in enterprise generative AI applications.\n\nPrerequisites: Experience programming, ideally in Python, a Github account, and laptop\n\nAssets: We will provide a link to the Github repo with step-by-step instructions on how to install the required libraries and how to run the Jupyter notebooks and Streamlit apps. We will also provide SambaNova API keys for the CoE and Llama-3 endpoints.\n\nGitHub Repo: https://github.com/sambanova/ai-starter-kit/tree/main/workshops/ai_engineer_2024/ Dev Setup for Exercise 1: https://github.com/sambanova/ai-starter-kit/blob/main/workshops/ai_engineer_2024/basic_examples/README.md Dev Setup for Exercise 2: https://github.com/sambanova/ai-starter-kit/blob/main/workshops/ai_engineer_2024/ekr_rag/README.md\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Varun\nVarun is a Sr Principal AI Solutions Engineer at SambaNova Systems. He is currently investigating the benefits of fine-tuning embedding & decoder LLMs in retrieval augmented generation (RAG). Previously, he led the deployment of AI/ML applications across CRM, e-commerce, healthcare, finance, energy, manufacturing, fraud detection, and cyber security at Fortune 500 enterprises. He has worked at C3.ai, Cisco, IBM Research, ABB, and research institutes in Singapore. He holds a Ph.D. in Computer Engineering from the University of Illinois at Urbana-Champaign.\n\nAbout Petro\nPetro is a Principal Engineer in the AI Solutions team at SambaNova Systems, where he is currently working on developing applications powered by large language models. His expertise spans AI for Science and Generative AI. He obtained his PhD and MS from the Georgia Institute of Technology and previously interned at Argonne National Laboratory. He has given several tutorials at conferences, e.g., Supercomputing, and in 2023, he was selected to participate in the prestigious US Frontiers of Engineering organized by the National Academy of Engineering.",
      "publishedAt": "2024-09-11T19:27:08Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT54M34S",
      "viewCount": 3641,
      "likeCount": 80,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ksgLoPxEQzM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ksgLoPxEQzM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ksgLoPxEQzM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ksgLoPxEQzM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/ksgLoPxEQzM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=ksgLoPxEQzM"
    },
    {
      "id": "cS6M6Jec0lU",
      "title": "Going beyond RAG: Extended Mind Transformers - Phoebe Klett",
      "description": "Retrieval Augmented Generation is such a hack. Why would an embedding of your prompt coincide with the documents needed to answer it? Meanwhile Transformers already have a key/query mechanism built in! In this talk, we'll introduce Extended Mind Transformers, a new flavor of transformer that allows the model to select and attend to the most relevant information at each generation step. We demonstrate EMT's state-of-the-art performance and discuss important design decisions for long context applications.\n\nGithub: https://github.com/normal-computing/extended-mind-transformers\n\nHF: https://huggingface.co/collections/normalcomputing/extended-mind-transformers-6655e9ba5853d86b32793aaf\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Phoebe\nML Engineer with background in abstract mathematics. Building language models that natively reason.",
      "publishedAt": "2024-09-11T18:47:12Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M4S",
      "viewCount": 16362,
      "likeCount": 543,
      "commentCount": 29,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/cS6M6Jec0lU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/cS6M6Jec0lU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/cS6M6Jec0lU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/cS6M6Jec0lU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/cS6M6Jec0lU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=cS6M6Jec0lU"
    },
    {
      "id": "IIL2tE4n1Q0",
      "title": "Judging LLMs: Alex Volkov",
      "description": "All rise! The honorable LLM Judge presiding. On the docket today, many cases of AI Engineers building with LLMs, without the ability to iterate, evaluate and improve their products.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Alex\nAlex Volkov is an AI Evangelist at Weights & Biases as well as the founder and host of ThursdAI, a weekly newsletter and podcast that explores the latest innovations in AI, their practical applications, and the open-source AI community. Alex is an AI startup founder with 20 years of full-stack software engineering experience, offering a deep well of insights into AI innovation. He’s celebrated for his ability to clarify and summarize the complexities of the rapid AI advances and advocating for its beneficial uses.",
      "publishedAt": "2024-09-09T18:39:17Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M39S",
      "viewCount": 1781,
      "likeCount": 50,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/IIL2tE4n1Q0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/IIL2tE4n1Q0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/IIL2tE4n1Q0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/IIL2tE4n1Q0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/IIL2tE4n1Q0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=IIL2tE4n1Q0"
    },
    {
      "id": "pZ4DIH2BVqg",
      "title": "Pydantic is STILL all you need: Jason Liu",
      "description": "PLEASE ONLY RETURN JSON\n\nIt's been a year after Jason's most popular talk at the AI Engineering Summit. I wanted to come back with all the learnings I've had in the past year. How I've learned that Pydantic is still all you need, and bring more applications and use cases that I've seen in businesses and my thoughts on where the space will be heading in the future.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Jason\nJason is an independent AI consultant, advisor, writer, and educator. His main interests are structured outputs, search and retrieval for RAG as well as understanding how to leverage AI to build scalable and valuable businesses.",
      "publishedAt": "2024-09-06T17:07:06Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M21S",
      "viewCount": 20452,
      "likeCount": 655,
      "commentCount": 21,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/pZ4DIH2BVqg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/pZ4DIH2BVqg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/pZ4DIH2BVqg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/pZ4DIH2BVqg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/pZ4DIH2BVqg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=pZ4DIH2BVqg"
    },
    {
      "id": "-zzP0EUsZz4",
      "title": "Hyperspace  More Nodes Is All You Need: Nicolas Schlaepfer",
      "description": "Hyperspace is launching a new kind of agentic planning model, alongwith a breakthrough new AI application for power users. This is meant to run on the Hyperspace peer-to-peer AI network: the world’s largest and most advanced Uber-like network of open source models running on consumer devices (with over 15,000 nodes registered so far). It’s time to put a dent in the universe.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Nicholas\nAI Software Engineer | Prompt Engineer | Passionate about AI & Team Collaboration",
      "publishedAt": "2024-09-04T16:32:49Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M48S",
      "viewCount": 2033,
      "likeCount": 43,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/-zzP0EUsZz4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/-zzP0EUsZz4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/-zzP0EUsZz4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/-zzP0EUsZz4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/-zzP0EUsZz4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=-zzP0EUsZz4"
    },
    {
      "id": "knDDGYHnnSI",
      "title": "GraphRAG: The Marriage of Knowledge Graphs and RAG: Emil Eifrem",
      "description": "A famous poet once said \"Natural language is most powerful when it can draw from a rich context.\" Ok fine, I said that. But that's true of both poetry, and of LLMs! Well, Knowledge Graphs excel at capturing context. How can combining Knowledge Graphs with RAG – an emerging technique known as GraphRAG – give context to your RAG application, and lead to more accurate and complete results, accelerated development, and explainable AI decisions? This talk will go deep on the why and how of GraphRAG, and where best to apply it. You’ll get concepts, examples, and specifics on how you can get started. You’ll walk away with an understanding of how GraphRAG can improve the context you pass to the LLM and the performance of your AI applications.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Emil\n\nEmil Eifrem is Neo4j’s Co-Founder and CEO. He sketched what today is known as the property graph model on a flight to Mumbai way back when dinosaurs ruled the earth and has devoted his professional life to building, innovating, and evangelizing graph databases and graph analytics. He is also co-author of the O'Reilly book Graph Databases. Neo4j today helps more than 75 of the Fortune 100, and a community of over hundreds of thousands of practitioners find hidden relationships and patterns across billions of connections deeply, easily, and quickly. Emil plans to change the world with graphs and own Larry's yacht by the end of the decade.",
      "publishedAt": "2024-08-28T18:57:35Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M15S",
      "viewCount": 179329,
      "likeCount": 4654,
      "commentCount": 93,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/knDDGYHnnSI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/knDDGYHnnSI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/knDDGYHnnSI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/knDDGYHnnSI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/knDDGYHnnSI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=knDDGYHnnSI"
    },
    {
      "id": "vNssL4u5jb8",
      "title": "Building State of the Art Open Weights Tool Use: The Command R Family: Sandra Kublik",
      "description": "We opened model weights for Command R and R+, and the response was incredible. This talk will showcase the community's innovative projects and our journey to building SOTA multi-step tool use proficiency with the R family. We will also share the design decisions that make the R family unique and effective.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Sandra\nSandra Kublik is a member of the Developer Relations team at Cohere, where she educates and leads the LLM community. In 2023, Sandra co-authored the first manual book on OpenAI API, \"GPT-3: The Ultimate Guide to Building NLP Products with OpenAI API.\" She hosts a YouTube channel and podcast where she explores the latest advancements and applications of LLMs.",
      "publishedAt": "2024-08-26T19:08:17Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M3S",
      "viewCount": 1858,
      "likeCount": 50,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/vNssL4u5jb8/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/vNssL4u5jb8/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/vNssL4u5jb8/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/vNssL4u5jb8/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/vNssL4u5jb8/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=vNssL4u5jb8"
    },
    {
      "id": "R7xlYs5p0yA",
      "title": "Git push get an AI API: Ryan Fox-Tyler",
      "description": "In this workshop you’ll build a demo that augments an app with AI for classification, natural language search, summarization, and outlier detection. Then you’ll learn how to iteratively improve before and after shipping to prod. We’ll use Hypermode to move fast and reduce infra overhead. You’ll walk away with a greater intuition for when & how to integrate AI without refactoring. Also, we have swag.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Ryan\nProduct creator Leading teams building devtools Now at Hypermode\n\nI'm on a mission Make each dev an AI eng Skip data science",
      "publishedAt": "2024-08-23T18:33:47Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT45M1S",
      "viewCount": 1602,
      "likeCount": 31,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/R7xlYs5p0yA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/R7xlYs5p0yA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/R7xlYs5p0yA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/R7xlYs5p0yA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/R7xlYs5p0yA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=R7xlYs5p0yA"
    },
    {
      "id": "8k848OeLc9E",
      "title": "Hypermode Launch: Kevin Van Gundy",
      "description": "Recorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Kevin\nAfter a decade Leading teams in tech through growth Founded Hypermode. I'm on a mission Make each dev an AI eng Skip data science",
      "publishedAt": "2024-08-23T18:30:56Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M3S",
      "viewCount": 1087,
      "likeCount": 20,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/8k848OeLc9E/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/8k848OeLc9E/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/8k848OeLc9E/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/8k848OeLc9E/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/8k848OeLc9E/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=8k848OeLc9E"
    },
    {
      "id": "L0kBWyziFlc",
      "title": "Disrupting the $15 Trillion Construction Industry with Autonomous Agents: Dr. Sarah Buchner",
      "description": "Dr. Sarah Buchner, Founder & CEO of Trunk Tools, envisions a future for construction where an army of AI agents works on behalf of our users. We are currently deploying an agent every 45 days: our Q&A agent, TrunkText, is already saving field professionals 1-2 hours every day. We believe that ~$2.5 Trillion of the construction industry can be automated with Trunk Tools.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Dr. Sarah\nDr. Sarah Buchner is the Founder & CEO of construction tech startup Trunk Tools. Backed by Innovation Endeavors, Sequoia, Accel, Lightspeed, Index and others, Trunk Tools is tackling the $15 trillion construction industry. Trunk Tools is building the brain behind construction; we're leveraging AI to organize mountains of unstructured data, automate workflows, and build for a better future. Dr. Buchner is a Forbes 30 Under 30 and ENR Top Young Professionals honoree.\n\nWith deep roots in all facets of construction, Sarah spent her young life as a carpenter in her native Austria beginning at the age of 12. She advanced in the field through various roles, including superintendent, and project manager of increasingly large and complex construction projects. Sarah has earned several post-collegiate degrees in conjunction with her full-time construction career, including a MS in civil engineering, a Ph.D. in data science / civil engineering, and an MBA from Stanford.",
      "publishedAt": "2024-08-22T18:23:18Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M32S",
      "viewCount": 3761,
      "likeCount": 110,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/L0kBWyziFlc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/L0kBWyziFlc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/L0kBWyziFlc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/L0kBWyziFlc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/L0kBWyziFlc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=L0kBWyziFlc"
    },
    {
      "id": "zwItokY087U",
      "title": "10x Development: LLMs For the working Programmer - Manuel Odendahl",
      "description": "In this hands-on workshop, learn how Large Language Models (LLMs) can significantly improve your productivity as a software developer. Drawing from three years of experience using LLMs in every aspect of his work as a principal engineer, the presenter will share practical insights and techniques that go beyond simple prompts and off-the-shelf tools.\n\nThrough a series of interactive exercises and real-world examples, participants will learn how to:\n\nCombine classic design patterns, such as domain-specific languages and declarative programming, with transformer-based models\nIdentify the most effective ways to use LLMs for writing software, beyond simply having them generate code\nCreate systems that use LLMs to write software that instructs LLMs to write more software\nThis workshop is designed for engineers and professionals working in software-related fields who want to use LLMs to solve concrete problems and improve their workflow. Attendees will gain valuable insights and practical techniques that they can immediately apply to their projects, regardless of their current level of expertise with LLMs.\n\nThe presenter, a passionate advocate for \"pragmatic programming\" with LLMs, has made over 6,000 GitHub contributions using these models in the past year, achieving a high level of quality that demonstrates the technology's potential.\n\nParticipants need access to a LLM of their choice (recommended: gpt-4o and claude 3.5 sonnet). Please prepare a list of programming topics (projects you want to build, legacy code you might want to work on, frameworks and technologies you want to learn). I will provide an extensive list of ideas to try out during the talk.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Manuel\n25-year software veteran specializing in embedded and systems programming. Heavy user of LLMs for day to day programming. Passionate about scalable, long-term solutions. Driven success in both companies and open-source projects.\n\ntrusted latent.space discord AI in Action safety fallback (slono)",
      "publishedAt": "2024-08-21T16:36:00Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H14M46S",
      "viewCount": 8408,
      "likeCount": 185,
      "commentCount": 11,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/zwItokY087U/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/zwItokY087U/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/zwItokY087U/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/zwItokY087U/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/zwItokY087U/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=zwItokY087U"
    },
    {
      "id": "bjNYEc908oQ",
      "title": "Building Reliable Agentic Systems: Eno Reyes",
      "description": "Agentic system design is a rapidly evolving and intellectually fascinating field, with huge potential for transforming how software is used across industries. Unlike traditional software, agentic systems rely on non-deterministic and oftentimes difficult to predict decision making. Taking inspiration from fields like robotics, cybernetics, and biology, we can start to develop intuitions around how to build systems that are ~more~ reliable than the sum of their individual stochastic parts.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Eno\nEno Reyes is founder and CTO of Factory.ai, an organization developing autonomous systems called Droids that automate software development tasks. Prior to Factory, he was an ML engineer at Hugging Face working on enterprise LLM deployment, fine-tuning, and productionization.",
      "publishedAt": "2024-08-20T13:44:51Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M14S",
      "viewCount": 3154,
      "likeCount": 90,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/bjNYEc908oQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/bjNYEc908oQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/bjNYEc908oQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/bjNYEc908oQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/bjNYEc908oQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=bjNYEc908oQ"
    },
    {
      "id": "hkhDdcM5V94",
      "title": "Building with Anthropic Claude: Prompt Workshop with Zack Witten",
      "description": "BRING YOUR PROMPTS -- we will workshop them live! No yapping, no slop, just writing, testing, and editing prompts. Let's see how many we can get through!\n\nGot prompts that aren't working quite the way you want them to? Bring 'em here and we'll see what we can do! You'll want to also bring a couple specific examples they misbehave on. Don't expect many slides -- this will be one hour of nothing but writing/editing prompts.\n\nIntro Speaker - Jamie Neuwirth, Head of Startup Sales, who will share notes on building with Claude and working with Anthropic.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Jamie\nJamie Neuwirth, based in San Francisco, CA, US, is currently a Head of Startup Sales at Anthropic, bringing experience from previous roles at Anthropic, Stripe and Google. Jamie Neuwirth holds a Political Science, Entrepreneurship and Management at The Johns Hopkins University. With a robust skill set that includes Social Media, Microsoft Office, Research, Cloud Computing, PowerPoint and more. Jamie Neuwirth contributes valuable insights to the industry.\n\nAbout Zack\nMachine Learning Engineer with a special interest in NLP and biology.",
      "publishedAt": "2024-08-17T15:24:49Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H34M56S",
      "viewCount": 34326,
      "likeCount": 875,
      "commentCount": 34,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/hkhDdcM5V94/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/hkhDdcM5V94/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/hkhDdcM5V94/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/hkhDdcM5V94/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/hkhDdcM5V94/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=hkhDdcM5V94"
    },
    {
      "id": "1t-9-s1brcg",
      "title": "Running AI Application in Minutes w/ AI Templates: Gabriela de Queiroz, Pamela Fox, Harald Kirschner",
      "description": "Building and deploying generative AI solutions can be challenging and time-consuming, especially for startups with limited resources and expertise. In this workshop, you will learn how to use AI templates and GitHub to quickly prototype and deploy generative AI applications in minutes. AI templates are ready-made solutions that leverage Microsoft Azure Services like Azure OpenAI and GitHub features like GitHub Codespaces.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Gabriela\n15+ years of experience in the data space, Gabriela has worked in research and in several startups from different industries, including Software, Financial, Advertisement, and Health. Throughout her career, she has built diverse teams, created sophisticated data science solutions, engaged with customers and stakeholders to deliver business insights and drive data-centric decisions. She is passionate about building innovative solutions, understanding business gaps, and customer needs, and delivering a flawless experience.\n\nAbout Pamela\nPamela is currently a Principal Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley, the creator of the computer programming curriculum for Khan Academy, an early engineer at Coursera, and a developer advocate at Google.\n\nAbout Harald\nExperienced leader in technical product management and strategy. 20 year track record in data analytics, customer-centric development, AI, software engineering, design, and open source. Skillfully connects the dots between stakeholders, customer needs & wants and technology into a comprehensive product vision.",
      "publishedAt": "2024-08-14T17:54:34Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H29M2S",
      "viewCount": 2195,
      "likeCount": 41,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/1t-9-s1brcg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/1t-9-s1brcg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/1t-9-s1brcg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/1t-9-s1brcg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/1t-9-s1brcg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=1t-9-s1brcg"
    },
    {
      "id": "NamKkerrlnQ",
      "title": "Decoding the Decoder LLM without de code: Ishan Anand",
      "description": "Spreadsheets are all you need: Decoding the Decoder LLM without de code\nThe struggle to grasp the inner workings of AI models can leave even experienced engineers from non-ML backgrounds feeling lost in a sea of terminology and new concepts. What if the key to understanding the intricate mechanics of LLMs didn't require a Ph.D.? This session offers an innovative approach, employing spreadsheets to dissect and demystify the architecture of decoder-based LLMs using a fully working implementation of GPT-2 entirely in Excel. Attendees will tour through GPT-2's architecture from tokenization, embeddings, attention, multi-layer perceptron, all translated into the accessible format of spreadsheets with minimal abstractions to get in the way. By the end, you'll gain unparalleled insights into AI's backbone, transforming abstract concepts into tangible, understandable processes, without ever touching code.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Ishan\nIshan was most recently VP of Product for Edgio Applications, a platform that leverages edge computing, serverless, and AI/ML to enable enterprise teams to accelerate, host, and secure their high-stakes websites. Ishan joined Edgio via the acquisition of Layer0, where he was the CTO and co-founder. He's also the creator of Spreadsheets-are-all-you-need.ai which combines AI and Spreadsheets into a course that teaches how LLMs work through an implementation of GPT2 (an ancestor of ChatGPT) entirely in Excel. Ishan spoken at conferences such as JSMobile, Next.js, JSWorld, and React Day New York on web performance, Jamstack, and Core Web Vitals.",
      "publishedAt": "2024-08-09T17:36:52Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M8S",
      "viewCount": 4510,
      "likeCount": 142,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/NamKkerrlnQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/NamKkerrlnQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/NamKkerrlnQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/NamKkerrlnQ/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/NamKkerrlnQ/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=NamKkerrlnQ"
    },
    {
      "id": "Dc99-zTMyMg",
      "title": "Using agents to build an agent company: Joao Moura",
      "description": "This talk is about a simple idea: Everyone should be able to use AI to make cool stuff.\n\nWhen I started making crewAI, a framework to build AI Agents, I didn't know just how much it would change the way I work. This isn't just a chat about building AI Agents; it's a story about how these tools helped us grow our business and how they can help you too.\n\nI'll share our adventure with crewAI, showing how we used AI to solve problems, save time, and come up with new ideas. It's a journey of discovery and making things better with AI, showing everyone that they can use AI in their work and projects.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout João\nFounder of crewAI / prev @clearbit (acc by @hubspot) In tech for 20 years, I love building things, programming and OpenSource.",
      "publishedAt": "2024-08-08T18:12:36Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M46S",
      "viewCount": 37483,
      "likeCount": 1271,
      "commentCount": 44,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/Dc99-zTMyMg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/Dc99-zTMyMg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/Dc99-zTMyMg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/Dc99-zTMyMg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/Dc99-zTMyMg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=Dc99-zTMyMg"
    },
    {
      "id": "EuC1GWhQdKE",
      "title": "What's new from Anthropic and what's next: Alex Albert",
      "description": "Explore Anthropic's latest strides in large language models, emphasizing enhanced reasoning and multimodal capabilities. We'll showcase how these advancements translate into powerful developer tools, APIs, and best practices for building sophisticated, RSP-aligned AI applications.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Alex Albert\nAlex Albert is the Head of Developer Relations at Anthropic. Prior to his current role, he spent a year as a Prompt Engineer on Anthropic's Product Research team.",
      "publishedAt": "2024-08-05T15:38:18Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M38S",
      "viewCount": 20062,
      "likeCount": 454,
      "commentCount": 20,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/EuC1GWhQdKE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/EuC1GWhQdKE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/EuC1GWhQdKE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/EuC1GWhQdKE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/EuC1GWhQdKE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=EuC1GWhQdKE"
    },
    {
      "id": "DuZXbinJ4Uc",
      "title": "How Codeium Breaks Through the Ceiling for Retrieval: Kevin Hou",
      "description": "Codeium is trailblazing the next frontier in retrieval and hint: it’s not just embeddings. Learn what the next generation of retrieval looks like and how 1M+ developers are already leveraging this superpower using the Codeium IDE plugin for AI autocomplete, chat, and search. We’ll dive deep into how existing benchmarks are failing us, what it takes to serve our custom models at scale, and what the future of AI-assisted software development looks like.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Kevin\nA full stack engineer by trade and a creator by heart. Enjoys the process of creation whether it be in the physical (woodshop, blacksmithing, circuity) or the digital (software engineering, photography, and film).\n\nCurrently building AI-powered dev tools at Codeium (Exafunction). Previously a tech lead manager at Nuro self-driving. Received a computer science engineering degree from Princeton University with certificates in entrepreneurship and statistics and machine learning.",
      "publishedAt": "2024-07-31T20:04:07Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M42S",
      "viewCount": 19430,
      "likeCount": 516,
      "commentCount": 24,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/DuZXbinJ4Uc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/DuZXbinJ4Uc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/DuZXbinJ4Uc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/DuZXbinJ4Uc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/DuZXbinJ4Uc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=DuZXbinJ4Uc"
    },
    {
      "id": "xhQfRSueFZI",
      "title": "Emergence Launch: AI Agents and the future enterprise: Dr. Satya Nitta",
      "description": "AI agents are poised to revolutionize software systems and devices, promising unprecedented automation and efficiency for enterprises. However, the road to this future is riddled with challenges such as inefficiency, non-determinism, high costs, discoverability, and rapid technological evolution. At Emergence, we are tackling these challenges head-on to transform the vision of useful AI agents into reality. Join us as we unveil our Orchestrator, which is a meta-agent designed to intelligently route tasks, integrate diverse AI agents, and future-proof enterprise systems. We will also show work from our R&D labs where we are advancing the science of agents and developing a web agent in the open source to automate complex enterprise workflows. Discover how our experience in building scalable AI solutions and our commitment to open-source development are paving the way for a seamlessly automated world.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Dr. Satya\nDr. Satya V. Nitta is a technologist and business leader with deep experience in launching major new initiatives that create significant technical and business impacts. He was the former global head of the AI solutions for the learning department at IBM Research, which he founded. In the AI space, the teams he has led and is currently leading have invented and developed technologies at the intersection of conversational systems, speech recognition, and natural language understanding, as well as AI hardware-based edge devices. Earlier, as manager and technical leader of the Advanced Interconnect Technology department at IBM Research, he helped invent and develop many aspects of IBM’s silicon on-chip interconnect technologies with significant technical and business impacts on several generations of IBM’s semiconductor technologies. Dr. Nitta received a Ph.D. from the Rensselaer Polytechnic Institute in Chemical Engineering. He was named the IEEE ACE “Innovator of the Year” and has won “Technology of the Year” awards from both IEEE Spectrum and IEEE ACE for his work on airgap-based silicon interconnects. In 2016, he was named one of the top 50 global movers and shakers in education technology by the World Innovation Summit in Education. He has authored or co-authored over 40 publications and currently holds over 100 US patents.",
      "publishedAt": "2024-07-31T18:23:50Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT5M41S",
      "viewCount": 3315,
      "likeCount": 68,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/xhQfRSueFZI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/xhQfRSueFZI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/xhQfRSueFZI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/xhQfRSueFZI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/xhQfRSueFZI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=xhQfRSueFZI"
    },
    {
      "id": "pRM_P6UfdIc",
      "title": "Low Level Technicals of LLMs: Daniel Han",
      "description": "This workshop will be split into 3x one hour blocks:\n\nHow to analyze & fix LLMs - how to find and fix bugs in Gemma, Phi-3, Llama & tokenizers\nFinetuning with Unsloth - continued pretraining, reward modelling, QLoRA & more\nDeep dive into LLM technicals - hand deriving derivatives, SOTA finetuning tricks\nIt's recommended you have Python with Pytorch and Unsloth installed (or use online Google Colab / Kaggle). College level maths and programming would be helpful.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Daniel\nHey I'm Daniel, the algos guy behind Unsloth. I love making LLM training go fast! We're the guys who fixed 8 of Google's Gemma bugs, a 2048 SWA Phi-3 issue, found tokenization issues and fixed untrained tokens with Llama-3, and I run Unsloth with my brother Michael!\n\nOur open source package makes finetuning of LLMs 2x faster and uses 70% less VRAM with no accuracy degradation. I used to work at NVIDIA making GPU algos go fast and helped NASA engineers process data from a Mars rover faster!",
      "publishedAt": "2024-07-31T17:36:54Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT2H52M26S",
      "viewCount": 48948,
      "likeCount": 2057,
      "commentCount": 69,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/pRM_P6UfdIc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/pRM_P6UfdIc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/pRM_P6UfdIc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/pRM_P6UfdIc/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/pRM_P6UfdIc/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=pRM_P6UfdIc"
    },
    {
      "id": "TKmfBnW0mQA",
      "title": "Fixing bugs in Gemma, Llama, & Phi 3: Daniel Han",
      "description": "The story behind our 8 bug fixes for Gemma, multiple tokenization fixes for Llama 3, a sliding window bug fix and Mistral-fying Phi-3, and learn about how we analyse and find and fix bugs in open source models. Learn also how we make finetuning 2x faster for all these models\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Daniel\nHey I'm Daniel, the algos guy behind Unsloth. I love making LLM training go fast! We're the guys who fixed 8 of Google's Gemma bugs, a 2048 SWA Phi-3 issue, found tokenization issues and fixed untrained tokens with Llama-3, and I run Unsloth with my brother Michael!\n\nOur open source package makes finetuning of LLMs 2x faster and uses 70% less VRAM with no accuracy degradation. I used to work at NVIDIA making GPU algos go fast and helped NASA engineers process data from a Mars rover faster!",
      "publishedAt": "2024-07-31T17:33:51Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M42S",
      "viewCount": 3058,
      "likeCount": 134,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/TKmfBnW0mQA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/TKmfBnW0mQA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/TKmfBnW0mQA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/TKmfBnW0mQA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/TKmfBnW0mQA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=TKmfBnW0mQA"
    },
    {
      "id": "nZEaxaKmTG0",
      "title": "Copilots Everywhere: Thomas Dohmke and Eugene Yan",
      "description": "Join GitHub CEO Thomas Dohmke for the closing keynote with a deep dive on Copilot Workspace, and what’s ahead as he talks on AI’s coming agentic wave.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Thomas\nFascinated by software development since his childhood in Germany, Thomas Dohmke has built a career building tools developers love and accelerating innovations that are changing software development. Currently, Thomas is Chief Executive Officer of GitHub, where he has overseen the launch of the world's first at-scale AI developer tool, GitHub Copilot. Before his time at GitHub, Thomas previously co-founded HockeyApp and led the company as CEO through its acquisition by Microsoft in 2014, and holds a PhD in mechanical engineering from University of Glasgow, UK.\n\nAbout Eugene\nI build ML systems to serve customers at scale, and write to learn and teach.",
      "publishedAt": "2024-07-26T17:35:17Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M22S",
      "viewCount": 1321,
      "likeCount": 17,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/nZEaxaKmTG0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/nZEaxaKmTG0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/nZEaxaKmTG0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/nZEaxaKmTG0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/nZEaxaKmTG0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=nZEaxaKmTG0"
    },
    {
      "id": "7TnkqfX84gI",
      "title": "Unlocking Developer Productivity across CPU and GPU with MAX: Chris Lattner",
      "description": "Today's leading generative AI applications have workloads that span high performance GPU compute, CPU preprocessing, data-loading, and orchestration — often spread across a combination of Python, C++/Rust, and CUDA C++ — which increases the complexity and slows down the cycle of innovation. This talk explores the capabilities and power of the Modular Mojo programming language and Modular Accelerated Xecution (MAX) platform, which unifies CPU and GPU programming into a single Pythonic programming model that is simple and extensible. This results in reduced complexity and improved developer productivity, and streamlines innovation. We'll walk through CPU and GPU support with real-world examples, providing details of how AI application developers can use MAX and Mojo to define an end-to-end AI pipeline and overcome the complexities.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Chris\nChris Lattner is a co-founder and the CEO of Modular, which is building an innovative new developer platform for AI and accelerated compute. Modular provides an AI engine that accelerates PyTorch and TensorFlow inference, as well as the Mojo🔥 language, which extends Python into systems and accelerator programming domains. He has also co-founded the LLVM Compiler infrastructure project, the Clang C++ compiler, the Swift programming language, the MLIR compiler infrastructure, the CIRCT project, and has contributed to many other commercial and open source projects at Apple, Tesla, Google and SiFive.",
      "publishedAt": "2024-07-25T16:11:18Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M33S",
      "viewCount": 6502,
      "likeCount": 230,
      "commentCount": 9,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/7TnkqfX84gI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/7TnkqfX84gI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/7TnkqfX84gI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/7TnkqfX84gI/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/7TnkqfX84gI/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=7TnkqfX84gI"
    },
    {
      "id": "90Ir4TMMbS0",
      "title": "From Software Developer to AI Engineer: Antje Barth",
      "description": "In this keynote, Antje explores how generative AI is transforming the landscape of software development, enabling developers to innovate like never before. She will showcase the latest advancements in AI and demonstrate the powerful capabilities of generative AI tools available on AWS. You will learn how to harness these tools to accelerate your development processes, enhance creativity, and build robust, AI-driven applications.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Antje\nAntje Barth is a Principal Developer Advocate for generative AI at AWS. She is co-author of the O’Reilly books Generative AI on AWS and Data Science on AWS. Antje frequently speaks at AI conferences, events, and meetups around the world. She also co-founded the global Generative AI on AWS meetup and the Düsseldorf chapter of Women in Big Data.",
      "publishedAt": "2024-07-24T17:33:49Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M48S",
      "viewCount": 6703,
      "likeCount": 165,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/90Ir4TMMbS0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/90Ir4TMMbS0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/90Ir4TMMbS0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/90Ir4TMMbS0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/90Ir4TMMbS0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=90Ir4TMMbS0"
    },
    {
      "id": "qBHfQT3YtyY",
      "title": "Lessons From A Year Building With LLMs",
      "description": "Special double-feature closing keynote from the 6 authors of the hit O'Reilly article on Applied LLMs. \n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Eugene Yan\nI build ML systems to serve customers at scale, and write to learn and teach.\n\nAbout Shreya Shankar \nI'm Shreya Shankar. I am a machine learning (ML) engineer and computer scientist in the Bay Area.\nI am completing my PhD in data management systems for ML, with a human-centered focus. I am fortunate to be advised by Dr. Aditya Parameswaran at UC Berkeley. Go Bears! 🐻\nI also consult on ML engineering and production AI strategy for enterprises. Prior to my PhD, I was the first ML engineer at a startup, did research engineering at Google Brain, and engineering at Facebook. Before all of that, I did my BS and MS in computer science at Stanford. Go Trees! 🌲\n\nAbout Hamel Husain\nHamel Husain started working with language models five years ago when he led the team that created CodeSearchNet, a precursor to GitHub CoPilot. Since then, he has seen many successful and unsuccessful approaches to building LLM products. Hamel is also an active open source maintainer and contributor of a wide range of ML/AI projects. Hamel is currently an independent consultant.\n\nAbout Jason Liu\nJason is an independent AI consultant, advisor, writer, and educator. His main interests are structured outputs, search and retrieval for RAG as well as understanding how to leverage AI to build scalable and valuable businesses.\n\nAbout Bryan Bischof\nBryan Bischof is the Head of AI at Hex, where he leads the team of engineers building Magic—the data science and analytics copilot. Bryan has worked all over the data stack leading teams in analytics, machine learning engineering, data platform engineering, and AI engineering. He started the data team at Blue Bottle Coffee, led several projects at Stitch Fix, and built the data teams at Weights and Biases. Bryan previously co-authored the book Building Production Recommendation Systems with O’Reilly, and teaches Data Science and Analytics in the graduate school at Rutgers. His Ph.D. is in pure mathematics.\n\nAbout Charles Frye\nAI Engineer at Modal Labs. Building useful technology with large neural networks. \n\n00:00 Introduction \n03:22 Strategic: Bryan Bischof & Charles Frye\n14:47 Operational: Hamel Husain & Jason Liu\n23:51 Tactical: Eugene Yan & Shreya Shankar",
      "publishedAt": "2024-07-19T17:41:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT35M21S",
      "viewCount": 14287,
      "likeCount": 379,
      "commentCount": 9,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/qBHfQT3YtyY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/qBHfQT3YtyY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/qBHfQT3YtyY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/qBHfQT3YtyY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/qBHfQT3YtyY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=qBHfQT3YtyY"
    },
    {
      "id": "eTTMUWP5B0s",
      "title": "Open Challenges for AI Engineering: Simon Willison",
      "description": "About Simon\nSimon Willison is the creator of Datasette, an open source tool for exploring and publishing data. He currently works full-time building open source tools for data journalism, built around Datasette and SQLite.\n\nPrior to becoming an independent open source developer, Simon was an engineering director at Eventbrite. Simon joined Eventbrite through their acquisition of Lanyrd, a Y Combinator funded company he co-founded in 2010.\n\nHe is a co-creator of the Django Web Framework, and has been blogging about web development and programming since 2002 at simonwillison.net",
      "publishedAt": "2024-07-17T17:14:00Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M49S",
      "viewCount": 8466,
      "likeCount": 252,
      "commentCount": 12,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/eTTMUWP5B0s/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/eTTMUWP5B0s/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/eTTMUWP5B0s/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/eTTMUWP5B0s/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/eTTMUWP5B0s/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=eTTMUWP5B0s"
    },
    {
      "id": "-mRi-B3t6fA",
      "title": "Llamafile: bringing AI to the masses with fast CPU inference: Stephen Hood and Justine Tunney",
      "description": "Mozilla's Llamafile open source project democratizes access to AI not only by making open models easier to use, but also by making them run fast on consumer CPUs. Lead developer Justine Tunney will share the insights, tricks, and hacks that she and the project community are using to deliver these performance breakthroughs, and project leader Stephen Hood will discuss Mozilla's approach to supporting open source AI.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Stephen\nOpen source AI at Mozilla. Formerly of del.icio.us, Yahoo Search. Co-founder of Storium (AI-assisted storytelling game) and Blockboard.\n\nAbout Justine\nJustine is a founder of Mozilla’s LLaMAfile project, a Google Brain alumni, and the owner of the Cosmopolitan C Library. She's focusing on democratizing access to open source AI software while elevating its performance and quality.",
      "publishedAt": "2024-07-16T17:39:03Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M25S",
      "viewCount": 46658,
      "likeCount": 1626,
      "commentCount": 80,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/-mRi-B3t6fA/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/-mRi-B3t6fA/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/-mRi-B3t6fA/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/-mRi-B3t6fA/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/-mRi-B3t6fA/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=-mRi-B3t6fA"
    },
    {
      "id": "zeAyuLc_f3Q",
      "title": "The Future of Knowledge Assistants: Jerry Liu",
      "description": "In this talk, LlamaIndex founder & CEO Jerry Liu covers how we go beyond single-LLM prompt calls. He discusses advanced single-agent flows, Agentic RAG, multi-agent task-solvers & service architectures, and more. Jerry also announces Llama Agents: Agents as microservices that are easily deployed and communicate via a single API (and much more). \n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Jerry\nJerry Liu is the CEO & Co-Founder of LlamaIndex",
      "publishedAt": "2024-07-13T17:58:56Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M55S",
      "viewCount": 140218,
      "likeCount": 3372,
      "commentCount": 34,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/zeAyuLc_f3Q/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/zeAyuLc_f3Q/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/zeAyuLc_f3Q/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/zeAyuLc_f3Q/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/zeAyuLc_f3Q/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=zeAyuLc_f3Q"
    },
    {
      "id": "T7NWjoD_OuY",
      "title": "The Making of Devin by Cognition AI: Scott Wu",
      "description": "Meet Devin, a state-of-the-art AI software agent that helps developers save time and achieve more. Scott Wu, co-founder and CEO of Cognition AI, demos its capabilities and shares some of the lessons that he and his team have learned while building Devin.\n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Scott\nScott is the co-founder and CEO of Cognition AI. He previously competed in international programming competitions (3x IOI gold medalist) and co-founded Lunchclub, an AI-powered professional networking platform. Scott grew up in Louisiana and attended Harvard University.",
      "publishedAt": "2024-07-11T17:12:07Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT20M4S",
      "viewCount": 13439,
      "likeCount": 273,
      "commentCount": 24,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/T7NWjoD_OuY/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/T7NWjoD_OuY/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/T7NWjoD_OuY/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/T7NWjoD_OuY/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/T7NWjoD_OuY/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=T7NWjoD_OuY"
    },
    {
      "id": "yJHw33cVeHo",
      "title": "From Text to Vision to Voice Exploring Multimodality with Open AI: Romain Huet",
      "description": "The future we are building towards: featuring a demo of GPT4o Omnimodel Voice, ChatGPT Desktop, Sora, and Voice Engine all in one talk. \n\nRecorded live in San Francisco at the AI Engineer World's Fair. See the full schedule of talks at https://www.ai.engineer/worldsfair/2024/schedule & join us at the AI Engineer World's Fair in 2025! Get your tickets today at https://ai.engineer/2025\n\nAbout Romain\nHello! I’m a software engineer based in San Francisco, I run Developer Relations at OpenAI.\n\nPreviously, I ran developer relations at Stripe. Prior to that I was a Senior Developer Advocate at Twitter and the first member of Twitter’s Developer Relations team outside the US. In 2014, I helped launch Fabric, our mobile developer platform, and Digits. In 2015, our developer tour has led me to meet thousands of developers and entrepreneurs in more than 30 cities around the world.\n\nPrior to Twitter, I was Co-Founder & CTO of Jolicloud, whose free operating system was designed to work on low cost computers and connect them to the cloud. Joli OS was the first OS based on Linux, Chromium, and HTML5, paving the way towards a new generation of browser-based platforms like Chrome OS. In 2010, the Jolibook was a finalist for “Netbook of the Year” at Engadget Awards, alongside Google’s first Chromebook.\n\nFrom Text to Vision to Voice: Exploring Multimodality with OpenAI: Romain Huet",
      "publishedAt": "2024-07-10T17:39:42Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT23M39S",
      "viewCount": 10503,
      "likeCount": 286,
      "commentCount": 15,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/yJHw33cVeHo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/yJHw33cVeHo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/yJHw33cVeHo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/yJHw33cVeHo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/yJHw33cVeHo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=yJHw33cVeHo"
    },
    {
      "id": "vaIiNZoXymg",
      "title": "AI Engineer World’s Fair 2024 - Keynotes & Multimodality track",
      "description": "https://twitter.com/aidotengineer\n\n\n1. Opening music - 00:00\n2. Announcement - 03:26\n3. AI Engineer Summit Opening Remarks - 17:12\n4. Benjamin Presentation - 17:22\nㄴ Simon Presentation - 18:39\n   ㄴ Mobile app function description\n   ㄴ How to manage session schedule\n   ㄴ Networking features\n   ㄴ Badge scanning function\n5. Chris Presentation - 21:46\nㄴ Problems and improvements in AI stack\nIntroduction to the Mojo programming language\nㄴ AI Framework Max Description\n6. AWS Presentation (Auntie Aart) - 40:13\n5 Steps to Become an AI Engineer\nIntroducing AWS Developer Tools and Amazon Q\nSelect your Amazon Bedrock and model\nㄴ How to use Converse API\nㄴ Example of agent construction and use\n7. AWS Presentation (Mike Chambers) - 55:01\nMinecraft Bot Agent Demo\n8. Alex Albert Presentation - 01:00:06\nㄴ Historical comparison of the electric revolution\nㄴ Current and future of LLM integration and utilization\nㄴ Claude 3.5 Sonet model introduction\nIntroducing new product feature “Artifacts”\nㄴ Project and team collaboration features\nㄴ Tool usage API and console features\nㄴ Introduction to upcoming models and research\n9. Harrison Chase Presentation - 01:14:10\nㄴ History and development of agent technology\nIntroduction to LangGraph\nㄴ Introduction to LangGraph Cloud and Studio\n10. Interview and Q&A Session - 01:27:06\n11. Music Performance - 01:30:08\n12. Introduction to Multimodality Track - 02:27:19\nㄴ Substrate Introduction (Rob) - 02:27:52\n   ㄴ Advantages of modular intelligence\n   ㄴ Substrate Developer SDK\n   ㄴ Substrate inference engine\nㄴ MoonDream Presentation (Vic Kapati) - 02:33:18\n   ㄴMoonDream model introduction\n   How to improve performance of small models\n   ㄴ AI agent construction case\n   ㄴ Data processing and learning methods\n   The importance of community and open source\n   ㄴ Live demo\nㄴ Ben Hilac Presentation - 02:54:00\n   ㄴ Concept and history of Unbounded products\n   ㄴ Vision OS design process\n   ㄴ Present and future of AI products\n   ㄴ Product structure and intuitiveness\nㄴ Karan Goyle Presentation - 03:15:00\n   ㄴ The importance of real-time intelligence\n   ㄴ Challenges and solutions of multimodal AI\n   ㄴ The need and development of compression models\n   ㄴ New model design methodology\n13. Music Performance - 03:30:00\n14. Chang Sha and Noah Presentation - 05:12:08\n   ㄴ Hierarchical necessity for dataset development\n   ㄴ Differences between pre-learning and post-learning\n   ㄴ The importance of data set management\n   ㄴ Dataset selection and analysis method\n   ㄴ Utilizing language models to improve language models\n15. Steph Dua Presentation - 05:31:29\n   ㄴ The future of education and multimodal AI\n   ㄴ The need for AI education\n   ㄴ AI learning activities for children\n   ㄴ AI education for parents and teachers\n   ㄴ Cases of improving education through AI\n16. Quinda Halman Kramer Presentation - 05:50:06\n   ㄴ Building a voice AI agent\n   ㄴ The need for real-time voice processing\n   ㄴ Voice recognition and text conversion\n   ㄴ Voice synthesis and user experience\n   ㄴ Use cases of voice AI\n   The importance of reducing latency\n   ㄴ Introduction to the PIP Cart Project\n17. Music Performance - 06:11:00\n18. Roman Presentation - 07:08:17\n   ㄴ Introduction to OpenAI’s developer experience\n   ㄴ Importance of AGI development\n   ㄴ Multimodal features of GPT-4\n   ㄴ Live demo (voice, vision, text)\n   ㄴ Efficiency of GPT-4 Turbo\n19. Presented by Brian Bishoff and Charles Fry - 07:32:03\n   ㄴ Strategic considerations in LLM application development\n   ㄴ Team composition and workflow settings\n   ㄴ Model customization and the future of agents\n20. Jason Lou and Hamama Hussein Presentation - 07:47:01\n   ㄴ Role and expectations of AI engineers\n   Choose the right tools and techniques\n   ㄴ Continuous improvement and use of data\n21. Presentation by Shrea Shankar and Eugene Yan - 07:56:09\n   ㄴ Tactical aspects of LLM applications\n   ㄴ Assess, monitor and set guardrails\n   ㄴ Performance evaluation method for LLM\n   ㄴ Data-driven approach\n   ㄴ Continuous improvement of the system\n22. Thomas Domke Presentation - 08:07:40\n   ㄴ Origin and Evolution of GitHub Copilot\n   ㄴ Integration strategy across GitHub\n   The future of collaboration tools\n23. Closing speech (Benjamin) - 08:26:00",
      "publishedAt": "2024-06-28T00:51:05Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT8H34M14S",
      "viewCount": 19343,
      "likeCount": 381,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/vaIiNZoXymg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/vaIiNZoXymg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/vaIiNZoXymg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/vaIiNZoXymg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/vaIiNZoXymg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=vaIiNZoXymg"
    },
    {
      "id": "JVSKlEmUr0k",
      "title": "AI Engineer World’s Fair 2024 — GPUs & Inference Track",
      "description": "https://twitter.com/aidotengineer",
      "publishedAt": "2024-06-27T22:12:38Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT4H8M41S",
      "viewCount": 2731,
      "likeCount": 41,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/JVSKlEmUr0k/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/JVSKlEmUr0k/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/JVSKlEmUr0k/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/JVSKlEmUr0k/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/JVSKlEmUr0k/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=JVSKlEmUr0k"
    },
    {
      "id": "R0X7mPagRiE",
      "title": "AI Engineer World’s Fair 2024 - Open Models track",
      "description": "https://twitter.com/aidotengineer",
      "publishedAt": "2024-06-27T10:17:16Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT3H34M55S",
      "viewCount": 5854,
      "likeCount": 131,
      "commentCount": 13,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/R0X7mPagRiE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/R0X7mPagRiE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/R0X7mPagRiE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/R0X7mPagRiE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/R0X7mPagRiE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=R0X7mPagRiE"
    },
    {
      "id": "5zE2sMka620",
      "title": "AI Engineer World’s Fair 2024 — Keynotes & CodeGen Track",
      "description": "https://twitter.com/aidotengineer",
      "publishedAt": "2024-06-27T01:03:15Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT8H38M54S",
      "viewCount": 24006,
      "likeCount": 389,
      "commentCount": 19,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/5zE2sMka620/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/5zE2sMka620/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/5zE2sMka620/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/5zE2sMka620/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/5zE2sMka620/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=5zE2sMka620"
    },
    {
      "id": "NOONz6SwKKg",
      "title": "AI Engineer World’s Fair 2024 - Open Models track",
      "description": "https://twitter.com/aidotengineer",
      "publishedAt": "2024-06-26T19:26:17Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M26S",
      "viewCount": 1525,
      "likeCount": 22,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/NOONz6SwKKg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/NOONz6SwKKg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/NOONz6SwKKg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/NOONz6SwKKg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/NOONz6SwKKg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=NOONz6SwKKg"
    },
    {
      "id": "jpKCIVlS9wM",
      "title": "The Code AI Maturity Model and What It Means For You: Ado Kukic",
      "description": "The Code AI Maturity Model provides a framework for understanding and benchmarking the progress of AI in coding assistant tools, similar to how the SAE Vehicle Levels classify self-driving cars. In this talk, you'll learn about the various levels of the Code AI Maturity Model, where we're at with the available tools today, where we think the future lies, and what it means for you.\n\nRecorded & streamed live for the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Ado\nAdo is the Director of Developer Relations at Sourcegraph",
      "publishedAt": "2024-02-13T18:13:57Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7M58S",
      "viewCount": 1766,
      "likeCount": 34,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/jpKCIVlS9wM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/jpKCIVlS9wM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/jpKCIVlS9wM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/jpKCIVlS9wM/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/jpKCIVlS9wM/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=jpKCIVlS9wM"
    },
    {
      "id": "a0NwFm5NxGo",
      "title": "How to Become an AI Engineer from a Fullstack Background - Reid Mayo",
      "description": "Swyx’s watershed essay “The Rise of the AI Engineer” revealed the need for evolving your talents to seize the opportunities of the future; but how can you rapidly learn a novel discipline mired in lack of structure, fluff, & clickbait?\n\nWhat if there was a single syllabus that “shifted you left” from Fullstack Engineer to AI Engineer upon completion?\n\nIn this talk, we’ll provide and review a syllabus that walks you step-by-step through a defined process (with practical & actionable references/tutorials) that teaches you the comprehensive best-practice skills, knowledge, and foundations required for professional AI Engineering. \n\nTopics include: Generative AI Fundamentals, Prompt Engineering, Retrieval Augmented Generation, Agents & Functions, Fine-tuning AI Models, Open Source AI Model Repositories & Communities, AI Development & Production/Monitoring Tooling, Required Libraries/Platforms/Tools to be aware of, and more.\n\nRecorded & streamed live for the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Reid\n15 years building as a full-stack engineer, serial entrepreneur over the same time period. As an engineer I've built systems that powered several of the highest traffic web properties in the US & led teams who built core tech for high-growth startups, unicorns, $10B+ enterprises. As an entrepreneur I built a UGC tech product (acquired by Orchard) a lifetime ago, and more recently built a $5MM/year software engineering firm.\n\nLiving in Austin, TX, I’m friendly & authentically respectful. I'm engaged by technology because it's impossible to learn it all -- I’m a perennial student! Excited to learn from you!",
      "publishedAt": "2024-02-02T18:56:00Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT10M19S",
      "viewCount": 7136,
      "likeCount": 287,
      "commentCount": 13,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/a0NwFm5NxGo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/a0NwFm5NxGo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/a0NwFm5NxGo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/a0NwFm5NxGo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/a0NwFm5NxGo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=a0NwFm5NxGo"
    },
    {
      "id": "_KFbT6eph5A",
      "title": "Using AI to Build an Infinite Game: Jeff Schomay",
      "description": "Making a game requires creating lots of content - tons of cheap and disposable ideas while prototyping, and a vast (or infinite?) depth of content to explore while playing. But making content is hard, expensive, and slow.  AI can help if you have the right processes. In this talk I share a number of workflows and tools I used while building out both a video game and a physical card game.  I show lots of examples and share what worked well and what didn't. With these tools, making the content became one of the most fun parts of making the game.\n\nRecorded & streamed live for the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Jeff\nSoftware engineer with a decade of experience and a passion for the intersection of games, narrative and AI.",
      "publishedAt": "2024-02-01T17:41:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT11M8S",
      "viewCount": 930,
      "likeCount": 32,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/_KFbT6eph5A/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/_KFbT6eph5A/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/_KFbT6eph5A/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/_KFbT6eph5A/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/_KFbT6eph5A/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=_KFbT6eph5A"
    },
    {
      "id": "atwSCxWFVMg",
      "title": "GPT Web App Generator - 10,000 apps created in a month: Matija Sosic",
      "description": "About the tool: Describe your web app idea using plain English, and GPT Web App Generator will scaffold the complete, full-stack app for you, along with all the source code! The code is generated in React, Node.js, Prisma & Wasp.\n\nWe will talk about how we built it (technical challenges) and how the community responded - 10k apps, #2 on PH devtools, ...\n\nRecorded & streamed live for the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Matija\nMatija is the CEO & co-founder of Wasp together with his twin brother. This is the second startup they started together, funded by Y Combinator and top deep tech funds in 2021.\n\nMatija's background is an MSc in Computer Science from the University of Zagreb. His previous work spans from a research institute in Singapore to top-growing startups in NYC and London, covering fields of bioinformatics, mobile, and web development.",
      "publishedAt": "2024-01-26T20:51:42Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT9M23S",
      "viewCount": 2076,
      "likeCount": 46,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/atwSCxWFVMg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/atwSCxWFVMg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/atwSCxWFVMg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/atwSCxWFVMg/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/atwSCxWFVMg/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=atwSCxWFVMg"
    },
    {
      "id": "KnndhPSVF3E",
      "title": "Storyteller: Building Multi-modal Apps with TS & ModelFusion - Lars Grammel, PhD",
      "description": "Developing a sophisticated AI application often involves integrating diverse models and tools. Using ModelFusion, this complexity can be streamlined. In this talk, Lars Grammel will take attendees through the journey of creating a kids' story generator, an example of the depth and richness achievable with ModelFusion in TypeScript.\n\nThe story generator listens to a spoken description, crafts a story with unique characters and images, and then brings it to life with synthesized narration. Through this hands-on example, attendees will discover ModelFusion's key features: type inference, comprehensive control, integrated support tools, and its capability to go beyond mere text models.\n\nFor AI developers keen on diving into practical applications of AI in TypeScript, this talk offers both inspiration and actionable insights.\n\nRecorded & streamed live for the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Lars\nLars Grammel, PhD, is an AI engineer with a passion for simplifying the integration of AI models into applications. He earned his doctorate at the University of Victoria, British Columbia, where he focused on helping novices create data visualizations.\n\nLars has an impressive professional background, including seven years at Trifacta, where he held various engineering roles and was the tech lead of the Cloud Dataprep project in collaboration with Google. Following this, he spent two years as a self-employed developer, creating refactoring tooling for JavaScript in Visual Studio Code.\n\nMore recently, Lars has spent a year working on AI engineering projects, such as the RubberDuck plugin for Visual Studio Code and various agent prototypes. He is the creator of the ModelFusion JavaScript library, designed to make working with AI models more accessible.\n\nYou can follow Lars on X at @lgrammel to stay updated on his work and projects.",
      "publishedAt": "2024-01-23T21:59:54Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7M30S",
      "viewCount": 1160,
      "likeCount": 41,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/KnndhPSVF3E/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/KnndhPSVF3E/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/KnndhPSVF3E/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/KnndhPSVF3E/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/KnndhPSVF3E/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=KnndhPSVF3E"
    },
    {
      "id": "AjLVoAu-u-Q",
      "title": "Open Questions for AI Engineering: Simon Willison",
      "description": "Recapping the past year in AI, and what open questions are worth pursuing in the next year! Covering local models, transparency, tool usage, prompt injection. Please will SOMEBODY solve these??\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Simon \nSimon Willison is the creator of Datasette, an open source tool for exploring and publishing data. He currently works full-time building open source tools for data journalism, built around Datasette and SQLite. Prior to becoming an independent open source developer, Simon was an engineering director at Eventbrite. Simon joined Eventbrite through their acquisition of Lanyrd, a Y Combinator funded company he co-founded in 2010. He is a co-creator of the Django Web Framework, and has been blogging about web development and programming since 2002 at simonwillison.net",
      "publishedAt": "2023-11-25T17:25:15Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT24M33S",
      "viewCount": 5313,
      "likeCount": 185,
      "commentCount": 6,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/AjLVoAu-u-Q/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/AjLVoAu-u-Q/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/AjLVoAu-u-Q/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/AjLVoAu-u-Q/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=AjLVoAu-u-Q"
    },
    {
      "id": "9-vGxMoUM9Y",
      "title": "Trust, but Verify: Shreya Rajpal",
      "description": "Large Language Models (LLMs) such as ChatGPT have revolutionized AI applications, offering unprecedented potential for complex real-world scenarios. However, fully harnessing this potential comes with unique challenges such as model brittleness and the need for consistent, accurate outputs. These hurdles become more pronounced when developing production-grade applications that utilize LLMs as a software abstraction layer. In this talk, we will tackle these challenges head-on. We introduce Guardrails AI, an open-source platform designed to mitigate risks and enhance the safety and efficiency of LLMs. We will delve into specific techniques and advanced control mechanisms that enable developers to optimize model performance effectively.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Shreya \nShreya Rajpal is the creator and maintainer of Guardrails AI, an open source platform developed to ensure increased safety, reliability, and robustness of large language models in real-world applications. Her expertise spans a decade in the field of machine learning and AI. Most recently, she was the founding engineer at Predibase, where she led the ML infrastructure team. In earlier roles, she was part of the cross-functional ML team within Apple's Special Projects Group and developed computer vision models for autonomous driving perception systems at Drive.ai.",
      "publishedAt": "2023-11-25T17:21:18Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M41S",
      "viewCount": 4310,
      "likeCount": 112,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/9-vGxMoUM9Y/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/9-vGxMoUM9Y/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/9-vGxMoUM9Y/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/9-vGxMoUM9Y/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=9-vGxMoUM9Y"
    },
    {
      "id": "MwqUYRQloGw",
      "title": "Harnessing the Power of LLMs Locally: Mithun Hunsur",
      "description": "Discover llm, a revolutionary Rust library that enables developers to harness the potential of large language models (LLMs) locally. By seamlessly integrating with the Rust ecosystem, llm empowers developers to leverage LLMs on standard hardware, reducing the need for cloud-based APIs and services.\n\nIn this talk, I'll explore llm's key features, including its high-speed inference, support for popular LLM architectures, and its lightweight design. Through practical examples, I'll showcase how llm can be applied in content generation, code completion, and language understanding tasks.\n\nAdditionally, I'll discuss the challenges of deploying and maintaining LLMs locally, along with best practices and real-world experiences from early adopters.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Mithun Hunsur\nMithun is a seasoned polyglot programmer and engineer with a passion for exploring the depths of computer science. With experience spanning from the low-level to the highest reaches of software development, Mithun has worked on a diverse range of projects across various industries. During the day, he works on Ambient, an open-source runtime/engine for building high-performance multiplayer games and 3D applications. In his free time, he's a tinkerer at heart, diving into the world of game reverse engineering and modification, low-level and embedded programming, virtual and augmented reality, compiler and language hacking, human-computer interface research, and computer architecture and design. Beyond his work in the tech industry, Mithun also has a creative side, dabbling in photography, writing, and AI art. He brings a unique perspective to his work, combining his passion for technology with his artistic sensibilities to build projects that are both innovative and visually stunning.",
      "publishedAt": "2023-11-22T19:12:40Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M9S",
      "viewCount": 2388,
      "likeCount": 76,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/MwqUYRQloGw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/MwqUYRQloGw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/MwqUYRQloGw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/MwqUYRQloGw/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=MwqUYRQloGw"
    },
    {
      "id": "MarPORTD8vo",
      "title": "The Weekend AI Engineer: Hassan El Mghari",
      "description": "How *YOU* can - and should - build great multimodal AI apps that go viral and scale to millions in a weekend. Featuring the Vercel AI SDK and the new v0.dev AI frontend tool.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Hassan\nCreator of RoomGPT",
      "publishedAt": "2023-11-22T17:58:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT21M49S",
      "viewCount": 4103,
      "likeCount": 201,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/MarPORTD8vo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/MarPORTD8vo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/MarPORTD8vo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/MarPORTD8vo/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=MarPORTD8vo"
    },
    {
      "id": "OimPoLxioYg",
      "title": "120k players in a week: Lessons from the first viral CLIP app: Joseph Nelson",
      "description": "When OpenAI released CLIP, the Roboflow team built an AI Pictionary game called paint.wtf. Players were given a prompt like “a giraffe in the arctic,” and players drew depictions. CLIP judged which image embedding most closely matched the text embedding. Over 120,000 players played in the first week, peaking at 7 submissions per second.\n\nFast forward, and multimodality apps are ready. Come learn the trials (strangers on the internet submitting drawings) and successes (infra scaled without outage) of building with foundation models. \n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Joseph Nelson\nJoseph is Co-founder/CEO at Roboflow, which makes tools over 250,000 developers use to build better computer vision models, faster. Roboflow is backed by Y Combinator, Craft Ventures, Floodgate, the founders of OpenAI, among others. He previously Co-founded and sold an NLP company that sorted the US Congress's mail and worked at Facebook. Joseph learned to code writing programs for TI-84 calculators.",
      "publishedAt": "2023-11-22T16:59:16Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT15M59S",
      "viewCount": 1317,
      "likeCount": 37,
      "commentCount": 1,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/OimPoLxioYg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/OimPoLxioYg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/OimPoLxioYg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/OimPoLxioYg/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=OimPoLxioYg"
    },
    {
      "id": "TRjq7t2Ms5I",
      "title": "Building Production-Ready RAG Applications: Jerry Liu",
      "description": "Large Language Models (LLM's) are starting to revolutionize how users can search for, interact with, and generate new content. Some recent stacks and toolkits around Retrieval Augmented Generation (RAG) have emerged where users are building applications such as chatbots using LLMs on their own private data. This opens the door to a vast array of applications. However while setting up a naive RAG stack is easy, productionizing it is hard. In this talk, we talk about core techniques for evaluating and improving your retrieval systems for better performing RAG.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Jerry Liu\nJerry Liu, the co-founder and CEO of LlamaIndex, brings a wealth of expertise to his role, with a career that spans the realms of ML engineering, AI research, and startups. Prior to his current position, he served as an ML engineer at Quora and engaged in AI research with Uber's ATG. A Princeton alumnus, Jerry's professional journey has been enriched by various publications, including his most recent works: Deep Structured Reactive Planning and MuSCLE: Multi Sweep Compression of LiDAR using Deep Entropy Models, reflecting his commitment to the field.",
      "publishedAt": "2023-11-15T19:46:23Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M35S",
      "viewCount": 382801,
      "likeCount": 9913,
      "commentCount": 84,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/TRjq7t2Ms5I/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/TRjq7t2Ms5I/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/TRjq7t2Ms5I/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/TRjq7t2Ms5I/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=TRjq7t2Ms5I"
    },
    {
      "id": "FDEmbYPgG-s",
      "title": "Retrieval Augmented Generation in the Wild: Anton Troynikov",
      "description": "In the last few months, we've seen an explosion of the use of retrieval in the context of AI. Document question answering, autonomous agents, and more use embeddings-based retrieval systems in a variety of ways. This talk will cover what we've learned building for these applications, the challenges developers face, and the future of retrieval in the context of AI.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Anton Troynikov\nAnton is the co-founder of Chroma. He does not believe AI will kill us all. Chroma build an open-source embeddings store, specifically built for AI-native applications.",
      "publishedAt": "2023-11-15T18:20:31Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M20S",
      "viewCount": 3500,
      "likeCount": 139,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/FDEmbYPgG-s/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/FDEmbYPgG-s/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/FDEmbYPgG-s/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/FDEmbYPgG-s/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=FDEmbYPgG-s"
    },
    {
      "id": "cXPYtkosXG4",
      "title": "Domain adaptation and fine-tuning for domain-specific LLMs: Abi Aryan",
      "description": "In this talk, we will talk about the different model adaptation methods from Prompt Engineering to RAGs to fine-tuning methods depending on the dataset and problem. We will also go into detail on some operational best practices for fine-tuning and how to evaluate them for specific business use-cases. Furthermore, we will conclude with a comparative framework, cost-benefit analysis benefits and tradeoffs of fine-tuning versus knowledge bases for improving the performance of large language models for a specific task.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Abi Aryan\nHi, my name is Abi. I am a computer scientist working extensively in machine learning to make the software systems smarter. Over the past seven years, my focus has been building machine learning systems for various applications including recommender systems, automated data labelling pipelines for both audio and video, audio-speech synthesis, forecasting and time-series analysis etc. In the past, I also attended Insight as a Data Science Fellow and was a Visiting Research Scholar at UCLA under Dr. Judea Pearl where I worked in AutoML, MultiAgent Systems and Emotion Recognition. I am also currently authoring LLMOps: Managing Large Language Models in Production book for O'Reilley Publications and an MLOps: Deploying ML models in production course for data scientists to learn fundamentals of data engineering and how to deploy machine learning models in production.",
      "publishedAt": "2023-11-14T18:54:28Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT25M9S",
      "viewCount": 8300,
      "likeCount": 218,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/cXPYtkosXG4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/cXPYtkosXG4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/cXPYtkosXG4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/cXPYtkosXG4/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=cXPYtkosXG4"
    },
    {
      "id": "UNKDAo8YNmg",
      "title": "Pragmatic AI with TypeChat: Daniel Rosenwasser",
      "description": "The recent wave of AI has created a frenzy to take radically different approaches to what we can build. The underlying LLMs, however, work off an incomplete canvas and dream up pictures and prose as they please. That’s great for chat apps, but what about the millions of applications out there today? Many can benefit from natural interfaces, but our code fundamentally expects structure. TypeChat is our experimental library to bridge the unstructured output of language models to the structured world of our code.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Daniel Rosenwasser\nDaniel is the Product Manager of the TypeScript programming language and more recently has been experimenting with TypeChat. He has a passion for programming languages, type systems, runtimes, and building great tooling for developers.",
      "publishedAt": "2023-11-14T18:31:59Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M34S",
      "viewCount": 2092,
      "likeCount": 76,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/UNKDAo8YNmg/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/UNKDAo8YNmg/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/UNKDAo8YNmg/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/UNKDAo8YNmg/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=UNKDAo8YNmg"
    },
    {
      "id": "qpPgCA664xw",
      "title": "Building Reactive AI Apps: Matt Welsh",
      "description": "AI.JSX is like React for LLMs -- it lets you build powerful, conversational AI apps using the power of TypeScript and JSX. Building LLM-powered apps is not like building other kinds of software. Not only can the AI model allow you to converse in natural language, but we can also use the LLM itself to replace a lot of the conventional code needed for processing data, interfacing with external APIs, and more. AI.JSX embodies this philosophy and makes it easy to build sophisticated AI experiences without a lot of code. It's also fully integrated with the Fixie platform, making deployment and management a breeze.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Matt Welsh\nMatt Welsh is the Chief Architect and Co-founder of Fixie.ai, a Seattle-based startup developing a new computational platform with AI at the core. He was previously head of engineering at OctoML, a software engineer at Apple and Xnor.ai, engineering director at Google, and a Professor of Computer Science at Harvard University. He holds a PhD from UC Berkeley.",
      "publishedAt": "2023-11-09T17:36:00Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M2S",
      "viewCount": 5243,
      "likeCount": 151,
      "commentCount": 11,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/qpPgCA664xw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/qpPgCA664xw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/qpPgCA664xw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/qpPgCA664xw/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=qpPgCA664xw"
    },
    {
      "id": "zl4EdALzktU",
      "title": "AI Engineering 201: The Rest of the Owl",
      "description": "Optional introductory course for AI Engineers, free for all Summit attendees. Advanced knowledge of AI Engineering, led by instructor Charles Frye of the massively popular Full Stack LLM Bootcamp.\n\nPart Two - The Rest of the Owl\n\n00:00 Intro\n01:09 Patterns for Language User Interfaces\n06:19 RAG: Information Retrieval for Generation\n21:52 Function Calling: Structured Outputs and Tool Use\n35:03 Agents and Cognitive Architectures\n40:52 Shipping to Learn in ML + AI\n45:42 LLM Monitoring and Observability Tools\n49:42 Evaluating LLMs\n55:48 Inspirational Outro",
      "publishedAt": "2023-11-08T17:00:09Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT56M57S",
      "viewCount": 3219,
      "likeCount": 100,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/zl4EdALzktU/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/zl4EdALzktU/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/zl4EdALzktU/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/zl4EdALzktU/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/zl4EdALzktU/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=zl4EdALzktU"
    },
    {
      "id": "oJz4wveQ4oM",
      "title": "Move Fast Break Nothing: Dedy Kredo",
      "description": "Testing is the backbone of quality code, yet it often takes a back seat as developers prioritize feature creation. The industry's reliance on metrics such as code coverage is insufficient and can even be misleading. In this evolving landscape, where AI coding agents are becoming commonplace, there's a pressing need to revolutionize our approach to testing.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Dedy Kredo\nDedy, Co-Founder and Chief Product Officer of CodiumAI, steers the product and engineering teams with an ambitious mission: to empower developers in creating software swiftly and flawlessly, harnessing the synergy of artificial and human intelligence. Prior to CodiumAI, Dedy took on the role of VP of Customer Facing Data Science at Explorium. There, he established and led a dedicated team of data scientists, playing a significant part in the company's progression from its seed stage to a Series C round. Dedy also ventured into entrepreneurship with a bootstrapped online marketing startup, scaling it from a modest beginning to impressive revenue figures. Earlier, as a product line manager at VMware's management business unit, he collaborated with Fortune 500 companies, launching several successful products.",
      "publishedAt": "2023-11-08T13:41:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT13M1S",
      "viewCount": 1449,
      "likeCount": 38,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/oJz4wveQ4oM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/oJz4wveQ4oM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/oJz4wveQ4oM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/oJz4wveQ4oM/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=oJz4wveQ4oM"
    },
    {
      "id": "yLa3i3rAdEE",
      "title": "The AI Evolution: Mario Rodriguez, GitHub",
      "description": "Since the days of open source, we've experienced fundamental shifts in how software is built. From the pull request to deploying code, join Mario Rodriguez as he shares the history of GitHub Copilot and invites us to envision a new developer experience completely redefined and powered by AI.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Mario\nMario Rodriguez is a VP of Product Management at GitHub, currently focusing on all things Productivity. He oversees Repos, Pull Requests, Issues, Projects, Mobile and our AI strategy, including GitHub Copilot. Mario’s core identity is one of a learner and time away from product engineering is spent with his wife and two daughters.",
      "publishedAt": "2023-11-07T21:21:36Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT19M32S",
      "viewCount": 1473,
      "likeCount": 36,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/yLa3i3rAdEE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/yLa3i3rAdEE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/yLa3i3rAdEE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/yLa3i3rAdEE/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=yLa3i3rAdEE"
    },
    {
      "id": "bDQn1w0idXs",
      "title": "The AI Pivot: With Chris White of Prefect & Bryan Bischof of Hex",
      "description": "This keynote panel, featuring Bryan Bischof, Head of AI at Hex, and Chris White, CTO at Prefect, will explore what it takes to launch AI-based products in the context of running a successful, non-AI startup. Hear in-the-trenches insights and hot takes from these two product leaders as they discuss how to create an AI strategy, how to (actually) move into production, and how to measure success. Conversation will be moderated by Brittany Walker, Principal at CRV.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nBrittany Walker\nBrittany Walker is a principal at CRV, an early-stage venture capital firm known for leading investments in companies such as Airtable, Vercel, Cribl, and Postman, among others. She specializes in data infrastructure and AI/ML infrastructure, and works with the founders of promising early-stage startups including Doppler, Meilisearch, Impart Security, and Lokalise.\n\nChris White\nChris White is a cofounder of Prefect, a data workflow orchestration and observability platform, for which he currently serves as the Chief Technology Officer. Chris began his journey into software while getting his PhD in Mathematics at the University of Texas at Austin, where he researched optimization guarantees for non-convex data-driven problems. In addition to his work at Prefect, Chris is an active angel investor in AI and developer tooling. Outside of tech Chris is also passionate about the ocean, literature, and is an avid runner.\n\nBryan Bischof\nDr. Bryan Bischof leads AI at Hex, and is an adjunct professor in the Rutgers Masters of Business and Analytics program where he teaches Data Science. Previously, he was the Head of Data Science at Weights and Biases, and built the DS, ML, and Data Engineering teams. Before that he built ML products at Stitch Fix, Blue Bottle Coffee, and IBM. He recently co-authored the O’Reilly book Building Production Recommendation Systems. His data visualization work appeared in the popular book The Day it Finally Happens by Mike Pearl. His Ph.D. is in pure mathematics.",
      "publishedAt": "2023-11-07T19:45:58Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT35M16S",
      "viewCount": 635,
      "likeCount": 15,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/bDQn1w0idXs/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/bDQn1w0idXs/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/bDQn1w0idXs/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/bDQn1w0idXs/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=bDQn1w0idXs"
    },
    {
      "id": "N7lJY5IKVLE",
      "title": "[Workshop] AI Engineering 201: Inference",
      "description": "Optional introductory course for AI Engineers, free for all Summit attendees. Advanced knowledge of AI Engineering, led by instructor Charles Frye of the massively popular Full Stack LLM Bootcamp.\n\nPart I: Running Inference\n\nWhat is the workload?\nOpen vs Proprietary Models\nExecution\nEnd User Device\nOver a Network\nServing Inference\n\nTimestamps \n\n0:00:00 Intro & Overview\n0:03:52 What is Inference?\n0:10:16 Proprietary Models for Inference\n0:21:22 Open Models for Inference\n0:30:41 Will Open or Proprietary Models Win Long-Term?\n0:36:19 Q&A on Models\n0:44:12 Inference on End-User Devices\n1:04:32 Inference-as-a-Service Providers\n1:10:00 Cloud Inference and Serverless GPUs\n1:17:46 Rack-and-Stack for Inference\n1:20:12 Inference Arithmetic for GPUs\n1:27:07 TPUs and Other Custom Silicon for Inference\n1:36:11 Containerizing Inference and Inference Services",
      "publishedAt": "2023-11-07T17:00:07Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT1H43M16S",
      "viewCount": 2921,
      "likeCount": 90,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/N7lJY5IKVLE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/N7lJY5IKVLE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/N7lJY5IKVLE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/N7lJY5IKVLE/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/N7lJY5IKVLE/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=N7lJY5IKVLE"
    },
    {
      "id": "YvobVu1l7GI",
      "title": "The Hidden Life of Embeddings: Linus Lee",
      "description": "We love text embeddings as a critical pillar of LLM applications, but there's so much to text embeddings beyond their value in vector search. This talk will be a grand tour through a series of experimental projects from my last two years of research for visualizing, manipulating, and interpreting embeddings. We'll start with the basics (t-SNE, UMAP, and PCA), talk about how language models can be used to manipulate and interpret embeddings, and end by using a new tool I've built that lets us directly observe which features popular embedding models like to encode into their embeddings.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Linus Lee\nLinus is a Research Engineer at Notion prototyping new software interfaces for augmenting our collaborative work and creativity with AI. He has spent the last few years experimenting with AI-augmented tools for thinking, like a canvas for exploring the latent space of neural networks and writing tools where ideas connect themselves. Before Notion, Linus spent a year as an independent researcher, during which he was Betaworks's first Researcher in Residence.",
      "publishedAt": "2023-11-07T16:35:15Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M15S",
      "viewCount": 8727,
      "likeCount": 351,
      "commentCount": 10,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/YvobVu1l7GI/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/YvobVu1l7GI/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/YvobVu1l7GI/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/YvobVu1l7GI/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=YvobVu1l7GI"
    },
    {
      "id": "C0ZUdFg-iTo",
      "title": "[Workshop] AI Engineering 101",
      "description": "Introductory course for AI Engineers, free for preregistered Summit attendees. Build 5 small projects covering GPT3 API Basics, Prompt Tooling and Memory , Code Generation with GPT4, Image Generation with Dall-E, Stability AI, Lexica, and Midjourney, Speech-to-Text with Whisper. First public run through of the Latent Space University material led by instructor Noah Hein!",
      "publishedAt": "2023-11-06T14:55:59Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT3H2M24S",
      "viewCount": 5329,
      "likeCount": 128,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/C0ZUdFg-iTo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/C0ZUdFg-iTo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/C0ZUdFg-iTo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/C0ZUdFg-iTo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/C0ZUdFg-iTo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=C0ZUdFg-iTo"
    },
    {
      "id": "MDxEXKkxf2Q",
      "title": "Supabase Vector: The Postgres Vector database: Paul Copplestone",
      "description": "Every month, thousands of new AI applications are launched on Supabase, powered by pgvector. We'll take a brief look into the role of pgvector in the Vector database space, some of the use cases it enables, and some of the future of embeddings in the database space.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Paul Copplestone\nPaul is the CEO and cofounder of Supabase, a database platform for developers. He is a 3-time founder and a developer with 20 years experience. Supabase is one of the fastest-growing communities of builders. with thousands of AI applications launched every week, and powering apps with millions of users.",
      "publishedAt": "2023-11-03T19:14:14Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M5S",
      "viewCount": 12213,
      "likeCount": 316,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/MDxEXKkxf2Q/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/MDxEXKkxf2Q/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/MDxEXKkxf2Q/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/MDxEXKkxf2Q/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=MDxEXKkxf2Q"
    },
    {
      "id": "PAy_GHUAICw",
      "title": "Climbing the Ladder of Abstraction: Amelia Wattenberger",
      "description": "How might we use AI to build products focused not just on working faster, but on transforming how we work? Let's talk about ways we can design using AI to help us “zoom out” and work better.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Amelia Wattenberger\nAmelia is a designer and builder of novel, interactive interfaces. She spent the last few years exploring the future of developer tools on the GitHub Next team and is now designing an AI teammate at Adept.ai.",
      "publishedAt": "2023-11-03T17:57:18Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT16M47S",
      "viewCount": 15906,
      "likeCount": 563,
      "commentCount": 20,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/PAy_GHUAICw/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/PAy_GHUAICw/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/PAy_GHUAICw/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/PAy_GHUAICw/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=PAy_GHUAICw"
    },
    {
      "id": "ieWT6X2Yh_g",
      "title": "The Intelligent Interface: Sam Whitmore & Jason Yuan of New Computer",
      "description": "ChatGPT was a turning point for consumer adoption of AI due to its easy-to-use interface. Just by changing some elements of design, interaction, and behavior, an existing model suddenly 'clicked' in terms of its utility for everyday people. What might be the next leap forward for making AI-driven applications even more accessible & intuitive? Join Sam & Jason as they showcase various demos of novel interaction & behavior paradigms for AI-driven applications.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Samantha Whitmore\nFormer Head of Engineering at Kensho, a startup which used early NLP techniques to organize information for financial clients, including Goldman Sachs, BAML, and JPMC. Kensho was acquired in 2018 by S&P Global for $550mm, at the time the largest Al acquisition in history. Subsequently was Head of Engineering at Maximus, a startup that partnered with IMAX to build video super-resolution software. Recently was one of the early core contributors to LangChain (pioneered the implementation of Memory).\n\nAbout Jason Yuan\nFormer member of Apple Design Team where he worked on the future of computing and artificial intelligence. Founder and co-inventor of MakeSpace (now known as Sprout), a multi-player-first video conferencing platform. Creator of mercuryos.com and helped pioneer ideas in generative interfaces. Worked on projects with culture makers like Blackpink, Chanel, Vogue, Jackson Wang, The MET Gala, Nike, Christina Aguilera, FKA Twigs and The Weeknd.",
      "publishedAt": "2023-11-02T14:11:42Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M56S",
      "viewCount": 5525,
      "likeCount": 161,
      "commentCount": 5,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ieWT6X2Yh_g/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ieWT6X2Yh_g/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ieWT6X2Yh_g/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ieWT6X2Yh_g/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=ieWT6X2Yh_g"
    },
    {
      "id": "LzeC1AQ-U5o",
      "title": "Building Blocks for LLM Systems & Products: Eugene Yan",
      "description": "“There is a large class of problems that are easy to imagine and build demos for, but extremely hard to make products out of. For example, self-driving: It’s easy to demo a car self-driving around a block, but making it into a product takes a decade.” - Andrej Karpathy\n\nThis talk is about practical patterns for integrating large language models (LLMs) into systems and products. We’ll draw from academic research, industry resources, and practitioner know-how, and try to distill them into key ideas and practices. There are seven key patterns. I’ve also organized them along the spectrum of improving performance vs. reducing cost/risk, and closer to the data vs. closer to the user.\n\nEvals: To measure performance\nRAG: To add recent, external knowledge\nFine-tuning: To get better at specific tasks\nCaching: To reduce latency & cost\nGuardrails: To ensure output quality\nDefensive UX: To anticipate & manage errors gracefully\nCollect user feedback: To build our data flywheel\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Eugene Yan\nEugene Yan designs, builds, and operates machine learning systems that serve customers at scale. He's currently a Senior Applied Scientist at Amazon. Previously, he led machine learning at Lazada (acquired by Alibaba) and a Healthtech Series A. He writes & speaks about ML systems, engineering, and career at eugeneyan.com and https://ApplyingML.com",
      "publishedAt": "2023-11-02T13:08:20Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M24S",
      "viewCount": 5459,
      "likeCount": 170,
      "commentCount": 2,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/LzeC1AQ-U5o/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/LzeC1AQ-U5o/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/LzeC1AQ-U5o/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/LzeC1AQ-U5o/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=LzeC1AQ-U5o"
    },
    {
      "id": "yj-wSRJwrrc",
      "title": "Pydantic is all you need: Jason Liu",
      "description": "Please return only json, do not add any other comments ONLY RETURN JSON OR I'LL TAKE A LIFE \n\nIf this was you, then you've probably been pretty happy to see OpenAI function_call get released, I'm here to show you how you can get the most out of such powerful feature. Instead of writing prompts that turn strings into strings, we can write Pydantic objects and get Pydantic objects out of OpenAI.\n\nIn this talk we explore some model driven development. Where we go step by step with some examples on how to represent your problem as simple code so we can model, generate diagrams, and write prompts as code to save time and model complex data correctly, allow us to use the same best practices rather than having to invent new ones for how we manage prompts.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Jason Liu\nPreviously stitch fix and Facebook. Currently consulting startups on production using llm systems.",
      "publishedAt": "2023-11-01T16:27:08Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT17M55S",
      "viewCount": 217535,
      "likeCount": 5093,
      "commentCount": 125,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/yj-wSRJwrrc/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/yj-wSRJwrrc/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/yj-wSRJwrrc/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/yj-wSRJwrrc/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=yj-wSRJwrrc"
    },
    {
      "id": "cwjs1WAG9CM",
      "title": "Building Context-Aware Reasoning Applications with LangChain and LangSmith: Harrison Chase",
      "description": "How can companies best build useful and differentiated applications on top of language models? Many of the products and companies built do this by providing the relevant context to LLMs and asking it to reason appropriately. In this talk, Harrison will discuss the different types of context you should be aware of, the different levels of cognitive architectures that are emerging, and how LangChain and LangSmith are built to help with this journey.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nHarrison Chase is the CEO and co-founder of LangChain, a company formed around the open source Python/Typescript packages that aim to make it easy to develop Language Model applications. Prior to starting LangChain, he led the ML team at Robust Intelligence (an MLOps company focused on testing and validation of machine learning models), led the entity linking team at Kensho (a fintech startup), and studied stats and CS at Harvard.",
      "publishedAt": "2023-11-01T15:15:07Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M54S",
      "viewCount": 3309,
      "likeCount": 119,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/cwjs1WAG9CM/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/cwjs1WAG9CM/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/cwjs1WAG9CM/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/cwjs1WAG9CM/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=cwjs1WAG9CM"
    },
    {
      "id": "bNZV9s3_u44",
      "title": "See, Hear, Speak, Draw: Logan Kilpatrick & Simón Fishman",
      "description": "We're heading towards a multimodal world. OpenAI is going beyond text models into vision, voice, and image generation, and we've been busy thinking about what kinds of things developers will be able to create with them. Presenting demos and insights into the near future for AI Engineers! In this talk from OpenAI's\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Simón\nSimón empowers builders to leverage OpenAI technologies in novel and impactful ways, most recently with the OpenAI Cookbook.\n\nAbout Logan\nLogan currently leads developer relations at OpenAI, supporting developers building with DALL-E, the API, and ChatGPT. Outside of OpenAI, Logan is the Lead Developer Community Advocate for the Julia Programming Language, and a Teaching Fellow for Harvard University's Extension School course CSCI E-33A. Logan was previously a Applied Machine Learning Engineer and Software Engineer at Apple as well as the Community Manager for the Julia Programming Language. Additionally, Logan is on the Board of Directors at NumFOCUS and formerly on the board at DEFNA.",
      "publishedAt": "2023-10-24T16:47:59Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT18M43S",
      "viewCount": 2306,
      "likeCount": 62,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/bNZV9s3_u44/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/bNZV9s3_u44/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/bNZV9s3_u44/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/bNZV9s3_u44/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=bNZV9s3_u44"
    },
    {
      "id": "lFMKXnpbhpQ",
      "title": "The Age of the Agent: Flo Crivello",
      "description": "How will ubiquitous AI agents impact our daily lives, and what do they mean for the future of computing? \n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\nAbout Flo\nFlo Crivello is the Founder & CEO of Lindy. Engineer for 8 years, product leader at Uber for 5. Raised $50mm to build Teamflow, a virtual office for remote teams, from Menlo, Battery, Coatue, Tiger, Elad Gil, Lachy Groom and more, which we pivoted to Lindy.ai, an AI person assistant.",
      "publishedAt": "2023-10-24T16:47:54Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT14M49S",
      "viewCount": 3747,
      "likeCount": 107,
      "commentCount": 7,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/lFMKXnpbhpQ/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/lFMKXnpbhpQ/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/lFMKXnpbhpQ/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/lFMKXnpbhpQ/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=lFMKXnpbhpQ"
    },
    {
      "id": "ZYoZSU58m_Y",
      "title": "The Future of Work: Toran Bruce Richards, Silen Naihin et al",
      "description": "",
      "publishedAt": "2023-10-24T15:49:27Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT12M53S",
      "viewCount": 1870,
      "likeCount": 42,
      "commentCount": 4,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ZYoZSU58m_Y/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ZYoZSU58m_Y/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ZYoZSU58m_Y/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ZYoZSU58m_Y/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=ZYoZSU58m_Y"
    },
    {
      "id": "ju73sWVtvU0",
      "title": "Building AI For All: Amjad Masad & Michele Catasta",
      "description": "What is the future of Software Engineering in the age of AI? Amjad Masad, Founder & CEO of Replit, and Michele Catasta, head of AI at Replit, provide their take on this in this opening keynote presentation from the AI Engineer Summit 2023.\n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\n00:00 Introduction - Amjad Masad\n00:42 Historical perspective\n02:22 How AI can change software\n04:29 ⚠️📢 Announcing AI for all!\n06:33 A tale of Code LLM & GPU-Poor - Michele Catasta\n07:29 How Replit's code completion works\n08:39 ⚠️📢 Announcing Replit's new model!\n13:45 ⚠️📢 Announcing the new model is open source!\n14:06 Model training\n15:26 Model evaluation\n17:31 Model data & training\n18:45 Model evaluation\n19:51 Model inference\n22:10 Why open source? \n23:10: Glaive AI Collaboration \n23:50 Morph Labs Collaboration\n24:42: Perplexity Collaboration",
      "publishedAt": "2023-10-23T21:47:08Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT25M13S",
      "viewCount": 1963,
      "likeCount": 47,
      "commentCount": 0,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/ju73sWVtvU0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/ju73sWVtvU0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/ju73sWVtvU0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/ju73sWVtvU0/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=ju73sWVtvU0"
    },
    {
      "id": "qaJXBMwUkoE",
      "title": "The 1,000x AI Engineer: Swyx",
      "description": "Born too late to explore the earth. Born too early to explore the stars. Just in time to bring AI to everyone.\n\nSwyx (https://twitter.com/swyx) is the co-founder of the AI Engineer Summit, editor & podcaster at https://latent.space, and the founder of https://smol.ai, a model distillation company. \n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\n00:00 Intro\n00:15 Multiple-dimension presentation\n01:00 Historical perspectives \n02:01 You're not too late: modern cynicism is incorrect\n02:35 Carlota Perez & tech revolutions\n03:27 When did the AI revolution start?\n04:58 What is an AI Engineer?\n06:07 3 major DEFINITIONS of AI Engineer\n06:47 3 major TYPES of AI Engineer\n07:42 Why Summit",
      "publishedAt": "2023-10-23T21:27:46Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT9M27S",
      "viewCount": 16991,
      "likeCount": 483,
      "commentCount": 26,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/qaJXBMwUkoE/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/qaJXBMwUkoE/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/qaJXBMwUkoE/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/qaJXBMwUkoE/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=qaJXBMwUkoE"
    },
    {
      "id": "dQmseZ6kz8w",
      "title": "Announcing the AI Engineer Network: Benjamin Dunphy",
      "description": "Benjamin Dunphy (https://twitter.com/benghamine), co-founder of the AI Engineer Summit and managing partner at Software 3.0, LLC, welcomes attendees to the Summit, and makes a few key announcements for the event's software app, Network. \n\nRecorded live in San Francisco at the AI Engineer Summit 2023. See the full schedule of talks at https://ai.engineer/summit/schedule & join us at the AI Engineer World's Fair in 2024! Get your tickets today at https://ai.engineer/worlds-fair\n\n00:00 Welcome\n00:55 Who's here?\n03:26 🌶️ joke that doesn't land 😅\n03:56 You're here! \n04:45 Network mobile app background https://ai.engineer/Network \n05:30 ⚠️📢 Announcing AI-Enhanced Matching! \n06:25 ⚠️📢 Announcing Network is now open source! https://github.com/aiDotEngineer/Network",
      "publishedAt": "2023-10-23T20:56:01Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7M44S",
      "viewCount": 2094,
      "likeCount": 37,
      "commentCount": 3,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/dQmseZ6kz8w/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/dQmseZ6kz8w/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/dQmseZ6kz8w/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/dQmseZ6kz8w/sddefault.jpg",
          "width": 640,
          "height": 480
        }
      },
      "url": "https://www.youtube.com/watch?v=dQmseZ6kz8w"
    },
    {
      "id": "6d60zVdcCV4",
      "title": "Principles for Prompt Engineering - Karina Nguyen (Claude Instant @ Anthropic)",
      "description": "Learn the state of the art on prompt engineering from experience leading engineering on Anthropic Claude.",
      "publishedAt": "2023-10-20T23:54:16Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT55M31S",
      "viewCount": 7794,
      "likeCount": 213,
      "commentCount": 8,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/6d60zVdcCV4/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/6d60zVdcCV4/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/6d60zVdcCV4/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/6d60zVdcCV4/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/6d60zVdcCV4/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=6d60zVdcCV4"
    },
    {
      "id": "qw4PrtyvJI0",
      "title": "AI Engineer Summit 2023 — DAY 2 Livestream",
      "description": "See the full schedule at https://www.ai.engineer/summit/schedule\nMario Rodriguez, VP of Product, GitHub, \"Keynote: The AI Evolution\"\nDedy Kredo, CPO, CodiumAI, \"Move Fast, Break Nothing\"\nMatt Welsh, Co-Founder, Fixie.ai, \"Building Reactive AI Apps\"\nAmelia Wattenberger, Design, Adept, \"Climbing the Ladder of Abstraction\"\nSamantha Whitmore, CEO, New Computer & Jason Yuan, CTO/CDO, New Computer, \"The Intelligent Interface\"\nJoseph Nelson, CEO, Roboflow, \"120k players in a week: Lessons from the first viral CLIP app\"\nHassan El Mghari, AI Engineer, Vercel, \"The Weekend AI Engineer\"\nPaul Copplestone, CEO, Supabase, \"Supabase Vector: The Postgres Vector database\"\nDaniel Rosenwasser, PM TypeScript, Microsoft, \"Pragmatic AI With TypeChat\"\nJason Liu, Founder, Fivesixseven, \"Pydantic is all you need\"\nAnton Troynikov, CTO, Chroma, \"Retrieval Augmented Generation in the Wild\"\nJerry Liu, CEO, LlamaIndex, \"Building Production-Ready RAG Applications\"\nMithun Hunsur, Senior Engineer, Ambient, \"Harnessing the Power of LLMs Locally\"\nAbi Aryan, ML Engineer & O'Reilly Author, \"Domain adaptation and fine-tuning for domain-specific LLMs\"\nSimon Willison, Creator, Datasette; Co-creator, Django, \"Open Questions for AI Engineering\"\nBenjamin Dunphy, Managing Partner, Software 3.0 LLC & swyx, Latent.Space & Smol.ai, \"Thank you and a special preview for 2024\"",
      "publishedAt": "2023-10-11T01:17:29Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT7H30M56S",
      "viewCount": 21820,
      "likeCount": 348,
      "commentCount": 14,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/qw4PrtyvJI0/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/qw4PrtyvJI0/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/qw4PrtyvJI0/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/qw4PrtyvJI0/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/qw4PrtyvJI0/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=qw4PrtyvJI0"
    },
    {
      "id": "veShHxQYPzo",
      "title": "AI Engineer Summit 2023 — DAY 1 Livestream",
      "description": "Full schedule at https://www.ai.engineer/summit/schedule\nBenjamin Dunphy, Managing Partner, Software 3.0 LLC, \"Welcome & Introduction\"\nswyx, Latent.Space & Smol.ai, \"The 1000x AI Engineer\"\nAmjad Masad, CEO, Replit & Michele Catasta, VP of AI, Replit, \"Keynote: What powers Replit AI?\"\nToran Bruce Richards, Inventor, AutoGPT, \"The Future of Work\"\nSimón Fishman, Applied AI Engineer, OpenAI & Logan Kilpatrick, Developer Relations, OpenAI, \"See, Hear, Speak, Draw\"\nFlo Crivello, CEO, Lindy, \"The Age of the Agent\"\nswyx, Latent.Space & Smol.ai, Barr Yaron, Partner, Amplify & Sasha Sheng, Stealth, \"One Smol Thing\"\nBenjamin Dunphy, Managing Partner, Software 3.0 LLC, \"Housekeeping\"\nHarrison Chase, CEO, LangChain, \"Building Context-Aware Reasoning Applications with LangChain and LangSmith\"\nShreya Rajpal, Founder, Guardrails AI, \"Trust, but Verify\"\nEugene Yan, Senior Applied Scientist, Amazon, \"Building Blocks for LLM Systems & Products\"\nLinus Lee, AI Lead, Notion, \"The Hidden Life of Embeddings\"\nBrittany Walker, Principal, CRV, Chris White, CTO, Prefect & Bryan Bischof, Head of AI, Hex, \"The AI Pivot: Fireside chat with Chris White of Prefect & Bryan Bischof of Hex\"",
      "publishedAt": "2023-10-10T03:54:51Z",
      "channelTitle": "AI Engineer",
      "tags": [],
      "categoryId": "28",
      "duration": "PT4H50M",
      "viewCount": 33357,
      "likeCount": 560,
      "commentCount": 23,
      "thumbnails": {
        "default": {
          "url": "https://i.ytimg.com/vi/veShHxQYPzo/default.jpg",
          "width": 120,
          "height": 90
        },
        "medium": {
          "url": "https://i.ytimg.com/vi/veShHxQYPzo/mqdefault.jpg",
          "width": 320,
          "height": 180
        },
        "high": {
          "url": "https://i.ytimg.com/vi/veShHxQYPzo/hqdefault.jpg",
          "width": 480,
          "height": 360
        },
        "standard": {
          "url": "https://i.ytimg.com/vi/veShHxQYPzo/sddefault.jpg",
          "width": 640,
          "height": 480
        },
        "maxres": {
          "url": "https://i.ytimg.com/vi/veShHxQYPzo/maxresdefault.jpg",
          "width": 1280,
          "height": 720
        }
      },
      "url": "https://www.youtube.com/watch?v=veShHxQYPzo"
    }
  ]
}